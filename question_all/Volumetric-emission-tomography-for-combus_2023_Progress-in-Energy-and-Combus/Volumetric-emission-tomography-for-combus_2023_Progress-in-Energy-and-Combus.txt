Progress in Energy and Combustion Science 94 (2023) 101024

Contents lists available at ScienceDirect

Progress in Energy and Combustion Science

journal homepage: www.elsevier.com/locate/pecs

Volumetric emission tomography for combustion processes
Samuel J. Grauer b,1, Khadijeh Mohri c,d,1, Tao Yu a,e, Hecong Liu a, Weiwei Cai a,∗
a Key Laboratory of Education Ministry for Power Machinery and Engineering, School of Mechanical Engineering, Shanghai Jiao Tong University, 800 Dongchuan
Road, Shanghai, China
b Department of Mechanical Engineering, Pennsylvania State University, University Park, PA 16802, USA
c Institute for Combustion and Gas Dynamics (IVG)–Fluid Dynamics, Tomography Group, University of Duisburg–Essen, 47048 Duisburg, Germany
d Center for Nanointegration Duisburg–Essen (CENIDE), University of Duisburg–Essen, 47048 Duisburg, Germany
e Clean Combustion Research Center, King Abdullah University of Science and Technology, Thuwal 23900, Saudi Arabia

A R T I C L E I N F O

A B S T R A C T

Keywords:
Volumetric imaging
Tomography
Combustion diagnostics
Chemiluminescence
Fluorescence
Incandescence

This is a comprehensive, critical, and pedagogical review of volumetric emission tomography for combustion
processes. Many flames that are of interest to scientists and engineers are turbulent and thus inherently
three-dimensional, especially in practical combustors, which often contain multiple interacting flames. For-
tunately, combustion leads to the emission of light, both spontaneously and in response to laser-based
stimulation. Therefore, images of a flame convey path-integrated information about the source of light,
and a tomography algorithm can be used to reconstruct the spatial distribution of the light source, called
emission tomography. In a carefully designed experiment, reconstructions can be post-processed using chemical
kinetic, spectroscopic, and/or transport models to extract quantitative information. This information can
be invaluable for benchmarking numerical solutions, and volumetric emission tomography is increasingly
relied upon to paint a more complete picture of combustion than point, linear, or planar tools. Steady
reductions in the cost of optical equipment and computing power, improvements in imaging technology, and
advances in reconstruction algorithms have enabled a suite of three-dimensional sensors that are regularly
used to characterize combustion. Four emission modalities are considered in this review: chemiluminescence,
laser-induced fluorescence, passive incandescence, and laser-induced incandescence. The review covers the
reconstruction algorithms, imaging models, camera calibration techniques, signal physics, instrumentation,
and post-processing methods needed to conduct volumetric emission tomography and interpret the results.
Limitations of each method are discussed and a survey of key applications is presented. The future of volumetric
combustion diagnostics is considered, with special attention paid to the advent and promise of machine learning
as well as spectrally-resolved volumetric measurement techniques.

1. Introduction

Volumetric imaging refers

to the measurement of a three-
dimensional (3D) field using one or more two-dimensional (2D) images
recorded with an optical device, such as a camera. In general, volumet-
ric ‘‘images’’ are synthetically formed by a tomographic reconstruction
algorithm, which is based on the inversion of a measurement model
that approximates the 2D imaging process. The details of this procedure
vary widely, depending on the measurement modality, number of
sensors, and availability of prior information about the target field.
Tomography first arose as a medical diagnostic following significant
developments in the 1970s and ’80s; since then, the technique has
been refined and utilized for scientific measurement in numerous
engineering disciplines and across the natural sciences. Central to this

review, tomography is increasingly used to characterize reacting and
non-reacting flow fields. Volumetric measurements of combustion play
an important role in capturing fluid phenomena, developing models,
and validating advanced numerical simulations. Decreasing costs of
imaging equipment, lasers, and computational resources are driving the
significant growth in volumetric imaging of flames, and recent develop-
ments highlight the potential for reliable, high-resolution, quantitative
3D measurements of combustion processes.

The purpose of this review is threefold. First, it provides a sys-
tematic guide to volumetric emission tomography for combustion pro-
cesses, covering the mathematical and physical foundations of key
diagnostics within a unified framework. Second, existing techniques are
critically reviewed, paying special attention to the proper usage and

∗ Corresponding author.

E-mail address: cweiwei@sjtu.edu.cn (W. Cai).

1 Authors made an equal contribution.

https://doi.org/10.1016/j.pecs.2022.101024
Received 23 March 2022; Received in revised form 19 June 2022; Accepted 30 June 2022
Available online 19 October 2022
0360-1285/© 2022 Elsevier Ltd. All rights reserved.

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

potential pitfalls of each method. Third, promising research avenues
are noted and assessed.

1.1. Motivation

Combustion is essential to many power generation, propulsion, and
chemical process applications [1]. Nevertheless, there is a need to
improve the efficiency of combustion-based power plants and vehicles
in order to mitigate their effects on the environment and minimize
the production of harmful emissions [2]. Turbulence is ever-present
within practical combustors and plays an important role in their per-
formance [3], hence the study of turbulent combustion is key to the
modification of existing power generation facilities as well as the design
of next-generation engines, aircraft, automobiles, and the like. Turbu-
lent flow fields exhibit nonlinear, multiscale behavior that is inherently
3D [4]. Volumetric measurements that have significant spatio-temporal
resolution are thus needed to support the study of turbulent phenomena
and the development of software to be used in the design and control
of engineering devices.

Various experimental techniques have been developed to investi-
gate combustion. Some probes can be inserted into a flow to obtain
point measurements of a physical parameter, e.g., measuring tem-
perature with a thermocouple. However, doing so invariably alters
the flow field and the probe may quench important reactions or act
as a catalyst. Moreover, the spatial resolution of such measurements
is usually inadequate, even when multiple probes are combined in
a rake, and temporal resolution can be lacking as well [5]. Optical
diagnostics were developed to address these issues, often through the
use of lasers and high-speed cameras. There are laser-based sensors
that yield line-of-sight (LoS), point-wise, one-dimensional (1D), 2D,
and 3D measurements of key quantities. For instance, both coherent
anti-Stokes Raman spectroscopy [6,7] and laser-induced grating spec-
troscopy [8–10] are point-wise or 1D techniques that provide accurate
temperature data. Laser absorption spectroscopy is another prevalent
diagnostic that is capable of simultaneously measuring temperature,
pressure, and species concentrations [11]. This method is normally
implemented with a handful of beams, each of which yields path-
integrated information [12]. 1D Raman spectroscopy can be used to
simultaneously measure multiple species along a probe line, although
the technique suffers from a low signal-to-noise ratio (SNR) [13,14].
There are many more quantitative, laser-based gas flow and combus-
tion diagnostics (Rayleigh scattering, cavity ringdown spectroscopy,
molecular tagging velocimetry, etc. [15]), most of which produce low-
dimensional (point-wise, LoS-integrated, or 1D) and/or time-averaged
information.

The emergence of high-energy pulsed lasers in the 1980s paved
the way for planar imaging techniques [16]; these methods have since
matured and become indispensable to the study of turbulence. To
name a few examples: Planar laser induced fluorescence (PLIF) is used
to measure flame temperature [17], species concentrations [18], and
mixture fraction fields [19]. Single-camera particle image velocimetry
(PIV) measures the two-component velocity distribution throughout
an illuminated plane [20]. A second camera can be added to extract
three-component (3C) velocity information via stereo PIV [21], and
thermographic tracer particles facilitate the simultaneous measurement
of temperature and velocity fields [22]. Lastly, planar laser-induced
incandescence data is used to infer the volume fraction and primary
particle size of soot aggregates within a laser sheet [23,24]. While
these techniques require laser illumination or stimulation of the flow
field, there are additional diagnostics such as chemiluminescence imag-
ing [25] and background-oriented schlieren (BOS) [26] that produce 2D
LoS-integrated measurements of the flow. In chemiluminescence imag-
ing, the light emitted by excited reaction intermediates is captured by a
camera, revealing the reaction zone of a flame, and BOS measurements
are based on the digital detection of beam steering at each pixel, which
is used to visualize density gradients in a fluid. It is more difficult to

extract quantitative information from LoS-integrated data than planar
laser measurements due to the convolution of overlapping flow field
structures from multiple planes, but these techniques can still provide
useful qualitative information about a gaseous flow or flame.

Despite the success of point-wise, 1D, and 2D diagnostics, none of
these techniques can adequately characterize transient 3D features of
interest. For example, the flame surface density is used to determine
system reaction rates, but estimates derived from planar measurements
can be off by as much as 40% [27]. Thermoacoustic oscillations are
another intrinsically 3D effect that can lead to inefficient combus-
tion and may even damage a combustor [28]. The source of these
instabilities can be tracked using 3D, time- or phase-resolved heat
release rate oscillations [29,30]. Flame synthesized nanoparticles are
widely used in the production of tires, pharmaceuticals, optical fibers,
etc. [31]. Crucially, the morphology (and thereby functionality) of
these particles depends on the spatial distribution of the precursor as
well as the particles’ temperature history, which itself depends on 3D
flow and combustion structures. Time-resolved 3D techniques are thus
required to understand and characterize the behavior of combustion
reactors [32,33]. Relatedly, identifying self-stabilization in a turbulent
lifted flame requires simultaneous volumetric scalar and flow field
measurements to estimate the flame displacement speed [34]. In these
scenarios and many others, volumetric measurements can be leveraged
to improve the understanding, modeling, and control of reacting and
non-reacting gaseous flows, alike.

1.2. Volumetric imaging

Inaugural developments in volumetric imaging of gas flows and
combustion processes were achieved by extending planar techniques
to multi-planar and swept-plane methods. An early demonstration in
1986 involved Rayleigh scattering measurements of a turbulent jet: two
planes were illuminated with different colored lasers; scattered light
from each plane was isolated through the use of a narrow bandpass
filter and imaged by one of two synchronized cameras [35]. One year
later, the authors introduced rotating mirrors to achieve the first time-
resolved 3D scattering measurement of a gas jet [36]. Around the same
time, scanning PLIF measurements of OH were conducted to produce
quasi-3D images of the reaction zone in laminar, transitional, and
turbulent flames [37]. Since then, several other groups have utilized
scanning techniques to acquire 3D information on fuel distributions,
soot formation, and supersonic mixing, to list a few examples [34,38–
42]. Scanning setups comprise a high-power, fast-repetition-rate laser,
which often requires a custom amplification setup; a high-speed scien-
tific camera; and a precision galvo mirror or similar. Data from these
diagnostics can deliver significant spatial resolution within each plane,
but the resolution is far lower in the direction of scanning, and the need
to acquire multiple, successive images for each 3D field results in sharp
trade-offs between the spatial resolution normal to the laser sheet,
temporal resolution, and scan depth. Even MHz-rate cameras and lasers
can be insufficient to freeze a practical turbulent flame during a single
pass through the domain. Furthermore, since the laser sheet is not
perfectly flat, complications arise when stitching the layers together,
and the extent of scanning is also limited by the imaging setup’s depth
of field [43,44] (a limited depth of field is problematic in tomography,
as well).

Tomography is an alternative approach to volumetric imaging that
is more versatile than multi-planar measurements in the context of
combustion diagnostics. This review is focused on volumetric imaging
via emission tomography. The basic concept is illustrated in Fig. 1.
Instead of imaging the signal produced by planar laser sheets, one or
more cameras are used to simultaneously capture images of a flame that
correspond to a LoS-integrated quantity. Light from the flame is emitted

2

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 1. Conceptual schematic of volumetric emission tomography. Twelve cameras are positioned around a turbulent swirl flame and simultaneously record 2D path-integrated
images of the light produced in the measurement volume. The image formation process is represented by an imaging model, which must be inverted to ‘‘reconstruct’’ the unknown
field from images thereof. This model requires camera calibration, which maps 3D points, x = [x, y, z]T, to a 2D location in each image, u = [u, v]T. The final panel depicts a
reconstruction of the swirl flame; the 3D field is usually discretized using a voxel basis, which consists of dividing the region of interest into small cubes (voxels) that contain a
uniform distribution of the unknown field.

either spontaneously or in response to laser-based stimulation. Individ-
ual measurements, e.g., resolved at a pixel, are called ‘‘projections’’,2
and the projection data are fed to a ‘‘reconstruction algorithm’’ to
deduce the source of emissions within the 3D region of interest, termed
the ‘‘emission source field’’. In certain circumstances, reconstructed
source fields can be post-processed to estimate quantities like the
equivalence ratio, heat release rate, or temperature of a flame. In order
to reconstruct the source flow, a model of the image formation process
must be devised. The model is typically based on a camera model that
describes the trajectory of light captured at each pixel as well as a
discrete representation of the flame, such as the voxel basis shown
in Fig. 1. Imaging models ultimately relate a known or hypothetical
distribution of the 3D field of interest to the corresponding projections
for a given optical setup. Reconstruction amounts to the inversion of
an imaging model to estimate a 3D flame from its projections. In other
words, the goal of reconstruction is to produce an emission source
field that satisfies the experimental projection data. This approach to
volumetric imaging can produce rich 3D information about a flame.

The use of multiple views is a key attribute of tomography. Im-
portant aspects of a flame’s shape and evolution are convolved in
LoS-integrated images, resulting in overlapping features that are hard
to tease apart. Projections from independent perspectives, or presumed
symmetries in the flame, are needed to resolve distinct structures.
Multiple views are typically acquired through the use of more than
one camera and/or ‘‘view splitters’’, i.e., endoscopes and fiber optics
or mirrors and prisms that relay several distinct images onto a sin-
gle sensor. Plenoptic (or light field) cameras are another technology
that can augment volumetric tomography and 3D particle-localization
techniques. These cameras have a micro-lens array in between the
primary lens and sensor; each micro-lens focuses light from a range
of angles onto a small subset of pixels. In effect, plenoptic cameras
capture multiple views such that a single camera is sufficient for
3D particle tracking and tomographic PIV (TPIV), in principle, and
multiple plenoptic cameras can provide ample data to reconstruct
continuous 3D fields, such as those produced by chemiluminescence
and fluorescence [46–48]. However, since each camera only resolves
a small angular range, more than one camera must be used to image
these fields [49]. Tan and Thurow [48] extensively discuss the role of
plenoptic cameras in volumetric gas flow and combustion experiments.
Regardless of the method used for volumetric measurement, there
are numerous complications associated with reconstruction (and other
post-processing) algorithms, imaging models, and camera calibration.

2 In some settings, ‘‘projection’’ refers to a set of LoS-integrated measure-
ments recorded at a single angle [45], e.g., all the measurements collected by
a single lens. This set is called a ‘‘view’’ in this text.

These issues are common to the emission modalities discussed in this
review. Consequently, said topics are covered up front in a general
manner. Chief among the drawbacks of tomography are the limited
resolution and errors that accompany reconstructions, which are dif-
ficult to quantify. This is in stark contrast to the precise measurements
on offer in 2D PIV, PLIF, and the like. Errors and uncertainties in
tomography arise due to the ambiguity associated with unwrapping
a series of projections to uncover the underlying field. Unfortunately,
this ambiguity is only truly resolved by an infinite set of projections
so reconstruction algorithms must employ additional information to
constrain the inversion. The supplemental information is invariably
incompatible with combustion physics to some degree, and artifacts or
inaccuracies are thus inevitable. The reliance on prior information can
be alleviated by additional projection data, e.g., acquired by installing
another camera. However, the high cost of the high-speed cameras,
intensifiers, and lasers required for volumetric imaging of turbulent
combustion, along with geometric constraints on the experimental
setup, limit the extent to which this strategy can be implemented. In
spite of these challenges, refinements to the algorithms, optics, and
assemblies used in emission tomography have enabled the use of 3D
imaging for research and development to impressive effect, as discussed
extensively throughout this review.

1.3. Emission modalities

Reaction intermediates produce the translucent blue light seen at
the base of many hydrocarbon flames, while hot particulate matter
glows from bright yellow to deep amber as it forms and then cools,
advecting, convecting, and diffusing away from the reaction zone.
The source of this light is chemiluminescence and incandescence, re-
spectively, and the direction of these emissions is typically isotropic,
i.e., light emitted at a point emanates outward in a spherical wave. For
this reason, irrespective of the emission modality, the light recorded
at a pixel amounts to an integral over the continuum of point sources
encountered along a path through the flame. Therefore, images of a
flame can be regarded as a set of projections of that flame, which may
be reconstructed to estimate the source of emissions. Emission tomogra-
phy is conducted using natural emissions such as these or laser-induced
emissions in the form of laser-induced fluorescence or incandescence
(LIF or LII). This paper surveys the four emission modalities used for
volumetric combustion diagnostics:

1. chemiluminescence,
2. laser-induced fluorescence (LIF),
3. incandescence, and
4. laser-induced incandescence (LII),

3

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

The principles underlying these signals are briefly recapitulated be-
low, and further elaborated in the corresponding sections. Readers
should consult Herzberg [50], Gaydon [51], Eckbreth [5], and Howell
et al. [52] for in-depth instruction on the pertinent physics.

Optical emissions from a gas occur when molecules at an elevated
energy level spontaneously relax to a lower level, which coincides with
the emission of a photon. The photon’s energy is equal to the energy
difference between the upper and lower states, and the wavelength of
emitted light is proportional to this value. Gas-phase molecules have
quantized rotational, vibrational, and electronic energy, meaning that
a molecule can only occupy discrete energy states. Roughly speaking,
light is emitted by the gas at wavelengths that correspond to allowable
transitions between valid energy levels; these transitions form spec-
tral lines that may be broadened and shifted by various temperature,
pressure, and electric effects. Radiation emitted by a gas is classified
in terms of the excitation mechanism, i.e., the means by which the
molecule undergoing relaxation initially arrived at its elevated state.
Random collisions can transmit energy from one molecule to another,
resulting in its transition from a low energy level to a higher one. When
such collisions occur due to thermal motion, the resulting radiation is
said to be thermal radiation or incandescence. Unlike thermal radiation
from solids or liquids, incandescence from a gas is often confined to dis-
tinct spectral lines or bands and is usually of secondary importance in
combustion imaging. Non-thermal radiation, termed ‘‘luminescence’’,
is more significant. Of particular interest are chemiluminescence, which
refers to the radiation emitted by molecules produced in an excited
state by a chemical reaction, and fluorescence, wherein the radiating
molecules are excited by the absorption of incoming light.

Chemiluminescence in flames is a byproduct of intermediate reac-
tions. Radicals such as OH* and CH* are formed in an excited state,
commonly indicated by an asterisk. As these molecules relax, they
give off visible or ultraviolet (UV) light. Images of chemiluminescence
may thus be reconstructed to recover the chemiluminescence source
field, which is directly linked to the reaction zone of a flame. Planar
tomography of chemiluminescence was first demonstrated by Hertz and
Faris [53] in 1988. The technique, often called computed tomography
of chemiluminescence (CTC), has since been extended to 3D and is now
a mainstay of combustion imaging. CTC is used to visualize and analyze
the topology of individual or interacting flames [54,55], assess combus-
tion instabilities [29,56], and monitor industrial flames [57], among a
host of other use cases. Relatedly, fluorescence may be stimulated in a
3D region using a laser slab and then imaged by a network of cameras
to conduct volumetric LIF (VLIF). As with outgoing radiation, incoming
photons are only absorbed if their wavelength is aligned with the
energy of valid molecular transitions. Therefore, the laser’s wavelength
must be tuned to probe the species of interest, such as ground state
OH or a tracer gas like acetone. This approach was pioneered by Wu
et al. [58], who seeded a nitrogen jet with iodine in a 503 mm3 domain
and then reconstructed the resulting fluorescence. VLIF is a laboratory
diagnostic that can produce data with high spatio-temporal resolution
to assess the morphology of flames and jets [59,60].

Solid-phase emission is another key source of light for combustion
tomography. All matter emits thermal radiation, or incandescence, due
to the random motion of particles that is associated with their thermal
energy. Thermal radiation from solids and liquids is predominantly
caused by the acceleration and deceleration of oscillating dipoles. The
continuous velocity distribution characteristic of lattice vibrations in
a solid, or of electron density fluctuations in a liquid, leads to the
continuous emission of light across a broad spectrum. Incandescence
is primarily produced by soot aggregates in the context of combustion
diagnostics. This radiation depends on the temperature, optical prop-
erties, size, and volume fraction of soot particles, and multi-spectral
or spectrally-resolved reconstructions of incandescence can be used
to infer these parameters as a result [61,62]. There are two types of
volumetric incandescence sensors. The first type detects thermal radia-
tion produced solely by heating that is endogenous to the flow, called

natural or passive incandescence, while the second type employs a laser
slab to actively heat up the particles in a 3D cross section and thereby
generate incandescence, called volumetric LII (VLII). Passive incandes-
cence tomography was first reported by Uchiyama et al. [63] in 1985
and is now frequently used to characterize industrial furnaces [64],
whereas VLII, like VLIF, is a laboratory diagnostic, developed by Meyer
et al. [65] in 2016, that can provide detailed measurements of soot
formation in a turbulent flame [66,67].

1.4. Roadmap through the paper

The reconstruction algorithms, imaging models, and camera calibra-
tion procedures used in volumetric emission tomography are applicable
to all four modalities covered in this review. The concept of volumetric
imaging via tomography is presented in Section 2, which contains an
exhaustive review of reconstruction algorithms. Most of these algo-
rithms require an explicit imaging model in the form of a matrix,
which relates a discrete representation of a flame to images thereof.
Section 3 details standard techniques for producing an imaging model
using a camera model; the latter describes the trajectory of rays from
the domain to the sensor (or vice versa) using parameters that must
be specified by camera calibration. Section 4 reviews pinhole and
polynomial camera models, followed by an overview of common cali-
bration methods. Lastly, the interpretation of 3D reconstructions must
be rooted in a proper understanding of their accuracy and resolution.
These issues are discussed in Section 5 alongside strategies to maximize
the performance of a sensor through the optimal placement of cameras.
Following the general overview of emission tomography fundamen-
tals in Sections 2 through 5, the next four sections cover the principles,
implementation, and applications of chemiluminescence, LIF, incan-
descence, and LII tomography in that order. The paper concludes
with a summary of the state of volumetric gas flow and combustion
tomography and an exploration of future research avenues.

2. Volumetric reconstruction

Tomography is based on the inversion of a forward ‘‘measurement
model’’ that converts a 3D field into 2D images of that field. For
instance, given knowledge of the 3D flame source field shown in the left
panel of Fig. 1, an imaging model can be used to generate the pictures
in the middle panel. Fields of interest include the intensity generated by
excited flame radicals and heated particles. Measurements are obtained
by recording the target volume with an imaging device: normally but
not always a camera. Simultaneous, mean, or phase-averaged images
are captured by one or more cameras (or similar), and 3D distributions
of the quantity or quantities of interest (QoI) are estimated by inverting
the forward model for a set of data. This process, depicted in Fig. 1, is
called reconstruction and is common to the techniques covered in this
review.

2.1. Modeling 2D imaging of a 3D field

Consider the measurement volume , shown in Fig. 1, which con-
tains a 3D distribution of the scalar QoI, denoted g(x), where x =
[x, y, z]T is a vector of world coordinates. Each imaging device records
a 2D image of the light generated within and transmitted through ,
which depends on the unknown field, g. Images of the domain are
resolved in terms of discrete sensor units (generally pixels), and a
projection function returns the destination of light rays generated at
x on the sensor,

u = Ψ (x) ,

(1)

where u = [u, v]T is a 2D vector of sensor coordinates in pixel units.
The sensor coordinate system is generally configured such that pixel
centroids correspond to integer values of u. Fig. 1 shows a point in
3D space and its location in a 2D image, which may be computed

4

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

using an expression like Eq. (1). The projection function must account
for the imaging device’s (potentially complex) optical system, which
can include lenses, mirrors, prisms, and filters. Light ultimately passes
through an aperture before reaching the sensor. Ideally, if diffraction
is ignored and the aperture is assumed to be an infinitesimal pinhole,
then each point on the sensor corresponds to a unique ray. However,
in reality, imaging systems have a finite aperture and diffraction can-
not be neglected; both of these effects result in blur, and Section 3
presents multiple models that can account for a finite aperture and
diffraction-limited imaging.

A key quantity in many imaging models is the LoS along which
Ψ (x) = u. The path beginning at a point on the camera sensor, u, and
extending out into the world is given by a back-projection function,

Ψ −1(u, l) = x,

(2)

where l is a distance along the ray and Ψ −1(u, 0) returns the camera
position for all values of u. A back-projection functions is the inverse
of a projection function. However, for a real aperture with a finite
opening, a point source of light that is not perfectly focused will
produce a circular region of illumination on the sensor. Consequently,
the inverse of Ψ may not be unique, in which case Ψ −1 is defined
with respect to the ‘‘primary ray’’ at each sensor position, i.e., the ray
that passes through the center of the aperture. Projection and back-
projection functions are obtained via camera calibration, as depicted
and described throughout Section 4.

Cameras record light across a range of wavelengths, but the prop-
agation of light is fundamentally described in terms of individual
wavelengths, λ. The production, attenuation, and transportation of
monochromatic light at λ within  are governed by the radiative trans-
fer equation (RTE), covered at length in the texts of Modest [68] and
Howell et al. [52]. A simplified form of the RTE is found by assuming
a dark background, negligible re-absorption, and minimal scattering.
Using this approach, the spectral intensity, Iλ, that is incident on the
sensor at u is

∞

Iλ(u) ∝ ∫
0

dl.

]
[Ψ −1(u, l)
I ′
λ
⏟⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏟
g(x) = ∫ I ′
λ(x) dλ

(3)

In this expression, I ′
λ is an intensity source term (or spectral irradiance)
that accounts for the volumetric emission of light at λ; the afore-
mentioned field of interest, g, is a spectrally-integrated source term,
which is roughly proportional to I ′
λ for a narrowband signal. When
measurements are affected by absorption or out-scattering, collectively
called extinction, Eq. (3) must be modified (see Section 8.1.2). The effect
of background radiation can generally be eliminated by subtracting a
reference (i.e., flame-off) measurement from the signal.

Ultimately, when the region of interest is in focus, the signal
recorded at each pixel of an imaging system, indicated by Si for the
ith pixel, is a function of the light transmitted to the sensor as well as
its physical response,

∞

Si = ∫∫i

∫
0

ηλ τf,λ ∫

0

∞

I ′
λ

[Ψ −1(u, l)

] Ωi(l)
4π

dl dλ du dv
⏟⏟⏟
du

.

(4)

Here, 
i is a region of the sensor that corresponds to the ith pixel;
ηλ is the sensor’s quantum efficiency and gain, which depends on the
wavelength of light and could conceivably vary as a function of u; τf,λ
is the net transmittance curve of the collection optics and filters; and
Ωi is the solid angle subtended by the ith pixel at a distance l from the
lens. The total solid angle, Ω, for volumetric emissions from a point at
a distance l equals the area of the aperture divided by l2. Assuming the
region of interest is in focus, Ω can be approximated as follows:

Ω =

πD2

ap∕4
l2

≈ f −2
#

(5)

where Dap is the diameter of the aperture, f is the focal length of the
lens, and f# = f ∕Dap is the resulting f -number. The ratio Ωi∕Ω is the

fraction of light incident on the sensor that falls inside 
target is in focus, this ratio is unity.

i; when the

Emission measurements, called ‘‘projections’’, are modeled in terms
of integrals over the unknown field, I ′
λ, a.k.a. g. The simplest projection
model corresponds to a single path integral along the primary ray of a
pixel,

pi = ∫

∞

Ω
ηλ τf,λ dλ
4π
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟
system constant, Csys

0

lout

∫

lin

g[Ψ −1(ui, l)]

dl,

(6)

where pi is a LoS measurement of g at the ith pixel, ui is the pixel
centroid, and lin and lout are the distance along the ray up to  and
through it, respectively. That is, the path begins at the lens at l = 0,
proceeds up to  at l = lin, and then passes through the volume at
l = lout , beyond which g is assumed to be zero. Eq. (6) neglects the
collection geometry of real optics, which can lead to large errors. A
more realistic model considers all the rays that reach a pixel, which
corresponds to a volume integral,

∞

pi = ∫

0

ηλ τf,λ dλ
⏟⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏟
Csys

lout

∫∫i

∫

lin

g[Ψ −1(u, l)

] Ωi(l)
4π

dl du.

(7)

In general, these models apply when

1. absorption, scattering, and refraction are negligible within ;
2. filters are employed to limit the spectral content of Si to a
narrow band of light that corresponds to the source field of
interest; and

3. the aperture is nearly closed and the volume is in focus, resulting
in thin rays and a constant solid angle (only pertains to Eq. (6)).

Methods for approximating Eqs. (6) and (7) can be found in Section 3.

2.2. Inverting the measurement model

The continuous measurement model for an imaging system consists
of one equation per pixel, i.e., Eq. (6) or (7). Consider a collec-
tion of one or more cameras that has a total of m pixels. Recon-
struction amounts to the calculation of g given a vector of data,
p = {pi} for i = 1, 2, ... , m, by simultaneously inverting all equa-
tions in the measurement model for p. This is typically a very large-
scale problem, since most tomography sensors have millions to tens
of millions of pixels (neighboring pixels provide similar information
about the unknown field, of course, but still constitute distinct ob-
servations). Broadly speaking, there are two categories of reconstruc-
tion algorithms: analytical and algebraic. Both forms exhibit simi-
lar mathematical properties due to the structure of the measurement
model.

2.2.1. Analytical reconstruction

Analytical algorithms consist of an explicit expression for g in terms
of p. This expression is based on a Fourier analysis of the measurement
model or presumed symmetry in the solution.

Fourier- or Radon-type reconstruction follows from the Fourier
slice theorem, which demonstrates that the 1D Fourier transform of
projections of g corresponds to a line through the 2D or 3D Fourier
transform of g [69]. Therefore, it is possible to write an expression for
g in terms of a Fourier transform of the projection data. Unfortunately,
this result assumes the availability of continuous measurement infor-
mation from an infinite set of transverse and angular perspectives. Real
measurements consist of a finite number of discrete projections, and a
filter function must be introduced to stabilize the inversion. The Fourier
slice theorem is covered in Section 2.3.1 along with a practical, filtered
algorithm.

Another analytical reconstruction technique is the inverse Abel
transform, in which the target is assumed to be rotationally-symmetric

5

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

in order to derive an explicit formula for the 3D field in terms of its
projections, as described in Section 2.3.2. However, this inversion is
unstable and is not used in practice. Instead, axisymmetric reconstruc-
tions are conducted using a polynomial interpolation of the projections,
discrete representation of the flow, or Fourier-based inversion.

2.2.2. Algebraic reconstruction

Algebraic algorithms are obtained by first introducing a finite basis
to represent the unknown field, g. The basis, Φ = {φ1, φ2, ... , φn},
consists of n basis functions, φj , which collectively span ; these
functions are used to represent the solution and discretize Eq. (6) or
(7). Far and away the most common discretization scheme in volu-
metric imaging is the voxel basis, wherein the measurement domain
is divided into n cubic ‘‘voxels’’ (conceptually: volumetric pixels) that
equal unity inside the voxel and zero outside. Fig. 1 depicts a voxel
in the reconstruction domain. The discrete nature of the reconstruction
based on this representation is apparent. Spherical basis functions with
a tapered edge [70,71] or simple linear ramps [72] have also been
employed for 3D tomography, although these models may complicate
the construction of an imaging model.

To begin, the function g is approximated using a set of n coefficients,

denoted gj ,

g(x) ≈

n
∑

j=1

gj φj (x) .

(8)

Assuming an orthonormal basis, the ideal value of gj
product of g and φj ,

is the inner

gexact,j = ∫∫∫

g(x) φj (x) dx dy dz
⏟⏞⏟⏞⏟
dx

.

Discretization of Eq. (6) or (7) yields the so-called ray-sum,

pi ≈

n
∑

i=1

Ai,j gj .

(9)

(10)

≡ ∂pi∕∂gj is the sensitivity of the ith measure-
In this expression, Ai,j
ment to the jth coefficient, which is given by the path integral along
the ith ray over φj when Eq. (6) is used or the volume integral over φj
when Eq. (7) is used. In general, the measurements and coefficients
are arranged as vectors, p = {pi} for i = 1, 2, ... , m and g = {gj }
for j = 1, 2, ... , n, and sensitivities are computed for each pixel with
respect to each basis function, Ai,j , resulting in the m × n sensitivity
matrix A, also called the weight matrix or ray-sum matrix. Section 3 is
a detailed guide to constructing A. Finally, measurements are modeled
by a matrix–vector product,

Ag = p.

(11)

In other words, A is the imaging model that relates a flame to its
projections. Algebraic reconstruction amounts to the estimation of g
given A and p.

2.2.3. Reconstruction as an ill-posed inverse problem

Volumetric reconstruction is an inherently ill-posed inverse problem
due to the inevitability of noise, model errors, and the frequency-
damping property of the measurement equations [73,74]. Ill-posed
problems are defined in contrast to well-posed problems, which are
characterized by three conditions [75]:

1. existence (there exists a solution),
2. uniqueness (the solution is unique), and
3. stability (the solution must change continuously with perturba-

tions to the data).

In algebraic tomography, stability is interpreted as a reasonable sen-
sitivity to noise and model errors. Reconstruction necessarily violates

either the uniqueness criterion, usually meaning that there are in-
finitely many solutions to Eq. (11), or stability, in which case there
exists a unique solution that is highly sensitive to measurement errors.
Eqs. (6) and (7) have a smoothing effect whereby high-frequency
components in g are damped in the projections. In other words, local
perturbations in g have a small effect on p, which is akin to a path or
volume average of the field variable: Eq. (6) or (7), respectively. Con-
sequently, a small perturbation to p can imply a large, local fluctuation
in g.3 Unfortunately, ‘‘small perturbations to p’’ are unavoidable.

Noise is intrinsic to the signal generation and collection mecha-
nisms in emission tomography. For instance, images of a combustion
experiment may be affected by shot noise, reset noise, readout noise,
fixed-pattern noise, relative intensity noise, thermal noise, and so on.
These effects may be characterized in terms of the SNR of the image
data, viz., low-SNR data leads to poor reconstruction accuracy [69].
In addition to noise, analytical and discrete representations of g nec-
essarily depart from the true field. For instance, a voxel discretization
presumes a uniform distribution of g within each voxel, whereas re-
alistic distributions of g are not homogeneous inside all the voxels.
Therefore, there will be a discrepancy between the measured projec-
tions, p, and projections calculated via the imaging model, Ag. This
occurs because the distributions given by g and Φ, per Eq. (8), are
not generally equivalent to the exact, continuous function g. Such
discrepancies are called ‘‘model errors’’. As mentioned above, inverting
the projections necessarily amplifies noise and model errors, thereby
corrupting estimates of g, so reconstruction algorithms must supple-
ment the measured projections with additional information in order
to produce a physically-plausible estimate of the 3D field. The use
of additional information to obtain accurate reconstructions is called
regularization.

Regularization takes different forms in analytical and algebraic
reconstruction algorithms. Analytical reconstruction is based on an
explicit expression for g that is a function of the measurements. Exact
analytical algorithms are predicated upon either

1. the presumption of infinite measurement information or
2. a strong assumption about the target function, such as axisym-

metry.

The finite nature of real measurements necessitates filtering and inter-
polation in Fourier-type reconstruction algorithms [76], which consti-
tutes regularization. Abel inversion assumes a rotationally-symmetric
target field, which is also a form of prior information. Exact ana-
lytical algorithms violate the uniqueness criterion since a finite set
of projections cannot specify a unique function g, whereas approxi-
mate analytical algorithms violate the stability criterion and require
regularization to suppress the effects of noise and model errors.

As in the analytical case, there are two classes of ill-posedness
in algebraic reconstruction. First, given enough cameras at enough
angles, the column rank of A may reach n, in which case there is a
unique least-squares solution to Eq. (11): gLS = (ATA)−1ATp. However,
provided that the basis is sufficiently fine to resolve a turbulent field,
A will necessarily be ill-conditioned.4 As a result, minor perturbations
to the data yield large, non-physical artifacts in the least-squares solu-
tion. Problems of this type are called discrete ill-posed. Second, when
the number of projections is smaller than the number of unknown
variables, as is typically the case, there are infinitely many solutions

3 The frequency-amplification produced by inverting Eq. (6) is demon-
strated by the Riemann–Lebesgue lemma (see [73, Ch. 1]). The secondary
convolution in Eq. (7) further increases frequency damping and, as a result,
increases noise amplification in the inversion.

4 In general, when large voxels are used, Φ cannot adequately represent
the target field so model errors are large and gLS is a bad approximation of g.
Therefore, small voxels should be used, in which case an imaging model, A,
with full column rank will be ill-conditioned.

6

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

that perfectly satisfy Eq. (11) and regularization is required to ob-
tain an appropriate estimate. Problems of the latter variety are said
to be rank-deficient. Discrete ill-posed matrix systems violate stability
and rank-deficient systems violate uniqueness, and there are various
strategies to regularize reconstructions in both cases.

2.3. Reconstruction algorithms

Tomographic imaging was originally developed for medical appli-
cations, and there is a large body of literature on medically-relevant
imaging algorithms as well as guidelines for using tomography as
a diagnostic tool [77]. Volumetric combustion sensors have unique
characteristics that must be considered in reconstruction. In particular,
quasi-instantaneous, phase-resolved, or time-resolved 3D estimates are
needed to capture the physics of an unsteady process and, as a result,
high-speed cameras are often required to record the projections. These
cameras are expensive and bulky and thus pose economic and geomet-
ric constraints on the number of views that can be implemented. More-
over, given sparse imaging data, volumetric estimates are especially
sensitive to regularization. It is important to incorporate appropriate
information about the target physics into the reconstruction algorithm.
Common examples of supplemental information include axisymmetry,
global smoothness, and piecewise smoothness; these assumptions may
be included explicitly (e.g., in terms of specified length-scales, diffu-
sion coefficients, statistical properties, and so on) or implicitly, but
regularization is always present in one form or another. Furthermore,
irrespective of the chosen algorithm, the computational cost of recon-
structing a single 3D field is large, typically lasting on the order of
hours to days (although the precise duration depends on the specific
algorithm, its implementation, and the computer hardware used to
perform the reconstruction). Therefore, computational cost is a signif-
icant consideration when selecting an algorithm, alongside accuracy,
especially for a time-resolved experiment.

At the outset of tomography, when medical X-ray imaging was the
dominant modality, reconstructions were computed by filtered back-
projection (FBP) [76]. FBP requires a dense set of regularly-spaced
projections, resulting in a high dose of radiation to the patient, so
scientists sought a limited-data solution. In 1970, Gordon et al. [78]
introduced the widely-used additive algebraic reconstruction technique
(ART) as well as the multiplicative ART (MART). Relative to FBP,
both of Gordon’s algorithms can produce acceptable estimates of a 3D
field from a small number of irregularly-spaced projections. Numerous
iterative techniques have been proposed since then, with key exam-
ples given in [79–81]. These methods do not inherently accommodate
target-specific prior information, however, which motivated the use of
explicit regularization in tomographic imaging.

Classical (non-statistical) methods of regularization in algebraic
tomography either augment the measurement equations with a penalty
function or truncate an iterative solver to promote low-frequency es-
timates. The most common methods of regularization in emission to-
mography involve truncation of an ART variant or Tikhonov-based
smoothing [82,83]. Another typical penalty term is the total variation
(TV) norm of g, which promotes piecewise-smooth solutions while
permitting sharp discontinuities, reminiscent of combustion structures.
This approach was first demonstrated in medical imaging in 2006 [84]
and subsequently applied to flame tomography by Cai et al. [85]
in 2013. Moving beyond classical schemes, a statistical framework
is required to conduct uncertainty quantification (UQ), which is in-
creasingly necessary to test physical models and validate simulations.
Many classical regularization techniques can be recast in a Bayesian
framework for this purpose [86]. Recently, Grauer et al. [87] demon-
strated Bayesian implementations of Tikhonov and TV regularization
for combustion tomography.

Normally, when Eq. (11) is augmented with an objective func-
tion, g is obtained using a gradient-based solver. Global optimization
schemes such as simulated annealing or an evolutionary algorithm

can also be used to solve for the QoI, as demonstrated by Cai [85],
Unterberger [88], and their colleagues. This approach may be neces-
sary when the measurement model is highly nonlinear, e.g., due to
self-absorption or multiple-scattering effects. However, the very high
computational cost of global optimization is a major drawback, even by
the standards of volumetric reconstruction algorithms. Parallel comput-
ing can be adopted to improve the speed of nonlinear reconstructions,
but the overall cost remains high, so gradient-based techniques are still
preferred.

Finally, the recent advent of deep learning has had a considerable
impact on many scientific disciplines, and practitioners of tomography
have begun to experiment with deep learning-based reconstruction.
Loosely speaking, deep learning mimics neural structures to form a map
between arbitrary inputs and outputs, often using a large repository
of training data. This approach can yield efficient algorithms that are
reliable for ‘‘in-sample data’’, namely: data that is well-represented by
a labeled training set. However, the technique becomes less accurate
for out-of-sample data, which is of primary interest when investigating
and characterizing novel physics. New developments are focused on
explicitly incorporating physics into the training process to produce
trustworthy, scientific-grade measurements.

2.3.1. Filtered back projection

Filtered back-projection provides a closed-form solution to the in-
version problem in tomography. FBP is based on the Fourier slice
theorem, which relates the Fourier transform of projections to the
Fourier transform of the unknown 3D field. This theorem is briefly sum-
marized here to set the stage for FBP, additional details can be found
in Bertero et al. [69]. Note also that the theorem is introduced for 2D
tomography; the technique is easily extended to 3D by independently
reconstructing a series of 2D planes.

Consider a 2D slice of the field variable, g(x, y), illustrated in Fig. 2.

The 2D Fourier transform of this function is

∞

∞

̂g(χ, ξ) = ∫

−∞

∫

−∞

g(x, y) exp

]
[
−i2π(χx + ξy)

dx dy,

(12)

where i is the square root of −1 and χ and ξ are the x- and y-direction
wavenumbers of ̂g. Projections of g are identified using sinogram coor-
dinates, (s, θ), where θ is the ‘‘angular position’’ of a ray and s is the
minimum distance of that ray to the origin of the domain. Points along
the (s, θ) ray are specified in terms of the distance l via the following
rotational transformation,
]
] [x
[s
y
l

[ cos(θ)
−sin(θ)

sin(θ)
cos(θ)

(13)

=

]

.

Using sinogram coordinates, the (s, θ) projection of g is

pθ(s) = ∫

∞

−∞

g(s, l) dl,

(14)

which is called the Radon transform of g. Note that this equation
presumes the ‘‘thin ray’’ formulation in Eq. (6). Given continuous
projection data for all s ∈ (−∞, ∞), the 1D Fourier transform of pθ is

̂pθ(ω) = ∫

= ∫

∞

−∞
∞

−∞

pθ(s) exp(−i2πωs) ds
[

∞

]

g(s, l) dl

exp(−i2πωs) ds.

∫

−∞

(15)

This is equivalent to integration over the original coordinate system,

̂pθ(ω) = ∫

∞

∞

∫

−∞

−∞

g(x, y) exp(−i2πωs) dx dy,

(16)

where s = x cos(θ) + y sin(θ). The left side of Eq. (16) is the 1D Fourier
transform of projections at a constant view angle and the right side
is a line through the 2D Fourier transform of g, i.e., Eq. (12). There-
fore, it is possible to construct ̂g by accumulating Fourier-transformed
projections for all θ.

7

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 2. Visualization of the Fourier slice theorem in 2D. The 1D Fourier transform of
LoS measurements through the target field from a given angle, i.e., ̂pθ , corresponds to
a line through the 2D Fourier transform of g, ̂g. In principle, 1D Fourier transforms of
the projection data at a given angle are used to build up ̂g, and the inverse 2D Fourier
transform is applied to recover g.

Conceptually, Fourier-based reconstructions are conducted by pop-
ulating the 2D Fourier transform of g using 1D Fourier transforms of pθ
and then taking the inverse 2D Fourier transform of the result,

g(x, y) = ∫

∞

∞

∫

−∞

−∞

[
̂pθ(ω) exp

]
i2π(χx + ξy)

du dv.

(17)

A change of variables is introduced to express this transform in polar
coordinates,

χ = ω cos(θ)

and

ξ = ω sin(θ),

such that

dχ dξ = ω dω dθ.

(18a)

(18b)

(19)

Applying the change of variables to Eq. (17) yields

2π

∞

g(x, y) = ∫
0

∫

−∞

̂pθ(ω) ×

exp{i2π[x cos(θ) + y sin(θ)]} ω dω dθ.

(20)

Note that outer integral in Eq. (20) can be split up into two integrals,
both carried out from 0 to π, where θ is replaced by θ + π in the second
integral. Moreover, ̂pθ+π (ω) = ̂pθ(−ω). As a result, the field variable can
be expressed in terms of pθ using projections from a 180◦ arc,

π

∞

g(x, y) = ∫
0

∫

−∞

̂pθ(ω) |ω| ×

exp{i2π[x cos(θ) + y sin(θ)]} dω dθ.

(21)

The outer integral in Eq. (21) is the ‘‘back-projection’’ operation,
which effectively smears pθ back along each LoS, corresponding to
a set of (s, θ) coordinates. Further, the term |ω| scales the integrand
such that high-frequency components are weighted more heavily than
low-frequency ones. In practical applications, noise dominates the high-
frequency content of measurements. Real-world projection data is re-
solved at discrete angular intervals and, as a result, the angular content
of the 2D Fourier map is poorly-sampled at high frequencies (picture
a fan of lines with equal angular spacing in Fig. 2: data becomes
increasingly sparse with ω). Therefore, |ω| is replaced with a filter
function to ensure that estimates of g are suitable, hence ‘‘filtered
back-projection’’.

The simplest filter in FBP consists of a frequency cutoff, where |ω|
is set to zero above ωmax. This is called a ramp filter. In discrete form,
the ramp filter is called the Ram–Lak filter, named for Ramachandran

8

Fig. 3. Illustration of the forward and inverse Abel transforms. The forward trans-
form projects an axisymmetric object to the image plane and the inverse transform
converts projection data to a rotationally-symmetric 3D object. This usually requires
regularization since Abel inversion is highly sensitive to measurement errors.
Source: Adapted from [93].

and Lakshminarayanan [89]. Shepp and Logan [90] modified this filter
by introducing smoothing in Fourier space to improve the quality of
reconstructions. The resulting Shepp–Logan filter is the most common
choice in FBP, but further modifications could be made to optimize the
frequency content of g for a specific application. An extensive overview
of FBP algorithms can be found in the third chapter of Kak and Slaney’s
textbook [91], several of which are implemented in MATLAB’s iradon
function.

Filtered back-projection is highly efficient from a computational
standpoint. However, FBP algorithms require a large number of projec-
tion angles (on the order of 1000 in modern CT scanners) to produce
accurate reconstructions, which should equally spaced in θ. Both of
these requirements effectively prevent the use of FBP for transient
flows due to the limited availability of cameras. Therefore, FBP is only
recommended for the reconstruction of steady flames in cases where
images of the target can be captured from a large set of equiangular
views.

2.3.2. Abel inversion

Many jets, wakes, shocks, and flames are axisymmetric, i.e., radi-
ally symmetric about the primary flow axis. Such flows are usually
axisymmetric in the mean sense, although plenty of burners produce a
steady laminar target. When a flame is judged to be radially symmetric,
centered 2D projections, recorded perpendicular to the central axis, are
assumed to be identical. These projections, p(y, z), are related to the
radial distribution of g(r, z) by the Abel transform [92],

p(y, z) = 2 ∫

∞

y

g(r, z)

r

√

r2 − y2

dr,

(22)

where the (r, y, z) coordinates system is depicted in Fig. 3 [93]. Eq. (22)
can be analytically inverted, resulting in the so-called inverse Abel
transform,

g(r, z) = −

∞

1
π ∫

y

py(y, z)
√

y2 − r2

dy,

(23)

where py = ∂p∕∂y. In practice, this expression is of limited utility
because derivatives of the projection data are unknown and high-
resolution finite difference approximations to py are sensitive to noise
while low-order approximations limit the resolution of g.

Numerous methods have been devised to stabilize Abel inversion.
Three-point Abel (TPA) inversion, invented by Dasch [92], is among
the most popular and robust of these techniques. In TPA, py is assumed
to be locally-quadratic along the y-axis about each projection, pi, and
Eq. (23) is calculated using this fit from y = yi−Δy∕2 to yi+Δy∕2 for each
LoS. Data along y (i.e., normal to the flow axis) are arranged as a vector,
p = {p(yi, z)}; the field variable is resolved at discrete radial positions,

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

and it is also arranged as a vector, g = {g(ri, z)}. TPA estimates are
given by the matrix equation,

g =

1
Δy

Dp,

(24)

where the spacing between projections, Δy, is uniform and equivalent
to that of the reconstruction, Δr. The text of Dasch [92] contains several
errors that were corrected by Martin [94]. Corrected elements of D are

Di,j =

⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩

0,
H 0

H 0

H 0

H 0

i,j+1 − H 1
i,j+1 − H 1
i,j+1 − H 1
−H 0
i,j+1 − H 0

,
i,j+1
i,j+1 + 2H 1
i,j ,
i,j+1 + 2H 1
,
i,j−1
i,j+1 − H 0
i,j+1 + 2H 0

i,j−1 − H 1

i,j

i,j+1

j < i − 1

j = i − 1

j = i

j ≥ i + 1

,

i = 1, j = 2

(25a)

Fig. 4. Illustration of the additive ART with g ∈ R2. An initial guess, g(0), is updated
to correct the first residual, and then the second, and then the first again, and so on.
Given a full rank matrix, A, and absent measurement and model errors, the sequence
approaches gexact as k goes to infinity.
Source: Adapted from [103].

(25b)

with

H 0

i,j =

and

0,

1
2π

1
2π

⎧
⎪
⎪
⎨
⎪
⎪
⎩

j = i = 1, j < i

[ √

log

[ √
√

log

(2j+1)2−4i2+2j+1
2j

(2j+1)2−4i2+2j+1
(2j−1)2−4i2+2j−1

]

]

,

,

j = i ≠ 0

j > i

.

]

−

√

√

H 1

[√

j > i

i,j =

(25c)

0,
1
2π
1
2π

− 2jH 0
i,j ,

(2j − 1)2 − 4i2

(2j + 1)2 − 4i2

j < 1
j = i ≠ 0

(2j + 1)2 − 4i2 − 2jH 0
i,j ,

⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
inversion techniques include onion peeling [95],
Additional Abel
Fourier expansions [96,97], and Tikhonov regularization [82]. Recent
evaluations demonstrate that each of these approaches can yield an
accurate reconstruction of g [93] when the forward Abel transform is a
suitable measurement model. However, the presumption of thin, paral-
lel rays is inconsistent with the collection geometry of real optics, which
can lead to significant reconstruction errors [98,99]. Notably, Hick-
stein et al. [93] published an open-source Python package containing
state-of-art axisymmetric reconstruction algorithms.

2.3.3. Algebraic reconstruction technique

In algebraic tomography, projections of the target are modeled using
the matrix system in Eq. (11), where the sensitivity matrix A is a
linear approximation to the imaging model introduced in Section 2.1.
While Fourier-based reconstruction algorithms provide a continuous
expression of the field variable parameterized by world coordinates,
g(x), generic algebraic techniques require a finite basis, Φ, to repre-
sent estimates of a flame.5 This basis typically comprises cubic voxels
within which the emission source field is said to be uniform. However,
turbulent flames feature small-scale structures, so a dense grid of voxels
(on the order of 105 to 106) is required to adequately represent these
targets. Moreover, modern cameras feature a large number of pixels
(> 106), each constituting a projection of the flow that must be included
in the measurement model by discretizing Eq. (6) or (7) using Φ,
and the imaging system generally includes multiple cameras. A has
one row per pixel and one column per basis function, resulting in a
matrix with hundreds of billions to trillions of elements. Since voxels
are non-overlapping, A is usually sparse, but explicit representations of
its pseudoinverse are not sparse and often cannot be held in memory.
Iterative algebraic reconstruction techniques were therefore introduced

5 Here,

‘‘generic’’ refers to algebraic techniques that do not inherently
presume the form of the solution, i.e., excluding the discrete inverse Abel
transform.

9

to obtain a solution to Eq. (11) without explicitly building the inverse
sensitivity matrix. Numerous methods have been crafted to incorpo-
rate explicit information about the target into iterative algorithms, in
order to obtain physically-plausible estimates of g. These methods are
discussed in Sections 2.3.7–2.3.10.

Historically, the additive algebraic reconstruction technique, or
ART, has been the most popular iterative algorithm for volumetric
imaging due to its ease of implementation and ‘‘acceptable’’ perfor-
mance given a small number of projections [78,100]. The ART begins
with an arbitrary initial estimate, g(0), whose elements are updated as
follows:

g(k+1) = g(k) + γ

pi − Ai,∗g(k)
Ai,∗‖
‖
‖
‖

2
2

AT

i,∗.

(26)

In this expression, γ is a relaxation parameter in (0, 2] and Ai,∗ is the ith
row vector of A. ART iterations loop through each LoS, usually using
i = k(mod m). Eq. (26) compares the projection of the current iteration,
Ai,∗g, to the corresponding projection measurement, pi, and spreads the
residual back along the ith LoS via AT
i,∗, much like the back-projection
integral in FBP. A nonnegativity constraint may be incorporated by
enforcing

(
g(k)
g(k)
j = max
j

, 0

)

(27)

for all j ∈ 1, 2, ... , n at each step. This algorithm was first introduced
to computed tomography by Gordon et al. [78] and was employed
to reconstruct data from the first medical CT scanner by Sir Godfrey
Hounsfield [101]. It should be mentioned that the ART was long-known
in linear algebra as the ‘‘Kaczmarz method of projections’’ [102], which
was devised as a general technique to calculate the solution to a
consistent matrix system such as Eq. (11).

Fig. 4 presents a geometric representation of the additive ART. For
simplicity, assume there are two voxels, two LoS measurements, and the
relaxation factor is set to unity. The x and y axes of the plot represent
values of g in one of the two voxels, and estimates of g are vectors
in this space. Row vectors of A are weights for the ray-sum along a
given LoS; these vectors indicate the sensitivity of a projection to g.
Each LoS measurement is maximally-sensitive to components of g that
are aligned with the vector given by the corresponding row of A, and
measurements are insensitive to components of g that are orthogonal
to that vector. The latter directions, defined by {g|Ai,∗g = pi}, are
plotted with purple lines in Fig. 4. An arbitrary initial guess, g(0),
is required, and the first residual is the mismatch between the first

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

measured projection and the projection implied by the initial guess:
p1 − A1,∗g(0). The initial guess is updated along A1,∗, which represents
a step orthogonal to {g|A1,∗g = p1}. This step corrects the discrepancy
between the measured and modeled projections along the first LoS, and
the process begins again with the second element of p.

Iterations continue until an appropriate convergence criterion is
satisfied. The ART converges to the solution to Eq. (11) that is closest
to g(0) so long as A is consistent [102,104]. However, when the system
is inconsistent, meaning that no vector g solves Ag = p (for instance,
due to noise or errors in the measurement model), then each sub-
sequence {g(km+i), k = 0, 1, ... }, for all i ∈ 1, 2, ... , m, has a unique
minimum, denoted g(i)
LC. This collection of solutions is called the limit
cycle [105,106]. To avoid this scenario, the ART can be applied to
the squared system, ATAg = ATp, to obtain the unique, least-squares
solution,

gART = arg min
g

2
‖
AT(Ag − p)‖
‖
‖
2
‖
‖

,

(28)

provided that ATA is invertible. However, this result does not guaran-
tee a good solution since the measurement information can be quite
limited and the minimum norm criterion does not have direct physical
significance with respect to the flame (see Sections 2.3.7–2.3.10).

The relaxation factor, γ, is used to elongate or shrink the correc-
tion vector, which affects the rate of convergence to the least-squares
solution (or to the limit cycle, as the case may be). Increasing γ
can speed-up convergence but also increases the sensitivity to noise
and model errors. Intuitively, the speed and stability of convergence
improves when the row vectors of A are orthogonal, which is related
to the optimal design-of-experiments. The convergence behavior of
Eq. (26) is difficult to characterize because it depends upon the order
in which residuals are updated; the consistency of Eq. (11), which is
itself a function of noise and model errors; and dynamic changes to
γ, i.e., when γ is a function of k or the kth residual, ‖p − Ag(k)
2
2.
‖
It has been shown that randomly shuffling the order of projections
in each iteration, wherein i is chosen at random with a probability
proportional to the magnitude of Ai,∗, considerably outperforms the
sequential ordering introduced above [107]. Another crucial feature of
ART iterations is semi-convergence, which was laid out by Natterer [108]
and examined at length by Hansen and Jørgensen [109]. In brief:

1. Initially, g(k) quickly approaches (but does not necessarily reach)

the desired error-free solution, gexact .

2. Later, g(k) asymptotes towards the undesired least-squares solu-
tion, gLS = (ATA)−1ATp, which is corrupted by the effects of
noise and discretization errors.

This phenomenon occurs because initial iterations of the ART con-
tribute robust, low-frequency elements of the solution whereas later
iterations contribute high-frequency elements that are more susceptible
to non-physical perturbations in p and errors in A. Clearly, it is desir-
able to halt the ART before the sequence converges. The ideal stopping
point and accuracy of the resulting solution depend upon the relaxation
parameter, and numerous heuristics have been devised to determine
an appropriate relaxation rate and stopping point. The most common
stopping criterion is the discrepancy principle, in which the magnitude
of errors in p, denoted δp, is assumed to be known. ART iterations are
halted when ‖p−Ag(k)
≤ δp, since it is assumed that further iterations
are fitting g to noise [110]. Optimization of the relaxation parameter
and stopping criteria in the ART are discussed at length by Hansen [73,
Ch. 6].

2
‖
2

Finally, note that the sensitivity matrix is generally rank-deficient,
meaning that there exists an infinite set of vectors g in the kernel of A,
where ker(A) = {g|Ag = 0}. Components of g in the kernel of A are not
updated by the ART so the initial guess is frequently chosen to be an
n × 1 vector of zeros such that only nonzero elements of the solution
are determined by the data.

2.3.4. Multiplicative algebraic reconstruction technique

Multiplicative ART, or MART, refers to a class of iterative recon-
struction algorithms in which g(k) is updated with a multiplicative
factor, as opposed to the additive factor in Eq. (26). Multiplicative
updates convey several advantages. For instance, once a voxel has been
set to zero, it remains at zero, assisting the rate of convergence and
enabling robust reconstructions of sparse fields, which is particularly
relevant in TPIV. Gordon et al. [78] first utilized the MART for to-
mography concurrently with their additive technique in 1970. Both
algorithms have been the subject of considerable analysis and further
developments since then.

As with the ART, the basic MART begins with an initial guess
that is iteratively updated to satisfy the measured projections. Verho-
even [111] presented three standard variations of the MART based on
the formulations of Herman et al. [78,104,112]:

[

(

g(k+1)
j

= g(k)
j

1 − γ

1 −

)]

,

pi
Ai,∗g(k)

which is only applied if Ai,j is nonzero;

[

g(k+1)
j

= g(k)
j

1 − γ

(

1 −

Ai,j
Amax,i

pi
Ai,∗g(k)

)]

;

and

g(k+1)
j

= g(k)
j

(

pi
Ai,∗g(k)

)γ

Ai,j
Amax,i

.

(29a)

(29b)

(29c)

All three variants incorporate a relaxation factor, γ, to stabilize the
procedure, and the latter two expressions contain the normalization
constant Amax,i = max(Ai,∗), which is the largest weight associated
with the ith projection. This constant did not appear in the original
algorithms, but the inclusion of Amax,i has been found to improve
the MART’s resilience to noise and discretization errors. As a result,
Amax,i has been incorporated into many subsequent MART codes [113].
Typically, γ is confined to (0, 1] since factors greater than 1 can lead
to divergence. Each iteration corresponds to a single projection, pi, and
the update is performed for every element of g before incrementing k,
i.e., for all j ∈ 1, 2, ... , n. The MART exhibits semi-convergence, just
like the additive ART, and the order in which projections are used to
update an element of g affects the rate of convergence and timing of
semi-convergence. It is common to proceed sequentially, setting i to be
k(mod m). However, randomly shuffling the order of projections in each
iteration has been reported to steady convergence, as in the additive
ART [107,111].

Multiplicative ART iterations depend on the ratio of measured to
modeled projections, p to Ag(k). When the model underpredicts the ith
projection and gj contributes to that measurement (i.e., Ai,j > 0), then
gj is increased, and vice versa when the projection is overpredicted.
This formulation inherently enforces non-negativity when g(0) ≥ 0. The
magnitude of the update in Eq. (29a) only depends on γ and the ratio
of measured to modeled projections. By contrast, Eqs. (29b) and (29c)
also account for the contribution of gj to pi, as indicated by the weight
Ai,j . With proper selection of γ and truncation of the algorithm, all three
versions proceed in a qualitatively similar manner, but the exponential
update is the most robust to both γ and the truncation criterion, so
Eq. (29c) is the prevailing implementation of the MART [111].

The ultimate solution and computational cost of the MART depend
upon the initial guess. Elements of g that are not visible in any of the
projections are constant so it is important to ensure that every voxel is
seen by at least one camera. Moreover, elements that are zero remain
zero, and it is common practice to set g(0) to be a vector of ones or
the uniform vector that minimizes Eq. (11). It is preferable, however,
to zero-out regions of the domain that are known to be void from the
start and then skip those elements of g during the reconstruction in
order to speed-up the algorithm.

10

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

While not the focus of this review, it is noteworthy that particle
fields in TPIV are amenable to a sophisticated initialization procedure
since there is usually a good deal of empty space between the particles.
There are three common initialization techniques used in TPIV. First,
Worth and Nickels [114] reported a multiplicative first guess (MFG),
constructed using subsets of the weight matrix that correspond to
distinct views,

(

)]◦

1
Nviews ,

[(

)
AT
1,∗p


(

)
AT
2,∗p


◦

◦ ... ◦

g(0)
AT
V ,∗p
MFG =
where 
v indicates the projections/rows of A from the vth camera or
view, Nviews is the number of views, ◦ is the element-wise Hadamard
product, and ⋅◦ is the Hadamard exponent. Second, Atkinson and
Soria [115] proposed multiplied LoS (MLoS) estimation, wherein g(0)
is composed on an element-by-element basis,

(30)

g(0)
MLoS,j =

p1∕Nviews
i

.

∏

i∈j

(31)

Here, 
j includes all of the projections that are sensitive to the jth
element of g. In other words, 
j indicates i ∈ 1, 2, ... , m where Ai,j > 0.
Although preparing this list for each basis function may seem like
an expensive procedure, the pixels can usually be determined directly
from the camera calibration functions (see Section 4). Finally, Novara
et al. [116] developed a motion-tracking enhanced (MTE) MART algo-
rithm for TPIV, which was streamlined by Lynch and Scarano [117].
All three of these techniques have been employed to initialize the
MART (and other iterative algorithms in the case of MFG and MLoS) in
order to reduce the cost of reconstruction and improve the accuracy of
estimates [114,115,118]. However, such procedures are less useful in
the context of a continuous emission field.

Simultaneous and block iterative MART (SMART and BIMART)
algorithms update the elements of g using all of the projections or
subsets thereof, respectively. The simultaneous form was devised by
Mishra et al. [113] in 1999 and applied to TPIV by Atkinson and
Soria [115] ten years later. SMART updates are given by

(

)μ

Ai,j
Amax,i

1
Nj

,

(32)

g(k+1) = g(k) ∏
i∈j

pi
Ai,∗g(k)
where Nj is the number of projections in 
j . This approach can reduce
memory usage relative to the conventional MART provided that the
initial guess has been suitably refined. The BIMART framework pre-
sented in [119] is a generalization of the SMART with simultaneous
updates applied to subsets of the projections. This formulation replaces

j in Eq. (32) with a smaller block of projections and then iterates
through each block, which can potentially be leveraged to parallelize
the SMART [120].

While the additive ART approaches the minimum norm solution
to Eq. (11), this is not necessarily a desirable criterion since it is not
related to salient physical attributes of the flame. MART algorithms,
by contrast, yield a maximum entropy solution which solves Eq. (11)
while maximizing the Kullback–Leibler divergence between g(k) and g(0)
as k goes to infinity [104]. In other words, gMART is the vector that
2
minimizes ‖Ag − p‖
2 subject to
)]
( gj
)
ng

( gj
ng

arg max
g≥0

n
∑

(33)

log

−

[

.

j=1

In this expression, g is the mean of g. The physical interpretation
and general applicability of this criterion have been the subject of
debate [111,121]. There is no direct physical interpretation of the
converged vector per se, but the action of the MART promotes sparse g
vectors, which corresponds to spatial sparsity when the basis consists of
a large number of non-overlapping functions (e.g., voxels). As a result,
the MART is intrinsically compatible with particle fields and is thus
the dominant reconstruction platform in TPIV [118]. Verhoeven [111]
reported that the MART performs well on continuous fields that exhibit
large spatial gradients relative to the additive ART, although MART
solvers are less commonly used to reconstruct a continuous 3D emission
field.

11

2.3.5. Maximum likelihood expectation maximization

The ART and MART do not inherently compensate for the distri-
bution of noise in p. Expectation maximization algorithms leverage
a statistical description of the measurement process to identify 3D
fields which are deemed more or less likely based on the measured
projections. Eq. (11) implies that p = Ag, but there is some chance of
observing p for a range of g vectors due to noise, errors in the measure-
ment model, and inherent variation in the emission, absorption, and
detection of light. These possibilities are represented using a stochastic
measurement model,

p = Ag + e,

(34)

where the random vector e accounts for all discrepancies between
measured and modeled projections, p and Ag. Since the errors are
not known by definition (or else they should be subtracted off p or
A would be adjusted), expectation maximization algorithms seek the
field g which best explains the data based on a presumed distribution of
errors as well as prior information about the QoI. These algorithms are
generally conducted in a Bayesian framework (Section 2.3.8), but there
is one non-Bayesian version that has been employed for volumetric
imaging of combustion.

Naturally enough, the maximum likelihood expectation maximiza-
tion (MLEM) algorithm is one that maximizes a likelihood function,
P(p|g). This function indicates the chance of observing p given the hy-
pothetical field g. The likelihood essentially describes the distribution
of errors for a measurement system, and the MLEM seeks the vector g
which maximizes P(p|g),
] .
[P(p|g)
gMLEM = arg max

(35)

g

Given a high-fidelity detector, absorption- and emission-based signals
are often well-modeled as a photon counting process. Random variation
in these signals follows a Poisson distribution [122]. The resulting
likelihood function is
(Ai,∗g)pi
m
∏
pi!

−Ai,∗g) ,

P(p|g) =

(
exp

(36)

i=1

where pi is the discrete photon count registered by the ith pixel or
photodetector. Shepp et al. [123,124] proposed an iterative MLEM
algorithm for Poisson-distributed errors in the context of medical imag-
ing; the refined algorithm developed by Lange and Carson is the form
most typically used [125]. Starting from an initial guess, the MLEM
solution is iteratively approached via

g(k+1)
j

=

(

g(k)
j
i=1 Ai,j

∑m

m
∑

i=1

Ai,j

pi
Ai,∗g(k)

)

,

(37)

which, like the MART, includes the ratio of measured and modeled
projections weighted by Ai,j . The emission-based signals discussed in
this review are ideally modeled as a Poisson count, assuming a clean
signal and accurate imaging model, and the MLEM has been employed
in the context of combustion imaging, accordingly [126,127]. However,
Herman and Meyer [128] reported that the MLEM is considerably
costlier than the additive ART, despite the fact that both algorithms
yield substantially similar reconstructions since they make the same
(minimal) assumptions about the QoI. Indeed, the Poisson-based MLEM
yields the minimum norm solution to Eq. (11) so long as the system
of equations is consistent [129]. Therefore, statistical reconstructions
normally take place in a Bayesian framework in order to incorporate
structural information about the target field [130].

2.3.6. Simultaneous iterative reconstruction techniques

Computing reconstructions with a row-by-row solver, as done by
the ART, MART, and MLEM algorithms, in an interpreted scripting
environment can be incredibly time-consuming. Numerous strategies
have been devised to simultaneously update every element of g, called
simultaneous iterative reconstruction techniques or ‘‘SIRTs’’. SIRT al-
gorithms are closely related to generic optimization techniques. In

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Table 1
Diagonal matrices for SIRT algorithms [109].

Method

Cimmino [134]
Landweber [135]

SART [79]

CAV [136]
DROP [137]

Tj,j

1
1
‖
A∗,j
‖
‖
1
S−1
T,j,j

−1

1

‖
‖
‖

Mi,i

m−1 ‖
‖
1

−2
Ai,∗‖
‖
2

−1
Ai,∗‖
‖
1
SMAi,∗‖
‖
−1
Ai,∗‖
‖
1

‖
‖
‖
‖
‖
‖

−2
2

particular, the SIRT framework is a special case of gradient descent
which can be tuned to deal with large, inconsistent linear systems.
Several of these algorithms predate computed tomography, such as
Cimmino’s method and Landweber iteration, while others, like the
simultaneous ART (SART), were explicitly motivated by volumetric
imaging. The term originates with Gilbert [131], who proposed a SIRT
algorithm in 1972, as did Goitien [132].

Just like the algebraic reconstruction methods discussed above,
SIRT algorithms begin with an initial guess that is iteratively updated
to solve Eq. (11). Hansen and Jørgensen [109] presented a general form
of SIRT iterations,

g(k+1) = g(k) + γkTAT

weighted residual
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
M (p − Ag(k))
,
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟
weighted back-projection

(38)

wherein γk is the relaxation parameter for the kth iteration and T and
M are n × n and m × m diagonal matrices, respectively. The matrix M
weights residuals along each LoS and T weights the back-projection
operation at each basis function. Iterates of Eq. (38) converge to a
weighted least-squares solution,

gSIRT = arg min

g ‖M (Ag − p)‖

2
2 ,

(39)

if and only if 0 < γk < 2∕ρ(TATMA), where the ρ(⋅) operator returns
the largest absolute eigenvalue of a matrix [133]. There may be more
than one vector which satisfies Eq. (39), e.g., when the column rank
of A is less than n, in which case gSIRT will be the vector that satisfies
Eq. (39) and is closest to the initial guess. As with the additive ART, a
nonnegativity constraint may be applied in SIRT solvers via Eq. (27).
Table 1 specifies the elements of T and M for five key SIRT methods;
the methods are listed chronologically by year of publication. These
algorithms are Cimmino’s method [134], Landweber iteration [135],
the SART [79], component averaging (CAV) [136], and dynamically
relaxed orthogonal projection (DROP) [137]. In this table, SM is an m×m
diagonal matrix where Si,i = nnz(Ai,∗) and nnz(⋅) returns the number of
nonzero elements in a vector or matrix. Similarly, ST is an n×n diagonal
matrix where Sj,j = nnz(A∗,j ) and A∗,j is the jth column of the weight
matrix.

Cimmino’s method simultaneously projects the residual between
p and Ag(k) onto the hyperplane associated with each equation, i.e.,
{g|Ai,∗g = pi} for the ith hyperplane, and takes the geometric average of
these values. This approach converges to the least-squares solution that
is closest to g(0) whether or not the matrix system is consistent, which
is an improvement upon the additive ART. Landweber’s algorithm is
based on the quadratic functional

F (g) =

1
2
2 .
2 ‖Ag − p‖

(40)

The slope of F at g is ∇F (g) = AT(Ag−p). Consequently, this functional
may be minimized by scaled gradient descent,
g(k+1) = g(k) − γk∇F (g(k)) ,

(41)

The SART algorithm was proposed for the purpose of tomographic re-
construction by Andersen and Kak [79] in 1984. In the SART, residuals
are weighted by the length of rays in each basis function. Andersen
and Kak [79] also reported the use of a 2D bilinear basis, akin to the
3D trilinear basis used in Atcheson et al. [72], though the basis is not
intrinsic to the SIRT implementation presented in Table 1. CAV is an
alternative to Cimmino’s method and the SART in which the sparsity
of A is leveraged via SM: residuals are weighted by not only weights
Ai,j but also by the number of projections that transect the jth basis
function. Finally, the DROP is an alternative modification of Cimmino’s
method wherein the sparsity of A is used to weight the back-projected
residuals via T rather than directly updating the residuals via M.

On their own, SIRT algorithms are susceptible to semi-convergence,
just like the ART, MART, and MLEM methods [109]. The main asset
of SIRTs is their ability to take advantage of array programming in
scripted environments like MATLAB or Python’s NumPy library [139].
This is facilitated by the lack of an explicit inverse weight matrix in
Eq. (38) and the simultaneous use of all residuals in each step. In other
words, there is no need to loop over j. The algorithms discussed here
have been implemented in several freely-available software packages,
including AIR Tools II [109] (MATLAB), the ASTRA toolbox [140]
(MATLAB, Python), and TIGRE [141] (MATLAB, Python), the latter two
of which have been optimized to run on a GPU. Therefore, SIRT-type
reconstruction is recommended when using a scripting language. SIRTs
have also been reported to reduce the cost of reconstruction with a
compiled solver [142].

It is essential to emphasize that SIRT solvers, like the ART, MART,
and MLEM algorithms, do not inherently supplement the measurement
equations with physically-relevant information in order to produce
a reasonable reconstruction of the flame. Instead, these techniques
merely provide a low cost procedure for solving a matrix equation
(although early truncation can occasionally yield acceptable estimates
of low-frequency fields). Additional constraints on the solution space
are typically required to adequately regularize reconstructions.

2.3.7. Regularization functionals

Classical regularization techniques are a cornerstone of inverse
analysis with a rich history in the area of tomographic imaging [86].
In these methods, the measurement equations are augmented with a
penalty function that is designed to promote desirable characteristics
in the flame and penalize undesirable characteristics. Reconstruction
algorithms with regularization differ from the preceding algebraic al-
gorithms in that regularization attempts to mitigate the ill-posed nature
of tomographic imaging by including additional, physically-motivated
information into the procedure.6 Two forms of classical regularization
are dominant in volumetric imaging: Tikhonov regularization, which
favors smooth solutions, and TV (total variation) regularization, which
also favors smooth solutions but more easily accommodates sharp
discontinuities.

Tikhonov regularization, proposed in 1963 by its namesake Andrey
Tikhonov [143], incorporates a matrix-based penalty function into the
general functional in Eq. (40), which results in a new minimization
problem,

gTik = arg min
g

= arg min

g

(

2
‖Ag − p‖
(
[ A
‖
‖
‖
γLTik
‖
‖

2 + γ 2 ‖
LTikg‖
‖
‖
)
2
[p
]
]‖
‖
‖
0
‖
2
‖

g −

,

)

2
2

(42)

In this expression, LTik is the so-called Tikhonov matrix, which implic-
itly promotes desired characteristics in gTik; γ > 0 is a regularization

which is equivalent to Hansen and Jørgensen’s [109] formulation in
Eq. (38). This technique was developed by Landweber to solve Fred-
holm integral equations of the first kind and has been a mainstay in
inverse analysis due to its simplicity and general applicability [138].

6 Discrete forms of Abel inversion are an exception to this statement since
the measurement equations inherently presume the spatial structure of the
target. However, by the same token, the applicability of Abel inversion is
limited.

12

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

parameter, which controls the degree of regularization; and 0 is an
n × 1 vector of zeros. There are multiple formulations of Tikhonov
regularization that differ in terms of the choice of LTik. Zeroth-order
Tikhonov regularization employs an identity matrix, LTik = I, which
limits the magnitude of elements of g, ideally to suppress the effects
of noise. This approach has been usefully employed in medical tomog-
raphy [106,144] but is less advantageous in gas flow and combustion
imaging due to the limited number of projections. That is, A is typ-
ically rank deficient and I does not impute spatial characteristics to
the reconstructions (spatial relations are included via the off-diagonal
elements of LTik). Second-order Tikhonov regularization employs a
discrete Laplacian matrix, LTik = ∇2, which may be approximated for
a voxel basis as follows:

LTik,i,j =

1,
−n−1
i
0,

,

⎧
⎪
⎨
⎪
⎩

i = j
i ∼ j
otherwise

,

(43)

where ni is the number of voxels bordering the ith voxel (three for
corner voxels, four for edge voxels, five for surface voxels, and six for
interior voxels) and i ∼ j indicates that voxels i and j are neighbors.
This formulation does not yield a properly-scaled second derivative,
but Eq. (43) is easy to implement and the scale factor is subsumed
into the regularization parameter, γ. LTik may be constructed for an
alternative basis using the corresponding finite difference scheme. In
second-order Tikhonov regularization, the magnitude of LTikg is large
when there are many abrupt changes in g and small when spatial
gradients in g are smooth. When γ approaches zero, Eq. (42) becomes
equivalent to the least-squares functional (Eq. (28)), and when γ is
very large then gTik is the uniform solution that minimizes ‖Ag −
2 because ∇21 = 0, where 1 and 0 are n × 1 vectors of ones
2
p‖
and zeros. By design, γ is carefully selected to balance the influence
of the data and the Tikhonov matrix, resulting in a solution that
exhibits smooth, continuous variation, representative of scalar fields
in a laminar diffusion flame. Moreover, the use of the Laplacian is
justified by its appearance in the advection–diffusion equation, which
governs many simple transport phenomena and produces spatially-
smooth scalar fields. Second-order Tikhonov regularization has been
used accordingly to reconstruct numerous 3D gaseous flow and com-
bustion fields [87,145]. Since Tikhonov regularization yields a large,
inconsistent matrix equation in volumetric imaging, reconstructions are
frequently obtained by solving the augmented system in Eq. (42) with
a SIRT algorithm. This generally requires a large number of iterations,
e.g., on the order of 104 [87], which poses a significant computational
cost.

Total variation regularization is another technique that imputes

structure to g via a penalty term,

gTV = arg min
g

(
‖Ag − p‖

2
2 + γ ‖g‖TV

) .

(44)

Like Tikhonov regularization, the TV method features a tunable param-
eter, γ, but the Euclidean norm of LTik is replaced with the ‘‘TV norm’’
of g. For a continuous 3D function, g, defined in , the TV norm is

‖g‖TV

≡

|∇g| dx,

∫∫∫

(45)

where ∇ is the 3D gradient operator. This norm quantifies spatial
variation in g throughout . However, unlike the Euclidean norm of
∇2g, the TV norm does not penalize large gradients relative to multiple
small gradients that sum to the same overall size. As a result, TV
regularization is more amenable to abrupt variation in g than Tikhonov
regularization; this feature of TV regularization is particularly useful
when measuring a combustion process.
The discrete form of the TV norm is

‖g‖TV =

[(∇xg)◦2

(∇zg)◦2]◦1∕2
where ∇x, ∇y, ∇z are n × n finite difference matrices that act in the x-,
y-, and z-directions. Eq. (44) is nonlinear due to the TV norm and the

(∇yg)◦2

(46)

+

+

,

resulting expression can be solved by nonlinear programming methods,
e.g., González et al. [146] used a Gauss–Newton algorithm to conduct
2D electrical impedance tomography with TV regularization. However,
the dimension of g is considerably larger in volumetric applications,
leading to an exponential increase in the cost of reconstruction, which
can be prohibitive in the case of TV regularization. Cai et al. [85] com-
pared numerous reconstruction algorithms for the purpose of 3D flame
tomography, including a TV functional minimized by simulated an-
nealing. They reported that the TV algorithm produced the best recon-
structions but the simulated annealing solver required disproportional
computational effort. As an alternative, Behrooz et al. [147] derived
an iterative approximation to Eq. (44) by using the Euler–Lagrange
equation to differentiate the functional and equating the result to
zero. Starting from an initial guess, the TV solution is approached by
repeatedly solving
(

)

g(k+1) = ATp.

(47)

ATA + γ

‖
‖

∇2
g(k)‖

‖TV

This expression can be efficiently solved with a SIRT algorithm, and it
is usually convenient to adopt a Tikhonov-regularized solution as the
initial guess, as described in [87].

Selection of the regularization parameter is a crucial aspect of these
techniques. If γ is too small then the penalty term has no influence on
the solution. On the other hand, if γ is too large then the structure of g
is dominated by the penalty term. Both Tikhonov and TV regularization
generate a uniform solution when the regularization parameter is too
large. Numerous techniques have been devised to identify an appro-
priate value of γ; the two most common methods are phantom studies
and L-curve analysis. It should be noted that, while these techniques
approximately locate the ideal regularization parameter, neither can
truly optimize γ.

The simplest approach to parameter selection is to simulate mea-
surements using one or more known fields, which are called phantoms
and are indicated by gexact . Exact projections of the phantoms, pexact =
Agexact , are corrupted by noise and reconstructed by Tikhonov or TV
regularization using many values of γ. Note that it is important to
construct A using the experimental camera parameters. The recon-
structions, called gγ , are assessed using an error metric, typically the
normalized-Euclidean distance, ε2(gγ , gexact ), defined in Eq. (120). The
‘‘optimal’’ parameter, γ ∗, is the one that minimizes this error,

γ ∗ = arg min

γ

[ε2

(gγ , gexact

)] .

(48)

Ideally, phantoms should exhibit characteristics similar to those of
the experimental flow. Common practice is to reconstruct multiple
stochastic phantoms, e.g., produced by a large-eddy simulation, and
then perturb each measurement vector with random noise. In this case,
ε in Eq. (48) is replaced with the average error for the phantom set.

Another approach to parameter selection is a graphical method
called L-curve analysis, initially proposed by Lawson and Hanson [148]
and developed further by Hansen [149]. The key insight behind this
technique is that, while numerous fields satisfy Ag = p when A is
rank-deficient (which is usually the case), reconstructions computed
with a large value of γ normally produce a large residual. Therefore,
to the greatest extent possible, γ should be selected to simultaneously
minimize the measurement residuals and the penalty term. This trade-
off is visualized with an L-curve plot. L-curves are produced by first
generating reconstructions, gγ , for many values of γ that span a large
2
range. Next, the residual norm, ‖Agγ − p‖
2, is plotted against the
2
penalty norm, ‖LTikgγ ‖
2 or ‖gγ ‖TV, usually using a logarithmic scale.
Fig. 5 shows a sample L-curve from Liu et al. [150], who used L-curve
analysis to select the Tikhonov regularization parameter for a limited-
data 3D flame tomography experiment. This plot features two clear
regimes. In one, the residual norm is roughly constant and the penalty
norm is changing, in the other, the residual norm is rapidly increasing
while the penalty norm remains relatively unchanged, resulting in a

13

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 5. Sample L-curve for a volumetric reconstruction. Each point corresponds to
2
a unique value of γ. There are large measurement residuals (‖Agγ − p‖
2) at high
2
values of γ and large penalties (‖LTik gγ ‖
2) at low values. Intermediate values of the
regularization parameter produce a good trade-off between satisfying the projection
data and minimizing the penalty term, resulting in a spatially smooth solution in this
case. This optimum is approximated by the point of maximum curvature in the ‘‘L’’,
indicated above by a red star.
Source: Adapted from [150].

curve that resembles the letter ‘‘L’’. By hypothesis, the optimal trade-off
between satisfying the residual and penalty norms occurs at the point
of maximum curvature, i.e., the bend in the ‘‘L’’. The L-curve is defined
implicitly with respect to γ, and its curvature (and hence the point of
maximum curvature) may be calculated as a function of γ using partial
derivatives of the curve with respect to the residual and penalty norms
(see Goldman [151]). L-curves may be generated in an experimental
setting where the exact solution is not known. This is especially useful
in scenarios where realistic phantoms are unavailable (otherwise, a
phantom study is preferable).

Regularized volumetric reconstructions are typically improved by
masking [145,152,153]. Tikhonov and TV penalty terms are minimized
by spatially-smooth fields, which can produce artifacts in estimates of
the QoI. There is an inherent trade-off between satisfying the mea-
surement equations and penalty term, so unmasked Tikhonov or TV
reconstructions can be nonzero in regions of  which are visibly vacant.
This issue can be avoided by introducing a mask, which is created for
a set of projections in two steps:

1. Identify projections above a critical threshold, pthr , 

mask =
{i|pi⟩pthr }, where measurements below the threshold are at-
tributed to noise.

2. Identify elements of g (i.e., voxels) that must be zero based on

the projections: 

mask = {j|Ai,j ⟩0 ∧ i ∈ 

mask }.

The mask is applied by forming a new weight matrix, Amask , using all
i ∈ 
mask and j ∈ 
mask . A new projection vector, pmask , is formed for the
same projections, i ∈ 
mask . In addition, the Tikhonov matrix or finite
difference operators in the TV norm must be trimmed accordingly.
Solving the masked regularized system yields gmask, which includes all
of the potentially nonzero elements of g.

2.3.8. Bayesian formulation

Bayesian inference is a statistical technique that employs Bayes’
equation to combine measurements with explicit prior information in
order to estimate a set of unknown parameters, in this case p and g,
respectively [154,155]. The application of Bayesian inference to volu-
metric imaging is motivated by the ill-posed nature of reconstruction
and the lack of measurement information, due to the limited number
of projections [74]. The statistical formulation elucidates the role of
prior information in reconstructions and can be used to quantify uncer-
tainties and optimize the measurement system, i.e., the arrangement of
cameras/views. Moreover, this framework is compatible with numerous
other reconstruction methodologies, such as classical Tikhonov regu-
larization [156], compressed sensing [157], and deep learning-based
tomography [158,159], lending a statistical perspective to solutions
generated by these methods.

The basic concept of statistical imaging is introduced above in Sec-
tion 2.3.5, wherein the projection data was considered to be a random
vector, characterized by a likelihood function. Bayesian tomography
extends this treatment to all elements of the problem: the data, QoI,
and other model parameters are conceived of as random variables
that are characterized by a probability density function (PDF), denoted
P(⋅). PDFs stand in for one’s knowledge of the variables. Narrow
distributions represent a high-degree of confidence about the value of
a parameter, whereas wide distributions represent ignorance thereof.
Bayes’ equation employs likelihood, P(p|g), and prior, P
pr (g), PDFs to
compute a posterior PDF:
P(p|g) P
P(p)

∝ P(p|g) P

P(g|p) =

pr (g).

pr (g)

(49)

The likelihood density, introduced above, indicates the chance of ob-
serving the data p, assuming a hypothetical field g, and the prior
contains one’s knowledge about g that is independent of the current
measurement. For instance, g should be nonnegative and spatially-
smooth, it should exhibit a certain correlation length, etc. Lastly, once
a projection has been recorded, the evidence, P(p), is a constant that
serves to normalize the posterior,

P(p) = ∫

P(p|g) P

pr (g) dg.

(50)

The resulting posterior PDF describes the relative plausibility of can-
didate solutions, g, given the observed projections, p. Critically, this
evaluation is based on the models and assumptions used to construct
the likelihood and prior. The posterior PDF is considered a compre-
hensive solution to the inverse problem because the posterior carries
all information about the QoI, both prior and measured, and reflects
uncertainties produced by noise, errors in the measurement model,
and imperfect prior information. However, the dimension of P(g|p) is
very large, with one dimension per element of g, and it is convenient
to summarize the posterior using a singular estimate of g that is
accompanied by a measure of uncertainty. As a result, Bayesian re-
construction generally consists in calculating the maximum a posteriori
(MAP) estimate,

gMAP = arg max

g

]
[P(g|p)

= arg max

g

[P(p|g) P

] .

pr (g)

(51)

This is the most likely value of g given both the measurement infor-
mation and one’s prior knowledge. Reconstruction requires only the
likelihood and prior densities. Conveniently, the MAP estimate can be
computed without determining the evidence since it is constant for
any value of p. Unlike maximum likelihood estimation, which makes
indirect statements about the probability of g based solely on the
measurements implied by g and the noise model, Bayesian inference
makes direct statements about the probability of g by combining the
likelihood with a prior.

Bayesian reconstruction requires an error model for the likelihood
function, just like the MLEM algorithm. The stochastic measurement
model introduced in Eq. (34) (p = Ag + e) features an error vector,
e, which accounts for noise produced by the detector, fluctuating
background conditions, and calibration and discretization errors that
corrupt A, viz., model errors. The MLEM algorithm is based on a
Poisson likelihood, assuming a low photon count, minimal background
fluctuations, and an accurate imaging model. There is usually enough
signal to approximate the detector noise as Gaussian, excepting low-
light experiments that require an intensified camera, and discretization
errors (e.g., due to the assumption of a uniform gas field within each
voxel) can be substantial. Since the form of overall errors (noise +
model errors) is unknown, it is typical to model e as a centered Gaussian
error vector [86],

P(p|g) =

[

det

(
2πΓe

)]−1

[
−
exp

1
2

2
Le(p − Ag)‖
2
‖

‖
‖

]

.

(52)

In this expression, Γe is the error covariance matrix, which describes
the variance of and correlations between errors for each projection; Le

14

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

e , LT

e Le = Γ−1

is the matrix square root of Γ−1
e , which can be obtained
via Cholesky factorization; and det(⋅) is the determinant operator. For
simplicity, a further assumption is commonly made that noise is inde-
pendent and identically distributed, in which case Γe = σ2
e I, where σe is
the average standard deviation of noise and I is an m×m identity matrix.
The resulting likelihood is fully-determined by the sensitivity matrix
and an estimate of the variance of measurement noise. In principle, the
accuracy of reconstructions is a direct consequence of the accuracy of
models in the PDFs. In practice, the marginal utility of an exact noise
model compared to a properly-scaled multivariate Gaussian model
tends to be low, and Eq. (52) is an adequate approximation [86].

Specifying the prior PDF is the most critical aspect of Bayesian
inversion. Ideally, the prior should account for all of one’s knowledge
of g, independent of the current measurement. This knowledge can
be derived from physical principles, simulations, and previous mea-
surements. However, knowledge about the flame is often qualitative
in nature, and it is difficult to enumerate general features of g which
do not depend on the data. A typical starting point is the multivariate
Gaussian prior [160],

P

pr (g) =

[

det

(
2πΓpr

)]−1

[

exp

−

1
2

2
Lpr (g − μpr )‖
‖
2
‖

‖
‖
‖

]

.

(53)

where μpr and Γpr are the estimated mean and covariance of g. This
form can accommodate significant structure; for example, μpr and Γpr
can be determined from a CFD simulation, which can be relaxed using
mixture models [161] or generic structure functions [162]. In the
absence of detailed information about the imaged process, however,
μpr is a vector of zeros and Γpr is either a smoothing covariance based
on the Tikhonov matrix,7

pr = γ −2LT
Γ−1

TikLTik,

or a set of homogeneous autocorrelation functions,
) ,

(
−β−1di,j

Γpr,i,j = σ2

pr exp

(54)

(55)

where σpr is a measure of spatial uncertainty akin to γ, β is a correlation
length-scale, and di,j is the distance between the centroid of the ith and
jth basis functions. The Bayesian interpretation of Tikhonov regulariza-
tion can be employed to both select the regularization parameter and
quantify uncertainties about gMAP [86,164]. Bayesian implementations
of other classical techniques include the use of a TV prior [87,146,157]
and statistical model reduction [165,166].

Once the likelihood and prior have been formulated and a set of
projections has been recorded, the posterior PDF is determined via
Bayes’ equation, Eq. (49). In high-dimensional applications such as
volumetric imaging, the MAP estimate may be difficult to compute,
let alone obtaining a full representation of the posterior. However, the
posterior can be analytically determined when Gaussian likelihood and
prior PDFs are employed and the measurement model is linear, as is
the case with Eqs. (52) and (53) and A. Under these circumstances, the
posterior is known to be Gaussian [86],

P(g|p) =

[

det

(
2πΓpost

)]−1

[

exp

−

1
2

2
Lpost (g − μpost )‖
‖
2
‖

‖
‖
‖

]

,

The latter expression is equivalent to the MAP estimate by definition
since the Gaussian posterior is peaked about its mean. As a result, gMAP
(a.k.a. μpost ) can be obtained by calculating the least-squares solution
to an augmented matrix system. This can be seen by minimizing the
negative log-posterior, which is equivalent to MAP estimation:

gMAP = arg min
g

{

where

− log

[P(g|b)

]}

− log

]
[P(g|b)

∝

1
2

2
Le(p − Ag)‖
2 +
‖

‖
‖

1
2

‖
Lpr (g − μpr )‖
‖
‖
‖
‖

2

2

such that

gMAP = arg min
g

(

[LeA
]
‖
‖
‖
Lpr
‖
‖

g −

)

.

[ Lep
Lpr μpr

2
]‖
‖
‖
‖
2
‖

(59)

(60)

(61)

This minimization, often conducted with a SIRT algorithm, is substan-
tially similar to the Tikhonov minimization in Eq. (42), especially when
a Tikhonov smoothing prior is employed. However, the Bayesian ap-
proach has several advantages. For instance, projections are weighted
by the variance of errors and correlations between errors, advanced
knowledge about the mean and covariance of g can be included to
improve the accuracy of reconstructions, and the posterior covariance
matrix can be used to determine a credible interval about gMAP for UQ.
This last advantage requires the computation of Γpost via Eq. (57); while
this is incredibly expensive in volumetric tomography applications,
since n is large, it only needs to be computed once for a given experi-
mental configuration and target. Additional information about Bayesian
imaging techniques can be found in Kaipio and Somersalo [86].

2.3.9. Nonlinear optimization

The ART, MART, and SIRTs are essentially generic iterative methods
for solving a large, inconsistent system of linear equations. However,
augmenting Eq. (11) with a nonlinear penalty function, like the TV
norm of g or a complex Bayesian prior, leads to a nonlinear functional
that usually cannot be minimized by the aforementioned reconstruction
algorithms. Moreover, measurement scenarios that feature appreciable
in-scattering or self-absorption effects result in a highly nonlinear
model that can yield a nonconvex optimization problem. In these situa-
tions, nonlinear programming or a global optimization technique must
be used to reconstruct g from the projection data. This section provides
a brief overview of algorithms that seek to minimize an arbitrary,
nonlinear, and potentially nonconvex functional,

gnonlin = arg min
g

[F (g, p, ... )

] ,

(62)

where F depends on the QoI, the projections, the (potentially nonlin-
ear) measurement model, and any supplemental information used to
regularize the final estimate of g.

When F is convex, then reconstruction may proceed in an iterative
manner using a gradient-based solver. The functional is evaluated at an
initial guess and F is minimized by taking a series of ‘‘downhill’’ steps,

(56)

g(k+1) = g(k) + αks(k).

(63)

where μpost and Γpost are the posterior mean and covariance and Lpost
is the matrix square root of Γ−1
post . These elements are computed using
arguments from the likelihood and prior. The posterior covariance is

Γpost =

(
ATΓ−1

e A + Γ−1

pr

)−1

,

and the posterior mean is
[

μpost = Γpost

ATΓ−1
e

(p − Aμpr

)

+ Γ−1

pr μpr

]

.

(57)

(58)

Here, s(k)
is the step direction and αk is the step size. The latter
parameter controls the speed of descent: small steps result in a long
journey, but large steps can overshoot the minimum and even prevent
convergence. Many solvers employ a fixed step size (αk usually equals
1), but line search methods are occasionally implemented to speed-
up the process. This is generally done by computing F (g(k) + αks(k))
using several values of αk and then solving for the step size that
minimizes a curve fit of F (αk). Nocedal and Wright [167, Ch. 3] provide
a comprehensive overview of line search methods.

The simplest method for selecting a search direction is to identify

7 The rank of LTik is n − 1 so Γpr in Eq. (54) must be approximated in terms
Tik LTik [86,163]. However, since Γpost is of interest,

of the pseudoinverse of LT
not Γpr per se, there is generally no need to perform this calculation.

the direction of steepest descent. In this case,
s(k) = −∇F (g(k)) ,

(64)

15

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

which, when substituted into Eq. (63), amounts to the general form of
Eq. (41). Unfortunately, this approach can lead to slow convergence
and is unstable when F is too erratic. Newton’s direction is an alterna-
tive to steepest descent that is obtained by solving a quadratic fit to F
at g(k) and thus accounts for the local curvature of the functional,

s(k) = −

[ΔF

(g(k))]−1

∇F (g(k)) ,

(65)

where the matrix ΔF is the n × n Hessian of F evaluated at g(k).
Newton’s direction is naturally scaled, which means that αk = 1.
However, the quadratic fit is generally only valid near the minimum
of F . The Levenberg–Marquardt algorithm combines the method of
steepest descent with Newton’s method in order to provide a stable
initial search with a fast and robust minimization close to the bottom
of F . This algorithm features a dynamic step direction,

s(k) = −

[ΔF

(g(k))

+ γkI]−1

∇F (g(k)) ,

(66)

where I is an n × n identity matrix and the parameter γk controls the
transition from steepest descent to Newton’s method; γk takes a large
value at the outset of minimization and becomes progressively smaller
throughout the search.

Algorithms based on steepest descent [168–170] and Newton’s
method [146,171] have been employed for nonlinear reconstruction,
but techniques that incorporate Newton’s direction require the inver-
sion of an n × n matrix. This can be cost-prohibitive when the number
of voxels is large: in effect, each step given by Eq. (65) or (66) needs
to be computed using an ART or SIRT algorithm. Steepest descent is
thus a common first choice for nonlinear reconstruction in volumetric
imaging. This and other gradient-based algorithms are widely avail-
able in environments such as MATLAB (e.g., lsqnonlin, fminunc,
fmincon) and Python (e.g., scipy.optimize.least_squares).
A comprehensive overview of nonlinear optimization algorithms can be
found in Numerical Recipes [172].

Sometimes the functional F is nonconvex, meaning that it con-
tains multiple local minima. In this scenario, a gradient-based solver
will converge upon a local minimum, but there is no guarantee that
any given algorithm will identify the global minimum of F . At the
outset, one must determine whether F is convex or not, which can
be challenging due to the high dimension of g. One approach is to
assume that F is convex and then, starting from a series of random
initial vectors, g(0), one should minimize F by gradient descent. If these
optimizations yield distinct minima, then the best course of action is
to adopt a metaheuristic approach. Metaheuristic algorithms employ
a random search strategy to approximately locate the global optimum
of an arbitrary function. Randomness enables the algorithm to avoid
getting trapped in shallow minima, and the search is tailored in a
heuristic manner to provide a good trade-off between the thoroughness
and efficiency with which the search space is explored. Metaheuristic
algorithms are often inspired by natural processes, such as evolutionary
adaptation in the case of genetic algorithms and phase transitions in
the case of simulated annealing, both of which have been used for
volumetric imaging.8

Genetic algorithms mimic reproduction and natural selection in
order to optimize a ‘‘fitness function’’. The QoI, g, is conceived of as
an individual genotype, such that the individual coefficients, gj , stand
in for a chromosome, and F (g) represents the fitness of a specimen.
A population of individuals is initialized, usually at random, and their
fitness is evaluated in terms of F . A subset of the fittest candidates is
selected to reproduce and form the next generation. This new genera-
tion is once again evaluated using F , the fittest offspring are selected
to reproduce yet another generation, and the process is repeated until

8 Genetic algorithms and simulated annealing have been found to be more
effective at tomographic reconstruction than other derivative-free techniques
such as random search algorithms and Nelder–Mead optimization [173].

a satisfactory level of fitness has been achieved. Ultimately, the vector
g that yields the lowest value of F is adopted as the reconstruction.

Reproduction is key to the performance of a genetic algorithm,
and there are several methods for generating new genotypes. Most
genetic algorithms feature a combination of reproduction mechanics,
including the mutation, crossover, and direct inheritance of chromo-
somes. Mutations involve random perturbations to a randomly selected
subset of coefficients, {gj }; mutations should be confined to a plausible
range of values and can be modified to account for the value of
neighboring coefficients, e.g., to promote spatial smoothness. Genetic
crossover involves merging random subsets of the genotype, g, of two or
more fit ‘‘parent’’ individuals from the current generation to produce a
new ‘‘offspring’’ individual. Finally, direct inheritance passes an exact
copy of the fittest specimen in the current generation on to the next
generation. Many aspects of a genetic algorithm can be customized,
such as the population size, the number and range of mutations as
well as correlations between them, interactions between mutations and
crossover events, and so on. However, it can be difficult to establish
the ultimate effect of these choices or to verify the robustness of an
extensively tailored algorithm. Evolutionary reconstruction algorithms
have been developed for optical [174], electrical impedance [175], X-
ray [174,176], and recently chemiluminescence [88] tomography. A
comprehensive tutorial on genetic algorithms can be found in [177].

Simulated annealing is another metaheuristic technique that has
been adapted for tomography. Loosely speaking, annealing is a process
in which a solid material is initially heated to a high temperature such
that crystalline structures in the sample can be modified or rearranged
by thermally-induced fluctuations in the position of molecules. The
sample is then cooled in a controlled manner, resulting in smaller
and smaller fluctuations, and the crystalline structures coalesce into an
arrangement that (ideally) minimizes the energy associated with the
material’s overall molecular configuration. In simulated annealing, g is
considered to be the material structure and the functional F returns the
‘‘free energy’’ of g. The procedure is initialized with a structure of one’s
choice, g(0), which is randomly perturbed to form a candidate structure,
g′. This candidate is accepted with probability

P(g′

|g(k))

{

= 1 − min

1, exp

[ F (g) − F (g′)
Tk

]}

,

(67)

where the ‘‘temperature’’ Tk is a heuristic parameter that decreases over
the course of the simulation (as in physical annealing). At each step of
the algorithm, P is compared to a random number, t ∼  [0, 1], which
is used to determine the next value of g,
t ≤ P(g′
t > P(g′

{ g′,
g(k),

g(k+1) =

(68)

|g(k))
|g(k)).

In other words, the candidate vector will always be accepted when the
energy of g′ is lower than that of g(k). However, even when F (g′) is
greater than F (g(k)), there is a chance that the candidate will still be
accepted. This chance depends on the difference in free energy as well
as the current temperature. The search begins in an erratic, exploratory
manner and then transitions to a monotonic progression towards a
local minimum. Generating candidate vectors and controlling the cool-
ing process are heuristic aspects of simulated annealing that must be
carefully tuned. The algorithm of Corana et al. [178] was adapted
by Cai et al. for absorption [173,179] and chemiluminescence [85]
tomography; there are also numerous examples of SA-based electrical
impedance tomography, e.g. [180,181], among other modalities.

Genetic and simulated annealing algorithms are highly sensitive to
the chosen heuristics and computationally costly compared to gradient-
based solvers. It thus bears repeating that metaheuristic optimization is
only appropriate when the functional is clearly nonconvex.

16

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

as well as the corresponding projections, ptrain = Agtrain, which are nor-
mally simulated using the imaging model. Reconstructions are rapidly
obtained by feeding a set of experimental projection data to a network
that has been trained on phantoms; the trained model can reconstruct
g from p in milliseconds to seconds instead of minutes to hours, which
is the norm for 3D reconstruction algorithms [186]. The robustness of
deep learning tomography depends heavily upon the network archi-
tecture, the loss function, and most importantly upon the quality and
comprehensiveness of the training set.

To date, three different methods have been used to build a training
set for supervised DNN tomography of a gas flow or flame. These
methods involve:

1. extracting phantoms from a series of CFD simulations [187,188],
2. using random Gaussian fields as phantoms [189], and
3. reconstructing experimental projection data with a traditional
algorithm, such as the ART, and then adopting those reconstruc-
tions as the training phantoms [186,190,191].

The latter approach is motivated by the speed of DNN reconstructions,
e.g., previous reconstructions of a target could be used to train a
DNN that would be employed for subsequent reconstructions. However,
establishing the validity of this model for other targets, or the gen-
eral validity of a CFD- or Gaussian-trained DNN, is an open research
area [191].

Regardless of the genesis of the phantoms, the simulated projec-
tions, ptrain, are usually corrupted with artificial noise to make the
model more robust. The demonstrations of DNN tomography reported
in [186–191] all used a convolutional neural network (CNN), which
is a DNN that contains convolutional and pooling layers for feature
extraction (see [192] for an overview of CNNs). CNNs are modeled
on the structure of the visual cortex and perform particularly well in
image processing applications, which motivates their use in volumet-
ric imaging. Crucially, these networks feature a highly customizable
architecture (vis-à-vis the number and size of filters, the number and ar-
rangement of layers, and so on), which can affect the model’s ability to
represent key features and generalize to novel inputs. The effects of the
model’s architecture on reconstruction accuracy and generalizability
have yet to be studied.

Neural networks trained on an appropriate set of phantoms can
produce accurate reconstructions. However, it is important to empha-
size that supervised DNN tomography presumes that the training data
accurately captures the target physics. This requirement can limit the
utility of supervised deep learning for volumetric imaging if the purpose
of an experiment is to supply benchmarking data, i.e., because the re-
constructions do not provide independent validation of the simulation.
Furthermore, DNNs trained on explicit functions are known to fail on
inputs that lie outside the training envelope [193], and ‘‘adversarial’’
inputs that are nearly identical to labeled training data can be tailored
to produce arbitrary outputs [194]. These and other failure modes
represent a challenge to the use of supervised training for tomography.
Physics-informed neural networks (PINNs) are an emerging class
of DNNs designed for scientific machine learning that could bypass
many of the pitfalls discussed in this section [195,196]. Instead of
the complex CNN architecture pictured in Fig. 6, PINNs comprise a
simple, fully-connected, feed-forward DNN. In the fluid measurement
context, the input layer consists of spatio-temporal locations, (x, y, z, t),
and the output layer produces the relevant flow fields at each in-
put coordinate, e.g., (u, v, w, ρ, p) and perhaps a scalar concentration,
temperature, and the like. The PINN utilizes automatic differentia-
tion to compute partial derivatives of the outputs with respect to
the inputs. These values can then be used to evaluate the governing
partial differential equations, e.g., Navier–Stokes, advection–diffusion,
reaction-based sinks and sources, etc. In effect, the PINN is a functional
representation of the flow that maps locations in space and time to
all the salient flow field variables at that position. A ‘‘physics loss’’
is obtained by aggregating residuals from the governing equations

Fig. 6. Schematic of a DNN including a supervised training and testing processes.
Training projection data (ptrain) are fed to the network and mapped to outputs, which
are compared to gtrain, i.e., the known 3D field corresponding to ptrain = Agtrain. Losses
are used to tune the network’s weights and biases. Reconstructions are conducted using
experimental projection data.
Source: Adapted from [184].

2.3.10. Deep learning algorithms

Deep learning refers to machine learning methods that employ an
artificial neural network that contains multiple hidden layers, called a
deep neural network (DNN), to complete a detection, classification, or
signal inversion task [182]. DNNs are widely used for image classifica-
tion and computational photography; moreover, deep learning has been
successfully employed for medical tomography and magnetic resonance
imaging [183]. Deep learning models exhibit remarkable performance
in those areas and are thus seen as an attractive tool for reconstructing
flames. However, the use of DNNs for volumetric reconstruction is a
recent innovation and, for the most part, existing methods are only
suitable in situations where a valid training set can be constructed.

Reconstruction algorithms based on deep learning are quite distinct
from the algorithms discussed above. Fig. 6 depicts the architecture of
a typical DNN. The network consists of nodes that mimic the function
of a neuron: inputs to a node are fed into a nonlinear activation
function that controls the node’s output, which is then passed on to
other nodes or to the end user. Nodes are formed into layers; input
and output layers are connected by a series of ‘‘hidden layers’’; and the
network’s behavior is determined by the connections between nodes,
the weights assigned to each node, and the biases in the activation
functions. A fully-connected network is typically initialized with con-
nections between each node in adjacent layers and random weights and
biases, although other architectures may be employed for tomography.
Training consists in pruning the network (eliminating connections)
and adjusting its weights and biases. This is often done using sample
inputs that correspond to a known output, which is called supervised
learning or training. In supervised learning, the DNN is fed a sample
input, the network’s output is then compared to a known reference
using a loss function, and a backpropagation algorithm is employed to
update the network parameters. This procedure is repeated until the
loss function has converged to a minimum value. There are several
well-established platforms for creating and training a DNN. Notable
examples include TensorFlow and PyTorch, and Bengio et al. [185]
provide an authoritative introduction to deep learning methods.

In general, the goal of deep learning is to obtain a DNN which
approximates the implicit, unknown function that relates a class of
inputs to the desired outputs. In volumetric imaging, the input layer
contains m nodes that each corresponds to one projection, pi, and
the output layer consists of n nodes and returns the reconstruction,
g, as shown in Fig. 6. Most current demonstrations of DNN-based
tomography are predicated upon a training set that is made up of
phantoms, i.e., sample 3D fields, gtrain, that are available to the user,

17

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

throughout the measurement domain; minimizing this loss ensures that
flow fields from the PINN obey physical constraints. This loss may
be combined with a ‘‘data loss’’ that compares the PINN’s output to
experimental projections using the measurement model, as proposed
by Molnar and Grauer [159]. PINN-based tomography is conducted
by simultaneously minimizing the physics and data losses, resulting
in flow fields that approximately satisfy both the measurements and
governing equations. In other words, there is no need for training data
from a CFD simulation or previous reconstructions. Cai et al. [197]
used a PINN to post-process temperature fields produced by a BOST
sensor, and other groups have used PINNs to post-process blood flow
fields measured by magnetic resonance imaging [198,199].9 However,
direct reconstruction of experimental data using a PINN has yet to be
demonstrated.

As adversarial examples and other such effects are better under-
stood, and as new deep learning methods are devised, DNN-based
tomography is likely to become an essential tool for volumetric imaging
of combustion. In particular, the use of PINNs and other scientific ma-
chine learning techniques for tomographic reconstruction could have a
transformative effect.

Fig. 7. Illustration of thin ray, cylindrical ray and conical ray models with a voxel
basis. Individual sensitivities, Ai,j , represent the intersection of one ray with one voxel.

2. Tracing light emitted within the reconstruction volume to the

cameras.

The first approach is said to be pixel- or ray-centric while the latter is
voxel-centric.

3. Imaging models

3.1. Ray-centric models

Emission tomography requires a forward model of the image forma-
tion process which is ultimately inverted to estimate the field of interest
from a set of projection data. The imaging model is implicit in analytical
reconstruction algorithms, which presume the shape of rays and their
relative trajectory through the measurement region. For instance, the
discrete Radon transform assumes a set of infinitely thin parallel rays
with equal transverse and angular spacing, i.e., regular rotations of
the projections shown in Fig. 2. This model is built into most FBP
algorithms [89,90], although there are also analytical techniques for
inverting cone beam projections [200].10 Similarly, the forward and
inverse Abel transforms are premised upon parallel 1D rays, but the
flame is assumed to be axisymmetric so there is no need for multiple
vantage points. While thin rays are ubiquitous in analytical reconstruc-
tion algorithms, they are unrealistic in many contexts, especially in
gas flow and combustion imaging. It is difficult to devise analytical
techniques that account for the effects of a finite camera aperture,
diffraction, radial lens distortions, and the transverse distortions pro-
duced by a lens mount. Neglecting these effects can lead to significant
reconstruction errors [98], which is a considerable disadvantage of
analytical reconstruction algorithms.

Algebraic tomography features a discrete imaging model that con-
sists of the matrix A in Eq. (11). This approach is much more flexible
than analytical methods, and A can be constructed to accurately ap-
proximate a wide range of imaging devices. The matrix product Ag =
p could represent the emission, absorption, or refraction of light in
the probe volume, in terms of the basis used to represent the flame,
accounting for the path and shape of each ray. Imaging light that is
emitted spontaneously or as a result of laser-based stimulation is of
particular importance in combustion tomography. In this context, there
are essentially two approaches to building A.

1. Directly modeling the ray or bundle of rays accepted by a pixel

and calculating the interaction of said rays with the basis.

9 When a PINN is used for post-processing, the data loss compares the
PINN’s output to a previously reconstructed field. However, directly recon-
structing the flow by embedding the imaging model into the loss function
yields superior estimates [159]

10 Analytical cone beam models are distinct from algebraic cone rays,
discussed in Section 3.1.3. Analytical cone beams form a pyramid of light
emanating from a point onto a rectangular sensor, reminiscent of X-ray
scanners. By contrast, algebraic cone rays comprise a double conical volume
produced by a finite aperture and short working distance, which corresponds
to camera-based imaging of emissions from the flame.

Fig. 7 depicts a schematic of three ray models and a voxel basis.
Rays are conceived of as 1D lines (‘‘thin rays’’), cylindrical volumes
(‘‘cylinder rays’’), or conical volumes (‘‘cone rays’’). A projection pro-
duced by the emission of light is accumulated along a ray, formally
defined by the path integral in Eq. (6), which applies to thin rays, or
along the bundle of rays within a volume per Eq. (7), which applies
to cylinder and cone rays. Regardless of the ray shape, elements of the
sensitivity matrix represent the intersection of one ray with one basis
function. Using the linear approximation in Eq. (10), Ai,j describes the
contribution of the jth solution component, gj , to the ith projection,
pi; this quantity is given by the integral in Eq. (6) or (7), depending
on the chosen ray model, and the integral is carried out over the
corresponding basis function. In other words, using the framework
described in Section 2.1, elements of the imaging model matrix are

Ai,j = Csys ∫

lout

lin

[Ψ −1(ui, l)]

φj

dl

for thin rays and

(69)

lout

[Ψ −1(u, l)

] Ωi(l)
4π

∫

φj

Ai,j = Csys ∫∫i
for cylinder and cone rays. In most cases, Ωi is assumed to be constant
throughout the volume and is grouped into Csys in Eq. (70).

dl du.

(70)

lin

The sensitivity matrix is sparse since any given ray only traverses
a small portion of voxels (on the order of n1∕3 in a cubic domain).
Therefore, it is desirable to identify elements of A that may be nonzero
by calculating the minimum distance between each ray and voxel
center, denoted dmin, and selecting ray–voxel pairs for which dmin is
below an appropriate cutoff distance. The minimum distance between
a ray that originates at the camera position, c, and travels along the
unit vector ̂r and a voxel that is centered at v is

√

dmin =

‖v − c‖

[

(v − c)T ̂r]2.

2
2 −

(71)

This operation can be vectorized in MATLAB or NumPy to simultane-
ously compute dmin from one ray to every voxel or vice versa. Camera
positions and ray directions are determined by camera calibration,
which is discussed in the next section. Each pixel/sensor position, u,
has a unique ray vector that may be obtained via the back-projection
function, ̂r = Ψ −1(u, 1), per Eq. (116), and the appropriate cutoff
distance depends on the chosen ray model, as described below.

Thin, cylindrical, and conical rays differ in terms of their accuracy
and cost of implementation. In the context of volumetric emission, thin
rays are the least accurate and should only be used to obtain a rough

18

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

first reconstruction or in scenarios where computational resources are
limited. Cylinder rays are appropriate when the whole measurement
region is in focus, and cone rays are needed when out-of-focus effects
become significant. However, where possible, a voxel-centric technique
should be used instead of a ray-centric method to minimize model er-
rors. That is, voxel-centric methods constitute the most realistic model
of light collection from a volumetric emission field, and model accuracy
is closely related to reconstruction accuracy [86,201].

3.1.1. Thin rays

In the thin ray approach, the projected volume integral recorded
by a pixel is simplified as a line. Consequently, for a voxel basis, Ai,j
is the chord length of the ith LoS inside the jth voxel. Exact ray–
cube intersections are relatively quick to compute. For instance, exact
calculations of Eq. (69) can be made with a ray–box algorithm [202].
While this method is inexpensive, it is still usually worthwhile to limit
the number of intersection tests. For instance, Ai,j is necessarily zero
in cases where dmin exceeds 31∕3lvox, where lvox is the side length of a
voxel. The thin ray model may be further simplified by treating voxels
as spheres and calculating ray–sphere intersections for each element
of A (see [203] for an efficient algorithm). Typically, the ‘‘voxel ra-
dius’’ is selected to conserve the voxel’s volume, rvox = lvox(3∕4π)1∕3.
Weights may be normalized by lvox to stabilize the inversion of A [204],
but doing so results in reconstructions having arbitrary units. This is
generally acceptable since most quantitative evaluations of volumetric
reconstructions are based on a relative signal or comparison between
signals over time, e.g., to estimate a Boltzmann fraction or track a
surface, respectively.

Thin rays can be used when the basis contains large voxels, although
large voxels introduce discretization errors that can corrupt reconstruc-
tions. Indeed, ray/sphere sensitivities are often used in TPIV [118].
However, the thin ray approximation breaks down when the projected
area of voxels onto the sensor approaches the size of a pixel. That
is, a very small voxel can fall between two thin rays originating at
neighboring pixels, which results in a non-physical insensitivity to light
emitted or scattered in that region.

3.1.2. Cylinder rays

Cylinder rays have a finite cross section. This accounts for the fact
that pixels do not represent points on the sensor but rather an area
on the sensor, which records light from a volumetric bundle of rays.
The use of a constant cross section is valid if the region of interest
is contained within the camera’s depth of field, discussed further in
Section 3.1.3, and a circular profile is employed to streamline the cal-
culation of cylinder–voxel intersections. Typically, the cylinder radius
is sized to preserve the pixel area, rpix = lpix∕π1∕2, where lpix is the
side length of a pixel. A minimum distance test can be used to identify
possible cylinder–voxel collisions: sensitivities are calculated for voxels
that satisfy

dmin

≤ rpix + 31∕2lvox,

(72)

where dmin is given by Eq. (71) and 31∕2lvox is the distance from the
centroid to the corner of a voxel. Note that this criterion is equivalent
to the thin ray collision test when rpix = 0.

When Ωi∕4π is assumed into Csys, exact cylinder ray sensitivities
are given by the volume of intersection. It is not practical to derive
an analytical expression for this volume, but it can be accurately
estimated by Monte Carlo simulation. To do so, a set of random points
that lie inside a voxel is generated by uniform sampling. Next, the
subset of these points that lie inside the cylinder is identified using a
modified form of Eq. (71) in which dmin is calculated using the random
points, themselves, instead of the voxel center, v. Points that fall in the
≤ rpix. Finally, Ai,j is given by the
intersection volume must satisfy dmin
fraction of points located inside the cylinder multiplied by the voxel
volume, l3

vox.

Populating the sensitivity matrix by Monte Carlo sampling is compu-
tationally expensive and there are three relatively-efficient alternatives.
First, Floyd [100] developed a ‘‘subvoxel’’ technique in which vox-
els that pass the initial collision test are divided into smaller cubes,
i.e., subvoxels. The collision test is repeated for the subvoxels, and the
overall sensitivity for a given ray and voxel is the ratio of subvoxels
transected by that ray to the total number of subvoxels. Floyd [100]
found that a 10 × 10 × 10 array of subvoxels yields an accurate
approximation to the intersection volume calculated by Monte Carlo
sampling. This method is akin to the Riemann sum technique for
estimating cone beam sensitivities in X-ray tomography [205].

The second approach, reported by Thomas et al. [204], is conducted
using ‘‘subpixels’’ instead of subvoxels. In this technique, each pixel
is divided into smaller pixels and then cylinder–voxel intersections
are determined for each subpixel using the aforementioned minimum
distance test. The sensitivity Ai,j is the ratio of subpixel intersections to
total subpixels for the ith pixel and jth voxel.

Lastly, Thomas et al. [204] developed an imaging model based
on cylinder-sphere sensitivities. Spherical ‘‘voxels’’ are used to simplify
the calculation since the resulting intersection volume is invariant to
the ray’s angle of approach. Lamarche and Leroy [206] derived an
analytical expression for cylinder–sphere intersections using elliptical
integrals, and Thomas et al. [204] utilized this work to devise the
following sensitivity:

Ai,j = 2

( rpix
dmin

)

−

rpix
dmin

⎡
acos
⎢
⎢
⎣

√

1 −

( rpix
dmin

)2⎤
⎥
⎥
⎦

,

(73)

where dmin is given by Eq. (71). Several proprietary codes use cylinder–
sphere intersections to estimate the elements of A on the fly rather
than storing the full matrix [118]. This is done by determining which
pixels ‘‘see’’ the current voxel and then retrieving the corresponding
intersections from a look-up table, which is parameterized by dmin,
rpix, and rvox. Pixels can be identified using the projection function
obtained by calibration (see Eq. (83)), i.e., using the four pixels that
surround Ψ (v). However, this strategy is only beneficial for sparse
fields, such as those encountered in TPIV, and does not speed-up
emission tomography reconstructions.

3.1.3. Cone rays

Cylinder rays have a constant cross section within the measurement
volume. In reality, the bundle of rays that is accepted by a pixel does
not have a constant cross section for two reasons. First, an ideal thin
lens focuses rays from an object plane onto the sensor (i.e., not rays
from a volume), and objects on either side of this plane are out of focus.
Second, pixels have a finite area and the aperture accepts light from a
range of angles so the set of rays incident on a pixel cannot be perfectly
focused by a single lens. The result is a limited region within which the
effects of blur are minimal, which is called the camera’s depth of field
and is illustrated in Fig. 8(a). Consequently, cameras must be positioned
far away from the target and the aperture should be closed as much
as possible to ensure that light from the volume remains in focus.
Unfortunately, this is not always possible. Recording sufficient light to
reconstruct a flame can be challenging, especially when the target is
unsteady or the spectral width of the signal is narrow. Short exposure
times are required to prevent blur for instantaneous or time-resolved
imaging and narrowband signals are produced by bandwidth-limited
emissions, illumination, or filtering. These effects can starve a camera
of light. Therefore, it may be necessary to place the cameras close to the
target, widen the apertures, or both. Conical rays, depicted in Fig. 8(b),
were introduced to account for the non-ideal effects associated with a
large measurement volume, large aperture, small working distance, or
combinations thereof.

Imaging of volumetric emissions can be modeled by a classical ray
tracing technique, provided that the camera’s aperture is much larger
than the wavelength of light and the angle of light incident on the

19

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 8. Ray tracing diagram that illustrates (a) the depth of field effect and (b) double-conical rays within the region of interest; dobj is the distance from the lens to the object
plane, dimg is the distance from the lens to the image plane, f is the lens focal length and DCoC is the circle of confusion diameter.

sensor is small [207]. By and large, these assumptions are reasonable
in volumetric imaging of combustion processes. The thin lens equation
relates the position of light from an object plane, dobj, to its ultimate
location on the image plane/camera sensor, dimg, in terms of the lens’
focal length, f ,

1
f

=

1
dobj

+

1
dimg

.

(74)

In general, dobj and dimg are empirical parameters whereas f is a known
property of the lens; dobj is determined by traversing a target object,
such as the USAF resolution chart in Fig. 17, until it is in focus, and
dimg may be inferred via Eq. (74). By assumption, the lens is co-located
with the aperture. Light emitted at a point emanates outward in all
directions, forming a spherical wave, and the conical shape represents
the portion of light that passes through a circular aperture. The camera
is focused on the object plane and, ideally, light emitted from this
plane forms a perfect image on the camera’s sensor. Ideal rays are
illustrated by the dashed lines in Fig. 8(a). However, a point source
of light positioned in front of the object plane is focused behind the
image plane and vice versa, shown as solid lines in Fig. 8(a). The latter
cases result in a circular region of illumination, called the circle of
confusion. Loosely speaking, points in the volume remain in focus when
this circle is smaller than a pixel, and objects that satisfy this condition
are said to be located within the camera’s depth of field. A point source
located outside a camera’s depth of field projects light onto multiple
pixels, so objects that are too far from the camera, or too near to it,
appear blurred, which is known as the bokeh effect. Hence, when the
measurement volume is not contained within a camera’s depth of field,
the imaging model must account for blurring.

Conical ray tracing was first employed for emission tomography by
Walsh et al. [98], who used it to assess the errors associated with Abel
inversion. The technique was subsequently employed by Floyd [100]
to account for non-ideal imaging effects in volumetric reconstruction.
Fig. 8(b) depicts a cross section of the conical volume of light from a
point in  that is accepted by a pixel. As with cylindrical rays, the cone
ray model is based on Eq. (70), where the volume integral corresponds
to a conical region. Cone–voxel intersections are approximated using
a sequence of cylinder–voxel intersections since the cross section of
a ray is roughly constant within a voxel. Therefore, the Monte Carlo,
subvoxel, and subpixel methods described in Section 3.1.2 can be em-
ployed to calculate intersection volumes along a conical ray. However,
cone–voxel sensitivities must be adjusted based on the fraction of a
pixel that is covered by the ray at each intersection, per the illustration
in Fig. 9. Doing so implicitly accounts for the dynamic solid angle of
collection, Ωi, along a ray. Cone rays are modeled by the following
expression,

Fig. 9. Diagram of possible intersection areas formed between a circular pixel and blur
circle whose centers are separated by a distance dmin.

and Aint is the area intersected by the pixel and ray projected onto the
sensor. In other words, Aint ∕Apix is the fraction of light emitted within
the cone ray–voxel intersection that is recorded by a pixel.

The first step to calculate Ai,j is to determine the projected radius
of a ray at a given location, which is illustrated in Fig. 8(a). Per the
derivation in [100, Ch. 5], the projected radius for a given voxel is

rproj =

f#
2

|
vox − d−1
d−1
|
obj
|
(

f −1 − d−1
obj

|
|
|
) ,

(76)

where dvox = (v − c)T ̂r is the working distance along the ray at a voxel
centered at v. This expression is convenient since it only requires the
focal length, focal ratio, and distance to the object plane, which is
determined experimentally. The intersection volume, Vi,j , is computed
for a cylindrical ray of radius rproj using one of the techniques described
in the previous section. Since this radius changes throughout the probe
volume, the cylinder collision test described in Section 3.1.2 should be
conducted using the largest feasible radius, given by Eq. (76) at either
the minimum or maximum working distance in the reconstruction
domain. The next step is to determine the fraction of light that is
accepted by a pixel, as illustrated in Fig. 9. Floyd [100] presented an
accurate linear approximation to this fraction,

Aint
Apix

=

1,
rproj−rpix−dmin
2rpix

⎧
⎪
⎪
⎨
⎪
⎪
⎩

0,

,

≤ rproj − rpix

dmin
rproj − rpix < dmin < rproj + rpix
dmin

≥ rproj + rpix

.

(77)

In summary, implementing cone rays is almost identical to imple-
menting cylinder rays except that the radius changes along the ray,
per Eq. (76), and the sensitivity must be adjusted to account for the
dynamic ray radius, per Eq. (77).

Ai,j = Vi,j

Aint
Apix

(75)

3.2. Voxel-centric models

where Vi,j
(essentially a cylinder ray sensitivity), Apix = l2

is the volume intersected by the ith ray and jth voxel
pix is the pixel area,

Ray-based imaging models approximate a path or volume integral
along each ray through the use of ray–voxel intersections that are

20

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 10. Illustration of the VSF (voxel spread function) concept. Uniform illumination
from a voxel is cast onto each camera’s sensor using its projection function (see Fig. 11).
The resulting distribution of light on a single sensor is called a VSF. VSFs produced by
the jth voxel are arranged into a column vector, A∗,j , and the imaging model consists
of VSFs from all the voxels on all the camera sensors.

calculated with thin lines, cylinders, or cones. This ray-centric approach
can incorporate key non-ideal imaging effects including

1. non-parallel rays through the use of arbitrary ray vectors,
2. volumetric intersections via cylindrical rays, and
3. blur by adopting a conical ray shape.

However, while thin ray sensitivities are easy to calculate, 1D projec-
tions are not representative of emission imaging, which is inherently
volumetric, and the use of thin rays can lead to large reconstruction
errors. Cylinder and cone rays are much more realistic, but these mod-
els still require coarse simplifications to the ray and voxel geometries
in order to populate the sensitivity matrix in a timely fashion. For
instance, while CCD and CMOS pixels are generally square, cylinder
and cone rays have a circular cross section, and overlapping spherical
‘‘voxels’’ are routinely used to speed-up the calculation of ray–voxel
sensitivities. These shortcomings motivate a voxel-centric technique
that dispenses with idealized ray shapes and non-cubic voxels. Instead,
ray paths in Eq. (70) are implicitly tracked using a camera’s projection
function.

A voxel spread functions (VSF) can be used to model the response of
an arbitrary imaging system to volumetric emissions from an arbitrary
basis (although a voxel basis is still employed in most instances, hence
‘‘VSF’’) [85,208]. Taking this approach, columns of A represent the
response of a camera (or set of cameras) to luminescence or incan-
descence from a single voxel, which is analogous to the traditional
concept of a point spread function (PSF). This is illustrated in Fig. 10,
where light from a single voxel is cast onto a camera sensor. Assuming
a unit value of radiance from the voxel, the brightness at each pixel in
the imaging system represents a local sensitivity, Ai,j , and the images
produced by one voxel form a column of A that corresponds to the
activated voxel. Following this logic, the sensitivity matrix is simply
a series of VSFs, with one VSF per camera for each voxel in the
measurement domain. The same technique is used in TPIV, where VSFs
are called optical transfer functions [209,210].

Yu et al. [211] proposed a method to calculate VSFs by Monte Carlo
simulation. First, projection functions are needed to map 3D points
in the domain to 2D sensor locations. Given a projection function for
each camera, 3D points in a voxel, denoted x, are chosen at random by
uniform sampling and then mapped to each sensor, u = Ψ (x). It should
be noted that voxels can be replaced with any arbitrary basis function
so long as the points are sampled in proportion to φj . The sensors are
divided into pixels, as shown in Fig. 11, and to a first approximation
the VSF at a pixel is simply the fraction of points from a given voxel
received by that pixel.

Assigning each point to a single pixel with a constant weighting
assumes that all points originate within the camera’s depth of field,

21

Fig. 11. A camera sensor ‘‘illuminated by a voxel’’, i.e., populated with points produced
by random sampling. World points are uniformly sampled within a voxel, x, and then
converted to sensor points via the projection function, u = Ψ (x). The sensitivity Ai,j is
given by the fraction of points generated in the jth voxel that land in the ith pixel.
Source: Adapted from Yu et al. [211].

which is often not the case. Therefore, in order to incorporate Ωi into
the VSF model, Yu et al. [211] calculated the diameter of the circle
of confusion for each point. This can be done using Eq. (76) only
substituting the random points, x(i), for v to determine dvox. When
the projected ray is sufficiently large (for instance, rproj > rpix), an
alternative procedure must be used to calculate the VSF. In the work
of Yu et al. [211], the light emitted at a point was assumed to cover
all the pixels whose center fell within the ray’s projected area. In other
words, if the distance from u to a pixel center was less than rproj, the
point was deemed to contribute to that pixel in the VSF. Ideally, this
contribution should be divided by the number of pixels covered by
the point, resulting in a ‘‘partial contribution’’. Yu et al. [211] set the
final VSF to the ratio of points that satisfied this condition to the total
number of points generated within a voxel.

Although it comes at an appreciable computational cost, the VSF
method provides the most accurate forward model for tomography.
As a note of caution, in absence of further calibration, reconstructions
computed using a VSF imaging model will have an arbitrary scale.
A controlled experiment is required to estimate Csys for quantitative
reconstructions. Devising a VSF calibration workflow for this purpose
is an area of active research. Zhou et al. [212] proposed a procedure in
which images produced by controlled blackbody and LED sources were
used determine the nonlinearity and nonuniformity of a camera sensor.
This method represents a step towards quantitative volumetric imaging
of emission fields.

4. Camera calibration

A projection or back-projection function, Ψ or Ψ −1, is needed to
construct the imaging models described above, and imaging models
for each camera are required in turn to reconstruct a flame. Projection
functions are obtained by camera calibration, sometimes called view
registration, and Ψ −1 may be found by explicitly inverting Ψ . Similar to
reconstruction, calibration begins with a model of the imaging process,
which is normally based on the concept of a pinhole camera. The model
contains unknown parameters that describe the position, orientation,
sensor size, and effective focal length of an imaging system, and cali-
bration of a single camera generally proceeds as follows: First, several
pictures of a ‘‘calibration target’’ are recorded; the target contains
features that are well-characterized, such as a board with a printed
pattern like dots of known spacing (Fig. 12(a)) or checks of specified
width (Fig. 12(b)). Second, a dot or edge finding algorithm is used to
determine the position of said features in each of the calibration images.
These steps produce a set of 3D world coordinates, x, as well as the
corresponding 2D sensor (or image) coordinates, u, each corresponding
to one feature in one of the images. The camera model provides a
mapping between world and sensor points, and calibration amounts to

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 12. Sample targets used to calibrate cameras for tomographic imaging: (a) dot card pattern from Calib.io, (b) checkerboard pattern [213], and (c) square grid imposed on a
3D object [214].

estimating the model parameters for a set of measured vectors. Lastly,
the fitted models are used to determine Ψ or Ψ −1 as needed.

Camera calibration is a rich topic in computer vision, an extensive
overview of which can be found in Hartley and Zisserman [215]. A
majority of calibration codes are based on an explicit camera model
that is formulated using geometric optics, but several codes employ
a non-physical polynomial model that can be used to represent an
arbitrary imaging system, as famously done by Soloff et al. [216].
Simple explicit models are often calibrated using a linear technique,
such as the direct linear transform (DLT) [217–219], although it is
more common to augment a pinhole camera with a nonlinear distortion
model that accounts for the effects of a lens and/or lens mount.
Numerous methods have been devised to estimate the parameters of
a pinhole model with distortion, either simultaneously or sequentially,
including most notably the works of Tsai [220], Weng et al. [221],
Heikkila and Silven [222], and Zhang [223]. The latter approach is
significant in that Zhang’s method does not require full knowledge
of the world points; instead, only the relative 2D position of features
(like dots or checks) on a planar target are needed for calibration.
Svoboda et al. [224] later devised a multi-camera calibration algorithm
that does not require any knowledge of the world points in order
to calibrate three or more pinhole cameras that are subject to radial
distortions from a lens. Several papers have compared the reliability
of linear and nonlinear calibration techniques to that of a generic
polynomial map in the context of PIV [225], stereo PIV [226,227], and
3D particle tracking velocimetry [228]. Nonlinear pinhole and Soloff-
style polynomial models exhibit similar performance when there are a
large number of features in each image and the world and sensor points
are known to a high degree of accuracy. The choice of algorithm is
thus a function of the imaging scenario, i.e., the number and spacing
of control points and whether features on the calibration target are
simultaneously visible to all of the cameras. These considerations are
discussed throughout this section.

Volumetric imaging poses unique requirements for camera calibra-
tion. In particular, there is usually a large number of cameras and it is
essential to calibrate them in terms of a global coordinate system. This
can be accomplished by using a calibration target that is simultaneously
visible to each camera in the imaging system, which may be aided by
the use of a 3D (i.e., non-planar) target, as can be seen in Fig. 12(c).
Alternatively, cameras may be calibrated on an individual basis and
then rotated and translated into a global system. An explicit camera
model must be used to conduct this operation. Unfortunately, multi-
stage, multi-camera calibration is subject to errors that accumulate
when the cameras are rotated and translated more than once. As
such, it is preferable to directly calibrate all the cameras into a global
coordinate system using images of a 3D target that is visible to each
camera.

It should be noted that reconstruction accuracy is closely connected
to that of the camera calibration procedure. The veracity of a projection

function is usually assessed in terms of a mean reprojection error,
which is a characteristic distance from the control points detected in
an image to the corresponding world points projected onto a sensor
via the calibrated model,

εprj =

1
NimgNfeat

Nimg
∑

Nfeat∑

i=1

j=1

u(i,j) − Ψ (x(i,j))‖
‖
‖2

‖
‖
‖

,

(78)

where i and j indicate an image and target feature, respectively; Nimg is
the number of calibration images; and Nfeat is the number of features
on the target. Elsinga et al. [229] suggested that εprj should be less
than 0.4 px in order to ensure accurate estimates of the velocity field
in TPIV, and Wieneke [230] prescribed an even lower limit of 0.1 px.
But the relationship between εprj and reconstruction accuracy has not
been assessed for emission tomography.

This section covers the essential aspects of calibration for volu-
metric reconstruction, beginning with an overview of pinhole imaging
with distortions. Next, the DLT and Zhang’s method are recapitulated,
including nonlinear fitting of a distortion model in each case. The in-
version of a pinhole camera model to obtain Ψ −1 is described, followed
by a review of polynomial calibration. Finally, this section concludes
with a brief synopsis of additional calibration-related topics that are
relevant to volumetric combustion experiments.

4.1. Pinhole model with distortion

A pinhole camera is a box that contains a sensor which is exposed
to light through an infinitesimal opening, analogous to the aperture
of a real camera. This scenario is depicted in Fig. 13: light from the
world passes through the pinhole onto the sensor, whereupon the in-
bound light forms a 2D image. The camera is characterized by internal
‘‘intrinsic’’ parameters that describe the sensor as well as external
‘‘extrinsic’’ parameters that detail the camera’s pose, i.e., its location
and orientation. Intrinsic parameters include the camera’s focal length,
f , which is the distance from the pinhole to the sensor. The principal
point or optical center, (u0, v0), is the location aligned with the center
of the lens/aperture. This point corresponds to the camera’s primary
ray, which is coincident with the camera’s pose. Pixels are defined by
their height, pu, width, pv, and a skew parameter, sskew, which accounts
for tilt. Extrinsic parameters comprise a 3 × 3 rotation matrix, R, and
translation vector, t = −Rc, where the vector c = [xcam, ycam, zcam]T
indicates the pinhole’s position in global coordinates.

The path of light from a position in the world to the sensor can
be computed with a matrix operation called the camera transform.
World points are rotated and translated into the camera’s frame of
reference via the extrinsic matrix, [R, t], and the resulting relative world
positions are mapped to a sensor position by the intrinsic matrix,
K, which contains the parameters described above. These operations
require so-called homogeneous vectors that are denoted with a tilde in

22

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

effects of a Scheimpflug adapter, including [235–239]. In particular,
Cornic et al. [239] developed a two-axis Scheimpflug model as well as
an initialization procedure for nonlinear fitting. Using one of these ad-
vanced camera models usually requires knowledge of the lens system,
such as the number and order of components, as well as a custom code.
In general, Brown’s distortion model is sufficiently robust for vol-
umetric imaging, and it is included in most commercial and open
source calibration packages. This model is based on normalized sensor
positions,

̃u′ ≡

u′
v′
1

⎡
⎢
⎢
⎣

⎤
⎥
⎥
⎦

= K−1 ̃u = ζ −1[R, t]̃x,

(81)

where the prime notation,
indicates a non-dimensional coordi-
nate and the scale, ζ, is given by Eq. (80). Next, the radially- and
tangentially-distorted sensor positions are calculated using Brown’s
polynomial model,

⋅′,

Fig. 13. Depiction of pinhole imaging: light emanating from an object passes through
a pinhole onto a detector, forming an image. The relationship between a 3D point,
relative to the camera’s pose, and the corresponding sensor location is given by similar
triangles.

this review, ̃x = [x; 1]; this format allows for the simultaneous rotation
and translation of a vector using a single matrix multiplication. The
intrinsic and extrinsic matrices are combined to form an overall camera
matrix, P = K[R, t], resulting in the camera transform,

ζ ̃u =

K
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
u0
sskew
fu
v0
fv
0
1
0
0

⎡
⎢
⎢
⎣
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟
P=[KR,−KRc]

[R, t]

⎤
⎥
⎥
⎦

̃x,

which is valid up to a scale factor,

ζ = R3,∗x + t3,

(79)

(80)

where R3,∗ is the third column of R and t3 is the third element of t.
In the intrinsic matrix, fu = f ∕pu and fv = f ∕pv are effective u- and v-
direction focal lengths in pixel units, where f is the overall focal length
(usually given in millimeters) and pu and pv are the pixel height and
width in the same units. Eq. (80) demonstrates that ζ depends on the
distance from the camera to a given point. This scale is simply the third
element of ζ ̃u in the forward camera transform, but the presence of ζ
complicates the calibration procedure since it is not generally known
for a set of control points. In other words, x and u may be known but
the unknown matrix P depends on the unknown scale ζ.

Lenses and lens adapters can warp the images recorded by a camera,
and these effects are not included in the linear camera transform
outlined above. Brown [231,232] proposed a polynomial distortion
model to compensate for the radial distortions produced by a system
of lenses and the tangential distortions produced by misalignment of
the lens and sensor. Note that this misalignment may be intentional,
e.g., in the case of Scheimpflug adapters, which are frequently used
to align a camera’s focal plane with a laser sheet or slab. While the
form of Brown’s polynomial distortion model is inspired by the physical
effects of a lens and lens adapter, the parameters are non-physical,
which can lead to calibration errors and increase the number of control
points needed to fit the model. There are several advanced camera
models that explicitly account for a complex system of lenses as well
as models that incorporate a Scheimpflug mount. Lin and Sung [233]
developed a camera-and-lens model by tracing incoming rays through
a series of refractive lenses via Snell’s Law. Their technique accurately
accounts for radial distortions and has been shown to outperform a
simple pinhole model in experiments [234]. Numerous modifications
of the pinhole camera transform have been proposed to incorporate the

radial distortion
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
(
)

3
∑

+

1 +

drad,kr′2k

dist = u′
u′
k=1
[
(
r′2 + 2u′2)]
2dtar,1u′v′ + dtar,2
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟
tangential distortion

and

(

dist = v′
v′
[
dtar,1

3
∑

1 +

)

drad,kr′2k

+

(

k=1

r′2 + 2v′2)

+ 2dtar,2u′v′]

,

(82a)

(82b)

where r′2 = u′2 + v′2 and drad,k and dtar,k are the radial and tangential
distortion parameters, respectively. The radial distortion polynomial
can be expanded, but it is normally limited to a second- or third-order
expression. For convenience, element-wise calculations of the distortion
vector may be compactly represented as a nonlinear, vector-valued
function of a non-dimensional sensor position,

(83)

(̃u′)

̃u′
dist

,

=

⎤
⎥
⎥
⎦

⎡
⎢
⎢
⎣

u′
dist
v′
dist
1
dist and v′

dist are given by Eq. (82), meaning that ̃u′

where u′
is a
function of the distortion parameters. Finally, the non-dimensional
distorted parameters are transformed to obtain the desired distorted
sensor positions,

dist

̃udist =

udist
vdist
1

⎡
⎢
⎢
⎣

⎤
⎥
⎥
⎦

= K̃u′

dist .

(84)

Putting these elements together, the projection function for a pinhole
camera with distortions is

Ψ (x) = K1∶2,∗ ̃u′

dist

[ζ −1 (Rx + t)

] ,

(85)

where K1∶2,∗ indicates the first two rows of K and ζ is the scale from
Eq. (80).

Calibrating a pinhole camera consists in estimating the elements of
P as well as drad,k and dtar,k, where applicable, using a set of K known
real world vectors,

̃X =

[̃x(1), ̃x(2), ... , ̃x(K)] ,

and the corresponding sensor positions,

̃U =

[̃u(1), ̃u(2), ... , ̃u(K)] .

(86)

(87)

The vectors in ̃X represent the absolute or relative positions of features
(dots, check intersections, etc.) on a calibration target in the world,
and the vectors in ̃U are the pixel locations of the same features. The

23

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

latter positions are determined from pictures of the target using a dot
or edge finding algorithm. Unfortunately, each pair of world and sensor
vectors has an unknown and potentially unique scale coefficient, ζ, so
it is not possible to solve for P by simply manipulating an expression
of the form ̃U = P ̃X. Moreover, the distortion model introduces the
need for nonlinear optimization to obtain drad,k and dtar,k and then
correct the initial estimate of P, which is corrupted by the effects of
distortion. Hence, nonlinear optimization is commonly employed to
simultaneously fit the linear and nonlinear parameters of Ψ .

4.2. Direct linear transformation

Direct linear transformation is a technique proposed by Abdel-Aziz
and Karara [217] to solve for P when the absolute 3D coordinates of
target features are known but the scales of vectors in ̃U are unknown.
This is often the case when a planar calibration target is swept through
the domain in a controlled fashion or the target is a 3D object with
known feature locations, e.g., the target of Wang et al. [214] depicted
in Fig. 12(c). The original method did not account for nonlinear dis-
tortions, but standard optimization techniques can be employed to
estimate drad,k and dtan,k.

4.2.1. Intrinsic calibration and localization

To begin, the camera transformation is expressed as follows:

ζ ̃u =

ζu
⎡
ζv
⎢
⎢
ζ
⎣

⎤
⎥
⎥
⎦

=

P1,∗ ̃x
P2,∗ ̃x
P3,∗ ̃x

⎡
⎢
⎢
⎣

⎤
⎥
⎥
⎦

,

where Pi,∗ is the ith row of P. It is trivial to see that

(88)

u =

and

v =

P1,∗ ̃x
P3,∗ ̃x

P2,∗ ̃x
P3,∗ ̃x

,

(89a)

i=1

j=1

(89b)

which can be used to construct an alternative formulation of the
transform. In order to do this, the camera matrix is rearranged into a
2,∗; PT
vector, pvec = [PT
3,∗]. Next, row vectors that contain the world
and sensor elements of Eq. (89) are introduced,

1,∗; PT

−̃xT, 0, ũxT]
[

0, −̃xT, ṽxT]
[

,

qu =

and

qv =

(90a)

(90b)

where 0 is a 1 × 4 vector of zeros and u and v are obtained from the
dot or edge finding algorithm. Lastly, Eq. (89) is expressed using inner
products,

qupvec = 0

and

qvpvec = 0.

(91a)

(91b)

This expression holds true for each combination of world and sensor
vectors. As a result, one can construct an overdetermined, homoge-
neous matrix system using K pairs of ̃x and ̃u vectors,
[

]

(92)

u ; q(2)

v ; q(2)

; q(K)
q(1)
u ; q(1)
v
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟
Q

v ; ... ; q(K)

u

pvec = 0,

where Q is a 2K × 12 matrix. Note that P contains 12 elements and
each feature in a calibration image contributes two equations to Q so
K must be greater than or equal to six. Clearly, pvec must be in the
null space of Q since pvec = 0 is not a valid camera matrix. A common
strategy for calculating the vectorized camera matrix is to conduct the

24

full singular value decomposition (SVD) of Q and then set pvec to be the
right-singular vector that corresponds to the smallest singular value.
This choice is the best approximation to pvec when the elements of Q
are subject to error and rank(Q) = 12.

The 3 × 4 camera matrix P is formed from the elements of pvec and
subsequently dissected to determine K, R, and c. To see how, recall that

P = K[R, t] = [KR, −KRc]

so the camera position can be found as follows:

c = −P−1

∗,1∶3P∗,4.

(93)

(94)

Next, observe that the intrinsic matrix is upper triangular and the
rotation matrix is orthonormal by definition. As a result, K and R can
be disaggregated using RQ decomposition or, equivalently, the more
conventional QR decomposition of P−1
∗,1∶3, in which case the Q factor is
RT and the R factor is K−1. The intrinsic matrix should be normalized
by K3,3 in order to obtain a properly-scaled operator. Lastly, K and R
are rotated about the z-axis using Rz = diag([−1, −1, 1]), where diag(⋅)
returns a diagonal matrix that contains the inputted vector input along
the diagonal.

4.2.2. Distortion parameters

Distortions induced by a lens or non-parallel lens mount introduce
errors into DLT-based estimates of K, R, and t so it is necessary to
both determine the distortion parameters and correct estimates of the
camera matrices. These operations are simultaneously conducted with a
nonlinear optimization routine. The objective function to be minimized
is
F (K, R, t, {drad,k
Nimg
∑

} , {dtan,k

Nfeat∑

})

=

̃u(i,j) − K̃udist
‖
‖
‖

2
(ζ −1[R, t]̃x(i,j))‖
‖
2
‖

,

(95)

where ̃x(i,j) and ̃u(i,j) are the world and sensor locations of the jth
calibration feature in the ith image and ζ is the scale in Eq. (80).
Free parameters in the objective function include all elements of the
intrinsic and extrinsic matrices as well as the distortion coefficients.
While the resulting minimization is highly nonlinear, the objective
function is relatively well-behaved and is often solved with a standard
implementation of nonlinear programming techniques such as the trust-
region-reflective algorithm or Levenberg–Marquardt algorithm. The
distortion parameters can be initialized at zero, although Zhang [223]
presented a more sophisticated initialization strategy.

It is important to ensure that the intrinsic matrix remains properly
normalized throughout the minimization and that the rotation matrix
is orthonormal. As such, the function used to evaluate Eq. (95) should
set K to K∕K3,3 before the residual is calculated. The rotation matrix
should also be optimized by conducting an SVD, R = UΣVT, and then
setting R to UVT to ensure that it is orthonormal.

4.3. Zhang’s method

It is not always possible to use controlled translations of the target
to calibrate a camera system for volumetric imaging. For instance, in
experiments with a large number of cameras that span a wide arc, a
planar target may not be visible from each camera’s vantage point in
any given image. Zhang’s [223] method relaxes the assumption that
the 3D coordinates in ̃x are known. Instead, it is assumed that one
has images of a planar calibration target that is randomly positioned
and oriented in each image, as depicted in Fig. 14(a). The method only
requires three of these images, although greater accuracy is achieved
through the use of additional photos (typically around 20). Calibration
of individual cameras is followed by a procedure to establish a global
coordinate system.

Zhang’s method is the basis of several widely-available calibration
codes, including OpenCV [241] as well as MATLAB’s camera calibration
app, both of which are based on the work of Bouguet [240]. As a result,
this approach has been used in a large number of volumetric imaging
experiments.

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 14. Illustration of Zhang’s method for camera calibration: (a) images of a randomly-oriented planar target, (b) single target with features detected, and (c) camera-centric
visualization of the extrinsic parameters.
Source: Adapted from [240].

4.3.1. Homography

First, a target-specific coordinate system is introduced wherein the
z-component of ̃x is assumed to be zero and the x- and y-components
are related to the target, for instance, the spacing between dots or size
of checks. Assuming that z = 0, the camera transform is rewritten as
follows:

ζ ̃u = K [R1,∗, R2,∗, t]
⏟⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏟
H

,

⎡
⎢
⎢
⎣

⎤
⎥
⎥
⎦

x
y
1
⏟⏟⏟
̃xtar

(96)

where H is called the homography matrix, ̃xtar contains the x- and y-
coordinates of detected features on the calibration target using a local
coordinate system, and the scale is

ζ = H3,∗ ̃xtar .

(97)

Note that ̃xtar is constant for any given feature on the target.

The problem of estimating H appears remarkably similar to solving
for P. For instance, the homography transform also results in equations
that yield u and v,

u =

and

v =

H1,∗ ̃xtar
H3,∗ ̃xtar

H2,∗ ̃xtar
H3,∗ ̃xtar

.

A new Q matrix is constructed out of the following row vectors,

qu =

and

qv =

[
−̃xT

tar , 0, ũxT

tar

[
0, −̃xT

tar , ṽxT

tar

]

]

,

(98a)

(98b)

(99a)

(99b)

where 0 is now a 1 × 3 vector of zeros. The homography matrix is
vectorized, hvec = [HT
3,∗], and Eq. (99) is formed into a matrix
system for a set of K points,

1,∗; HT

2,∗; HT

Qhvec = 0,

(100)

as in Eq. (92). In this case, K is the number of features (check intersec-
tions, dots, or whatever) on a given target and the vector hvec for that
target can be estimated using the ninth right-singular vector from the
SVD of Q. A homography matrix must be estimated for each picture of
the calibration target.

4.3.2. Intrinsics and relative extrinsics

The next step of Zhang’s method is to determine the intrinsic matrix
of a camera from several homography matrices, each corresponding

to a unique position and orientation of the target. Note that QR de-
composition is no longer viable because [R1,∗, R2,∗, t] is not inherently
orthonormal. However, it can be seen in Eq. (96) that R1,∗ = K−1H1,∗
and R2,∗ = K−1H2,∗, and these vectors are indeed orthogonal so
RT
1,∗

R2,∗ = 0 and, therefore,

HT

1,∗ K−TK−1
⏟⏞⏟⏞⏟
B

H2,∗ = 0.

(101)

It is also known that the magnitudes of R1,∗ and R2,∗ must both equal
unity, so

HT

1,∗BH1,∗ = HT
or, equivalently,

2,∗BH2,∗ = 1

HT

1,∗BH1,∗ − HT

2,∗BH2,∗ = 0.

(102a)

(102b)

Note that the matrix B, introduced above, is symmetric so it can be
vectorized in terms of its six unique components,

bvec =

[B1,1, B1,2, B1,3, B2,2, B2,3, B3,3

]T .

(103)

Next, 1 × 6 vectors vi,j are devised to transform the matrix multiplica-
tion HT
i,∗BHj,∗ into the inner product vi,j hvec. It is simple to verify that
these vectors are

vi,j =

[H1,iH1,j , H1,iH2,j + H2,iH1,j ,
H3,iH1,j + H1,iH3,j , H2,iH2,j ,
] .

H3,iH2,j + H2,iH3,j , H3,iH3,j

(104)

The constraints described above can be expressed using inner products,
i.e., Eqs. (101) and (102b) are

v1,2bvec = 0

(105a)

) bvec = 0,

and
(v1,1 − v2,2
respectively. Consequently, each calibration image results in a 2 × 6
homogeneous matrix system,
[

(105b)

]

bvec = 0.

(106)

v1,2
v1,1 − v2,2

A matrix V is constructed by stacking the vectors v1,2 and v1,1 − v2,2
from at least three calibration images. The resulting system, Vbvec = 0,
can be solved in the same manner as before via the SVD method. This
time, bvec is the sixth right-singular vector of V.

Cholesky decomposition is used to calculate the matrix square root
of B: Chol(B) = K−T so K = Chol(B)−T. The extrinsic matrix relative to a
given calibration target can be calculated using this estimate of K and
the corresponding homography matrix,

R1,∗ = (γK)−1H1,∗,

25

(107a)

Grauer, Mohri et al.

R2,∗ = (γK)−1H2,∗,
R3,∗ = R1,∗ × R2,∗,

and

t = (γK)−1 H3,∗,

where γ is a constant scale,

γ = ‖
K−1H1,∗
‖
‖

‖
‖
‖2

= ‖
‖
‖

K−1H2,∗

.

‖
‖
‖2

(107b)

(107c)

(107d)

(108)

The rotation matrix in Eq. (107) should be corrected using the SVD
method described in Section 4.2.2.

Carrying this out for each homography matrix yields a set of ro-
tation matrices, {R(i)}, and translation vectors, {t(i)}, with one set
of extrinsic parameters per calibration image. The matrix [R(i), t(i)]
describes the camera’s pose relative to the calibration board in the ith
image. Fig. 14(c) depicts the result of Zhang’s method relative to the
camera.

4.3.3. Distortion parameters

Distortion parameters are estimated by nonlinear optimization, just
like in Section 4.2.2 except using a unique extrinsic matrix for each
image. In this case, the objective function is
F (K, {R(i)} , {t(i)} , {drad,k
Nfeat∑

Nimg
∑

})

=

2

} , {dtan,k
ζ −1 [
(

(109)

R(i)

∗,1∶2

, t(i)]

̃x(j)
tar

̃u(i,j) − K̃udist

‖
‖
‖
‖

i=1

j=1

)‖
‖
‖
‖

2

,

where the scale is given by Eq. (97). Notice that ̃x(j)
the image, unlike ̃x(i,j) in the post-DLT optimization.

tar is independent of

4.3.4. Establishing a global coordinate system

When cameras are calibrated using the DLT and a single target
(either a translated plate or 3D object), the global system of coordinates
is automatically established in terms of the world coordinates assigned
to the target features. By contrast, extrinsic parameters estimated by
Zhang’s method are relative to the location and orientation of the target
in each image. Therefore, in order to establish a global system, it is
necessary to select a reference camera and then rotate and translate
the other cameras into the corresponding system.

The relative pose of two cameras can be deduced using the Kabsch
algorithm [242], as described by Muller et al. [243]. First, the rotation
matrix between two cameras, c and c′, denoted R(c→c′), is determined
from target points in the shared images, i.e., images in which the target
is visible to both cameras. Zhang’s method yields a rotation matrix for
each target position, here referred to as R(c,i) and R(c′,i) for the ith
image. These matrices are used to determine a set of relative world
points for both cameras: x(c,i,j) = R(c,i)x(j)
tar and so too for c′. A cross-
covariance matrix is computed by summing over the target points and
shared images,

Γ(c→c′) =

∑

∑

i

j

(
x(c,i,j) − x(c)

world

) (

x(c′,i,j) − x(c′)
world

)T

,

(110)

world and x(c′)

where x(c)
world are centroids of the rotated points. The rotation
between cameras c and c′ is determined using the SVD of this matrix,
Γ(c→c′) = UΣVT,

R(c→c′) = U

1
0
0

⎡
⎢
⎢
⎣

0
1
0

0
0
(UVT)]
det

⎤
⎥
⎥
⎦

VT,

[
sign

(111)

where the sign(⋅) function returns 1 for non-negative arguments and
−1 for negative arguments. Given the relative rotation of c and c′, the
relative translation is simply t(c→c′) = t
and t
c′.

(c)
world
(c′)
world are the average target translation vectors for cameras c and

(c′)
world − R(c→c′)t

(c)
world, where t

Progress in Energy and Combustion Science 94 (2023) 101024

The relative pose is calculated between each pair of cameras, if
possible, and optimal camera extrinsics are obtained in two steps. First,
the translation vectors are obtained by a minimization,

t(c) = arg min

t

∑

∑

c≠c′

c′

2
R(c→c′)t(c′) − t(c→c′) − t‖
‖
‖
‖
2
‖
‖

,

(112)

subject to t(1) = 0. Second, the rotation matrices are obtained by
another minimization,

R(c) = arg min
R

∑

∑

c≠c′

c′

R(c→c′)R(c′) − R‖
‖
‖
‖
‖
‖

2

F

,

(113)

subject to R(1) = I. Cameras that cannot be directly rotated and trans-
lated into the reference system of coordinates can be so transformed
in two or more steps, and the overall system can be arbitrarily rotated
and translated as desired, for instance, to relocate the origin.

4.4. Inverting the camera model

Once a pinhole model has been specified by DLT, Zhang’s method,
or otherwise, the projection function in Eq. (85) may be inverted to
obtain a back-projection function, Ψ −1. This is accomplished by solving
for the x-, y-, and z-components in Eq. (79) in terms of the distance
traveled along a ray. Notice that

ζ ̃u = KRx − KRc

so

ζRTK−1 ̃u + c = x,

(114)

(115)

where ζ now indicates a scaled distance along the LoS that corresponds
to a sensor position, u. The normalized back-projection function at u is

Ψ −1(u, l) =

l
RTK−1[u; 1]‖
‖2

‖
‖

RTK−1[u; 1] + c,

(116)

where l is a distance along the ray in world units. This function returns
a 3D position along the ray, starting from the camera and traveling out
towards the measurement domain.

When there is significant distortion, then pixel locations on the
sensor correspond to ̃udist in Eq. (83). As a result, values of u on the
right side of Eq. (116) need to be determined by inverting the distortion
model,

̃udist = K̃u′

dist (K−1 ̃u),

(117)

which must be iteratively solved. In this expression, ̃udist is the location
of a pixel centroid and ̃u is the effective origin of the corresponding ray.
Alternatively, if the distortions are purely radial, which is frequently
the case, then ̃u can be directly computed using the inverse radial lens
distortion model derived by Drap and Lefèvre [244].

4.5. Polynomial calibration

Optical systems can contain numerous components that are difficult
to explicitly model, especially when there are refractive interfaces
between the measurement domain and camera. Moreover, the pinhole
camera and polynomial distortion models are subject to error. Soloff
et al. [216] introduced an arbitrary polynomial model in the context
of planar PIV methods. Their approach has been widely adopted by
the PIV community [118] and is implemented in commercial software
such as DaVis from LaVision.

The standard Soloff polynomial features a third-order expansion in
the x- and y-directions and a second-order expansion in the z-direction,

Ψ (x) = a(0) + a(1)x + a(2)y + a(3)z + a(4)x2

+ a(5)xy + a(6)y2 + a(7)xz + a(8)yz
+ a(9)z2 + a(10)x3 + a(11)x2y + a(12)xy3
+ a(13)y3 + a(14)x2z + a(15)xyz

26

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

+ a(16)y2z + a(17)xz2 + a(18)yz2
]

[u
v

=

= u,

(118)

where a(i) are 2 × 1 vector-valued coefficients and x, y, and z are the
elements of x. Calibration proceeds by linear least-squares regression,
which is conducted separately for the u- and v-components of Eq. (118).
The above projection function contains 36 unknowns and each target
feature contributes two observations so at least 18 pairs of u and x
points are required for calibration. However, it is beneficial to include
considerably more points whenever possible since the technique does
not include physical constraints on the trajectory of rays. Indeed, the
projection function may be subject to significant errors in between the
target features unless they are densely distributed throughout the entire
reconstruction domain [239].

Soloff et al. [216] found that third-order expansions in the x and
y directions were adequate to capture radial distortions in any given
plane, and they used a second-order expansion along z due to the
limited number of planes in their calibration tests. It is possible to fit
higher-order expressions by increasing the number of dots and target
positions, but many of the coefficients are not statistically significant
and the marginal utility of a higher-order polynomial is low [245].
That said, the literature contains examples of polynomial projection
functions with a third-order expansion in the z direction, e.g., the
plenoptic camera model reported by Hall et al. [246]. In general,
polynomial calibration yields an accurate projection function when the
target

1. is visible to all of the cameras,
2. fills each image,
3. contains a large number of detectable features (dots, checks,

lines, corners), and

4. is translated through the domain using small steps.

When these conditions are not satisfied, it is preferable to use an ex-
plicit camera model that is calibrated by one of the methods described
above.

It should also be noted that the projection function obtained by
polynomial calibration is sufficient to construct a VSF-based imaging
model, but a back-projection function is needed to construct a ray-
based imaging model and it is challenging to analytically invert a Soloff
polynomial. Nevertheless, a similar approach can be taken to directly
approximate Ψ −1. This is done by creating an alternate polynomial
function that is akin to Eq. (118) except that the inputs are u, v, and
z and the outputs are x and y (u and v can simply be swapped with x
and y in Eq. (118)). The resulting pseudo-back-projection function can
be used to determine the x and y location of a given ray at an inputted
z location. In order to stabilize Ψ −1, it is usually necessary to scale u
and v by the sensor width and height and z by the distance between
the first and last calibration targets. Moreover, since the trajectory of
rays is straight within the reconstruction domain, it may be beneficial
to approximate the ray vector as the line of best fit to the world points
computed via Ψ −1 at the calibration plate positions.

4.6. Additional calibration methods

Several complications to camera calibration can arise in the context
of combustion tomography. Common problems include instabilities in
the position and/or focus of the cameras over time, refractive interfaces
that are incompatible with a pinhole model, and the substantial labor
required to calibrate a large number of cameras with a planar target.
Techniques and devices devised to address these issues are covered
below.

27

4.6.1. Self-calibration

Camera calibration is prone to error, and it has been experimentally
shown that calibration parameters can be subject to drift [239]. Drift
occurs due to instability of the camera mounting fixtures, heating of
the camera, and vibrations, among other causes. As a result, there is a
need to ensure that the calibration remains valid during testing.

Self-calibration refers to a set of techniques that leverage images of a
flow field to update projection or back-projection functions throughout
a test. The concept was pioneered by Wieneke [230,247] in the context
of TPIV. In his method, 3D particle (or particle cluster) positions are
triangulated via epipolar geometry. That is, observed sensor positions,
uobs, from multiple cameras are used to estimate the world position of
one or more particles, xest . Then, the mismatch or ‘‘disparity’’ between
uobs and Ψ (xest ) is employed to correct the projection function. Alterna-
tively, Cornic et al. [239] treated pairs of uobs and xest like features
on a calibration target in order to re-run a conventional calibration
procedure. In their algorithm, the authors only updated the extrinsic
parameters of a pinhole model, preserving the intrinsic parameters
from an initial calibration. This approach reportedly outperformed
Wieneke’s [247] original self-calibration algorithm, although it has not
been compared to the updated method from 2018.

Particle-based self-calibration is not possible in emission tomogra-
phy, but re-projections of a reconstruction may still convey information
about the accuracy of calibration. Liu et al. [248] proposed a self-
calibration technique for emission tomography called reconstruction
integrating view registration (RIVR). The premise of RIVR is that the
mismatch between measured projections, p, and reprojections of a
reconstruction, Ag, is inversely related to the accuracy of the camera
model (although this was not explicitly confirmed in [248]). Therefore,
the RIVR algorithm begins with reconstruction of the emission source
field, after which the quality of reconstructions is assessed in terms of
the Euclidean distance between p and Ag. Next, the authors generate a
new set of randomly-selected calibration parameters. These parameters
are employed to build an updated imaging model, A′, and the projec-
tions are reconstructed anew to determine the corresponding residual.
Residuals based on A and A′ are compared, and the proposed param-
eters are accepted or rejected according to the Metropolis criterion,
as described in [248]. This procedure is repeated until the parameters
have converged. It should be noted that this approach is sensitive to
the chosen reconstruction algorithm since many of techniques out-
lined in Section 2 inherently yield reconstructions that perfectly satisfy
the projection data. Moreover, the cost of repeatedly building A and
reconstructing g is substantial, which limits the practicality of RIVR.

4.6.2. Refractive bodies

Combustion experiments are often conducted within an enclosed
vessel, for instance, to maintain an elevated pressure or contain an
intense flame, in which case optical access is mediated by one or
more refractive surfaces. Refraction through a planar access window
is incompatible with a pinhole projection function [249], although the
resulting errors may be small if the window is thin and the working
fluid has a refractive index similar to that of air. Camera model errors
are more severe in the case of cylindrical liners, as illustrated in Fig. 15;
such liners are commonly used to contain a combustion process [250]
or natural convection experiment [251]. In these scenarios, calibration
is usually conducted with a polynomial model, especially in PIV tests
that feature a liquid fluid [118]. However, it is not always possible
to translate the calibration target through a confined geometry in
a controlled manner and planar targets cannot reach the edge of a
cylindrical liner, both of which limit the applicability of a polynomial
projection function. Therefore, it is preferable to extend the imaging
model to encompass refractive interfaces between the cameras and a
flame.

Imaging models are generalized to account for transparent con-
tainment vessels by tracing light rays from the measurement domain
to the camera and applying Snell’s Law at each interface along the

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 15. Camera rays refracted through a transparent, cylindrical casing, resulting in
warped images of a flame as well as occluded regions.
Source: Adapted from [252].

path. Ray tracing-based camera calibration was independently devel-
oped by Kotowski [253] and Mulsow [254]. The latter proposed the
alternating forward-ray tracing (AFRT) algorithm, which was extended
by Belden [237] for use in TPIV. AFRT proceeds in two stages. First,
a ray that corresponds to a detected feature (usually a dot) is traced
from the camera through the refractive system into the working fluid.
Second, another ray is traced back from the feature’s known world
location in the opposite direction. In principle, these rays must travel
along the same LoS. Parameters that define the camera (viz., pinhole
and distortion parameters) as well as the refractive surfaces are thus
optimized by minimizing the distance between the forward and back-
ward rays at each surface. While the AFRT algorithm can be used to
calibrate a complex imaging system that includes refractive bodies, the
method suffers from slow convergence and breaks down for rays that
undergo total internal reflection.

Paolillo and Astarita [252,255] developed an alternative technique
for calibrating a complex imaging system with refractive interfaces.
The method begins by rotating and translating the camera and control
points into a refractive body’s frame of reference. The vector between
the known location of a control point and a point along the unrefracted
LoS corresponding to the image of that point is deemed the optical ray
distortion. A line from the hypothetical, undistorted point to the camera
can be used to determine the location where the ray intersects the
outer-most refractive surface. Reversing the ray at this location should
yield a LoS that returns to the control point. Paolillo and Astarita [252]
iteratively solve for the optical ray distortion that returns to the control
point by adjusting parameters of the refractive body. Notably, this
technique was employed by Liu et al. [250] to reconstruct an unsteady
flame encased in a quartz cylinder. A graphical schematic of both
the AFTR algorithm and that of Paolillo and Astarita can be found in
Figs. 1–3 of [252].

4.6.3. 3D targets

Relative to planar calibration targets, 3D objects reduce the number
of target positions and/or orientations needed to calibrate a large
number of cameras, especially when they span a wide arc. Calibration
can occasionally be conducted with a single image when one uses an
appropriate target. Figs. 12(c) and 16(b) depict non-planar targets that
facilitate single-image calibration. The object in Fig. 12(c), used by
Wang et al. [214], comprises two cubes that are marked with a grid,
intersections on the grid correspond to control points with a known
spacing. The authors were able to calibrate 12 cameras positioned
around a 172◦ arc using only one image from each camera. LaVision
offers a 3D target with two planes and control points on both sides,
pictured in Fig. 16(a). This object can also be used to calibrate a set
of cameras with one image, including test configurations that feature
cameras on two sides of the measurement domain.

Notably, Unterberger et al. [256] developed a phosphorescent tar-
get (Fig. 16(b)) that requires a novel calibration strategy. The target
features numerous irregular shapes so the profile projected onto each

Fig. 16. Samples of 3D calibration targets that can be used to specify a pinhole model
with a single image: (a) Two-sided multi-plane target from LaVision and (b) luminescent
3D object presented by Unterberger et al. [256].

camera sensor is unique. Pictures of the target are captured in a dark
environment and the images are binarized such that 1 indicates a pixel
that ‘‘sees’’ the target and 0 is used for dark pixels. A synthetic binary
image is generated by ray tracing images of the target via a pinhole
camera with distortion, and the camera parameters are evaluated in
terms of the residual between the experimental and ray traced binary
images. Unterberger et al. [256] devised a genetic algorithm to cal-
ibrate the cameras using this target; the approach was demonstrated
in several flame tomography experiments with a high camera count
(around 30 cameras).

5. Performance metrics and optimization

Volumetric imaging is used to measure combustion structures that
span a wide range of spatial and temporal scales. This information
may be employed to observe turbulent phenomena or benchmark com-
putational codes, but doing so requires knowledge of the validity of
reconstructions. Several metrics can be used to quantify the perfor-
mance and applicability of a volumetric imaging system, including
its reconstruction accuracy and spatio-temporal resolution. However,
the concept of resolution is ambiguous in tomography and there is a
complex interplay between resolution and accuracy. In general, it is
desirable to quantify the performance of a volumetric imaging system,
and performance metrics can be leveraged to optimize the system’s
design, for instance, to identify the ideal vantage point of each camera.
In practice, it is usually necessary to numerically or empirically assess
accuracy and resolution, applied to specific features of interest within
the measured flame. This section outlines techniques to characterize the
accuracy and resolution of reconstructions, followed by an overview
of the optimal arrangement of cameras for volumetric imaging of
continuous fields as well as particle fields.

5.1. Reconstruction accuracy and precision

Noise, model errors, limited measurement information, and the per-
formance of the reconstruction algorithm all contribute to reconstruction
artifacts, which are discrepancies between the exact QoI and estimates
thereof. Accuracy refers to the congruity between a reconstruction, gest ,
and the corresponding ground truth field, gexact (which is seldom known
with precision in an experiment).11 Quantitative accuracy metrics are
needed to ensure that the fidelity of reconstructions is sufficient for
an experiment. The required level of accuracy may vary from situation

11 This discussion concerns the comparison of vectors that comprise coeffi-
cients for one set of basis functions. If a Fourier-based algorithm is used, then
the reconstruction may be compared to the ground truth using these metrics
at selected points in space.

28

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

‖a − b‖p =

( n
∑

i=1

)1∕p

,

p
ai − bi|
|

|
|

(119)

and

to situation: high accuracy is needed to validate turbulence models
but reconstructions used to visualize large-scale combustion structures
can be less exact. Furthermore, accuracy metrics facilitate the selection
and optimization of an appropriate reconstruction algorithm as well as
the imaging setup. What follows is a brief discussion of key accuracy
metrics, numerical assessments thereof, and a note on precision.

5.1.1. Accuracy metrics

Measures of accuracy provide a single number that is intended
to summarize the correspondence or difference between two vectors.
These measures fall into two categories. Similarity metrics gauge the
degree to which the vectors are alike: higher values indicate greater
similarity and the results are often normalized to [0, 1]. Dissimilar-
ity metrics constitute a measure of the difference between vectors,
which is equivalent to summarizing the magnitude of reconstruction
errors when the vectors are gest and gexact . To wit, there is an inverse
relationship between accuracy and dissimilarity.

There are two dominant accuracy metrics in volumetric imaging.
The first of these is the normalized Euclidean distance from gest to
gexact , which is a measure of dissimilarity. The p-distance between two
vectors, denoted ‖ ⋅ ‖p, is a general notion of distance, meaning that
comparisons are non-negative, symmetric, satisfy the triangle inequal-
ity, and only equal zero when the inputs are identical. The p-distance
between vectors a and b is given by the p-norm of the difference
between them,

where p = 2 corresponds to the Euclidean distance. The normalized
Euclidean error or normalized root-mean-square error (NRMSE) of a
reconstruction is

(gest , gexact

ε2

)

=

gexact − gest ‖
‖
‖2
‖
gexact ‖
‖2

‖
‖

,

(120)

which is often multiplied by 100 and stated as a percentage error.
Eq. (120) is also occasionally squared, although doing so does not
serve any practical purpose (the main effect of this is to reduce the
apparent magnitude of errors). A related metric is the normalized
Manhattan error, which is identical to Eq. (120) except that p = 1.
Although uncommon, Aggarwal et al. [257] suggested that the use of
Manhattan errors or even fractional norm errors (0 < p < 1) could
mitigate the ‘‘curse of dimensionality’’, which refers to the difficulties
associated with comparing distances in a high-dimensional space. How-
ever, flames usually occupy a relatively low-dimensional manifold and
reconstructions are fairly local to the ground truth. Therefore, in most
circumstances, the Euclidean distance is a reasonable choice.

The second dominant accuracy metric is the Pearson correlation

between a reconstruction and ground truth vector,

r(gest , gexact

)

=

(gest − gest
gest − gest ‖
‖
‖

)T (gexact − gexact
gexact − gexact ‖
‖2 ‖
‖2
‖

)

,

(121)

where gest and gexact are the mean values of gest and gexact , respectively.
This is a similarity metric that equals 1 for perfectly correlated vectors,
indicating a high-degree of accuracy, and 0 for uncorrelated vectors.
Unfortunately, Eq. (121) is insensitive to the magnitude of vectors,
i.e., r(a, b) = r(sa, tb) for any nonzero scalars s and t that have the same
sign. This feature is an advantage in some settings, but the magnitude of
g is an important aspect of any quantitative reconstruction. Moreover,
the correlation between two vectors is directly related to the Euclidean
distance between the corresponding standardized vectors,

r(a∗, b∗)

= 1 −

ε2(a∗, b∗)2
2n

,

(122)

where n is the dimension of the standard vectors a∗ and b∗, which have
been centered and normalized by their respective standard deviations.

29

In other words, the correlation between two vectors provides struc-
turally similar information to the normalized Euclidean distance but
neglects differences in magnitude. This may be useful in cases where
the shape or movement of a reacting surface is of primary interest, but
the magnitude is significant when quantifying thermochemical fields.
As a result, p-norm error metrics are usually preferable to Eq. (121).

Numerous additional metrics are used to quantify the similarity
(or lack thereof) between images and other large datasets. Examples
include the structural similarity or ‘‘SSIM’’ index, cosine similarity,
cross correlation, mutual entropy, and peak SNR between a recon-
struction and phantom. While these alternatives may be well suited to
certain tests, they are not in common use in volumetric imaging and
it is advisable to select a metric that is widely understood, such as a
normalized distance or simple correlation.

5.1.2. Numerical benchmarking

Accuracy metrics presume knowledge of a ground truth vector, also
known as a phantom, which is compared to the associated recon-
struction. This information is clearly unavailable in most experimental
settings. Nevertheless, numerical tests, or ‘‘phantom studies’’, may be
run to assess and perhaps optimize the performance of an experimental
setup and reconstruction workflow. Phantom studies consist of four
steps.

1. One or more ground truth ‘‘phantom’’ vectors, gexact , are created;
2. projections of gexact are calculated for a given imaging system;
3. these projections are reconstructed, resulting in the estimate gest ;

4. gest and gexact are compared using a suitable metric.

There are a few important issues to consider at each step.

It is desirable to generate phantoms that mimic the experimental
target because reconstruction accuracy varies as a function of the size,
position, and complexity of a flame. Realistic phantoms can often be
obtained from a CFD simulation; for instance, Mohri et al. [258] used
the heat release field from a large-eddy simulation of a turbulent swirl
flame to stand in for a chemiluminescence source field. Structures in
this field closely matched those observed in the authors’ subsequent
CTC experiment. As a result, the phantom study provided useful infor-
mation about the accuracy of experimental reconstructions. Ideally, a
series of multiple unique phantoms should be used to provide statistics
about the accuracy of reconstructions, as opposed to a point estimate.
However, it is not always possible to obtain appropriate CFD data, let
alone a large number of statistically-independent fields. Under such
circumstances, phantoms with a range of spatial scales can be obtained
from software packages such as TomoPhantom [259], which includes
MATLAB and Python wrappers.

Projections of gexact should correspond to views from the experimen-
tal setup to ensure representative results. It is often advantageous to
try out a variety of camera positions prior to running an experiment in
order to select the best arrangement, as will be discussed in Section 5.3.
Once the cameras are in place, numerical tests may be conducted with
a matrix, A, constructed using camera parameters from the calibration
procedure, i.e., pexact = Agexact . However, while this ensures parity of
the camera positions, it is also a classic case of the ‘‘inverse crime’’ [86,
260], which occurs when the same (or nearly the same) model is used
to both generate and invert a set of data. Tomographic reconstructions
can be highly sensitive to structural errors in the imaging model, and
it is useful to introduce systematic inaccuracies into A to assess their
effects. The most important structural errors in volumetric imaging
are calibration and discretization errors. Calibration errors are easily
simulated by altering the camera parameters with a random offset;
creating another matrix with these parameters, A′; and then using A′
to reconstruct the projections produced via A.

Discretization errors pose a trickier problem since the resolution of
the basis is usually limited by computational constraints. One possible
solution is to compare reconstructions using a planar cross section,

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

where projections are generated with a high-resolution basis and re-
constructed on a low resolution basis. Another approach is to use a
super-sampling, in which each projection is obtained by high-order
numerical integration through a well-resolved phantom along multiple
rays [261]. However, conventional ray tracing is inconsistent with
volumetric emissions, as discussed in Section 3, and super-sampling the
projection data is rarely reported. In practice, the effects of discretiza-
tion errors are usually overlooked, and the topic of discretization errors
in combustion tomography is ripe for future research.

In addition to these deterministic errors, it is essential to perturb
the projections with artificial noise. Noise is unavoidable in real mea-
surements and reconstructions are highly sensitive to the image data’s
SNR. Indeed, the SNR is particularly low in ultra-fast or otherwise
low-light experiments that require an intensified recording device,
contributing to uncertainty about the reconstructions. One way to
characterize the effects of noise is to corrupt the exact projections of
a phantom with additive IID Gaussian errors whose magnitude exceeds
that of the experimental fluctuations. While this generally provides a
conservative estimate of the robustness of reconstructions, fixed-pattern
noise can have a disproportionate effect and should be incorporated
into the phantom study if present in one’s experimental projection data.
Ultimately, projections free of calibration errors, discretization errors,
and noise are comparatively trivial to reconstruct, and omitting these
imperfections undermines the purpose of a phantom study.

Once a good set of synthetic projections has been created, the
data are reconstructed and compared to the corresponding phantoms.
This practice provides an opportunity to test different reconstruction
algorithms and regularization parameters. It is advisable to conduct
a parameter sweep and optimize the reconstruction workflow subject
to a given camera arrangement and simulated combustion features.
Reconstructions in a phantom study are usually benchmarked using one
of the accuracy metrics outlined above. When doing so, it is important
to consider how the experimental reconstructions will be used. In
principle, any post-processing of the experimental data should also
be applied to the phantoms, and accuracy metrics should be applied
to the ultimate QoI. For instance, if the goal of an experiment is to
measure the surface area of combustion structures, then the phantom
study should be tailored to assess the accuracy of surface area estimates
and not just the Euclidean error of gest .

5.1.3. Precision

Lastly, the distinction between accuracy and precision should be
noted. While accuracy indicates distance from the truth, precision refers
to the repeatability of a measurement. Consequently, the precision of
an element of g is essentially given by its number of significant digits.
This concept is closely related to the dynamical range of a sensor:
projections with a low dynamic range beget imprecision reconstruc-
tions and high dynamic range data leads to high-precision estimates. In
practice, accurate reconstructions tend to be precise, although precise
reconstructions are not necessarily accurate (i.e., precision is consistent
with biased noise and reconstruction errors). Meanwhile, imprecise
projection data is often the consequence of a faint signal (low photon
count), which is inherently coupled to a small SNR and thus low
reconstruction accuracy. Given an estimate of the precision of p, the
numerical assessment techniques discussed above can be employed to
adjudicate the precision of g along with its accuracy.

5.2. Spatial resolution

The concept of spatial resolution was originally devised to char-
acterize the performance of a purely optical imaging system [262].
The term has various meanings that generally relate to the process
of separating objects (entities, forms, structures), often quantifying the
degree to which they can be differentiated. This notion implies a binary
distinction between cases where some feature of interest is adequately
resolved and cases where it is not [263]. In order to give a precise

Fig. 17. Image of the resolving power test target from the U.S. Air Force MIL-STD-
150 A standard of 1951. Spatial resolution is determined by identifying the scale at
which the white and black bars blur together and the border between them can no
longer be identified.

definition of resolution, it is necessary to specify the objects to be
resolved and the contrast and space that must exist between nearby
objects in order to distinguish them [264]. Common features used
to judge the resolution of an imaging device include a pair of point
sources, bars of alternating color, and the Landolt C [265]. Resolution
is frequently assessed on a subjective basis since it relates to the ability
of an observer to visually discern key details in a scene from an
image. However, there are several objective metrics that are intended
to standardize the concept.

It is relatively straightforward to gauge the spatial resolution of 2D
images recorded by a camera at a given working distance. For instance,
one can take a picture of a chart that contains progressively smaller
white and black bars and identify the spatial scale at which the bars
blur together. Numerous commercial vendors sell copies of the U.S. Air
Force resolving power test target for this purpose (see Fig. 17). The
spatial resolution of 2D images is contingent on the camera’s sensor
size, the lighting conditions, the depth of the scene versus the camera’s
depth of field, and the effects of digital post-processing, to name a
few factors, all of which naturally affect the resolution of tomographic
reconstructions, as well.

Characterizing the resolution of a tomographic sensor is more com-
plicated than characterizing a purely optical system because recon-
structions are formed synthetically and their resolution can vary with
the measured field. This effect is nicely illustrated by the presence
of ghost particles in TPIV, as depicted in Fig. 18. Images of two
particles that are recorded by two cameras can be explained by the
real particles, two ‘‘ghost particles’’, or combinations thereof (naturally,
this problem grows considerably worse as the number of particles
increases). Since the particle locations are not fully determined by the
measurements, it is impossible to distinguish real particles from ghost
particles and the resolution of reconstructions (however defined) is
degraded, accordingly. From this example, it can be seen that one’s
ability to distinguish particles depends not only on the number and
arrangement of cameras, the imaging model and basis, and the recon-
struction algorithm, it also depends on the arrangement of particles
in the measurement volume at any given instance. Moreover, when
the view count is limited, the measurements are always ambiguous
vis-à-vis the unknown 3D field, as discussed in Section 2.2.3. This
ambiguity, along with measurement noise and model errors, manifests
as reconstruction errors in the context of continuous emission fields
and particle fields, alike, and such errors diminish spatial resolution.

30

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Δθ = π∕Nviews so the arc length between adjacent lines of radius Tres is
π∕(lresNviews). Therefore, in order to ensure that the grid spacing is no
more than 1∕D, the number of views must satisfy

Nviews

≥ πD
lres

.

(124)

In other words, the length scale that can be resolved by a tomographic
sensor with equally-spaced views via Fourier-type reconstruction is
estimated to be

lres =

πD
Nviews

.

(125)

This expression indicates that a moderate view count is considerably
better than a low view count (e.g., ten views compared to five), but
each additional view provides diminishing marginal returns.

There are several weaknesses of Bracewell et al.’s derivation. For
instance, the maximum frequency at the corner of the points sampled
in Fourier space is 21∕2Tres, i.e., greater than Tres, which suggests a
lower value of lres. Further, since each view consists of discrete rays, the
resolution of ̂g along any given line, ̂pθ, is limited, accordingly [265].
Therefore, it is necessary to populate ̂g by interpolation, implicitly or
explicitly, which is a source of error alongside measurement noise and
the errors associated with a thin ray imaging model (Section 3.1.1).
Interpolation errors in Fourier space can be significant, and Eq. (125)
should be understood as an estimate of resolution, not a theoretical
guarantee. Furthermore, it is challenging to interpret the frequency
space resolution of a sensor with respect to physical space artifacts.
High-frequency artifacts (or aliasing in the case of a filtered reconstruc-
tion) can make it difficult to distinguish nearby combustion structures,
so this resolution metric should not be construed as a simple measure
of the distance between identifiable features.

Eqs. (123) and (125) presume the use of a Fourier-based recon-
struction algorithm such as FBP. However, the algebraic techniques
covered in Sections 2.3.3–2.3.8 are more common than FBP in com-
bustion tomography, and algebraic methods do not involve Fourier
transformations of the projections or QoI. Moreover, the basis acts as a
spatial filter and the prior information inherent in algebraic algorithms
can lead to errors that limit the resolution of reconstructions. Frieder
and Herman [265] suggested an alternative notion of resolution, based
on a distance metric, which can be applied to discrete reconstructions,

max
i

gexact,i − gest,i|
|
|
|

≤ ε,

(126)

where gexact,i and gest,i are elements of the exact QoI and reconstruc-
tion, respectively; ε is the largest absolute difference between those
elements; and the domain size, D, and pixel or voxel length, lres, are im-
plicit in the reconstruction procedure.12 Reconstructions are said to be
(D, lres, ε)-resolved if they satisfy Eq. (126). Of course, this metric varies
as a function of the ground truth distribution, gexact , which is unknown,
so it is not usually possible to assess the (D, lres, ε)-resolution of a recon-
struction in a real test. (This limitation also applies to Eq. (123), which
is rarely amenable to experimental verification.) Using their notion of
resolution, Frieder and Herman [265] devised a specific arrangement
of views that can yield (D, lres, 0)-resolution given noise-free measure-
ments, sufficiently small pixels, and no model errors (i.e., the value of g
is assumed to be truly uniform within each pixel or voxel). Using their
≤ tan−1[1∕(i−
configuration, if the viewing angles are confined to 0 ≤ θi
1)], where i is the index of a single LoS, then a length scale of

lres =

D
Nviews

(127)

can be achieved by the additive ART. A derivation of this expression is
provided in the appendix of [265]. Unfortunately, the arrangement of
views proposed by Frieder and Herman [265] is nearly impossible to

12 Eq. (126) is a discrete formulation of the continuous definition provided

in [265].

31

Fig. 18. Illustration of ghost particles in TPIV. Two real particles imaged by two
cameras results in ambiguous data that can be explained by the real particles, two ghost
particles, and combinations thereof. Therefore, the resolution of a sensor depends on the
arrangement of particles as well as the position of cameras, reconstruction algorithm,
size of pixels and voxels, and so on.
Source: Adapted from [266].

(Indeed, the entire concept of resolution becomes problematic in the
context of reconstruction artifacts.) Since the distribution of errors is a
function of the true emission source field at each instance, resolution
must be assessed with respect to the measured combustion structures.
Despite these conceptual hurdles, there are several ways to op-
erationalize ‘‘spatial resolution’’ in volumetric imaging. For instance,
a characteristic length scale may be derived with respect to a given
reconstruction algorithm. Alternatively, an empirical resolution map
may be extracted from one or more reconstructions of a specialized
phantom. Both of these methods are presented and assessed, below.
There is also a Bayesian approach to quantifying resolution that is
based on the uncertainties created by spatial correlations inherent in
the reconstruction algorithm. This technique was developed by Emmert
et al. [163] in the context of 2D limited-data tomography, but it begins
with the inversion of a very-large-scale matrix, having n4 elements, and
requires the Fourier transform of the resulting columns, which is not
practical in volumetric imaging.

5.2.1. Analytical length scales

A common working definition of resolution in tomography is the
Fourier space definition put forth by Bracewell and Riddle [267]. The
authors derive a reconstruction algorithm akin to FBP (Section 2.3.1),
and resolution is taken to be the smallest wavelength that can be mea-
sured by a sensor using their approach. To be more precise, Bracewell
and Riddle [267] consider a 2D source function g of diameter D.
Assuming that the frequency content of g is known, the source is said
to be resolved to length lres if
Tres∑

Tres∑

̂g(χ, ξ) exp

[
i2π (χx + ξy)

] ,

g(x, y) =

(123)

1
D2

χ=−Tres

ξ=−Tres

where Tres = 1∕lres is the cutoff frequency and the spacing between
points in the χξ-plane is 1∕D. As with the Fourier slice theorem
from Section 2.3.1, this notion generalizes to three dimensions but is
presented in 2D for simplicity.

Bracewell and Riddle [267] and Crowther et al. [268] indepen-
dently determined the number of equally-spaced views required to
achieve a resolution of lres with a Fourier-type reconstruction algo-
rithm. According to the Nyquist–Shannon sampling theorem, a source
of diameter D with no frequency content beyond Tres can be perfectly
reconstructed via Eq. (123) so long as the grid spacing is 1∕D or lower.
Recall that the Fourier transform of a view at the angular position
θ yields a line through the 2D Fourier transform of g at an angular
frequency of θ, per Eq. (15) and as illustrated in Fig. 2. Provided that
the viewing angles are equally distributed around a half-circle, then

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

implement using cameras so Eq. (127) should be regarded as a lower
bound on lres when the ART is used to estimate g, especially in light of
noise and discretization errors.

Floyd [100] proposed a modification of Eq. (127) for ART re-
constructions, assuming equally-spaced views instead of Frieder and
Herman’s [265] tailored configuration of projections. Floyd noticed
that the rank of A is approximately n when n equiangular views having
n pixels per view (i.e., m = n) are employed to reconstruct g with an
n×n grid of pixels, although this observation was not rigorously verified.
Supposing that such a setup yields a fully-determined matrix, A, and
assuming minimal noise and model errors, Floyd [100] estimated that
the ART can achieve (D, lres, 0)-resolution at a length scale of

lres =

√
2D
2
Nviews

.

(128)

This equation comes from applying the Nyquist limit along the grid
diagonal.

While Eqs. (127) and (128) may superficially suggest that the
ART is superior to Fourier-based methods, since they yield a lower
resolution length scale than Eq. (125), the ART and Fourier length
scales have different meanings and it is difficult to compare them as
measures of resolution. That is to say, the length scale derived via
Fourier analysis relates to the maximum detectable frequency whereas
(D, lres, ε)-resolution indicates the maximum reconstruction error in a
pixel of length lres. Furthermore, none of these lengths is directly
related to the minimum distance between separable combustion struc-
tures. It should also be emphasized that the real world resolution and
accuracy of FBP and ART reconstructions depends on the applicability
of the selected imaging model, measurement noise, and the rank and
condition number of A. Still, despite their distinct origins and interpre-
tations, Eqs. (125), (127), and (128) are remarkably similar: they are
only scaled by a constant factor. This result suggests that lres ∼ D∕Nviews
may be a robust indicator of the trend in resolution with respect to the
object size and view count, although none of these expressions should
be relied upon as a definitive resolution metric.

The resolution of ART reconstructions was numerically evaluated by
Floyd [100]. He devised a series of 2D cosine phantoms (Figs. 19(a)–
19(c)) supported by a grid of 256 × 256 pixels. Each view consisted of
256 projections with a width equal to that of the pixels. Floyd [100]
reconstructed the phantoms using five to 50 views and judged whether
the results were resolved by eye. When a reconstruction was not
resolved, he increased the phantom’s wavelength and repeated the
procedure until he deemed the estimate to be adequately resolved. This
process is depicted in Figs. 19(d)–19(f); Fig. 19(f) was classified as
‘‘resolved’’ whereas Figs. 19(d) and 19(e) were not. There was a strong
relationship between the length scale determined by Floyd and the
correlation between phantoms and reconstructions, which approached
unity at lres ≈ 40 px. A plot of the observed resolution versus the view
count, shown in Fig. 20, revealed the theoretical lres ∼ D∕Nviews trend
for each phantom, suggesting an empirical connection between the
subjective ‘‘distinguishability’’ notion of resolution and the analytical
length scales presented in this section In the figure, ‘‘256’’ stands for
the number of pixels along one side of the domain (n = 2562) and ‘‘C’’,
‘‘OC’’, and ‘‘TL’’ indicate the focal point of the wave: center, off-center,
and top left, as detailed in Table 4.2 in [100]. Eqs. (125) and (127)
acted as upper and lower bounds on resolution, respectively.

Floyd’s [100] cosine resolution tests were highly idealized, viz., free
of noise and model errors, and the results depended on his personal
evaluation of resolution. Nevertheless, these tests showed that trends
in lres calculations were borne out by qualitative trends in recon-
struction accuracy; the tests also revealed a close connection between
the complexity and orientation of flow structures and the resolution
of reconstructions, as can be seen in Figs. 19(g)–19(i). Axisymmetric
targets proved easier to reconstruct and discern from artifacts than
their non-axisymmetric counterparts. This finding holds especially true
in turbulent combustion experiments, which feature highly dynamic
fields. As such, it is important to consider the complexity of a target
flame when reporting and interpreting the resolution of reconstructions
in terms of an analytical length scale.

Fig. 19. Numerical test of the resolution of ART reconstructions using cosine phantoms.
Three phantoms were considered, in which the cosine function is centered at the
(a) top left, (b) middle left, and (c) center of the domain. The phantom wavelength
was increased until it was deemed to be resolved; this process is depicted in (d–f)
with a wavelength of (d) 20 px (not resolved), (e) 35 px (not resolved), and (f)
40 px (resolved). Resolution was a strong function of the phantom. Reconstructions
of phantoms with a 20 px wavelength computed using Nviews = 20 are shown in (g–i).
Top left and middle left phantoms were not resolved whereas the center phantom was
resolved.
Source: Adapted from [100].

Fig. 20. Comparison of theoretical and observed resolution length scales using re-
constructions of the cosine phantoms in Figs. 19(a)–19(c). The Fourier-based length
is plotted as a solid line and the idealized ART length scale,
scale, Eq. (125),
Eq. (127), is plotted as a dashed line. Reconstructions of the axisymmetric phantom
had a systematically higher resolution (lower length scale) than reconstructions of the
non-axisymmetric phantoms.
Source: Adapted from [100].

5.2.2. Empirical resolution maps

Analytical estimates of the spatial resolution of a volumetric imag-
ing system are derived for a specific reconstruction technique. FBP and
the ART, used to obtain the length scales presented above, are often un-
desirable in combustion tomography due to limitations on the number
of cameras as well as the inadequacy of a thin ray imaging model in the
case of FBP. Furthermore, such derivations require a formal definition
of resolution that does not necessarily equate to the commonplace no-
tion, i.e., to the visual separation of reconstructed features. The length

32

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

those in the U.S. Air Force test chart. Accordingly, the frequency ω is
often expressed in terms of line pairs per unit distance (lp/mm, lp/in,
etc.), which is a common unit of resolution. The gap between resolvable
line pairs is approximated by the period 1∕ω, and a cutoff frequency,
Tres, is determined by identifying the frequency at which the MTF falls
to a minimum threshold and below which the signal is deemed ‘‘not
visible’’. For instance, a threshold of 20% means that MTF(Tres) = 0.2
and the intensity of spatial frequencies above Tres are diminished by
more than 80%. Past works have employed a threshold of 10% [211]
as well as a more conservative selection of 20% [270], but the choice
is ultimately arbitrary. Once the cutoff frequency has been identified,
it is converted to a resolution length scale via the Rayleigh criterion,

lres =

1
Tres

.

(130)

This criterion holds that identical point sources are distinguishable if
they are separated by the full width at half maximum of the correspond-
ing PSF.

The MTF is ultimately deduced through the use of a phantom that
has one or more sharp edges. Reconstructing such a phantom yields a
blurred edge due to the frequency damping effect of sparse projections,
and the degree of blurring is quantified through the use of an edge
spread function (ESF). Differentiating an edge yields a line; likewise,
differentiating an ESF yields a line spread function (LSF). Moreover,
since a line can be interpreted as an infinite string of point sources, the
MTF can be obtained by taking the amplitude of the Fourier transform
of an LSF (assuming the PSF is spherically symmetric). Fig. 22(a) de-
picts a hypothetical ESF that would be obtained from a reconstruction;
the ESF is plotted normal to the phantom’s edge. Differentiating the ESF
results in an LSF (Fig. 22(b)), which is Fourier transformed to produce
the desired MTF, shown in Fig. 22(c). Local spatial resolution is deter-
mined by identifying the cutoff frequency in the MTF and converting
it to a length scale via Eq. (130). This procedure can be conducted
at various points along the phantom’s edges, and the phantom can be
re-positioned to align its edges with new points of interest.

Empirical resolution maps were first developed and implemented by
Tsekenis et al. [270] in the context of 2D absorption tomography, and
Yu et al. [211] adapted the technique for 3D emission tomography.
The latter group filled a glass container, shown in Fig. 23(a), with
a reactant and fluorescent dye to generate a sharp-edged emission
field, a.k.a. an experimental phantom. Slices of the true fluorescent
field have a circular profile that abruptly stops at the liquid–glass
interface, and the intensity of fluorescence is approximately uniform
throughout the container provided that the reaction has stabilized and
the dye is well-mixed. Eight views of the dye were recorded with a
set of cameras, each having a 1 MP sensor and large aperture (f ∕1.8),
spaced out around a semicircle. The projections were reconstructed
using the ART, and one slice of the reconstructed emission field is
shown in Fig. 23(b). Yu et al. [211] executed the procedure outlined
above to assess the reconstruction’s spatial resolution at the periphery
of the container, and they presented a 3D empirical resolution map.
There are two aspects of this implementation worth highlighting. First,
a special calibration procedure is required to account for refraction
through the glass and liquid (see Section 4.6.2), and the system must
be re-calibrated to conduct an emission tomography experiment. The
effect of re-calibration on spatial resolution is not clear. Second, the re-
construction exhibits distinct ‘‘pinched’’ artifacts around the container,
likely due to the calibration procedure; the result is a non-circular,
non-uniform emission field such that the intensity at the edge of the
container does not represent an ideal ESF. Devising an alternative
sharp-edged phantom to test the resolution of a volumetric emission
sensor is an area of ongoing research.

Ultimately, this technique produces quantitative estimates of the
spatial resolution of a specific reconstruction throughout the measure-
ment volume. However, several cautionary notes are warranted. The
most fundamental issue with empirical resolution maps is that the

Fig. 21. Illustration of an MTF and the resulting effect on reconstructed spatial
frequencies. The MTF describes the attenuation of a signal as a function of spatial
frequencies. Reconstructed line pairs cannot be distinguished beyond a cutoff frequency,
Tres, which is used to define the sensor’s resolution.
Source: Adapted from [270].

scale metrics described above also fail to account for the detrimental
effects of noise and model errors on spatial resolution, which is a
significant shortcoming because such effects may be large and they
vary from experiment to experiment (sometimes even from snapshot
to snapshot). Yet another drawback of these length scale estimates is
that they do not yield information about the spatial variation of spatial
resolution, which depends on the number of projections that transect a
given region of the flame. An alternative approach is to quantify the res-
olution of experimental reconstructions, computed using an algorithm
of one’s choice, throughout the measurement domain, resulting in a
so-called empirical resolution map. This black box treatment requires a
formal notion of spatial resolution, as before, and a physical phantom
that is tailor-made to facilitate the calculation of resolution throughout
the domain.

Empirical resolution maps are based on PSFs, which describe the
response of an imaging system to a point source of light. When two
point sources are brought into close proximity, their PSFs overlap and
a cutoff distance may be introduced to differentiate cases where the
sources can be individuated (resolved) from cases where the points are
indistinguishable. However, the fabrication of a point source is non-
trivial and characterizing PSFs by traversing the source throughout the
measurement volume is tedious and impractical [269].

A more convenient strategy is to compute the modulation transfer
function (MTF) at various points in the measurement volume using a
much larger phantom. An MTF is the amplitude of the Fourier trans-
form of a PSF, which is typically assumed to be spherically symmetric
such that both functions may be represented in 1D,

̂PSF(ω)|
MTF(ω) = |
|
|
|
|

.

(129)

MTFs describe the attenuation of a signal at each spatial frequency, as
illustrated in Fig. 21. Ideally, the MTF would be a line, but the mono-
tonic decay depicted in this figure is typical of most reconstructions,
i.e., there is a damping effect that increases with frequency [270]. This
behavior is directly related to the visual separation of line pairs such as

33

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 22. Procedure to determine the MTF (modulation transfer function) of a volumetric sensor from the reconstruction of a sharp-edged phantom: (a) the blurred edge is used to
determine a ESF (edge spread function), (b) the ESF is differentiated to determine the LSF (line spread function), and (c) the MTF is given by the Fourier transform of the LSF.
The local resolution of a reconstruction is determined from the MTF via Eq. (130), where the cutoff frequency, Tres, corresponds to a prescribed minimum value.
Source: Adapted from [211].

analytical nor numerical framework for the design of a volumetric
tomography sensor. Often times, heuristic methods are employed to
select the measurement positions, focal length, aperture size, and so
on. Several researchers have investigated the camera setup’s influence
on reconstruction accuracy, and results from these studies can inform
the design of a volumetric imaging sensor. Some general heuristics are
presented below, followed by a description of relevant studies in the
context of combustion tomography.

5.3.1. General heuristics

Reconstruction accuracy typically improves with added projections,
and the angular separation of views should be maximized within a half-
circle or half-sphere. While some groups have employed as few as three
vantage points for 3D combustion tomography [272], these setups lead
to large reconstruction errors and should be avoided. In practice, 10–
20 views are needed to resolve fine structures in a wrinkled flame, as
discussed in the next section.

Cameras are normally arranged in a single plane due to practical
constraints, but adding views with an upward or downward tilt pro-
vides a new perspective of the target that can increase the accuracy
of reconstructions [271]. Whenever possible, the measurement volume
should be contained within the cameras’ depth of field, magnification of
the volume should be consistent across the views, and the aperture size
should be minimized to avoid blurring of the QoI. Per Scarano [118],
a measurement volume of depth Δz will be in focus if the lens has a
magnification of

(√

M =

Δz
4.88λ

1
f#

)−1

− 1

.

(131)

Recall that λ is the wavelength of light and f# is the f -number.
Lastly, for a ‘‘thin’’ domain, the Scheimpflug condition dictates that the
focal plane should be aligned with the spanwise-center of the probe
volume [118].

5.3.2. Empirical tests

Meyer [65], Mohri [258], Liu [271] and their colleagues conducted
VLII, CTC, and incandescence tomography, respectively, of a turbulent
or unsteady flame using the camera configurations shown in Fig. 24.
All of these tests featured a high view count: 14, 24, and 14, respec-
tively. In each case, several subsets of views were reconstructed and
compared to a baseline that was reconstructed with the maximum
number of views. Cameras were regularly spaced in the setups, and
Meyer et al. [65] used vertical stereoscopes to bisect each camera
sensor, doubling the view count from seven to 14. Reconstructions were
computed using the SMART in Meyer et al. [65] and the ART in Mohri
et al. [258] and Liu et al. [271]. The ‘‘accuracy’’ of reconstructions,
compared to the max-view-count estimate, consistently improved with

Fig. 23. Empirical determination of a resolution map: (a) fluorescent dye in a glass
container that yields a sharp-edged phantom and (b) one slice of the eight-camera
reconstruction.
Source: Adapted from [211].

resolution of reconstructions will change as a function of the measured
emission field, per the ghost particle scenario mentioned earlier. That
example can be extended to the present context: consider a small sharp-
edged phantom, introducing a second phantom into the domain will
generally alter the reconstruction of the first phantom and thereby
alter the estimated resolution. In other words, the spatial resolution
of a volumetric imaging system may change throughout an exper-
iment as the target evolves, and empirical resolution maps do not
provide information about such effects. Another complication involves
the assumptions used to compute the local MTFs. To start, the ESF is
generally found by interpolating the reconstruction, and the choice of
interpolation scheme will affect the LSF and MTF. Furthermore, PSFs in
the domain are not usually spherically symmetrical and may not even
be localized to a point. For instance, a ghost particle can be thought of
as part of one particle’s PSF conditional on the distribution of the other
particles. At the very least, a 3D PSF and 3D Fourier transform would
be required to determine the actual MTF. However, the notion of local
spatial resolution breaks down in the presence of global reconstruction
artifacts. Therefore, as with the length scale metrics presented in the
previous section, empirical resolution maps must be interpreted in light
of these effects. Resolution maps in volumetric tomography are best
thought of as a rough estimate of resolution.

5.3. Optimizing the camera setup

There is usually some leeway to adjust the position of cameras in
a volumetric imaging setup. However, distinct modalities and mea-
surement scenarios may entail unique instrumentational constraints,
owing to, for instance, the size and cost of equipment, the presence
of optical obstructions (containment vessel walls and the like), and
the access needed for calibration. There is currently no prevailing

34

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 24. View configurations used in design of experiments studies with continuous scalar fields, including the (a) VLII test of Meyer et al. [65], (b) CTC test of Mohri et al. [258],
and (c) incandescence tomography test of Liu et al. [271].

By comparison, Mohri et al. [258] reported appreciable differences
between their 12-view and 24-view reconstructions, i.e., with plane-
by-plane correlations below 0.95 (Fig. 25(b)). These differences could
reflect either improved resolution of the 24-view estimate, the effects
of noise and model errors, or both. Mohri et al. [258] also analyzed the
effect of unequal spacing between the cameras and reported that, for
a constant view count, variations in angular spacing has a detrimental
effect on reconstruction accuracy. Meyer et al. [65] and Liu et al. [271]
both employed view arrangements with inconsistent angular spacing
but did not discuss the implications of camera spacing vis-à-vis ac-
curacy. While these studies broadly support the heuristics described
above, a comprehensive evaluation of reconstruction accuracy and spa-
tial resolution that accounts for interactions between the discretization
scheme and regularization (or prior information) in the reconstruction
algorithm is needed for volumetric combustion tomography.

6. Chemiluminescence

Chemiluminescence is light emitted by particles that are formed
in an excited state by a chemical reaction. The position and intensity
of chemiluminescence in a combustion process is directly related to
the reaction zone’s thermochemical state, so images of a flame convey
information about its development and stability. However, these signals
have a complex dependence upon local conditions at the point of emis-
sion as well as signal trapping by surrounding ground state molecules.
The path-integrated nature of chemiluminescence imaging is another
major limitation because reacting structures that emit chemilumines-
cence are typically thin surfaces that may be highly wrinkled, and they
are usually overlapping in any given image. It is particularly difficult
to interpret images of a practical turbulent flame. Tomography must
be utilized to pinpoint the source of emissions, and careful attention
should be paid to the experimental setup, reconstruction procedure,
and post-processing workflow in order to draw reliable conclusions
about a reactive flow from 3D reconstructions.

Tomography of chemiluminescence was introduced by Hertz and
Faris [53] in 1988. They reconstructed the 2D CH* source field of two
different premixed flames. Later, in 1996, Obertacke et al. [274] devel-
oped a volumetric chemiluminescence sensor that measured broadband
light from a brown coal combustor. The authors reconstructed a spec-
trally integrated signal that was produced by OH*, NH*, CN*, CH*,
C2*, and broadband emissions. Developments in chemiluminescence
tomography accelerated in the 2000s with the advent of low-cost digital
cameras and increased computing power. The technique, frequently
called CTC or ‘‘computed tomography of chemiluminescence’’, has thus
far been focused on the characterization of combustion instability and
measurement of 3D structures in unsteady flames. Future developments
may take advantage of spectrally-resolved imaging to quantify the
3D thermochemical state of a flame. This section describes the CTC
methodology and enumerates its key applications.

Fig. 25. Assessment of reconstructed emission fields as a function of view count. (a)
Selected 2D slices from the VLII test of Meyer et al. [65], reconstructed using four and
eight views; structures were qualitatively similar in 4-, 5-, 6-, 7-, and 8-view tests. (b)
Mohri et al.’s [258] CTC reconstructions, including correlations between the 24-view
baseline and Nviews reconstructions.

additional views in all three studies. Quantitative comparisons from
Meyer [65] and Mohri [258] are shown in Figs. 25(a) and 25(b).

Specific trends in reconstruction accuracy reported in these studies
were influenced by the imaging system (pixels per view, focal length,
f -number, etc.), reconstruction algorithm, and discretization scheme.
Moreover, view splitters introduce a trade-off between the number of
views and the pixels per view, which was not addressed by Meyer
et al. [271] but has been numerically investigated by Wang et al. [273].
Meyer et al. [65] reported convergence between multiple reconstruc-
tions using eight views (of 14), but this was the maximum number
tested due to a limitation of the SMART in LaVision’s Davis 8 software.

35

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 27. OH* chemiluminescence from an atmospheric H2/air flame. Three vibrational
lines can be seen, centered at 280, 310, and 345 nm.
Source: Adapted from [292].

Newly formed radicals populate a range of rotational–vibrational
states in one or more excited configurations, termed the ‘‘upper man-
ifold’’, and then quickly relax to a lower electronic state (typically
the ground state). Quantum ‘‘selection rules’’ determine the allowable
transitions from an upper state, j, to lower states, i [50]. Each valid
transition results in a ‘‘spectral line’’ with a characteristic vacuum
linecenter, λj→i = hc∕(Ej − Ei), where h is Planck’s constant, c is the
vacuum speed of light, and Ej and Ei are the upper and lower state
energies of the transition from j to i. The vertical axis in Fig. 26 relates
the energy of a transition to the wavelength of light emitted as a result.
Line broadening and shifting mechanisms distribute light from the j → i
transition across a short spectral region, described by a normalized line-
shape function, Yj→i, which is centered about λj→i [279]. Ultimately,
chemiluminescence emitted at any given wavelength is the sum of light
produced by all the valid transitions from the upper manifold, weighted
by Yj→i. Therefore, the source term in Eq. (4) is

I ′
λ =

≈

hc
λ

hc
λ

∑

∑

j

i∈j

Yj→i(λ) Ae

j→i

̃Nj

Ae

M∗→M

̃N ∗.

(132a)

(132b)

In Eq. (132a), Ae
j→i is the Einstein A coefficient, which indicates the
probability of spontaneous emission from j to i; 
j is the list of energy
states below j that correspond to a valid transition; and ̃Nj
is the
number density of state j. Eq. (132b) is a simplified source term that
describes the bandpass filtered signal from a generic radical, M*, where
Ae
M∗→M is the average Einstein A coefficient of the detected transitions
and ̃N ∗ is the energy state population of the detected upper states. Valid
transitions and line parameters are tabulated in the literature, e.g., for
OH [280–283], CH [284–287], and C2 [288,289], and in databases such
as HITRAN [290] and HITEMP [291].

Changes in rotational energy are small so transitions that only differ
in their upper and/or lower rotational states yield very closely-spaced
lines. These lines are rarely resolved in CTC because the instrument
linewidth is much larger than the broadened lineshape function. As
a result, Yj→i can be discarded in Eq (132b). Changes in vibrational
energy are considerably larger and the spacing between them is fairly
consistent across the excited and ground electronic states, i.e., the
energy difference associated with Δv = v′ − v′′ (see Fig. 26) is similar
for v′ = 0, 1, 2, etc. Therefore, transitions at a given Δv tend to cluster
together, forming ‘‘vibrational bands’’ which may be further divided
into ‘‘rotational branches’’.

Three vibrational bands can be seen in Fig. 27, which depicts the
OH* chemiluminescence spectrum from an atmospheric H2/air flame.
Note that individual spectral lines are convolved in this plot due to
the limited resolution of the spectrometer, resulting in large ‘‘humps’’.
The central band, Δv = 0, is much stronger than its neighbors, Δv =
−1 and 1. This is explained in part by the Franck–Condon principle,
which roughly holds that transitions are more probable when the

Fig. 26. Energetic structure of the electronic ground state and first excited state of
OH, including vibrational levels.
Source: Adapted from [278].

6.1. Signal model

A global combustion reaction results in the exothermic oxidation
of a fuel. The overall reaction occurs through a series of reversible
elementary reactions, some of which produce short-lived electronically
excited intermediate species, i.e., radicals [275,276]. Flame radicals
have an excited lifetime on the order of 10−8 to 10−6 s [51], meaning
that the emission of chemiluminescence is effectively instantaneous
compared to the evolution of most flow fields. The central wavelength
of emitted light is inversely proportional to the change in energy levels,
and a molecule’s energy levels depend on its chemical structure. As a
result, the light emitted by each radical has a unique spectral profile, or
‘‘fingerprint’’, and chemiluminescence from specific radicals can often
be isolated through the use of a narrow bandpass filter. Since each rad-
ical has its own fingerprint and every global reaction features distinct
chemical pathways, spectroscopic and chemical analyses are required
to interpret the chemiluminescence signal from a flame. What follows is
a brief overview of the physics of chemiluminescence. Details about the
quantum foundations of emission spectroscopy can be found in the texts
of Herzberg [50] and Eckbreth [5]; the chapter of Lauer et al. [277]
contains a useful engineering overview of chemiluminescence imaging.

6.1.1. Spectral structure and source term

The wavelengths at which light is emitted by an excited radical are
largely determined by the radical’s energetic structure. Fig. 26 shows
the potential energy levels of an OH (hydroxyl) radical in its electronic
ground state and first excited state. Solid curves indicate the potential
energy of a molecule in a given electronic configuration as a function of
the average distance between nuclei. At small distances, the potential
energy is high and OH molecules repel one another. At large distances,
OH dissociates into its atomic components. Intermediate distances cor-
respond to a potential well in which OH has a stable configuration. In
addition to electronic energy, molecules have quantized vibrational and
rotational energy. The vibrational levels of OH are plotted in Fig. 26.
Rotational energy levels are much closer together than electronic or
vibrational levels so they are not shown in this figure. The structure of
OH is emblematic of diatomic molecules writ large and especially of
combustion radicals like CH (methylidyne) and C2 (diatomic carbon).

36

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

intermolecular distance between the upper and lower states is small
and the vibrational energy level remains constant [5]. As a result,
chemiluminescence imaging is usually focused on emissions from the
Δv = 0 band of selected radicals.

6.1.2. Formation and deactivation mechanisms

Eq. (132) demonstrates that modeling a chemiluminescence signal
amounts to modeling the upper state population distribution, ̃Nj for all
j. This can be simplified by grouping the upper manifold into a single
state, usually indicated with an asterisk. Consider a generic radical that
has two energy levels: ground and excited, denoted M and M*. There
are three mechanisms by which M* can relax to M.

1. Chemiluminescence:

,

M∗

M +

hc
λ

Ae
M∗ →M
←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←⇀↽←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←
Be
M→M∗
where Ae
M→M∗ are the Einstein coefficients of M for
the spontaneous emission and absorption of light and λ is the
wavelength of a photon.

M∗→M and Be

(133)

2. Collisional quenching, in which the energy associated with M’s
excited state is transferred to a collision partner, Q, increasing
its translational energy:

Here, WM→M∗ = ∫ [hc∕λ]Be
M→M∗ dλ is the rate of absorption and [hc∕λ]
is the photon density. For the most part, absorption and predissociation
can be neglected [5], in which case Eq. (136) simplifies to

[M∗] =

[M][Q]kth + [A][B]kch

[Q]kQ + Ae

M∗→M

.

(137)

Hence, emissions from M* generally represent a blend of thermal
radiation and chemiluminescence.

There are two important limits to Eq. (137). First, at low temper-
atures and atmospheric pressure, thermal excitation is negligible such
that

[M∗] ≈

[A][B]kch
[Q]kQ + Ae

M∗→M

(138)

and all the radiation emitted by M* is chemiluminescence. Second, at
elevated temperatures and pressures, thermal excitation and collisional
quenching dominate chemical excitation and spontaneous emission
such that

[M∗] ≈

[M][Q]kth
[Q]kQ

= [M]

kth
kQ

.

(139)

When this occurs, the species is in thermal equilibrium and the ratio of
[M*] to [M] is given by the Boltzmann distribution,

(

−

ΔEM→M∗
kBT

)

,

(140)

M∗ + Q

kQ
←←←←←←←←←←←←←←←←←⇀↽←←←←←←←←←←←←←←←←←
kth

M + Q.

(134)

[M∗] = [M] exp

Reaction rates for quenching and thermal excitation are given
by kQ and kth.

3. Predissociation, wherein M* breaks apart into component atoms

or molecules A and B:

kp
←←←←←←←←←←←←←←←←←⇀↽←←←←←←←←←←←←←←←←←
kch

A + B

M∗

or

M∗ + Q

kp
←←←←←←←←←←←←←←←←←⇀↽←←←←←←←←←←←←←←←←←
kch

A + B + Q.

(135a)

(135b)

Predissociation is characterized by predissociation and chem-
ical formation rates, kp and kch, and may also occur during a
collision, per Eq. (135b).

The inverse mechanisms are (1) absorption,13 (2) thermal excitation,
and (3) chemical formation.

6.1.3. Detailed balance

The transient energy state population distribution of a molecule can
be described by rate equations, in terms of the activation and deactiva-
tion mechanisms listed above. Rate equations for a two-level molecule
are presented in Section 7.1.2. However, chemiluminescence features
a large number of energy states compared to LIF and an unknown
initial population distribution, so rate equations are rarely used to
model chemiluminescence (see [296] for an exception). Nevertheless,
energy transfer in chemiluminescence can be analyzed using a detailed
balance. Fiala and Sattelmayer [297] presented a simplified balance for
a two-level molecule, where Q represents a universal quenching species
and there is only a single formation reaction (involving A and B alone):

d[M ∗]
dt

= 0 ⇌

[M∗] =

[M][Q]kth + [M]WM→M∗ + [A][B]kch

[Q]kQ + Ae

M∗→M + kp

.

(136)

13 Neglecting self-absorption is not equally valid for all radicals. For in-
stance, some flames have an abundance of OH outside the flame brush that
may absorb chemiluminescence from OH* and thereby corrupt reconstruc-
tions [293]. The distribution of excited and ground state molecules can be
estimated by performing kinetic calculations for a 1D adiabatic flame, and
nonlinear techniques can be used to correct for absorption [100,294,295].

where the energy difference between M* and M, ΔEM→M∗ = hc∕λ,
corresponds to the central wavelength of emissions. At this limit, all
radiation emitted by M* is thermal radiation.

When thermal excitation is dominant, e.g., for OH in high-pressure
combustion [298], Eq. (140) can be leveraged for quantitative analysis
of the flame. However, the rates of chemical formation and collisional
quenching affect the abundance of M* in Eq. (138) and are typically
unknown. As a result, even within this ideal construction, additional
modeling would be required to infer [M] or any other thermochemical
̃N ∗, which represents a challenge to
parameters from an estimate of
quantitative chemiluminescence in many practical systems.

6.1.4. Reaction pathways

The network of reactions that gives rise to flame radicals and
thereby chemiluminescence is quite complex. Global combustion re-
actions comprise a large number of elementary steps, ranging from
several hundred for CH4 [299] to several thousand for liquid hydro-
carbon fuels [300]. The interplay between elementary steps in a given
thermochemical environment, itself influenced by flow conditions, gov-
erns the number density and hence the intensity of light emitted by
each radical.

One-dimensional flame simulations can be used to understand the
relationship between QoI, such as the equivalence ratio and heat re-
lease rate, and one or more chemiluminescence source fields [301].
These simulations are based on coupled continuity, momentum, energy,
and species equations, which can be solved using a widely-available
software package like PREMIX [302], Cantera [303] or FlameMas-
ter [304]. Source and sink terms in the species equations require a
kinetic mechanism, such as GRI-Mech 3.0 [299] for the oxidation of
CH4, which must be supplemented to account for the production of
chemiluminescent species. The reaction kinetics that yield OH*, CH*,
and C2* were studied in detail by Kathrotia et al. [305–307], and the
kinetics responsible for CO2* and other broadband emitters were in-
vestigated by Kopp et al. [308,309]. Reactions and rate constants from
these studies can be added to an appropriate mechanism to simulate
the distribution of radicals throughout a flame. However, results are
highly sensitive to the mechanism, and validation tests are needed to
ensure a suitable selection of reactions [310]. This approach has been
demonstrated by Kojima et al. [25,311,312], Nori and Sietzman [313–
315], and many others. Notably, Smith et al. [316–318] utilized Abel
inversion to assess chemiluminescence mechanisms for axisymmetric

37

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 28. Reaction pathway diagram for a CH4/air flame. Broadband emissions from
CO2* are produced along the primary reaction path whereas CH* and OH* are formed
along minor paths. The fuel and combustion conditions have a significant effect on the
relative abundance of radicals.
Source: Adapted from [277,320].

flames, and Zhao et al. [319] recently applied this method to study
H2-enriched fuel.

Fig. 28 depicts a typical reaction pathway diagram for a premixed
CH4/air flame; these reactions were tabulated using CHEMKIN by Najm
et al. [320] and annotated by Lauer et al. [277]. The emission spectrum
produced by this flame is plotted in Fig. 29(a) and the global reaction
is

CH4 + 2 O2 → CO2 + 2 H2O.

(141)

Green arrows in Fig. 28 indicate the dominant pathway, which pro-
duces CO2* among other (non-excited) species. However, carbon diox-
ide is a triatomic molecule with a complex energy structure, and CO2*
generates a faint glow of broadband light as a result [309]. Never-
theless, CH* and OH* are produced along minor paths in sufficient
quantities to yield stronger, narrower emissions.

In general, per [277,306], the elementary steps thought to dominate

the formation of CH* are

C2 + OH → CH∗ + CO2,
C2H + O2 → CH∗ + CO2,

and

C2H + O → CH∗ + CO;

the steps responsible for OH* are

CH + O2 → OH∗ + CO

and

H + O + Q → OH∗ + Q;

and the steps responsible for C2* are

CH2 + C → C2

∗ + H2

and

C3 + O → C2

∗ + CO.

However, the relative prevalence of these reactions is still debated
[277].

6.1.5. Controlling parameters

Aggregate and local flame parameters are used to summarize reac-
tion pathway and spectroscopic effects on chemiluminescence signals.

38

Fig. 29. Chemiluminescence spectra from an atmospheric premixed natural gas/air
flame using a (a) stoichiometric mixture and (b) lean mixture (equivalence ratio of
0.7).
Source: Adapted from [277].

These relationships can be leveraged to quantify local conditions from
reconstructed source fields. As an example, Fig. 29 shows the chemi-
luminescence spectrum of a stoichiometric natural gas/air flame as
well as that of a lean flame. Both flames exhibit significant CH*, OH*,
and C2* emissions, as well as a broadband continuum, and vibrational
bands of the diatomic radicals are clearly visible in the stoichiometric
case. The equivalence ratio has a profound effect on these spectra:
visible contributions from CH* and C2* are far less distinct in the lean
flame because carbon is subtracted from the minor reaction branches
shown in Fig. 28 as the equivalence ratio decreases [320]. Crucially,
this effect is known to be independent of strain in premixed turbulent
flames of moderate intensity [310] such that the local, broadband-
corrected OH*/CH* ratio [321] can be used to estimate the local
equivalence ratio. This was demonstrated in [313,322–324].

Lauer et al. [277] enumerated seven key combustion parameters

that influence chemiluminescence. Namely, the

1. fuel/oxidizer combination,
2. turbulent intensity (often characterized using a Reynolds num-

ber),

flow),

4. mean pressure,
5. reactant (or preheat) temperature,
6. degree of premixing, and
7. equivalence ratio (if premixed).

Each of these parameters plays a significant role in the combustion
process, thereby affecting the production of radicals and hence the
emission spectrum. Accordingly, CTC reconstructions should be inter-
preted in light of these parameters. Indeed, the high complexity of
chemiluminescence measurements poses a barrier to the quantitative
interpretation of CTC reconstructions, and most demonstrations are
better conceptualized as ‘‘semi-quantitative’’ in nature.

(142a)

(142b)

(142c)

(143a)

(144a)

(144b)

(143b)

3. overall heat release (closely connected to the overall fuel mass

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 30. Examples of multi-camera CTC setups from (a) Weinkauff et al. [337] and (b) Jin et al. [187].

Many studies have experimentally examined the spectral effects
of the parameters listed above, usually by adjusting them one at a
time. For instance, [311,314,325–327] varied fuel composition, [325,
328–334] studied flow rate effects, [310,313,314,320,323,325,330,
335] investigated the equivalence ratio, [313,314,334] the reactant
temperature, and [314,315,327,333,336] looked at pressure. In gen-
eral: the fuel and oxidizer combination determines the overall spectral
structure, and the fuel flow rate is linearly related to the intensity of
chemiluminescence in adiabatic flames (although this is more compli-
cated in non-adiabatic combustion). Per Fig. 29, the equivalence ratio
can alter the relative abundance of radicals, and increasing pressure
causes the background continuum to swell in comparison to emissions
from diatomic radicals, diminishing the visibility of OH* and CH*.
A detailed overview of these relationships can be found in Lauer
et al. [277].

6.2. Instrumentation

The generic laboratory setup for chemiluminescence imaging is in-
herently non-intrusive, simple to configure, and achieved at a relatively
low cost [316,338], making this technique an ideal starting point for
flame tomography. One or more cameras are equipped with a suitable
lens and filter. The lens is usually selected to keep the region of interest
in focus, as described in Section 5.3.1 (Eq. (131)), and a bandpass
filter should be employed to eliminate unwanted emissions, including
chemiluminescence from off-target radicals like CO2* and thermal radi-
ation from hot water vapor. Industrial and scientific cameras have both
been used for CTC. The former are far less costly, but low-cost cameras
often have a limited frame rate, long exposure time, nonlinear sensor
response, rolling shutter, and limited sensitivity to non-visible radia-
tion, e.g., UV emissions from OH*. Conversely, high-speed scientific
cameras offer a consistent sensor response, fast and controlled exposure
times, global shutter, and greater resolution, among other advantages.
Intensifiers are generally required to image UV emissions, and multi-
camera systems should be simultaneously triggered using a delay/pulse
generator.

In the case of a statistically stationary flame, one can record the
projections needed to characterize the target with a single camera by

1. using a single image, assuming the flame is axisymmetric [319];
2. rotating the flame/burner [339];
3. moving the camera around the burner [54]; or
4. generating virtual views by phase-averaging [340].

A single image of an axisymmetric flame is sufficient for Abel inversion
(Section 2.3.2), and a large number of projections (real or virtual) can
be measured in scenarios 2–4, thereby facilitating FBP reconstruction
(Section 2.3.1). However, a network of synchronized cameras is needed
to obtain instantaneous or time-resolved reconstructions of an unsteady
combustion process.

Sample multi-camera setups are pictured in Fig. 30. In general,
the cameras are arranged around the burner with equal angular spac-
ing. As discussed in Section 5.3, adding more cameras increases the
accuracy of reconstructions, although the number of cameras needed
for CTC depends on the requisite level of accuracy and complexity
of the flame. Camera setups reported to date vary considerably in all
respects, including the sensor size, spectral response, focal length, and
selection/use of filters. For instance, Weinkauff et al. [337] used eight
cameras (2560 × 2160 px with 6.5 μm pixels) positioned around a half-
circle to reconstruct a moderately turbulent jet flame (Re = 5000);
Jin et al. [341] used a semicircle of 12 cameras (1920 × 1200 px
with 5.86 μm pixels) to measure an unsteady laminar flame; and Ma
et al. [55] imaged a premixed turbulent Bunsen flame with six high-
speed cameras (900 × 600 px with 12 μm pixels). The make, model and
number of cameras are usually determined by the available funds. Tem-
poral resolution and sensor linearity trade-off against spatial resolution,
i.e., faster cameras with large precision sensors may be preferred to
more cameras at a lower unit cost. However, there is a lack of detailed
investigations concerning the design of CTC experiments, and most
papers simply report the setup without providing much justification
for the system’s design. One study by Mohri et al. [258], covered
in Section 5.3, was conducted with the 24-camera system shown in
Fig. 24(b) (659 × 494 px with 9.9 μm pixels). The authors reconstructed
instantaneous snapshots of a turbulent swirl flame and found that there
is a significant return to increasing the camera count beyond 12; this
finding was also supported by a numerical study.

Several groups have increased the view count of their CTC system
without adding cameras. One offbeat configuration which appeared
early on was that of Ishino and Ohiwa [127], who mounted 40 lenses
along a half-circle (Fig. 31(a)). Free-falling slit shutters were placed
in the front of the lenses and a long strip of panchromatic film was
positioned behind them. The film was responsive from 400–600 nm
(i.e., sensitive to chemiluminescence from CH*, C2*, and triatomic
radicals), and the shutters were triggered in unison to generate 40
synchronous images with a 1.2 ms exposure time of a turbulent pre-
mixed C3H8/air flame. The film was developed and digitized into
380 × 550 px images, which were processed using the MLEM algorithm
(Section 2.3.5), resulting in high-quality 3D reconstructions. However,
despite the success of this effort, most modern CTC setups use digital
cameras due to the labor-intensive workflow associated with Ishino’s
technique.

In general,

‘‘view splitting’’ is achieved by relaying light from
multiple perspectives onto one camera chip using mirrors, prisms,
and/or fiber optics. View splitters that project two or four views onto
a single sensor using only mirrors and prisms are called stereoscopes
and quadscopes, respectively. Gilabert et al. [343] designed an early
stereoscope for an incandescence tomography experiment (Section 8),
which is similar to CTC from an instrumentation perspective. Stereo-
scopes have also been added to CTC sensors by Floyd et al. [344,345]
and Yu et al. [103]. Fig. 31(b) depicts a quadscope from the group of
Meyer [60], this particular quadscope was used for VLIF (Section 7) but

39

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 31. Methods to project multiple views onto a single sensor (i.e., view splitters): (a) multi-lens imaging with continuous photographic film [127], (b) mirror-and-prism-based
quadscope [60], and (c) single-camera FBE imaging [342].

similar devices have been employed in CTC experiments. Utilizing one
sensor to capture two or four views usually improves the resolution of
reconstructions, although additional views are achieved at the cost of
reducing the number of pixels per view. Moreover, the range of views
that can be acquired with a stereoscope or quadscope is limited and
optics mounts invariably obstruct a portion of the sensor.

Alternatively, fiber bundles can be arranged to image light from
a large number of perspectives onto a single camera sensor, which
enables time-resolved volumetric CTC using only one or two cameras.
This concept was introduced by Anikin et al. [346,347], who developed
a system of telescopes, mirrors, and fibers to collect projections from a
180◦ arc onto a single CCD sensor. The authors used a UV filter centered
at 334 nm and an intensified CCD camera to record 90 projections of
OH* from a CH4/air flame, which was reconstructed with a custom
algorithm. However, Anikin et al. [346,347] only reconstructed 2D
slices of their flame. More recently, telescopes have been replaced
with fiber-based endoscopes (FBEs) to project 2D images from multiple
views onto subregions of a camera sensor, as depicted in Fig. 31(c).
This technique has been developed and demonstrated by the groups of
Yan [61,348–350], Ma [55,342,351–355], Cai [213,271,356,357], and
Yu [212,358–360]. FBEs are often needed to conduct time-resolved CTC
due to the cost of high-speed cameras. However, these devices also pose
several challenges, namely:

1. it is difficult to properly align the fiber outputs with pixels on a

camera’s sensor,

2. the number of pixels per view is reduced,
3. the signal can be diminished by up to 90% [295], and
4. there is usually vignetting at the edge of the projections.

Details on the characterization of FBEs for flame tomography can be
found in Hossain et al. [349] and Kang et al. [351].

6.3. Characterizing 3D combustion structures

A significant portion of studies using CTC have focused on recon-
structing and analyzing the shape of one or more unsteady flames us-
ing an instantaneous, phase-averaged, or time-resolved configuration.
While these works do not relate the reconstructions to thermochem-
ical QoI, 3D reaction surfaces are useful for qualitative analysis of a
combustion system.

In some circumstances, the overall flame shape provides impor-
tant information about a combustion process [361–364]. For instance,
swirled flames are ubiquitous in gas turbines and a host of other
industrial devices. Laboratory-scale swirl flames are a common target
for CTC since they can be tailored to produce a wide swathe of
turbulent structures that are representative of premixed combustion in
practical engineering devices. For example, Mohri et al. [258] used
instantaneous CTC to reconstruct a series of turbulent CH4/air swirl
flames, two of which are depicted in Fig. 32. The flames exhibited
an M-shape at stoichiometric conditions but transitioned to a V-shape

Fig. 32. Exemplary slices of a swirl-stabilized TECFLAM flame reconstructed by Mohri
et al. [258]. M- and V-shaped flames, drawn in yellow, were observed at different
equivalence ratios, highlighting the presence of a PVC at lean conditions.

during leaner operation, and the degree of wrinkling increased with
the height above the burner at both equivalence ratios.14 Swirling jet
flames in the wake of a bluff body typically curl over to form an M-
shaped shear layer, highlighted by the yellow line in the top panel of
Fig. 32. These flames have two re-circulation zones: the inner zone
sits directly above the bluff body while the outer zone is contained
between the shear layers. By contrast, the reaction zone in a V-shaped
flame resides fully within the inner shear layer, which can suppress a
hydrodynamic instability called the precessing vortex core (PVC). PVCs
enhance fuel/air mixing within the inner recirculation zone and are
thought to cause roll-up, stretch, and local quenching of the reaction
zones [362]. Consequently, M- and V-shaped flames yield distinct
temperature fields, pollutant emissions, and stability characteristics.
Visualizing the shape of one or more flames, as in [258], can thus
be used to deduce various aspects of a burner’s performance. Further,
given a large sequence of instantaneous measurements (albeit not time-
resolved), flow decomposition can be conducted to reveal coherent
dynamical structures such as a PVC [366–369].

Phase-resolved reconstructions help to grasp and track dynamic
phenomena, and can often be realized with a single camera. Samaras-
inghe et al. [370] assessed the behavior of acoustically-forced flames

14 Such observations cannot be made via 2D measurements, such as the H2O

reconstructions in [365].

40

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

which has long been used to assess combustion structures, e.g., to
identify a departure from equilibrium conditions [51]. Foo divided the
29 cameras into three groups, equipped with a narrow bandpass filter
centered on CH* chemiluminescence, thermal emissions from strontium
monohydroxide Sr(OH), and those from atomic Na. These salt tracers
only radiate in the hot products and hence they highlight the burnt
side of the flame/re-circulation zone. Fig. 33 depicts instantaneous and
time-averaged CH*, Sr(OH), and atomic Na reconstructions from Foo
et al. This information enables qualitative analysis of the complex flame
and flow structures produced by a multi-stream burner, and subsequent
tests were conducted to characterize the statistics of a nanoparticle
reactor [33]. multi-spectral data of this variety can also be harnessed
for quantitative measurement, as covered in Section 6.5.

6.4. Quantifying flame morphology

Manually identifying combustion phenomena from volumetric mea-
surements is a laborious task that may be subject to considerable
observer bias. Therefore, many CTC practitioners post-process their
reconstructions to quantify the propagation speed and geometric prop-
erties of reacting surfaces, viz., surface area, volume, and curvature [55,
56,354,378–383]. This is an attractive prospect because, in addition
to providing insight about key phenomena (stretch, local quenching,
pocket formation, and the like [384]), spatially-resolved propagation
speed and flame shape statistics calculated from CTC reconstructions
can be compared to those produced by a CFD simulation for validation
purposes. Although such a comparison has yet to be made, there is a
rich literature on the numerical simulation of these properties [385–
388]. Most CTC studies in this area feature a unique algorithm to
extract flame surfaces using some combination of thresholding re-
constructions, calculating gradients, fitting surfaces, and discretizing
curvature equations. As an example, Fig. 34 contains a schematic
depiction of the flame surface identification procedure developed by
Wiseman et al. [378]. They first pinpointed voxels bounded by large
gradients of the reconstruction and then fit polynomial surfaces to the
selected regions. The fitted surfaces were used to estimate principal,
mean, and Gaussian curvatures as well as the overall propagation
velocity, i.e., the flow velocity plus the reaction speed normal to the
surface. Alternatively, Ma et al. [55,354,382] used thresholding and
discrete curvature equations, Dong et al. [380] fit ellipsoids to quasi-
spherical ignition kernels, and Yu et al. [383] proposed a generic
point-based method in which curvature metrics are calculated from
a triangle mesh that is fit to a cloud of points on the reconstructed
surface.

In an early attempt to extract quantitative information by way of
CTC, Ishino et al. [381] estimated the local flame speed in a turbulent
premixed C3H8/air flame from the relative motion of the flame front
in successive planar cross sections (Fig. 35). Ishino and his coauthors
assumed a uniform flow field throughout the interrogation region,
calculated from the inflow rate, which would be difficult to verify. Ma
et al. [354] measured ignition kernels in a Mach 2 cavity combustor
using two high-speed cameras that were equipped with a total of
eight FBEs. Projections were recorded at 20 kHz, which was sufficient
to observe the kernels from their initial spark to stable combustion.
Moreover, since the flame speed was considerably lower than that
of the flow, time-resolved kernel positions were used to extract La-
grangian 3D3C velocity data from the reconstructions. Dong et al. [380]
conducted a similar study of ignition kernels in a liquid-fueled gas
turbine model combustor. By monitoring a kernel’s shape over time,
quantified by fitting an ellipsoid to individual kernels at each timestep,
the authors were able to decouple advection from burning to produce
a more reliable estimate of the turbulent flame speed. Measured flame
speeds were used to specify a flame speed model, confirming the
presence of a self-similar propagation regime. Fig. 36 depicts sequential
reconstructions of four kernels from this study. More recently, the same

Fig. 33. Slices from simultaneous 3D reconstructions of CH* (blue), Sr(OH) (red), and
atomic Na (green). These fields highlight the location of combustion and hot products
from each annulus of the Cambridge–Sandia swirl burner.
Source: Adapted from [32].

in a lean premixed swirl-stabilized multi-nozzle can combustor using
phase-averaged tomography of CH*. Around the same time, Worth
and Dawson [54] employed phase-averaged tomography of OH* to
investigate vortex–flame interactions using a pair of adjacent bluff-body
stabilized CH4/air jet flames. As in the work of Samarasinghe, Worth
and Dawson utilized variable acoustic forcing to stimulate flame–vortex
interactions; the authors demonstrated that collisions between vor-
tices generated in the flames’ shear layers lead to the formation of
complex structures at the interface, potentially causing an instability.
The authors also introduced the practice of benchmarking volumetric
reconstructions against planar measurements, using OH PLIF in [54].
Their CTC and PLIF results exhibited strong qualitative agreement,
supporting the use of CTC for analysis of 3D flame topology, but
the PLIF images revealed an abundance of ground state OH, which
could potentially corrupt reconstructions by way of signal trapping.
Simultaneous planar validation, conducted with PLIF or planar Mie
scattering, has since been developed by the groups of Ma [58,371,372]
and Dreizler [373], discussed further in Section 7.

Given a large number of views, time-resolved volumetric measure-
ments are the gold standard for monitoring the evolution of complex
3D combustion structures, which are difficult to follow in 2D (due
to out of plane motion) and are not captured by instantaneous or
phase-resolved reconstructions. Sample CTC measurements of a swirl
flame were conducted at 4 kHz by Yu et al. [374] and at 1 kHz by
Ruan et al. [375]. Yu et al. resolved local extinction and bisection
events as well as a robust helical structure, indicative of a PVC, in a
lean laboratory-scale CH4/air flame. Ruan later conducted CTC in a
model gas turbine combustor (i.e., within a quartz confinement vessel)
using a lean mixture of CH4 and air. The flame rotated in the same
direction as the swirler, propagating downstream in a helical fashion.
This was confirmed by tracking the flame centroid in a series of phase-
averaged reconstructions. Detailed inspection of the results revealed
pocket stretching at the tip and local quenching at the throat.

In addition to spatio-temporal resolution, multiple filters can be
used to visualize distinct combustion structures, called multi-spectral
CTC. Recently, Foo et al. [32] used 29 cameras to simultaneously
reconstruct instantaneous combustion structures at three distinct wave-
lengths. They used the dual-annulus Cambridge–Sandia swirl burner
[376,377] to produce a nested set of premixed CH4/air flames; in
addition, the outer annulus was seeded with Sr(NO3)2 and the inner
annulus with NaCl. Adding vaporized alkali metal salts like Sr(NO3)2
or NaCl to a flame leads to thermal radiation with a distinct color,

41

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 34. Sample procedure to extract a flame surface from a reconstructed source field: (a) 2D cross section from a 3D reconstruction, (b) gradients of the source field, (c) pixels
bounded by large gradients, and (d) the magnitude and direction of curvature. Volumetric estimates of the mean surface curvature are shown in (e). Note that six views can be
sufficient to estimate curvature throughout much of the flame surface.
Source: Adapted from [378].

Fig. 35. Volume rendered surface and selected cross sections of an unsteady premixed
C3H8/air flame. Sequential reconstructions were used to estimate the burning speed.
Source: Adapted from [381].

group adopted the point cloud method of Yu et al. [383] to measure
the propagation velocity of a lifted diffusion flame [379].

As a cautionary note: it is important to consider the source of
emissions when using CTC to quantify flame shape properties. Many
of the studies surveyed above employed broadband chemiluminescence
or luminosity (including soot incandescence) as a flame front marker.
However, the distribution of radicals is not constant throughout a flame
brush, as discussed in the next section. Aggregating all the visible
emissions leads to an overly-broad ‘‘flame surface’’ that can distort esti-
mates of the surface area, curvature, or propagation speed. Moreover,
research groups tend to use an in-house code to assess, identify, and
characterize combustion surfaces, generally without any ground truth
for comparison. Therefore, a rigorous, open assessment of flame shape
calculation workflows is needed.

6.5. Field variable measurements

Quantifying field variables like the equivalence ratio or number
density of a target radical is of considerable interest in CTC. Unfor-
tunately, the intensity source field at one wavelength is ambiguous
with respect to the thermochemical state of a flame. Not only that,

Fig. 36. Spatio-temporal evolution of four reconstructed flame kernels in a liquid-
fueled gas turbine model combustor. The kernels’ morphological time history was used
to estimate the turbulent flame speed.
Source: Adapted from [380].

but the number density of an excited radical, which can be used
to estimate reaction rates or validate a kinetics model, cannot be
determined without compensating for emissions from the background
continuum. Hence, multi-spectral measurements are generally required
for quantitative field measurements in chemiluminescence tomography.
Chemiluminescence is related to both heat release and the equiva-
lence ratio, and there is a long history of assessing these parameters
via 2D chemiluminescence imaging [322]. The relationship between
chemiluminescence and the heat release rate is modulated by the equiv-
alence ratio as well as turbulence–chemistry interactions [320,321,330,
334,389], commonly characterized in terms of the local strain rate and
flame curvature. Despite the complications associated with mapping
heat release, the equivalence ratio can be assessed without knowledge
of the strain rate in weakly-turbulent natural gas/air flames, which are
regularly used to study gas turbine combustion [322]. The equivalence
ratio is estimated from the ratio of the reconstructed OH* source field

42

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

suitable correction procedure [321,391]. Lauer and Sattelmayer [321]
reported that the continuum can be fit with a fifth-order polynomial;
after subtracting the background emissions, empirical spectra are used
to model the diatomic peaks. This information is combined with filter
transmission profiles to specify a system of equations that relates the
unknown emissive power of each radical to the measured signals.
Solutions can be pre-calculated and tabulated in a look-up table. Back-
ground correction requires one filter/measurement per target radical
and another filter for the background continuum.

The need to use background correction in order to measure the
equivalence ratio is debated. Hardalupas et al. [323] used a Cassegrain
reflector to collect the emission spectrum of a methane/air flat flame
in a quasi-point probe volume. The authors investigated relationships
between OH*/CH*, C2*/OH*, and C2*/CH* across a range of equiva-
lence ratios from 0.7 to 1.3 and strain rates between 80 and 400 s−1.
Hardalupas observed that OH*/CH* was independent of strain, while
other ratios were not. Moreover, the authors claimed that the OH*/CH*
ratio and background continuum are similarly affected by the equiv-
alence ratio and strain such that uncorrected signals can be used to
estimate the equivalence ratio. Conversely, Cheng et al. [392] used a
similar setup to study similar flames but reported a strong dependence
on the background correction, as did Docquier et al. [393,394]. Mu-
ruganandam et al. [395] provided further evidence that background
correction is needed, showing that the use of a correction significantly
increases sensitivity to the equivalence ratio. Therefore, correcting
diatomic signals for quantitative evaluations is advisable.

Measurements of the absolute excited state number density of a
radical can also be performed via chemiluminescence tomography.
This is done using the relationship in Eq. (132), in which ̃N ∗ is
proportional to the reconstructed source field, I ′
λ. There are two key
considerations when conducting such measurements. First, an absolute
intensity calibration is required to estimate I ′
λ (by contrast, scaled
intensities are acceptable for ratiometric estimates of the equivalence
ratio). Calibration is performed with a light source that produces a
known radiance. For example, Walsh et al. [396] used Rayleigh scat-
tering, Giassi [397] measured incandescence from a heated SiC fiber,
and Zhao et al. [319] recorded incandescence from a radiant source
using an integrating sphere. Once the cameras have been calibrated and
an absolute intensity field has been reconstructed, the average Einstein
A coefficient is used to estimate ̃N ∗. Ideally, Ae
M∗→M is an average of
̃Nj ,
Ae
j→i that is weighted by the relative population of upper states,
and the filter transmittance at λj→i if τf,λ is not constant. However,
the excited state population distribution is not known a priori and may
exhibit a non-equilibrium distribution. Hence, this coefficient must be
modeled, e.g., using the approach of Brockhinke et al. [296]. However,
there is limited discussion of Ae
M∗→M in the literature. Sample absolute
CH* number densities in an axisymmetric CH4/air flames are shown in
Fig. 38. These results were used to benchmark numerical simulations
of microgravity combustion [397].

Thus far, CTC has only been utilized to estimate axisymmetric
equivalence ratio or number density fields, e.g., corresponding to a
laminar [397] or statistically stationary [398] flame, which can be
measured using a single camera. However, view splitters equipped with
multiple filters [62] or large camera count systems [258] could enable
time-resolved, volumetric, quantitative CTC.

6.6. Assessing combustion instability

Thermoacoustic instability is highly problematic in jet engine aug-
menters, power generating gas turbines, rockets, boilers, and even small
household burners, leading to reduced efficiency, increased emissions,
and even catastrophic failure [399]. The effect occurs when pressure
fluctuations, P ′, produced by an enclosed flame become resonant in the
̇q′, which can
combustor and couple to heat release rate fluctuations,
lead to an unstable positive feedback loop. Instabilities take hold when
P ′ and ̇q′ are coupled in-phase and generate more energy than is lost
to damping. Growing instabilities can produce excessive mechanical

43

Fig. 37. The relationship between the integral OH*/CH* ratio and equivalence ratio of
a swirl stabilized natural gas–air flame exhibits considerable variability across operating
parameters.
Source: Adapted from [390].

to that of a carbon-based radical, most often CH* but also C2* or even
CO2*. Experiments have shown that, for premixed hydrocarbon flames
of moderate turbulent intensity, there is a monotonic (albeit nonlinear)
relationship between the OH*/CH* ratio and the equivalence ratio. This
relationship is an emergent property of the reaction pathways depicted
in Fig. 28: as the fuel becomes richer, the amount of carbon reacting
along minor pathways increases, thereby decreasing the ratio of OH*
to CH* [320].

Sample OH*/CH* vs. equivalence ratio curves for premixed CH4/air
flames are shown in Fig. 37, showing pressure and preheat temperature
dependencies [390]. While simulations based on a 1D flame model
can recover these trends [315], numerical results are highly sensitive
to chemiluminescent reaction rates in the mechanism, which must
be verified with experiments to begin with. Therefore, the simplest
approach to calibrate the OH*/CH* ratio to equivalence ratio curve
is through controlled experiments. Usually, a laminar flat flame is
operated across a range of equivalence ratios and imaged with a
representative optical setup. Ratios of ‘‘global’’ OH* to CH* (or C2* or
CO2*) chemiluminescence are plotted against the known equivalence
ratios, where the global intensity from a radical is the total image
intensity. One should note that there is no guarantee of a monotonic
relationship between OH*/CH* and the equivalence ratio, however.
For instance, Nori [314] reported experimental measurements of high-
pressure, preheated, premixed CH4/air flames; the OH*/CH* ratio was
concave at 5 bar, exhibiting a complex dependence on the preheat
temperature at this pressure, but the trend reversed at 10 bar. In
other words, the relationship cannot be assumed or simply interpolated
but must be established for the operating conditions of interest on a
case-by-case basis.

Another key factor is the effect of broadband radiation on diatomic
chemiluminescence signals. That is, the continuum in Fig. 29 makes a
differential contribution to measurements of OH*, CH*, and C2* signals,
and these contributions depend upon the fuel chemistry and optical
filter used to isolate each peak. ‘‘Broadband subtraction’’ or ‘‘correc-
tion’’ refers to the process of eliminating the contribution of broadband
chemiluminescence from measurements of a diatomic radical like OH*
or CH*. It has been observed that emissions from individual radicals
as well as the broadband continuum exhibit a self-similar profile for a
wide range of flame parameters [321].15 Therefore, spectrally-resolved
measurements of a calibration flame can be employed to establish a

15 This is not true for rotationally-resolved spectra but is a good ap-
those in

proximation for vibrationally-resolved measurements,
Fig. 29 [277].

such as

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

̇q ∝ I ′

of gas turbine engines. Many authors have assumed that this global
relationship holds for local oscillations,
λ, in which case a time-
resolved pressure trace and OH* or CH* source field could be used to
evaluate the sign of Rf and Θ. Unfortunately, this assumption is invalid.
Turbulence has a significant impact on the spatial location of minor
reaction pathways throughout a reacting surface [310,321,326,402].
Therefore, simultaneous or phase-averaged velocity measurements are
needed to estimate strain and correct the source field to obtain a signal
that is truly proportional to ̇q. Lauer et al. [326] developed such a
correction procedure. However, the results reported below are based
on heat release rate surrogates that do not account for strain and are
thus subject to error.

Most studies reporting a Rayleigh field used an axisymmetric recon-

struction workflow, in which case the definition of Rf is

Rf (r, z) =

tp

2πr
tp

∫
0

P ′(t) ̇q′(r, z, t) dt,

(146)

as proposed by the group of Santavicca [403–407]. However, while
this definition is reasonable, the radially-integrated fluctuating field
̇q′(r, z, t) cannot be recovered from one view, alone, because the in-
verse Abel transform does not apply to projections of an instantaneous
non-axisymmetric flame. Hence, whereas many groups have utilized ax-
isymmetric CTC to calculate the Rayleigh field in Eq. (146), e.g., [334,
403,408–410], or the RMS intensity source field, e.g., [411,412], these
results must be interpreted with caution.

Multi-view reconstructions of combustion dynamics are more appro-
priate for analysis of the Rayleigh field. For instance, swirl at the inlet
of a gas turbine combustor generates a recirculation zone, resulting
in a region of slow flow that anchors the flame but also leads to
hydrodynamic instabilities, including helical modes and a PVC [28].
Helical structures can manifest in the inner and outer shear layers
of the annular jet in swirling combustion, directly affecting the local
rate of heat release. The resulting fields are non-axisymmetric and
cannot be fully understood from LoS-integrated images or axisymmetric
reconstructions.

Moeck [340], Geraedts [29], Yu [30], Lückoff [413], and their
coauthors studied the interactions between a PVC and thermoacous-
tic modes by reconstructing non-axisymmetric combustion structures.
Moeck et al. were the first to estimate a non-axisymmetric heat re-
lease rate surrogate in a swirling flame. They recorded broadband
chemiluminescence from a lean CH4/air flame with a single high-speed
camera, resulting in a qualitative estimate of ̇q′. The helical frequency
was extracted from a Fourier transform of the image sequence and
the authors resolved and reconstructed 180 views of this mode by
phase-averaging the images. Geraedts [29] also employed a single-
camera setup, using a bandpass filter to isolate OH* emissions, but
they incorporated pressure measurements to facilitate double phase
conditioning and then calculate phase-specific Rayleigh fields. Energy
transfer between six coherent thermoacoustic modes from this study
are shown in Fig. 39. Yu et al. [30] utilized an FBEs system and
CH* filter to estimate instantaneous Rayleigh fields, and Lückoff and
Oberleithner [413] used OH* emissions to investigate a PVC’s response
to acoustic forcing. The latter experiment demonstrated direct control
of the PVC without qualitatively altering the overall flow dynamics.
This technique can be used to enhance or damp turbulence at the flame
root. Multi-camera sensors and/or multi-phase conditioning could also
be used to assess instabilities in multi-flame configurations of direct
relevance to practical combustors. However, it bears emphasis that
strain-correction is required to properly assess oscillations in ̇q.

Despite the advantages of multi-view CTC, a good deal of infor-
mation can be gleaned by reconstructing mean projections [405–407,
410,414–417]. This is often done in concert with additional diagnos-
tics [410,417–420]. As an example, Palies et al. [414] used recon-
structions of OH*, laser Doppler velocimetry, and hot wire velocimetry
to both construct and interpret the flame describing function of swirl
flames subjected to acoustic forcing. Notably, the authors estimated the

Fig. 38. Comparison of measured CH* distribution under normal (1 g) and reduced
(0 g) gravity over a range of fuel blends. F and C in the figure stand for fuel and
coflow, respectively.
Source: Adapted from [397].

and heat loads that diminish performance and may ultimately cause
lasting damage to the system. Considerable research effort has thus
been invested in characterizing combustion instability, with an em-
phasis on lean premixed combustion and a recent focus on alternative
low-carbon fuels. Axisymmetric chemiluminescence tomography has
long been used to help identify instability mechanisms and verify
the performance of damping strategies. Further, phase-averaged and
time-resolved reconstructions of non-axisymmetric structures are in-
creasingly leveraged to understand the spatio-temporal characteristics
of incipient instabilities.

One way to assess the stability of a flame is through the eponymous
criterion proposed by Lord Rayleigh in 1878 [400]. The Rayleigh
field, Rf , describes local coupling of pressure and heat release fluctu-
ations over a characteristic period, tp [401]. Integrating the Rayleigh
field yields a Rayleigh index, Θ, which must be greater than zero for
thermoacoustic instability to arise:

Rayleigh field, Rf (x)
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞

tp

1
tp

∫
0

P ′(x, t) ̇q′(x, t) dt dx

∫∫∫
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟
Rayleigh index, Θ

> 0.

(145)

When Θ is negative, then P ′ and ̇q′ are coupled out-of-phase such
that acoustic energy is damped by the flame. Conversely, a positive
value indicates in-phase coupling, which can lead to unstable operation.
Eq. (145) must be satisfied for thermoacoustic instabilities to develop,
but it is not a sufficient condition since various damping mechanisms
can remove acoustic energy, e.g., mechanisms like viscous dissipation,
flame–vortex interactions, and entropy waves. Moreover, Θ > 0 is
merely a post-hoc marker of stability and does not inherently yield
causal information about the source of instability. Nevertheless, the
Rayleigh criterion is a useful indicator of unstable combustion and the
Rayleigh field can convey spatial information pertaining to the onset of
instability.

The wavelength of pressure waves is usually much longer than a
flame so pressure is assumed to be constant across the burner. In other
words, P ′(x, t) ≈ P ′(t) and pressure fluctuations can be monitored using
one or two transducers. There is also a linear relationship between
global values of ̇q′ and the spatially-integrated chemiluminescence signal
from OH*, CH*, and CO2* in many premixed flames [322],16 including
natural gas or CH4/air flames, which are highly-relevant to the study

16 The C2* source field is a more problematic indicator [323].

44

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Volumetric LIF is conducted by exciting a target species with a laser
slab, recording the fluorescence with a series of cameras, reconstructing
the intensity source field, and potentially interpreting the field with
a LIF model. Two-dimensional LIF tomography was implemented in
2000 by the group of McCann [427,428] and first extended to 3D
by Wu et al. [58] in 2015. In the latter study, the authors visualized
a turbulent gas flow seeded with iodine. Since then, several groups
have implemented and refined a VLIF setup, and the method has been
used to characterize turbulent jets and flames. The LIF signal model
is presented below, followed by notes on instrumentation and key
applications. Future developments are discussed throughout.

7.1. Signal model

Laser-induced fluorescence involves the same coupled rotational,
vibrational, and electronic transitions that occur in chemiluminescence.
However, the controlled excitation mechanism used to generate fluores-
cence enables a suite of quantitative techniques that are not applicable
to spectra produced by chemical excitation. LIF is thus a good candidate
for making 3D measurements of temperature and species in reacting
and/or high-speed flows. This section contains a brief overview of the
LIF model, starting with a description of spontaneous emissions. Rate
equations for a generic two-level model are presented, after which some
target-specific considerations are discussed. Full details are available in
the texts of Herzberg [50], Eckbreth [5], and Hanson et al. [279]; the
reviews of Daily [429] and Schulz and Sick [18]; and the chapter by
Carter and Lee [430].

7.1.1. Spontaneous emission

Fig. 40 contains a schematic of LIF. Atoms or molecules in the
ground electronic state are excited by absorbing incident laser light,
followed shortly by spontaneous emission a.k.a. fluorescence. The en-
ergetic structure of target species and library of valid transitions are
the same in chemiluminescence and LIF. Moreover, the formation and
deactivation mechanisms listed in Section 6.1.2 still apply. However,
the population distribution is typically unknown in chemiluminescence
and the signal of interest overlaps with difficult-to-model broadband
emissions from off-target molecules. By contrast, laser excitation pro-
vides greater control over the target species, the resulting population
distribution, and thus the ensuing emissions. This enables quantitative
estimates of key variables, but collisional quenching, predissociation,
and photoionization can take place prior to fluorescence, altering the
population of excited states. As a result, LIF data must be interpreted
with a spectroscopic model that accounts for multiple energy levels and
transfer mechanisms.

j→i for spontaneous emission, Be

To begin, take the generic target M from Section 6.1. The number
density of M is ̃N = P [M]∕(kBT ), which can be divided into specific en-
ergy level populations, denoted ̃Nj . Transition probabilities for a given
pair of upper and lower states are calculated in terms of Einstein A
and B coefficients: Ae
j→i for stimulated
emission, and Be
i→j for stimulated absorption (see Hilborn [431] for a
nice overview). Photons produced by stimulated emission travel in the
direction of the laser so the LIF signal consists solely of spontaneous
emissions from valid transitions. Therefore, Eq. (132) from Section 6.1
is used to model LIF and chemiluminescence signals, alike. Unlike
chemiluminescence, however, the population distribution in LIF can be
explicitly modeled in many cases, which facilitates the quantification
of species and temperature.

7.1.2. Rate equations for a two-level molecule

Dynamic energy state population distributions for an atomic or
molecular system are modeled using a set of coupled rate equations.
The simplest system is a two-level molecule, depicted in Fig. 41, which
helps to explain the basic principles of fluorescence. Auxiliary energy
levels may be introduced to elucidate the LIF spectrum as needed.

Fig. 39. Doubly-conditioned non-axisymmetric Rayleigh fields of six thermoacoustic
modes in a lean swirl-stabilized flame. The green isosurface indicates regions where Rf
is greater than 50% of its maximum while the red surface corresponds to the volume
where Rf is less than 50% of its minimum. Θ is estimated by summing the integrated
fields.
Source: Adapted from [29].

ratio of the intensity source field to local heat release through a global
balance in which the volume integral of ̇q was estimated using the mass
flow rate of fuel and its heat release conversion rate. Strollo et al. [411]
studied the stability of transient H2/natural gas fuel blends via CTC
of CH* coupled with pressure transducer data. Cirtwill et al. [410]
conducted simultaneous OH* CTC and stereo PIV to estimate the ef-
fect of the phase shift between fuel and pressure oscillations on the
amplitude of P ′, and Chterev and Boxx [412] used a similar setup in
a pressurized combustor (up to 5 bar) to assess the stability and shape
of natural gas/air combustion as a function of hydrogen enrichment.
In addition to stereo PIV, CTC has also been combined with Raman
scattering [417,418], PLIF [419,420], and LII [419].

7. Laser-induced fluorescence

Fluorescence and phosphorescence, collectively called photolumi-
nescence, refer to the light emitted by particles that were excited
by the absorption of a photon. These two mechanisms differ with
respect to the modes of energy transfer in the excited molecule that
precede spontaneous emission. In fluorescence, the spin of the excited
electron is constant and emission takes place rapidly, on the order of
nanoseconds, while phosphorescence features a change in spin prior
to emission, which occurs slowly as a result, on the order of millisec-
onds to seconds [18]. Of these mechanisms, fluorescence is far more
prevalent in the context of combustion measurement.

Laser-induced fluorescence is an active measurement technique in
which light from a laser is absorbed by a target molecule and the
resulting emissions are recorded by one or more photomultiplier tubes,
spectrometers, or cameras. LIF can be resolved in a quasi-point [421],
linear [422], planar [423], or volumetric [58] interrogation region,
constructed with a laser beam, sheet, or slab. The signal is a func-
tion of the target species’ energy state population distribution, which
itself depends upon the local thermochemical state as well as the
wavelength and power of the laser. Many modern lasers produce nar-
row, wavelength tunable output so the stimulation wavelength can be
aligned with selected absorption transitions or even swept across a
range of transition energies. As a result, controlled LIF signals may
be interpreted with a spectroscopic model to estimate the number
density, temperature, or bulk velocity of a target species, depend-
ing on the setup. LIF can detect trace concentrations of atomic and
molecular species, which enables the measurement of combustion rad-
icals like OH [424] and CH [425] or a well-characterized tracer like
acetone [426]. The speed, sensitivity, and selectivity of LIF make
quantitative VLIF an attractive prospect for turbulent gas flows and
combustion sensing.

45

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

and
d ̃N ∗
dt

=

(WM→M∗ + kth

) ̃N
(WM∗→M + Ae

−

M∗→M + kQ

) ̃N ∗.

The total population remains constant over the laser pulse,

̃N(0) = ̃N(t) + ̃N ∗(t) ,

(148b)

(149)

assuming the molecule was relaxed prior to stimulation, that is, ̃N ∗(0) =
0. Note that ̃N is the collective number density of states that are excited
by the laser in this example, it is not the total number density of M.
Substituting Eq. (149) into Eq. (148) yields the solution

̃N ∗(t) =

̃N(0)

WM→M∗
r

[
1 − exp(−rt)

] ,

(150)

where r = WM→M∗ + WM∗→M + Ae

M∗→M + kQ.
For long laser pulses, lasting from 10−8 to 10−6 s, the excited state
population builds up linearly before rolling over and plateauing at a
steady state number density [5],

Fig. 40. Schematic of energy transfer in LIF. Ground state atoms or molecules are
excited by the absorption of
laser light. Excited particles may undergo
rotational and vibrational energy transfer before fluorescing to ro-vibrational levels
in the ground electronic state. Dark horizontal lines indicate vibrational levels, light
lines indicate rotational levels.

incident

Fig. 41. Two-level model of the LIF system in which energy is transferred between a
ground state, M, and excited state, M*, which are coupled by a laser.
Source: Adapted from [429].

Neglecting chemical reactions, predissociation, and photoioniza-
tion, rates of energy transfer included in the two-level model are the
rate of stimulated absorption and stimulated emission, WM→M∗ and
WM∗→M; thermal excitation and collisional quenching, kth and kQ; and
spontaneous emission, Ae
M∗→M, i.e., the rate of photonic emission in
Eq. (132b). Stimulated signals depend on the laser’s spectral irradiance,
I las
λ ,

∞

Wi→j = ∫
0

Yi→j (λ) Be

i→j I las

λ dλ ≈ Be

i→j I las
λ ,

(147)

where the approximation holds if the width of the laser’s output en-
velopes the absorption transition. By balancing the population and
depopulation mechanisms shown in Fig. 41, the rate of change of the
̃N, and that of the excited state density,
ground state number density,
̃N ∗, are found to be

d ̃N
dt

=

(WM∗→M + Ae

−

(WM→M∗ + kth

M∗→M + kQ
) ̃N

) ̃N ∗

(148a)

46

̃N ∗

SS = ̃N(0)

= ̃N(0)

WM→M∗
r

Be
M→M∗
M→M∗ + Be
Be

M∗→M

1
λ ∕I las
1 + I sat
λ

,

is the so-called saturation spectral irradiance,

where I sat
λ
Ae
M→M∗ + Be
Be

I sat
λ =

M∗→M + kQ

M∗→M

.

(151)

(152)

There are two important limits to steady state LIF. At the weak exci-
tation limit, stimulated emission is insignificant, I sat
λ ≫ 1, and the
time-integrated LIF source, indicated by an overline, becomes

λ ∕I las

̄I ′ weak
λ

=

hc
λ

Ae
M∗→M
Ae
M∗→M + kQ
⏟⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏟
φSV

WM→M∗ τdet

̃N(0) .

(153)

In this equation, τdet is the measurement interval and φSV is the fraction
of relaxation events that contribute to the signal, often called the Stern–
Volmer coefficient or ‘‘quantum yield’’. This value is typically on the
order of 0.01 to 0.1%, i.e., irradiance from the laser is much stronger
than the resulting fluorescence. Saturated fluorescence occurs when
irradiance from the laser is far greater than the saturation irradiance,
in which case

̄I ′ sat
λ

=

hc
λ

Be
M→M∗
M→M∗ + Be
Be

M∗→M

τdet

̃N(0) .

(154)

Note that the saturated signal is independent of quenching as well as
the incident laser power. In other words, stimulated absorption and
emission dominate the energy transfer between M and M* and the
signal is maximized. Saturated LIF can be difficult to achieve due to
rotational and vibrational energy transfer within the upper manifold,
which are poorly modeled by a two-level system, and nonlinearities
become salient when WM→M∗ ≈ Ae
M∗→M + kQ [430]. It is particularly
difficult to ensure saturation throughout the measurement volume in
VLIF due to spatio-temporal variations within the incident laser light
and attenuation of the laser slab.

Considerable power is needed for volumetric probing so it is often
necessary to use a short excitation pulse, lasting on the order of 10−9 s
or less [5]. The result is a linear increase in ̃N ∗ for the duration of
stimulation, τlas. The excited state population at the end of the pulse is
found by evaluating Eq. (150) at τlas. After that point, ̃N ∗ exponentially
decays to zero at a rate of (Ae
M∗→M + kQ) since there is no stimulated
emission. In other words,
(Ae
̃N ∗(t) = ̃N ∗(τlas

M∗→M + kQ

(155)

) t]

[
−

exp

)

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

for t > τlas. Integrating Eq. (155) over a large measurement interval,
such that (Ae
M∗→M +kQ)t ≫ 1, and substituting the result into Eq. (132b)
yields the expression for a gated LIF signal,

̄I ′ gate
λ

=

hc
λ

φSV WM→M∗ τlas

̃N(0)
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟
̃N(τlas)

.

(156)

If the decay is temporally-resolved, for instance, with a handful of
data points recorded over approximately 100 ns, then the decay rate
can be used to assess kQ [429,432,433]. Even though the expressions
for steady state LIF in the weak excitation limit and gated LIF are
similar, these techniques require a distinct experimental setup, with
a much longer laser pulse in the former case which persists during
measurement.

Despite the complex nature of LIF spectra, evident

from the
schematic in Fig. 40, a two-level model is often sufficient for analysis of
fluorescence data [430]. In particular, the expressions developed above
can be used when

1. excitation is within the linear regime, i.e., I sat

λ ∕I las

λ ≫ 1 and/or

the laser pulse is short, and

2. the quantum yield, φSV, is reasonably consistent across the

excited states (e.g., within 5%–10%).

When either condition is violated, a more complex model may be
required. For instance, OH(A) LIF is complicated by different rates
of fluorescence from the first and second vibrational state; Dunn and
Masri [434] developed a six-level model for quantitative evaluation
of the ‘‘integrated quasi-steady-state’’ signal. Such ornate corrections
are not usually required, however. Three- and four-level models are
relatively common, and a detailed overview of the uses of and so-
lutions to these systems can be found in the review of Daily [429].
Crucially, higher-level models feature rotational and vibrational en-
ergy transfer within the upper manifold of excited states. Rates of
quenching and excited state energy transfer, kQ and kQ,i→j , are key
considerations in these systems. Such processes generally vary with
the temperature and composition of the bath gas. Models of kQ and
kQ,i→j for combustion-relevant targets are available in the literature,
e.g., [435,436].

7.1.3. Quantitative methods and considerations

All the expressions for I ′

Fluorescence signals can be used to infer various physical quan-
tities such as temperature, species, pressure, and velocity [429]. Of
these, only temperature has been measured using VLIF [437]. LIF
measurements of pressure [438–440] and velocity [440–443] require
some combination of spectrally-resolved measurements, scanning of
the excitation spectrum, or counter-propagating laser beams to resolve
broadening of the lineshape or the velocity-induced Doppler shift.
Implementing these methods in a volumetric configuration with ex-
isting equipment may not be practical. Nevertheless, temperature has
been volumetrically measured using LIF and, in principle, PLIF species
measurements can be expanded to perform a volumetric measurement.
λ developed in the previous section are
directly proportional to the initial number density of the pumped
̃N(0). Therefore, the simplest methods for quantitative
energy level,
LIF involve the use of a calibration procedure in which the target
population is known. This can be done sequentially, with a controlled
LIF experiment followed by measuring the target of interest, or simul-
taneously, with a multi-modal system. Controlled calibration is often
conducted with a flowing or static gas of known composition. Laminar
flames are also used in conjunction with an independent diagnostic or
theoretical calculations of the target concentration. For instance, Yin
et al. [444] conducted PLIF and laser absorption measurements of OH
in the laminar CH4/air flame produced by a Hencken burner to baseline
their LIF system. Alternatively, point-wise scattering measurements
(Rayleigh or Raman) can be conducted in sync with LIF to provide
an absolute Ref. [445–447]. When doing this, it is advisable to ensure

Fig. 42. Stokes (3 → 2) and anti-Stokes (3 → 1) lines measured in two-line LIF
thermometry.
Source: Adapted from [429].

that measurements are being conducted in the linear regime by varying
the laser power and monitoring the resulting LIF signal. Carter and
Lee [430] provide expressions relating a Rayleigh or Raman signal to
a LIF signal.

Temperature is a critical parameter that affects reaction rates and
transport properties, thereby affecting the efficiency of combustion,
production of pollutants, and more. There are two strategies for mak-
ing instantaneous, spatially-resolved LIF measurements of temperature,
broadly classified as perfect gas law and two-line thermometry.17 Per-
fect gas law thermometry utilizes the ideal gas assumption to convert
an absolute number density field to a temperature field,

T =

P
̃NkB

.

(157)

This calculation requires knowledge of the pressure and target number
density fields, discussed immediately above, as well as the volume
fraction of the target species. Perfect gas law LIF thermometry has been
conducted using a planar signal, e.g., using NO [448] and O2 [449], but
has yet to be demonstrated in 3D.

Two-line LIF thermometry utilizes three energy states to estimate
the temperature: two rotational levels in the ground electronic state
and one excited energy state [5]. Fig. 42 depicts the basic measurement
strategy, which features two sequential measurements in the weak
saturation limit. State 1 is pumped to 3 and fluorescence from 3 → 2
is measured. Next, state 2 is pumped to 3 and fluorescence from 3 → 1
is measured (or vice versa). The population of states 1 and 2 can be
obtained by rearranging Eq. (151),
3→2 + kQ,3→1 + kQ,3→2

3→1 + Ae
Ae

(158a)

̃N3,1→3

̃N1 =

W1→3

and

̃N2 =

3→1 + Ae
Ae

3→2 + kQ,3→1 + kQ,3→2

W2→3

̃N3,2→3.

(158b)

̃N2 to

=

3→2

Ae
Ae

̃N2
̃N1

W1→3
W2→3

λ3→2
λ3→1
(

Substituting Eq. (153) into Eq. (158) and solving for the ratio of
̃N1 yields
̄I ′
λ3→1
̄I ′
λ3→2
gd
2
gd
1
where gd
i = 2J +1 is the degeneracy of state i and J is the corresponding
total angular momentum quantum number. Eq. (159b) is the Boltzmann
ratio for ̃N2 to ̃N1, which is approximately valid in the weak excitation
limit since the laser does not significantly depopulate the ground states

E2 − E1
kBT

3→1
)

(159b)

(159a)

exp

−

=

,

17 Excitation scan thermometry is time-averaged and the temporal resolution
needed for thermally-assisted thermometry is difficult to achieve in PLIF and
VLIF.

47

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

in that regime. This expression can be rearranged to solve for the
temperature,

7.2. Instrumentation

T =

log

( gd
2
gd
1

)

(E2 − E1
I ′
λ3→1
λ3→2
I ′
λ3→2
λ3→1

∕kB

W2→3
W1→3

Ae
Ae

3→1

3→2

) .

(160)

Note that the quantum efficiency and filter transmittance, ηλ and τf,λ,
should be pulled in from Eq. (4), which requires that they are roughly
constant over the range of the bandpass filters. Further, the logarithm
in Eq. (160) is generally expanded, log(gd
) + ... ,
but is consolidated here for brevity. There are many other excita-
tion schemes for two-line thermometry, which yield distinct forms of
Eq. (160); a summary of these schemes and thermometry equations can
be found in Zizak et al. [450]. For complex molecular systems, such
as aliphatic ketone tracers, a more sophisticated modeling approach is
required to determine the relationship between the two-color ratio and
temperature [451,452].

1 ) + log(I ′

2 ∕gd

∕I ′

λ3→1

λ3→2

The LIF signal ratio-to-temperature curve can be pre-calculated for
post-processing of two-color reconstructions [18,437]. Selection of the
line pair is non-trivial and a few guidelines should be followed [430].
First, the temperature should be monotonically related to the ratio.
Second, the selected lines should guarantee both good temperature
sensitivity and SNR and be free of inferences from adjacent transitions.
Third, the separation between the two lower levels should be maxi-
mized to increase E2 − E1. However, the number density of ground
state molecules quickly tapers off with increasing rotational energy,
decreasing the signal strength as a result, so these effects must be
balanced [429].

The intensity source field at a point is proportional to the intensity
of incident laser light. This can be problematic at high concentrations
of the target or for very strong absorption/excitation transitions since
there may be enough attenuation to significantly bias quantitative
estimates. Attenuation of the laser slab follows the Beer–Lambert Law,
which may be expressed in differential form,

−dI las

λ (l) = κλ I las

λ (l) dl ∝ ̃N(x) I las

λ (l) dl

(161)

The absorption coefficient, κλ, is the difference between stimulated
absorption and emission at λ, i.e., the wavelength of the laser’s output,

κλ =

hc
λ

∑

∑

j

i∈j

(

Be

i→j

̃Ni − Be

j→i

̃Nj

)

Yi→j (λ)

(162)

This expression simplifies when the gas is in local thermodynamic equi-
librium, in which case tabulated coefficients, e.g., from HITRAN [290]
or HITEMP [291], or the proportional expression on the right side of
Eq. (161) may be employed. Given a reconstructed intensity source
̃N, an absorption-corrected field may be
field and initial estimate of
obtained by rearranging and integrating Eq. (161) in the direction of
the laser slab,

λ (l) = I las
I las

λ (0) exp

(

−

κλ,0
̃N0

l

∫
0

̃N(l) dl

)

,

(163)

̃N0.
where κλ,0 is evaluated at an arbitrary reference number density,
Eq. (163) must be discretized to calculate I las
λ , per Desgroux et al. [453],
and the updated field may be used to re-estimate ̃N. This cycle is
repeated until convergence.

Several software packages have been developed to simulate and
evaluate LIF signals for select species, including LIFBASE [454], LASKIN
[455], LIFSim [456], and PGOPHER [457]. These resources can be
leveraged to design and analyze the results of a VLIF experiment,
e.g., by predicting the excitation spectrum at conditions of interest or
pre-calculating ratio curves for two-line thermometry.

48

Laser-induced fluorescence is an active technique that uses a laser to
excite the target molecules. As such, the measurement system comprises
a laser source and series of beam forming optics in addition to the
system of cameras used to record the projections. Beam forming optics
consist of lenses and mirrors that redirect the laser’s output and shape
it into a thin beam, planar sheet, or volumetric slab. In order to excite
the chosen species, the laser should produce light that is resonant with
that species. Targeted atoms or molecules may already exist in the
measurement volume, such as OH, CH2O (formaldehyde), or NO, which
are intermediate species or products of combustion. Alternatively, flu-
orescing tracers like toluene or acetone can be seeded into a fuel,
oxidizer, or coflow stream [18]. Ketones are popular tracers for study-
ing reacting flows because of their well-known photophysics, which
enables quantitative measurements of temperature and concentration.

7.2.1. Excitation

Lasers for LIF can be single frequency or tunable, and they may
be pulsed or continuous wave, although tunable pulsed lasers are
most common in VLIF. Theoretical and practical guides on lasers can
be found in the works of Eckbreth [5, Ch. 3], Siegman [458], and
Demtröder [459]. Numerous studies have surveyed the excitation and
fluorescence spectra of important flame radicals and tracers across a
range of temperatures and pressures, e.g., using a tailored optical gas
cell [452], shock tube [460] or optical engine [461]. For excitation
of toluene or acetone, for instance, one could use a fourth-harmonic
Nd:YAG laser at 266 nm [462–465] or KrF laser at 248 nm [466–
469]. Excitation of CH2O can be achieved using a third-harmonic
Nd:YAG laser at 355 nm [91,462,463,470], whilst other combustion
intermediate species such as OH and CH are often excited around
283 nm and 431 nm, respectively. Alternatively, a dye laser [59,373]
or optical parametric oscillator [60,471] may be employed to produce
a wavelength tunable laser slab.

Given a laser source, the outputted beam must be formed into a
3D slab. First, in order to minimize spatial variation, the near-field
laser beam is relayed using telescopes to curtail diffraction and imaged
through an optical aperture (like an iris) to produce a quasi-top-hat
profile. Each telescope consists of two lenses that are separated by the
sum of their focal lengths. Proceeding along a beam, these are called
the ‘‘objective lens’’ and ‘‘image lens’’, respectively, as indicated in
Fig. 43. When both lenses have a positive focal length, the telescope
is said to be ‘‘Keplerian’’ (Fig. 43(a)), whereas a ‘‘Galilean’’ telescope
contains a positive lens followed by a negative lens (Fig. 43(b)). A high-
powered laser can ionize the air at internal foci in a Keplerian telescope,
resulting in damage to surrounding optomechanics, so Galilean systems
are generally preferred in planar and volumetric LIF.

In point-wise LIF and LII, the telescopes are made up of spherical
lenses and a reverse telescope (i.e., having an absolute magnifying
power greater than one) is often placed behind the aperture to reduce
the size of the beam waist [473]. Planar and volumetric experiments
require sheet forming optics, which utilize plano-convex cylindrical
lenses to expand the beam into a quasi-2D sheet or 3D slab. Some
researchers use matched pairs of spherical and cylindrical lenses with
alternating negative and positive focal lengths, as shown in Fig. 43(c).
Others employ a pair of spherical lenses and a single cylindrical lens
with a negative focal length, which saves a lens but degrades the quality
of collimation. Sheet optics are often followed by a slit aperture in the
planar case to produce a sheet on the order of 60–200 μm thick. Lastly,
knife edges are often used in volumetric applications to clip the laser
slab to the desired depth [59,372,472].

The formation and uniformity of a 3D laser slab are key considera-
tions in VLIF. Spatio-temporal variations arise in the output of many
high-power pulsed lasers due to the presence of multiple axial and
transverse cavity modes. This can lead to nonuniform excitation of the
target, and the LIF signal must be interpreted accordingly. One way to

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Table 2
Summary of selected VLIF experiments.

Ref.

Li et al. [373]
Halls et al. [60]
Halls et al. [437]
Pareja et al. [474]
Ma et al. [59]
Xu et al. [472]
Halls et al. [476]
Wang et al. [475]
Wu et al. [176]
Wu et al. [477]
Halls et al. [478]

Target

OH
OH
OH
OH
CH
CH
acetone
acetone
iodine
iodine
CH2O/PAH

Laser Energy [mJ/pulse]

View Count

Frame Rate [Hz]

Domain Size [mm3]

Voxels

25
0.1–0.4
13, 23
3, 4.5
10
up to 10
80
30
600
15–72
130

8
8
8
8
5
5
8
9
5
7
8

10
10
10
10
–
10
20
10
–
10
20

30 × 30 × 30
45 × 45 × 15
14 × 14 × 24
30 × 30 × 30
9.3 × 9.3 × 32.7
50 × 50 × 15
35 × 35 × 75
80 × 100 × 100
50 × 50 × 50
50 × 50 × 50
–

1.5 × 106
180 × 180 × 60
70 × 70 × 120
3.7 × 106
64 × 64 × 224
128 × 128 × 128
175 × 175 × 175
120 × 120 × 120
120 × 120 × 120
128 × 128 × 128
–

Fig. 44. Profile of the UV light incident on a VLIF the laser volume used in a VLIF
experiment, measured using a custom UV beam profiler.
Source: Adapted from [472].

appear in Table 2. The output wavelength is also important since the
wavelength of tunable lasers can drift due to changes in the ambi-
ent conditions. One should monitor and properly control the output
wavelength to guarantee consistent excitation. This can be done with
a wavelength meter or even by using a portion of the laser beam to
conduct point-wise LIF in a nearby reference flame [430].

7.2.2. Detection

As with chemiluminescence, the detection system for VLIF is com-
posed of multiple cameras, intensifiers, optical filters, and a triggering
and acquisition timing system. Image acquisition should directly follow
the laser excitation and be within the fluorescence lifetime. Multiple
cameras are normally distributed along an arc that surrounds the
measurement volume/laser slab. Since the cameras and optics needed
to detect the LIF signal are costly,18 the number of cameras that can
be used in a VLIF setup is usually limited. To date, no more than nine
independent views have been used. Xu et al. [472] used five cameras,
whilst others have employed different methods to capture more than
one view with one camera. For example, Li [373], Pareja [474], and
colleagues used four cameras, each equipped with a stereoscope; Halls
et al. [437] used two cameras, fitted with a pair of quadscopes; and
Wang et al. [475] used a single camera coupled to nine FBEs. These se-
tups are shown in Fig. 45. The benefits and drawbacks of view splitting
in LIF are the same as for CTC, per the discussion in Section 6.2.

In order to single-out the detection wavelength range and eliminate
interfering signals, optical filters with a suitable bandwidth are essen-
tial. For example, OH LIF has been performed with 309 ± 5 nm [462]
and 320 ± 20 nm [373] filters, and CH with 431 ± 10 nm [462] and

18 Low-cost

industrial cameras,

sometimes used for CTC, are wholly

inadequate for LIF.

49

Fig. 43. Telescopes consist of two lenses separated by the sum of their focal lengths,
the sign and order of lenses can be used to reduce the size of a laser beam or expand
it into a sheet or slab. This figure depicts (a) Keplerian and (b) Galilean telescopic
beam expanders. In (c), a telescope with spherical lenses expands the beam, which is
formed into a slab by a pair of cylindrical lenses.

assess the laser is using a beam profiler that records a 2D relative inten-
sity map of the light incident on the probe volume. Fig. 44 shows the
profile of a UV slab from the VLIF experiment of Xu et al. [472], whose
measurements revealed significant spatial and shot-to-shot variations in
the incident light. Therefore, in addition to the absorption correction
described above in Section 7.1.3, the data processing workflow should
compensate for incident laser sheet inhomogeneities.

Lastly, the intensity and wavelength of the laser ought to be moni-
tored to ensure a quality measurement. If the species concentration is
low and the laser fluence is not high enough, the excited fluorescence
intensity could be too weak to be recorded by a camera with a good
SNR. On the other hand, the laser fluence must not be so high as to
surpass the linear LIF regime [472]. Consequently, the laser energy
and slab volume need to be balanced to obtain a suitable fluence.
Laser energies used in the works reported throughout this section

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 45. Sample custom imaging systems used for VLIF in which cameras are combined with (a) stereoscopes [474], (b) quadscopes [437], and (c) FBEs [475].

CH surface was extracted from the PLIF image and superimposed on the
VLIF reconstruction, showing remarkable agreement between the two
distributions. Following the work of Ma, VLIF imaging of combustion
has been taken up by the groups of Meyer [437] and Dreizler [373].

One important feature of VLIF is the ability to control the size of
the interrogation region by clipping the laser slab with knife edges.
This was investigated by Wu [58], Ma [59,372], Li [373], and their
colleagues. Li et al. also assessed the effects of the camera count
on the accuracy of reconstructions. In essence, the complexity of the
unknown intensity source field decreases as the measurement volume is
constricted. Individual cameras can convey more complete information
about the field in a narrow rectangular volume as compared to a cubic
domain. This is an intuitive result since VLIF reduces to PLIF as the
measurement volume is narrowed to a quasi-planar slice. The same
principle is at work in TPIV, where narrow aspect ratio measurement
volumes are standard practice [118]. Fig. 46 provides a powerful
demonstration of the resolution that can be achieved with VLIF through
the use of a narrow domain. In the study of Li et al. [373], the authors
reconstructed laminar and turbulent CH4/air jet flames using laser slabs
of depth 2, 4, 10, and 30 mm. As the measurement volume decreased,
1D profiles of the VLIF estimates approached the profile extracted from
the PLIF image. The authors estimated effects of the domain size on the
spatial resolution of reconstructions (see Section 5.2) by convolving the
PLIF image with increasingly wide filters. Naturally, they found a direct
relationship between the laser slab’s depth and the filter width needed
to match the VLIF and PLIF profiles.

Two aspects of the aforementioned studies should be noted. First,
the PLIF laser used to validate VLIF reconstructions was aligned span-
wise with the laser slab in each case [58,59,372,373]. Although highly
probable, it has yet to be confirmed whether VLIF provides additional
resolution in the normal direction as the domain is shrunk. Second,
for OH VLIF, used by Li et al. [373], the effects of signal trapping are
likely to increase with decreasing domain width, but this effect was not
specifically investigated.

Recently, Halls et al. [437] reported the first demonstration of
quantitative VLIF. They measured the 3D, instantaneous temperature
field of laminar and turbulent H2/air flames using two-color OH VLIF.
Temperature evaluations were based on the two-line thermometry tech-
nique outlined in Section 7.1.3, using the Q1(5) and Q1(14) rotational
transitions of the (1, 0) vibrational band in the A2Σ ← X2Π electronic
system. Calibration was conducted using H2/air flat flames of varying
equivalence ratios produced by a Hencken burner, since these flames
have a well-known equilibrium temperature [480]. Fig. 47 presents iso-
contours of the normalized Q1(5) and Q1(14) distributions as well as the
resulting temperature field. Halls et al. [437] estimated the uncertainty
of their temperature field to be roughly 7%, stemming from fluctuations
in the laser output, measurement noise, and reconstruction errors. How-
ever, full details on the calculation of uncertainty were not provided.
An obvious limitation of VLIF thermometry is that temperature can
only be measured in regions with an appreciable concentration of OH.
Nevertheless, temperature in the OH-containing regions of a flame is an
important indicator, and the quantitative 3D reconstructions of Halls
et al. [437] represent a significant advance towards the creation of a
3D dataset that could support modeling efforts.

Fig. 46. A qualitative comparison between CH-VLIF and -PLIF data for a reacting
turbulent flow. (a) The 3D structure of the CH-VLIF, (b) the central slice extracted
from the VLIF, and (c) superimposed VLIF slice and PLIF image (white line).
Source: Adapted from [372].

434±17 nm [479] filters. In many cases, LIF is conducted using sep-
arate colored-glass filters to block fluorescence from off-target species,
Rayleigh scattering and specular reflections of the laser, and ambient
light. Weak emissions, short lifetimes, and attenuation due to multiple
filters collectively result in a low LIF signal. Accordingly, intensified
cameras are normally required to conduct VLIF.

7.3. Instantaneous measurement

Volumetric LIF was first proposed by the group of Ma in 2015 [58].
They reconstructed a single 3D snapshot of iodine fluorescence from
a non-reacting iodine/N2 turbulent jet. A rod was inserted into the jet
to increase the complexity of the flow field, resulting in a V-shaped
iodine field with a range of visible length scales. The authors used an
Nd:YAG laser to excite the iodine tracer, and five cameras were set
up to simultaneously record LIF projections from a unique perspec-
tive. Each camera was outfitted with a notch filter to block scattered
laser light. Validation of the reconstruction was performed with a
quasi-simultaneous PLIF measurement that was conducted 0.2 ms after
recording the VLIF projections. There was a very close correspondence
between the PLIF image and VLIF reconstruction, motivating further
development of the technique. Since the laser was pulsed at 10 Hz, tem-
poral evolution of the flow field was not resolved (hence ‘‘instantaneous
measurement’’).

Utilizing VLIF to measure a combustion process is a natural ex-
tension since various molecules that can be targeted by LIF are pro-
duced by reactions in the flow. Therefore, Ma’s group applied their
VLIF technique to measure CH in laminar and turbulent premixed
CH4/air flames, both at stoichiometric and rich conditions [59,372].
The group’s Nd:YAG laser was used to pump a dye laser, whose output
was frequency doubled to excite CH at 314 nm; the same five cameras
from [58] were equipped with intensifiers and UV Schott lenses to
record the projections. Again, quasi-simultaneous PLIF was performed
for validation purposes, this time with a much faster, 45 ns time
delay to freeze the flame. Fig. 46 presents a volumetric reconstruction
from [372] alongside the corresponding PLIF image. An outline of the

50

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 47. 3D isocontours of the reconstructed Q1(5) and Q1(14) fields followed by the
corresponding temperature field.
Source: Adapted from [437].

Fig. 49. Time-series of 3D isocontours using acetone VLIF of a turbulent non-reacting
fee jet, conducted at 20 kHz.
Source: Adapted from [476].

out, such as island structure that separates from the main jet. While
the authors did not calculate a concentration field, their acetone recon-
structions were proportional to concentration. Hence, Halls et al. [476]
were able to compare mean and RMS concentration profiles along the
centerline and radial profiles in the far field to previously measured
estimates. The VLIF reconstructions of Halls were in good agreement
with the PLIF measurements of Dahm et al. [481,482]. By contrast, less
analysis of the H2/CH4/air diffusion flame was presented in [478].

There are two other time-resolved VLIF studies of note, both oper-
ated at 10 kHz. First, Pareja et al. [474] performed volumetric LIF of
OH to investigate the spatio-temporal evolution of auto-ignition kernels
formed by methane jets injected into a NOx-vitiated, highly-turbulent,
hot air coflow. Kernels were reconstructed and tracked to determine the
statistical profile of random auto-ignition events throughout the flow
field; Pareja and his coworkers found that the kernels were preferen-
tially aligned with the mean flow direction. Later, Wang et al. [475]
seeded a weakly forced swirl flame with acetone and measured the
flame using VLIF. Effects of acoustic forcing were analyzed in terms
of the center of ‘‘mass’’ of the reconstructed acetone LIF source field,
which stood-in as a surrogate for the fuel. Periodic movements of the
fuel height were tracked to identify the flame–flow response to forcing.
While VLIF is an early-stage diagnostic compared to chemilumines-
cence tomography, it has considerable potential for several reasons.
First, the probe volume is set by the user, facilitating accurate recon-
structions in a narrow volume with a small number of cameras. Better
reconstructions enable more accurate calculations of surface area, 3D
autocorrelation functions, and the like, suitable for benchmarking CFD
codes. Second, the excitation process can be tailored to conduct quan-
titative measurements of temperature and concentration. Third, the
advent of ultra-high-speed cameras may lead to VLIF at the time scale of
the signal decay, such that established methods for quantitative point
LIF could be volumetrically applied. Hence, the use of VLIF to study
turbulent reacting and non-reacting flows is expected to increase in the
coming years.

8. Incandescence

All matter emits radiation as a consequence of the vibrational and
rotational motion of charged atoms/molecules. Some of this motion is
associated with the temperature of the radiating body, and emissions
generated by thermal energy are deemed to be thermal radiation,
also known as ‘‘incandescence’’. Radiation is a significant mode of
heat transfer in many combustion devices, especially within large-scale

Fig. 48. Time-resolved iodine-VLIF reconstructions of a turbulent iodine/N2 jet at two
different time instants, separated by 2 ms.
Source: Adapted from [477].

7.4. Time-resolved measurement

High-power, high-repetition-rate lasers and high-speed cameras
have enabled time-resolved VLIF, which can be used to capture and
assess the evolution of turbulent reacting flows. As with instantaneous
VLIF, Ma’s group reported the first time-resolved VLIF measurement
using a non-reacting, turbulent, iodine-seeded N2 jet [477]. To do this,
they excited the iodine with a 10 kHz Nd:YLF laser and recorded the
projections with seven cameras. Fig. 48 depicts two successive volume-
rendered snapshots of the iodine field; as before, a rod was inserted to
break up the jet, resulting in a V-shaped flow. Increasing the temporal
resolution of measurements, from 10 Hz in [58] to 10 kHz in [477],
decreases the signal and thus the SNR of projections. Experimental and
theoretical tests, based on a two-level model (see Section 7.1.2), were
used to determine the effect of the pulse duration and repetition rate
on the accuracy of reconstructions. Ma et al. estimated that errors,
computed in terms of ε2 (Eq. (120)), would increase from 0.02 for
1 kHz measurements to 0.12 for 10 kHz measurements. Although these
numbers are based on the setup reported in [477], the trend is expected
to hold for other systems and the calculated increase in ε2 represents a
significant qualitative degradation. Hence, there is an important trade-
off between temporal and spatial resolution in VLIF that is related to
the signal strength.

The group of Meyer also made substantial inroads in high-speed
VLIF. Halls et al. conducted VLIF measurements of an air jet seeded
with acetone [476], followed by formaldehyde VLIF of an H2-enriched
CH4/air diffusion flame [478]. In the latter test, LIF from soot pre-
cursors (polycyclic aromatic hydrocarbons, PAHs) was also detected.
Temporal evolution of the air jet is shown in Fig. 49. Halls et al. tracked
the evolution of local coherent structures, for instance, highlighting the
elongated inner core at 0 ms in Fig. 49, which pinches off 0.25 ms later
and eventually rolls up at 0.75 ms. Smaller features were also pointed

51

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

chambers that have long optical paths, and there can be significant
coupling between radiative fluxes and turbulent motion in a react-
ing flow, called turbulence–radiation interactions [483]. Volumetric
tomography of incandescence almost always features a particle-laden
flame since combustion heats up the particles enough to induce visible
thermal radiation. The particles are usually soot, and the incandescence
emitted by soot is responsible for the luminous yellow-to-amber hues
produced by many flames. The color of incandescence is related to
the temperature of the source, meaning that optical measurements
of incandescence can, in principle, be utilized for thermometry. As a
consequence, passive incandescence from soot or ash is a natural target
for flame tomography because it is both easy to measure and related to
important properties of combustion. These include the efficiency and
stability of combustion as well as the peak flame temperature, which
affects the formation of pollutants.

Common parameters of interest in volumetric incandescence include
the temperature and volume fraction of soot. Besides temperature,
the incandescence produced by soot aggregates is influenced by their
optical properties and geometric characteristics, neither of which are
well known or homogeneous throughout the measurement volume.
Quantitative reconstructions of soot-related fields must be interpreted
in light of these significant uncertainties. The same can be said of fields
associated with pulverized coal or fly ash, and the majority of publica-
tions reporting quantitative results do not employ a realistic model of
the incandescence signal, calling the accuracy of these reconstructions
into question. Nevertheless, tomography of incandescence can provide
important qualitative information about the generation, agglomeration,
and burning of solid-phase particles, thereby shedding light on the
performance of a combustion device.

As with CTC, incandescence tomography was first conducted in
a series of 2D planes. This was done by Uchiyama et al. [63] in
1985 to estimate the temperature field of a laminar CH4/air flame
using a broadband IR signal from 1–5 μm. Since then, a number of
other groups have reconstructed the incandescence emitted by a sooty
flame in an open laboratory environment, e.g., [61,484–486], but the
technique is mostly used to characterize large-scale industrial targets.
For instance, several works report the use of tomography to visualize
combustion within a coal-fired furnace [64,487,488], although compli-
cations due to absorption, scattering, and thermal radiation from the
furnace walls pose significant hurdles to the technique. Tomography
has also been used to reconstruct incandescence from pool, forest,
and whirl fires in order to understand their initial development and
subsequent spread [489,490]. The principle and selected applications
of incandescence tomography are reported below.

8.1. Signal model

Flame incandescence is often modeled as graybody emissions in
volumetric incandescence experiments, and it is common to neglect
the effects of self-absorption and scattering. This section provides an
overview of the incandescence signal with an emphasis on spectral
models for soot, demonstrating that common simplifications may be
insufficient for quantitative analysis.

8.1.1. Blackbody emissions

It is convenient to describe thermal radiation in terms of the black-
body emissive power spectrum. A blackbody is an idealized object
that absorbs all incoming electromagnetic radiation and is in thermal
equilibrium with its surroundings. Hence, thermal radiation emitted
by a blackbody is a function of temperature and wavelength, only, as
described by Planck’s Law:

Eb,λ(T ) =

≈

2hc2
λ5
2hc2
λ5

[

(

exp

(

exp

−

hc
λkBT
hc
λkBT

)

]−1

− 1

)

,

(164a)

(164b)

52

Fig. 50. Emissive power spectrum of a blackbody at increasing temperatures. The
visible spectrum is indicated by a gray band.
Source: Adapted from [68].

where h is Planck’s constant, c is the speed of light, and the approx-
imation of Wien (Eq. (164b)) holds for small values of λT , i.e., λT ≲
3000 μm⋅K. Blackbody radiation curves for bodies of increasing tem-
perature are shown in Fig. 50 along with the visible light spectrum.
Most thermal radiation at combustion-relevant temperatures occurs in
the visible–IR range.

Incandescence from a non-ideal emitter in local thermodynamic
equilibrium is modulated by a spectral absorption coefficient, κλ, which
depends on the chemical structure, thermodynamic state, surface char-
acteristics, and size of the radiating body. Local emissions are given by
the product of κλ and Eb,λ(T ),

I ′
λ = κλ Eb,λ(T ).

(165)

When κλ is constant across all wavelengths, the emitter is said to be a
graybody. However, most materials exhibit significant variation in κλ,
including the particulate matter relevant to incandescence tomography.

8.1.2. LoS emission and extinction

Absorption is usually neglected in chemiluminescence imaging since
ground state radicals are quickly consumed by chemical reactions and
the reaction zone is thin. Hence, κλ is approximately null from the
flame surface to a camera. Indeed, this is a key assumption used to
derive Eq. (3). In incandescence tomography, however, the source
field is far thicker and attenuation becomes significant. While self-
absorption and out-scattering are critical considerations in tomography
of incandescence, it is often reasonable to neglect in-scattering, in
which case Eq. (3) may be rewritten as follows:

∞

Iλ ∝ ∫

0

]
[Ψ −1(l)
I ′
λ
{

∞

× exp

− ∫
l∗

βλ

⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟
extinction

[Ψ −1(l∗)]

dl∗

}

dl,

(166)

where βλ = κλ + σs,λ is the spectral extinction coefficient, which
depends on the absorption and scattering coefficients, κλ and σs,λ. Note
that the dependence of Iλ and Ψ −1 on the sensor location have been
omitted from Eq. (166) for brevity. Given the spatial distribution of
βλ, the imaging models in Section 3 can be modified to compensate
for attenuation, per Eq. (166). When κλ and σs,λ are unknown, as
is typically the case since they are generally a function of the QoI,
reconstruction proceeds in a nonlinear fashion, frequently through the
use of an iterative technique [295,491,492].

The extinction term in Eq. (166) is required for ‘‘optically thick’’

targets. The optical depth of a medium is

∞

]
[Ψ −1(l)

dl,

βλ

τλ = ∫

0

(167)

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

which is also called the soot absorption efficiency factor, Qabs,λ [68].
For a cloud of uniform particles, the absorption coefficient is

π d2
p

κλ = ̃Np Cabs,λ =

(mλ
6πEs
λ
where ̃Np is the number of primary particles per unit volume and fv is
the soot volume fraction,

̃Np ελ
4

(171)

fv,

=

)

fv =

πd3
p

6

̃Np.

(172)

Realistic soot fields contain aggregates that comprise a string of
primary particles. This raises three issues. First, there is almost always a
variety of particle sizes, called ‘‘polydispersity’’; second, soot aggregates
absorb more light than an equivalent number of individual parti-
cles [500]; and third, aggregates can indeed scatter light effectively
(see the next section). For a polydisperse aerosol, one can define an
effective particle volume in terms of the particle size PDF, P(dp),

∞

d3
p = ∫
0

d3
p

P(dp) ddp,

(173)

which may be used to calculate fv and κλ. However, the distribution of
primary particle diameters is typically unknown and may vary through-
out the flame [473]. In principle, T-matrix [501] and generalized mul-
tisphere Mie [502] techniques can be used to estimate κλ for a known
distribution of aggregate properties, but these methods are labor inten-
sive and subject to large uncertainties associated with unknown fractal
aggregate parameters. Alternatively, simultaneous calibration measure-
ments can used to estimate the absorption coefficient, for instance,
using broadband, spectrally-resolved absorption measurements [66].

A superficial glance at Eq. (171) might suggest that κλ is propor-
tional to 1∕λ. However, the refractive index of soot varies considerably
as a function of wavelength and there is disagreement in the literature
over the correct functional form [503], as can be seen in Fig. 51.
Therefore, it is common to avoid modeling Es, P(dp), and aggregate
absorption altogether and to replace Eq. (171) with an empirical fit,

κλ ∝

fv
λa

,

(174)

where the typical range of the dispersion exponent, a, is 0.7–2.2 [68].
Unfortunately, as with Eq. (171), this approach is problematic since
a is directly affected by the maturity of an aggregate, in general, and
its hydrogen content, in particular [504]. Again, as before, calibration
measurements can be used to estimate a and the constant of proportion-
ality. For instance, Ma and Long [505] used multi-angle light scattering
and spectrally-resolved attenuation measurements to estimate a for
incandescence tomography.

8.1.4. Soot scattering coefficient

Light scattering by soot is more complex than absorption. The
scattering cross section exhibits wavelength dependencies that vary
considerably with the size and geometry of aggregates. Aggregates are
often characterized using a mass fractal formalism in order to model
their scattering behavior, and this approach is briefly summarized here.
To begin, the number of particles in an aggregate is

̃Np = kf

)Df

,

( 2Rg
dp

(175)

where Rg is the aggregate’s radius of gyration and kf and Df are the
fractal prefactor and dimension, respectively. These parameters are
generally determined by experimentation. For instance, by:

1. using transmission electron microscopy to measure the number
and diameter of primary particles in an aggregate along with its
radius of gyration and then

2. determining the fractal properties of multiple aggregates by

(170)

regression.

53

Fig. 51. Complex refractive index of soot from a variety of experiments: (1) polystyrene
and Plexiglas [494], (2) amorphous carbon [495], (3) propane [496], (4) pyrographite
at 300 K [497], (5) propane [498], and (6) propane [499].
Source: Adapted from [68].

and τλ ≪ 1 must be satisfied in order to use Eq. (3) instead of
Eq. (166). Unfortunately, the strength of the incandescence signal is
directly proportional to κλ, meaning that bright targets are likely to
be optically thick. (A practical consequence of this fact is that regions
of hot, yellow soot are generally opaque.) At a moderate concentration,
isolated soot particles exhibit values of κλ on the order of 0.1–0.2 cm−1
in the visible range [68]. Therefore, hot soot pockets of even a few
centimeters depth are likely optically thick so extinction effects must
be included in the model.

8.1.3. Soot absorption coefficient

Incandescence tomography is primarily concerned with radiation
from soot or ash. Consider soot: soot is made up of small, spherical,
carbonaceous particles, on the order of 5–80 nm in diameter, that
agglomerate into clusters or elongated filaments [493]. The soot life
cycle begins with the synthesis of gas-phase precursors in hot, fuel-
rich regions of a flame; this is followed by the inception of ∼1 nm
particles, surface growth, the coagulation and agglomeration of primary
particles into clusters, and their ultimate oxidation or advection away
from the flame. Due to their small size, soot particles essentially exist
in thermal equilibrium with the surrounding gas. Moreover, since the
diameter of individual particles is much smaller than the detection
wavelength (generally in the visible–IR range), many researchers have
utilized Rayleigh theory to model soot–light interactions. This approach
suggests negligible scattering by isolated particles, i.e., σs,λ = 0.

The absorption cross section of a single particle computed using the

Rayleigh approximation is

Cabs,λ =

)

(mλ

,

π2d3

p Es
λ

(168)

where dp is the particle diameter and Es is the soot refractive index
function,

)

(mλ

Es

= −Im

( m2
m2

λ − 1
λ + 2

)

=

6nλkλ
)2

(n2

λ − k2

λ + 2

.

+ 4n2

λk2
λ

(169)

Here, mλ = nλ − ikλ is the complex index of refraction, which describes
the phase velocity, nλ, and attenuation, kλ, of light passing through
a medium, and Im(⋅) returns the imaginary component of a complex
number. Practitioners often report the spectral emissivity of a soot
particle,

)

(mλ

,

4πdpEs
λ

ελ =

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Optical methods may also be employed to estimate the parameters in
Eq. (175), subject to absorption and scattering models.

Rayleigh–Debye–Gans (RDG) theory is often used to calculate the
scattering properties of fractal aggregates [506]. The theory assumes
that primary particles (monomers) are small and the aggregate is thin
so shielding and multiple scattering events can be neglected. Using this
approach, individual particles have a scattering cross section of

Csca,λ =

2π5d6

p Fs
3λ4

)

(mλ

,

(176)

where Fs is the dimensionless refractive index scattering function,

)

(mλ

Fs

=

|
|
|
|
|

m2

m2

λ − 1
λ + 2

2
|
|
|
|
|

.

The scattering cross section of an aggregate is

σs,λ = ̃N 2

p Csca,λ GRDG,

(177)

(178)

where GRDG is a shape correction factor derived from RDG theory,

(

GRDG =

1 +

)−Df ∕2

.

16π2
3Df λ2

R2
g

(179)

Like κλ, The aggregate scattering coefficient can be expressed in terms
of the soot volume fraction,
(mλ

)

σs,λ =

24π3Fs
λ4

f 2
v .

(180)

Sorensen [506], Michelsen et al. [507], and Modest [68] discuss the
derivation and applicability of this scattering model for soot along with
a few empirical alternatives.

8.1.5. Thermometry

Assuming that the intensity source field can be faithfully recon-
structed at two or more wavelengths, Planck’s Law and the source term
model in Eq. (165) may be used to deduce the temperature distribution.
This is usually done by invoking Wien’s approximation, Eq. (164b);
taking the ratio of local source terms at two wavelengths, λ1 and λ2;
and solving for T ,

T =

log

)

( I ′
λ1
I ′
λ2

(λ−1

kB
hc

)

2 − λ−1
1
)
( κλ2
κλ1

+ log

+ 5 log

( λ1
λ2

.

)

(181)

While Wien’s approximation is reasonably accurate for most flames, ac-
curacy can be improved by directly solving Planck’s Law via nonlinear
optimization or a pre-calculated look-up table [62]. For instance, one
can iteratively solve the following expression:

I ′
λ1
I ′
λ2

=

κλ1
κλ2

( λ2
λ1

)5 exp

( hc
λ2kBT
( hc
λ1kBT

exp

)

)

− 1

− 1

.

(182)

Similar nonlinear techniques can be used for measurements that are
resolved at three or more wavelengths [508,509]. Note that properly
reconstructing I ′
λ requires the concurrent estimation of both κλ and
σs,λ. In principle, the soot volume fraction and temperature fields can
be simultaneously estimated through a nonlinear procedure in which
absorption is modeled via Eq. (171) or (174) and scattering is modeled
with Eq. (180). This method requires a nonlinear optimization algo-
rithm, such as those discussed in Section 2.3.9, or an iterative solution,
as done by Kempema and Long [491]. However, it is common to assume
a uniform value of κλ and neglect σs,λ [62].

It should be emphasized that practitioners do not have a priori
̃Np, Rg, or Df throughout the measurement vol-
knowledge of P(dp),
ume, and tomography experiments reported to date do not feature
enough spectral information to infer these quantities. Moreover, Es
exhibits considerable spectral variation and its precise form depends on
the fuel, operating conditions, and local soot maturity. Quantitative es-
timates of temperature derived from soot incandescence are predicated

54

Fig. 52. Two-camera setup with a view doubler coupled to nine FBEs for incandescence
tomography of combustion from a turbulent diffusion flame.
Source: Adapted from [62].

upon the accuracy of the extinction model. Therefore, going forward,
the uncertainty of temperature estimates should be assessed through a
sensitivity analysis that accounts for unknown (or imperfectly known)
parameters in the absorption and scattering models.

8.2. Instrumentation

The equipment needed to record incandescence is highly similar
to that required for chemiluminescence imaging, so the discussion in
Section 6.2 is also pertinent here. Most practitioners of incandescence
tomography employ one or more CCD or CMOS cameras that pre-
dominantly capture visible light. As before, axisymmetric laminar and
statistically stationary turbulent flames can be characterized using a
single fixed view. However, multiple cameras are needed to capture
unsteady combustion dynamics as well as the mean structure of non-
axisymmetric targets, which are commonly encountered in practical
burners and furnaces.

Numerous groups have reconstructed the incandescence from
laboratory-scale flames to better understand soot formation. A sample
setup, taken from the work of Yu et al. [62], can be seen in Fig. 52. Yu’s
apparatus features two cameras attached to a cube beamsplitter-type
view doubler that is itself coupled to nine FBEs. Both cameras were
equipped with a unique narrow bandpass filter, with one having an
indigo filter centered at 425 nm and the other a yellow filter at 600 nm.
In this way, the authors were able to simultaneously record two-color
projections from nine perspectives. The reconstructed source fields
were ultimately employed to calculate the temperature field in sooting
regions of the flame. FBEs are relatively common in incandescence
tomography, especially when imaging combustion within a furnace,
e.g., [61,62,272,342,348,349].

The use of monochromatic measurements is important due to the
nonlinearities associated with self-absorption, scattering, spectral vari-
ation in mλ, and spectral variation in the quantum efficiency curve
of the camera sensors, i.e., ηλ in Eq. (4). However, the majority of
volumetric incandescence experiments utilize a broadband signal, often
corresponding to the red, blue, and/or green channels on a color
camera. This practice is a source of error that amplifies the (already
considerable) uncertainty of temperature and soot volume fraction
estimates. Furthermore, color camera sensors generally feature an inter-
laced arrangement of dedicated red, blue, and green pixels, frequently
arranged in the Bayer filter pattern or similar. Hence, at any given pixel,
two channels are interpolated, meaning the resolution of a color sensor
is lower than that of a monochrome sensor of the same size.

In addition to laboratory studies, many researchers have deployed
multi-camera incandescence imaging to study industrial furnaces. Fur-
naces feature harsher conditions and far less optical access than an
open laboratory, imposing numerous constraints on the imaging array.

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 53. Sample industrial furnace setup showing: (a) the arrangement of 20 cameras inside a 660 MW pulverized-coal arch-fired boiler [510] and (b) sketch of a CCD probe [64].

Fig. 53 depicts the schematic of a volumetric incandescence sensor in a
pulverized-coal arch-fired furnace. The system features 20 CCD sensors,
each encased in a stainless steel probe that is inserted into the furnace
wall. The probes are fitted with a lens, relay optics, and cooling system
to protect the lens and camera, as shown in Fig. 53(b). In addition to
cooling, air from the probes is directed at each lens to prevent the build-
up of particulate matter. Due to the varied operating temperatures and
levels of optical access of industrial furnaces, each furnace typically
requires a tailored imaging solution.

8.3. Passive soot characterization

Soot plays an essential role in radiative heat transfer in combus-
tion [511] and has significant effects on human health and morbid-
ity [512] as well as the environment [513]. Therefore, in situ measure-
ments of soot are needed to gain understanding and control of soot
emissions. Passive incandescence tomography offers a low-cost, non-
intrusive technique to study soot in laboratory-scale flames. Fuel-rich
diffusion flat flames, often produced using C2H4, serve as a represen-
tative target for the investigation of soot inception and its subsequent
growth [514–516]. The laminar, axisymmetric structure of these flames
enables high-SNR measurements via multiple repeats and accurate
reconstructions through Abel inversion. As a result, the maturation
of soot throughout a flame can be mapped via tomography. Ideally,
this is done using both absorption and emission modalities [514].
Absorption measurements yield the spatial distribution of κλ at two or
more wavelengths and emission measurements provide the emission
source field, I ′
λ. Eq. (181) or (182) can then be used to deduce T
without knowledge of the soot refractive index function. However, if Es
is known at any of the detected wavelengths, then the local soot volume
fraction can be calculated with Eq. (171), i.e., given estimates of κλ
and T . Early examples of two-color soot pyrometry can be found in the
works of Lee, Cignoli, Connelly, and their coworkers [515,517,518].

Developments in imaging soot pyrometry for axisymmetric flames
are embodied by the work of Long’s group. At the outset, in 2005,
Connelly et al. [518] estimated the temperature field of an ethy-
lene diffusion flame with a color camera, assuming an optically thin
flame and negligible absorption and scattering. Soot was modeled as a
graybody, meaning that ελ was treated as an arbitrary constant, and
the camera’s absolute spectral response was not considered. Hence,
the signal was adjusted for τf,λ, only, as opposed to ηλ × τf,λ. The
authors compared their estimates to a simulated temperature field
and found poor agreement. Several steps were taken to improve this
procedure in subsequent papers. For instance, the group used a mercury
vapor lamp and blackbody source to calibrate their camera’s spectral
response [519]; they conducted simultaneous emission, absorption,
multi-angle light scattering, and LII measurements to estimate κλ and
σs,λ [505,520]; and they augmented their reconstruction algorithm
to account for self-absorption [491] using the iterative correction of
Snelling et al. [516]. Fig. 54 typifies later reconstructions from Long’s

Fig. 54. Temperature fields of a conventional and microgravity CH4/air flame.
Source: Adapted from [521].

group [521]. In this example, incandescence tomography was used to
determine the temperature and soot volume fraction fields of CH4/air
flames under normal gravity and microgravity conditions. A 2D disper-
sion exponent map, determined using absorption and LII measurements
in [505], was used in conjunction with Eq. (174) to interpret the
emission source fields. This work exemplifies the need for multi-modal
measurements to properly utilize incandescence tomography as a soot
diagnostic, due to the complexity of soot optical properties.

Despite secular improvements in these works, readers are advised
that a color camera should not be used for incandescence tomography
without a narrowband filter for each channel, e.g., using a dual- or
tri-band filter or non-simultaneous measurements [522]. Spectral in-
tegration over the red, blue, and green channels is a source of error,
caused by the nonlinearity in Eq. (4) that occurs when there is spectral
variation across ηλ × τf,λ. In most cases, ηλ, κλ, mλ, and Eb,λ will all
exhibit significant variation over the range of each channel. Therefore,
it is better to use a view doubler or filter wheel equipped with multiple
filters than a color sensor. Nevertheless, color cameras remain in use for
two-color pyrometry [523,524].

The effects of self absorption and Es on estimates of T and fv were
studied in detail by Liu et al. [525]. They revisited 2D experimental
results from earlier papers [526,527] using absorption correction tech-
niques developed by Freeman and Katz [528], Hall and Bonczyk [514],
and Snelling et al. [516]. Self-absorption effects on temperature esti-
mates were deemed insignificant for optical depths up to 0.3, which
holds true for many small sooting flames up to 10 mm in diameter;
scattering was found to be negligible in all cases. Errors in the peak
temperature were around 20–50 K for the small flames investigated by

55

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

a boiler. This is often done using the forward or backward Monte
Carlo method, as described in [68,542,543], as opposed to the linear
reconstruction algorithms discussed in Section 2. Furthermore, the
images must be recorded with a rugged industrial CCD camera, per the
example in Fig. 53, and it is rarely possible to record adequate signal
through a narrow bandpass filter. The experimental and data analysis
methods required to reconstruct temperature fields in a large boiler are
thus outside the scope of this review.

9. Laser-induced incandescence

Incandescence occurs naturally in sooting flames because the aggre-
gates are in thermal equilibrium with product gases that are hot enough
to induce visible thermal radiation. However, richer information can be
extracted from incandescence by heating the particles with a controlled
laser pulse and recording the resultant radiation while the particles
cool. This technique, called LII or ‘‘laser-induced incandescence’’, is an
established method for characterizing particulate matter, especially in
combustion and environmental applications [473]. Notably, LII can be
used to estimate the volume fraction, temperature, and size distribution
of particles in the probe region. Targeted particles may be formed
inadvertently, like soot, or intentionally, in the case of engineered
nanoparticles. Quantitative information from LII is used to develop a
better understanding of the formation, growth, and oxidation of such
particles in flames, liquids, exhaust gases, and other scenarios. LII was
initially realized as a point diagnostic, followed by planar [23,544] and
then linear [545,546] implementations; 2D LII tomography was dis-
cussed by Wright et al. [547] but never conducted. Recent advances in
ultra-high-speed imaging and the development of high-powered high-
repetition-rate lasers have enabled VLII (volumetric LII) to measure
unsteady flames, which was pioneered by the group of Meyer [478]
in 2017. This diagnostic can potentially provide crucial information
about soot development in turbulent combustion and shed light on the
behavior of nanoparticle reactors. This section introduces the basics of
LII modeling followed by a brief description of point-wise, 2D, and 3D
setups. Current applications of VLII are reviewed.

9.1. Signal model

Laser-induced incandescence is similar to natural incandescence in
that the signal results from the emission and self-extinction of thermal
radiation along a LoS. Therefore, an LII signal can also be modeled
using Eqs. (165) and (166). However, in LII, the particles are heated
with a laser pulse and reach a peak temperature in the range of
2500–4000 K, which is followed by rapid cooling [24]. Consequently,
quantitative analysis of an LII signal, such as those shown below in
Fig. 58, requires detailed heat and mass transfer models in addition
to the spectroscopic models presented in Section 8.1. These models
are summarized below. Comprehensive details can be found in the
review of Michelsen et al. [473]. Note also that there are several
freely-available software packages for analyzing LII signals, including
LIISim [548] and CLiiME [549].

9.1.1. Energy and mass balance

The basic concept in LII is to model the target particles using a time-
dependent energy and mass balance. Michelsen et al. [473] provided
the following expression to describe the rate of change of a particle’s
internal energy, Uint :
dUint
dt

= ̇Qabs + ̇Qrad + ̇Qcond + ̇Qsub+

̇Qann + ̇Qox + ̇Qtherm,

(183)

where each ̇Q is a heat rate in watts due to absorption, radiation,
conduction, sublimation, annealing, oxidation, or thermionic emission,
̇Qcond, and ̇Qsub
as illustrated in Fig. 56. In most circumstances,
are several orders of magnitude larger than the other terms, which are

̇Qabs,

Fig. 55. Evolution of the 3D temperature field in soot pockets from a turbulent C2H2
diffusion flame.
Source: Adapted from [62].

Liu et al. [525], which was subsequently confirmed by the imaging
pyrometry study of Kempema and Long [491]. Crucially, however,
spectral variation in the soot refractive index function has a significant
effect on fv. Spectrally-resolved emission and absorption measurements
can be used in tandem to assess κλ, Es, fv, and T , e.g., [529–531].
Per these references, hyperspectral imaging is a powerful tool for
characterizing soot formation in laminar flames.

The need for multi-diagnostic, spectrally-resolved data poses a chal-
lenge to the study of soot formation in turbulent flames. Therefore,
early work on 3D pyrometry of non-axisymmetric flames also made
use of color cameras, sans bandpass filters. The group of Yan reported
the first such measurements of a series of unsteady non-premixed sooty
flames [61,272,343,348,349,532,533]. To start, they used three color
CCD cameras and stereoscopes to record six views of an unspecified
sooting flame [343]. Quickly thereafter, they developed an FBE system
and characterization workflow [349], and they adopted the procedure
described above to estimate the flame temperature and soot emissivity
in a small scale enclosed furnace [350]. While the calculations in [350]
model soot as a graybody, later works [61] adopt the more appropriate
model of Chang and Charalampopoulos [498] to estimate fv in addition
to T and ελ. Yan’s group also estimated geometric flame parameters
like the surface area and volume [534], and applied their techniques to
a rich premixed swirl flame [533]. Few details about the combustion
process are provided in these works. It should also be noted that the
geometric properties of a luminous soot field are not directly related
to the flame surface area and volume of interest in Section 6.4. In
recent years, several other researchers have utilized the techniques of
Yan et al. to conduct color camera visualization of soot temperature
fields [535–537].

Future developments in incandescence tomography are likely to
focus on improved characterization of soot optical properties, partic-
ularly via multi-modal measurements, and the use of filters to iso-
late monochromatic emissions. As an example, Yu et al. devised the
two-camera, nine-FBE setup shown in Fig. 52 to facilitate two-color
pyrometry of a turbulent C2H2 diffusion flame. A series of succes-
sive reconstructions from this work can be seen in Fig. 55. With the
addition of time-resolved absorption data, perhaps recorded through
the use of frame straddling, this technique could be used to observe
the development of soot in laminar and turbulent flames of identical
composition. Another recent study using time-resolved 3D incandes-
cence tomography is described in the paper by Windle et al. [342].
There, the authors utilize a single-camera system equipped with FBEs to
reconstruct fire events for ground vehicle testing, reporting soot fields
resolved at 500 Hz.

Lastly, it is worth mentioning that several groups utilize techniques
similar to incandescence tomography to characterize industrial boil-
ers [64,484,487,488,538–541]. Imaging conditions in a boiler are harsh
relative to the small targets described above. There is appreciable
thermal radiation from the furnace walls, which serves as an unknown
and dynamic boundary condition, as well as long path lengths that lead
to significant attenuation and multiple scattering events. Consequently,
the full RTE must be solved to interpret images of incandescence in

56

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

integration can be used to compute ̇Qrad when Es exhibits a strong
wavelength dependence (see Fig. 51). However, errors associated with
a variable soot refractive index function are of secondary importance
since radiative cooling is relatively insignificant at atmospheric pres-
sures and above. Instead, the primary role of radiation is to produce the
temperature- and particle size-dependent LII signal, which is needed to
solve Eqs. (183) and (184).

9.1.3. Conduction

Conductive cooling by the bath gas is dominant at low-to-moderate
fluences when the target particles have a high boiling point. The
conduction regime depends on the frequency of collisions, often charac-
terized in terms of the Knudsen number, which is the ratio of the mean
free path of gas-phase particles to the target particle diameter. When
the Knudsen number is much less than one, targeted nanoparticles are
continually bombarded by the bath gas particles and cooling occurs in
the continuum regime,

̇Qcond = −kgasπdp

(Tparticle − Tgas

) ,

(187)

where kgas is the average thermal conductivity of the bath gas. Alterna-
tively, Knudsen numbers much greater than one correspond to the free
molecular regime, in which collisions between bath gas and targeted
particles are much rarer. Under these circumstances, conduction is
modeled in terms of the frequency and average energy of collisions.
Sipkens [551] provided a detailed discussion on free molecular con-
duction and Michelsen et al. [473] summarized the resulting model as
follows:

Fig. 56. Illustration of the physical mechanisms that can take place during LII,
including the absorption of laser light, oxidation and annealing, particle mass loss
by oxidation and sublimation, particle cooling by conduction to the surroundings and
sublimation, and thermionic and radiative emission.
Source: Adapted from [473].

often neglected as a result. The change in internal energy over time
can be expressed in terms of a particle’s density, ρ, specific heat, cs,
diameter, dp, and temperature, T ,

dUint
dt

= csρ

πd3
p

6

dT
dt

= csmp

dT
dt

,

(184)

̇Qcond =

√

−πd2

p αTpgas
RTgas

(

RTgas
2πWgas

Cp −

R
2

) (T − Tgas

) ,

(188)

where mp is the particle’s mass, which may be treated as a dynamic
quantity due to the effects of sublimation and oxidation. Given models
of the heating and cooling terms in Eq. (183), as well as time-resolved,
multi-spectral data, the temperature trace can be found pyrometrically
and then Eqs. (183) and (184) can be simultaneously solved to deduce
the size of particles in the probe region. In VLII, measurements of Iλ
from multiple cameras are employed to reconstruct I ′
λ, which is used
in turn to estimate QoI such as the volume fraction of target particles
or their primary particle diameter, discussed in Sections 9.3 and 9.4,
respectively.

9.1.2. Radiative absorption and emission

Specifying an appropriate set of heat transfer models for LII is a
difficult task since there is far more ambiguity in presence of laser
heating than there is with natural incandescence. To start, absorption
is a function of heating by the laser,

where pgas and Tgas are the ambient pressure and temperature, Cp and
Wgas are the specific heat and molecular weight of the bath gas, R is the
universal gas constant, and αT is the so-called thermal accommodation
coefficient. This parameter is difficult to model and therefore acts as
a key source of uncertainty in many LII analyses. While the Knudsen
number is rarely much less than one in LII, the assumption of free
molecular conduction breaks down at high pressures and temperatures
(i.e., at relatively low Knudsen numbers), leading to a transitional
regime between continuum and free molecular conduction. There is
some debate over the appropriate model to use for transitional con-
duction, as discussed in [473,551,552]. It should also be noted that
shielding of inner nanoparticles in a soot aggregate [553] and heating
of the bath gas by the laser [554] can introduce errors into the cooling
model.

9.1.4. Sublimation

̇Qabs(t) = κλ ̇qlaser (t),

(185)

Coupled heat and mass loss via sublimation becomes dominant at

high laser fluences. This effect is typically modeled as

where ̇qlaser is a time-resolved profile that may be determined exper-
imentally and ∫ ̇qlaser dt is the laser fluence, i.e., the incident energy
divided by the beam’s cross sectional area [550]. Under the assump-
tions of Rayleigh theory, the particle diameters in Eq. (185) (in κλ)
and Eq. (184) will cancel out such that the target particles heat up
at the same rate and eventually reach a single peak temperature, viz.,
when heating and cooling are balanced [551]. However, laser beams,
sheets, and slabs typically exhibit spatial variation that can change over
time. This effect, coupled with the decay in ̇qlaser due to absorption
and scattering along the path of illumination, can result in nonuniform
heating.

The radiation model is obtained by multiplying Eq. (165) by 4π to
account for volumetric emission and integrating over all wavelengths,

∞

̇Qrad = 4π ∫

0

κλEb,λ(T ) dλ.

(186)

Michelsen [550] presented a closed-form solution to this integral using
Eq. (171) for κλ and assuming a constant value of Es. Numerical

̇Qsub = Δhv

( dmp
dt

)

,

sub

(189)

where Δhv is the specific heat of vaporization. In LII, sublimation is
thought to occur in the free molecular regime, wherein individual
atoms and clusters of atoms are spontaneously ejected, which can
be modeled by applying a continuity condition at the surface of a
nanoparticle [551]. Mass loss in Eq. (189) is due to sublimation (as op-
posed to oxidation), and this rate can be estimated using the following
expression:
( dmp
dt

p W αMpv
RT

( RT
2πW

−πd2

(190)

)K

)

=

,

sub

where W is the molecular weight of the carbon clusters, αM is the
mass accommodation coefficient, pv is the vapor pressure, and K ≈ 0.5
is a constant that can be modified to account for nonideal effects.
An extensive treatment of sublimation can be found in Michelsen
et al. [555]. Note that additional models are needed to estimate the

57

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

time-resolved cooling curve, and use it to estimate the primary particle
size and (potentially) aggregate morphology parameters [23,544,559].
The intensity of a laser beam can be attenuated through the use
of half-wave plates as well as thin-film polarizers, and a power meter
should be installed to monitor the laser’s fluence throughout an ex-
periment. Laser fluences used to conduct point-wise LII measurements
of the primary particle size of soot are around 0.1–0.2 J/cm2 [560–
562]. Fluences are somewhat higher in planar tests, ranging from
0.3–0.5 J/cm2 [563,564], and more power still may be required for
VLII. For instance, Meyer et al. [65] used a total output of 1 J/pulse to
form a laser slab with an average fluence of 0.1 J/cm2 throughout the
probe volume; Bauer et al. [66] used 0.58 J pulses to produce a fluence
of about 0.08 J/cm2; and Hall et al. [67] used 0.725 J pulses to produce
a fluence of ∼0.15 J/cm2. As with VLIF, quantitative evaluations of
VLII require careful calibration of the illumination field and attenuation
of the laser slab, which may be done using a beam profiler and LoS
attenuation measurements [66,544].

Temporal mode structures can be minimized through the use of laser
injection seeding [67]. While very short pulses, on the order of 50–
100 ps, help to isolate specific heating and cooling mechanisms, which
is essential for the development and validation of LII models, longer
pulses, lasting approximately 0.1–1 μs, are preferred for volume fraction
measurements [473].

Point-wise measurements are generally made using optics that col-
lect light from a quasi-point probe volume located at the beam waist.
The light is passed to one or more fast photomultiplier tubes that
can resolve the cooling process (see Fig. 58), and bandpass filters
are frequently installed to isolate emissions from a narrow spectral
range [562,565]. Spectrally-resolved 1D measurements can be con-
ducted with a streak camera [545,546], and single-channel (broadband
or monochromatic) planar measurements are recorded using a high-
speed intensified camera [566–568]. Selection of an appropriate filter
is a key component of LII since there are many sources of emission-
based interference and self-extinction behavior is highly wavelength-
dependent. As a result, it is advisable to record emissions from the
target with a spectrometer to check for interference and identify a
narrow detection range that is dominated by thermal radiation from
the target particles. Michelsen et al. [473] provided guidelines for
the selection of detection wavelengths under different experimental
conditions (see Table 2 of [473]). In some setups, the cameras are fitted
with notch filters to eliminate the laser’s wavelength from the signal.
Time-resolved VLII requires simultaneous high-speed imaging from
multiple perspectives, which considerably increases the cost of experi-
mentation. View splitters, such as stereoscopes [65,67] and FBEs [66]
(Section 6.2), are ubiquitous in VLII since they reduce the number
of cameras needed for tomographic imaging. For instance, Meyer
et al. [65] used the stereoscope system pictured in Fig. 24(a) to
record projections from 14 views with seven cameras. The authors
reconstructed the soot volume fraction field using LII signals that were
integrated over 100 ns and recorded at rates from 10–50 kHz: fast
enough to capture the turbulent flow field but insufficient to resolve the
LII cooling curve, which must be measured at a rate of tens to hundreds
of MHz. This was recently done by Hall et al. [67], who also used
stereoscopes to capture six views with three ultra-fast cameras to make
time-resolved measurements (10 MHz) of the LII signal; their setup
is depicted in Fig. 57. All VLII experiments reported to date featured
a quasi-monochromatic signal in the visible range, imaged through a
narrow bandpass filter.

9.3. Soot volume fraction fields

Evolution of the soot volume fraction field throughout a flame
can provide valuable insights into the mechanisms that underpin soot
formation and growth. Measuring and interpreting 3D fv fields is
particularly challenging in a turbulent flame, and turbulence can have
a profound effect on the production and morphology of soot. Since

Fig. 57. Stereoscope and camera configuration for time-resolved VLII. Six views were
recorded at 10 MHz by three Shimadzu HPV-X2 cameras using a custom set of
stereoscopes. This ultra-high-speed imaging setup facilitated quantitative estimation of
the primary particle size field.
Source: Adapted from [67].

specific enthalpy, mass accommodation coefficient, vapor pressure and
other parameters, depending on the chosen expression for ̇Qsub. Select-
ing appropriate sub-models to estimate the amount of heat and mass
lost to sublimation is thus a nontrivial task that is examined at length
in [473,551,555].

9.1.5. Other mechanisms and considerations
Additional models that account

for annealing, oxidation, and
thermionic emission are outside the scope of this review. However, it
bears mentioning that annealing and oxidation can affect the optical
properties of targeted nanoparticles. A number of studies attempt
to model these phenomena, as covered in the review of Michelsen
et al. [473], but the inclusion of additional models is unlikely to yield
significant returns in the context of volumetric imaging due to the
limited spectral and temporal content of the reconstructed signals.
It should also be noted that the LII models discussed in this section
presume uniform particle temperatures within each aggregate and
monodisperse particles. In reality, particle diameters and the fractal
properties of aggregates are usually polydisperse, and shielding effects
can lead to a distribution of particle temperatures at any given in-
stance [556]. These and other such effects considerably complicate the
interpretation of an LII signal.

9.2. Instrumentation

As with LIF, LII involves a combination of laser-based stimula-
tion (heating, in this case) and optical detection equipment. As a
result, many of the techniques, considerations, and concerns outlined
in Section 7.2 are applicable here, as well.

In most cases, target particles are heated with the first harmonic
of an Nd:YAG laser, which generates IR light centered at 1064 nm.
Shorter wavelengths and higher fluences increase the probability of
fluorescence, e.g., from C2 or PAHs, so longer (ideally IR) stimulation
wavelengths are preferred [473,557,558]. The laser fluence must be
high enough to induce visible incandescence, but careful control is
required to tailor the signal, depending on the application. For instance,
high fluences can lead to a balance between absorption and sublimation
such that a ‘‘saturation’’ peak temperature is reached. (In other words,
the peak temperature will not increase beyond the saturation temper-
ature with higher fluences or longer pulses.) Under these conditions,
the LII signal is assumed to be proportional to the volume fraction of
nanoparticles, as discussed in the next section. Sublimation and the
ensuing model uncertainties are mostly avoided at lower temperatures,
provided that the nanoparticles exhibit a high boiling point; therefore,
an alternative mode of LII is to use a weaker laser pulse, record the

58

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Fig. 58. Sample LII cooling curves produced by heating soot above a premixed
ethylene/air flame with an equivalence ratio of 2. These results depict distinct cooling
curves as a function of the height above the burner (HAB); differences are attributed
to changes in the absorption cross section that correspond to soot maturity.
Source: Adapted from [572].

soot particles are usually small relative to the wavelength of detected
light (see Section 8.1.3), there is a volumetric interaction between the
particles and electromagnetic field such that I ′
λ ∝ fv. Unfortunately,
this relationship is insufficient to surmise the local soot volume fraction
from I ′
λ because the temperature of the heated particles is not gener-
ally known. Nevertheless, the peak temperature can be controlled by
stimulating the particles with high-intensity laser light until there is a
balance between ̇Qabs and ̇Qsub, at which point the particle temperature
saturates. Melton [569] analyzed the peak LII signal in this limit and
showed that it is approximately proportional to the volume fraction of
soot. Therefore, following calibration of the signal to obtain the con-
stant of proportionality, LII can be used to estimate fv at a point [570]
or to resolve 1D [571], 2D [544], or 3D [65] regions of the volume
fraction field.

Adequate control of the laser beam, sheet, or slab as well as proper
calibration of the signal are key aspects of quantifying fv. Melton’s
model presumes large (visible or IR) excitation and detection wave-
lengths [569], and filters are needed to omit LIF-based interference.
For gated signals, a short integration time is preferred because small
particles cool quickly and long-lived incandescence from large particles
can bias the results [473]. When processing spatially-resolved signals,
it is important to verify that the cooling curve is consistent throughout
the interrogation region, for instance, by recording time-resolved LII
signals at various points throughout the domain. Cooling curves often
change throughout a flame, as can be seen in Fig. 58, where the rate
of cooling exhibits a complex dependence on soot maturity due to
the myriad effects of soot chemistry, density, specific heat, etc. [572].
Moreover, attenuation of the laser beam throughout the flame can
affect the heating and thereby peak temperature of ‘‘downstream’’ soot
particles, altering the scaling between I ′
λ and fv. These effects cannot be
discerned from a temporally-integrated signal, which limits the utility
of such measurements in absence of additional calibration.

The first application of VLII to an unsteady flame was reported by
Meyer et al. [65], who used a 100 ns integrated signal to capture the
soot flow field produced by a turbulent ethylene/air flame (ReD ≈
9000). The flame was heated using the fundamental harmonic of a
high-power burst-mode Nd:YAG laser and recorded at rates ranging
from 10–50 kHz. Stereoscopes were used to record 14 views of the
flame, as discussed in Section 9.2, although only eight of them were in-
cluded in the reconstruction procedure due to limitations of the SMART
algorithm in DaVis. This algorithm presumes that LoS extinction is
negligible, i.e., τλ ≪ 1, which is not typically true of sooting flames.
The short path lengths of 1–3 cm through soot pockets in this study
suggest that errors produced by neglecting absorption and scattering
could be small but this was not verified. Moreover, errors associated
with changing soot maturity and attenuation or steering of the laser
slab are likely to be appreciable. Therefore, the measurements of Meyer

59

Fig. 59. Selected snapshots from a time-resolved reconstruction of the soot volume
fraction field produced by a turbulent ethylene/air flame, obtained using VLII. Imaging
was conducted at 10–50 kHz, which was sufficient to record the formation and
extinction of soot pockets.
Source: Adapted from [65].

et al. [65] are considered to be a qualitative indicator of sooting.
Further experiments, such as LoS extinction [573], multi-angle elastic
light scattering [574], or beam profilometry [575], could be used to
estimate the optical properties of soot throughout the domain and
characterize attenuation of the laser slab in order to extract quantitative
information about fv in a nonstationary target (see Fig. 59).

9.4. Primary particle diameter fields

The size of soot particles throughout a flame is another important
indicator that can inform soot formation models. In pointwise and
planar tests, two-color time-resolved LII signals are used to calcu-
late the particle temperature via pyrometry; the temperature trace is
then used to determine dp through the use of heating and cooling
models [548,576,577]. However, the number of projections is already
severely limited in time-resolved VLII due to the appreciable cost
of ultra-high-speed cameras. Adding a second set of filters, thereby
halving the number of projections, may not be feasible. Alternatively,
quantitative evaluations of the primary particle diameter can be made
using single-color LII at the cost of increased uncertainties, i.e., since
it is not possible to fix the particle temperature with pyrometry. This
technique was recently demonstrated by Hall and her colleagues [67]
and subsequently evaluated by Bauer et al. [66].

Hall et al. [67] were the first to conduct quantitative measurements
of dp in a turbulent flame with VLII. They used the fundamental
harmonic of a high-power Nd:YAG laser (725 mJ/pulse) to heat soot in
a 10 × 50 mm2 cross section of a turbulent ethylene/air diffusion flame
(Re ≈ 10, 000). Projections were recorded by three cameras (Shimadzu
HPV-X2) from six angles using the setup shown in Fig. 57. The cameras
recorded approximately 10 frames of bandpass filtered light, centered
at 600 nm, after each pulse. This data was reconstructed using the
MART algorithm in DaVis and dp was estimated by comparing the
local cooling curve in each voxel to a precomputed library of cooling
curves. Fig. 60 depicts (a) the library of cooling curves as well as
(b) instantaneous isosurfaces and planar cross sections of the primary
particle diameter field.

̇Qabs,

Hall et al. [67] used the method of Cenker et al. [577] to convert
local LII signals into an estimate of dp. Normalized cooling curves
̇Qcond, and ̇Qsub.
were produced in LIISim, accounting for
Uncertainties due to unknown parameters, such as the flame tem-
perature and soot optical properties, were considered by varying the
flame temperature from 1450–1750 K and the soot absorption function
from 0.2–0.4. Sample cooling curves from the procedure can be seen
in Fig. 60(a), with reconstructed cooling data from a single voxel
superimposed on the library. (The method of comparing voxel data
to the library was not discussed.) The effects of laser slab steering

̇Qrad,

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

and performance metrics are covered in a unified framework. Chemi-
luminescence, laser-induced fluorescence, passive incandescence, and
laser-induced incandescence are discussed in that order, including an
overview of the pertinent signal physics, requisite instrumentation, and
utilization of these modalities.

Optical combustion diagnostics began with point, linear, planar, and
line-of-sight integrated methods, implemented with some combination
of cameras, photodiodes, spectrometers, and lasers. However, 0D–2D
measurements are insufficient in many cutting-edge combustion exper-
iments because they cannot resolve the intrinsically three-dimensional
dynamics. In particular, 3D measurements with a significant dynamic
range are needed to capture coherent structures in turbulent com-
bustion, as they play a central role in stabilization, thermoacoustic
instability, molecular mixing, heat transfer, and other processes. For-
tunately, the optical signals discussed in this review can be combined
with a tomographic reconstruction algorithm to recover 3D combustion
structures from 2D images. Averaged images from a single camera may
be unwrapped via Abel inversion in the case of an axisymmetric flame,
whereas multiple synchronous images from unique perspectives are
required to reconstruct instantaneous snapshots of a turbulent field. By
expanding laser sheets into slabs, adding cameras to the experimental
setup, and conducting measurements in rapid succession, it is possible
to perform time-resolved, volumetric ‘‘4D’’ measurements of combus-
tion fields. The accuracy and resolution of 4D combustion sensors,
most of which are based on light emission, are rapidly increasing
as the equipment becomes cheaper and reconstruction algorithms are
improved. Therefore, the role of volumetric emission tomography for
combustion processes is expected to grow in the coming years.

Emission tomography begins with single- or multi-camera imaging
of the light produced within the probe volume, sometimes using a laser
to stimulate this light. Images of a flame are recorded with industrial- or
scientific-grade cameras, often coupled to an intensifier to amplify a UV
or dim visible signal. Multi-camera image capture must be orchestrated
with a precise timing system, especially when conducting laser-based
methods like LIF or LII. A narrow wavelength range, often selected to
isolate emissions from a target species, is enforced with bandpass filters
to ensure a quasi-monochromatic measurement that is free of interfer-
ence. Many cameras and/or view splitters can be used to accommodate
more than one filter per view, e.g., to conduct ratiometric estimation of
the equivalence ratio field or the temperature of soot pockets. Further,
high-speed cameras and high-repetition-rate lasers have enabled 4D
measurement. Spectral resolution could be achieved via fast imaging
spectrometry, for instance, by way of snapshot imaging [578,579].
Spectrally-resolved measurements convey richer information about a
combustion process than do multi-spectral data, potentially increasing
the number of parameters that can be measured in an unsteady flame
and paving the way towards fully-fledged data assimilation. Commer-
cially available imaging spectrometers are currently limited to a frame
rate on the order of 1 kHz, which is insufficient for turbulent com-
bustion. Nevertheless, recent developments in optical metasurfaces and
computational spectrometry [580,581] represent a significant advance
towards high-speed detection.

With LoS-integrated emissions data in hand, the images must be
reconstructed to estimate the 3D source field. Reconstruction consists
in the inversion of a measurement model that represents the image
formation process. This paper covers models of increasing realism,
from thin rays to cylinders, and thereon to cones and lastly ‘‘voxel
spread functions’’, which directly model a camera’s response to a 3D
continuum of point sources. Realism comes at a computational cost:
it takes far more computing power to calculate VSFs than thin ray
sensitivities. However, the fidelity of the imaging model has a con-
trolling effect on reconstructions, and this cost is repaid in terms of
reconstruction accuracy. The chosen imaging model must be calibrated
using techniques from the computer vision literature, after which the
discrete measurement model can be specified.

Fig. 60. Time-resolved VLII experiment of Hall et al. [67]: (a) soot cooling curves for
variable dp, predicted using the model of Cenker et al. [577], and (b, left) isosurfaces
and (b, right) horizontal slices of the primary particle size field in a turbulent flame.
Source: Adapted from [67].

or attenuation, polydisperse primary particles, and self-extinction are
likely significant in this context and should be addressed in future work.
Moreover, while Hall et al. [67] mentioned that values of dp were
insensitive to slight changes in temperature and Es, most studies report
a significant dependence of dp on these properties, e.g., [548,561].

More recently, Bauer et al. [66] performed VLII of a laminar diffu-
sion flame using the same monochromatic technique as Hall et al. [67]
to evaluate the signal. Unlike Hall and her coauthors, Bauer et al. [66]
investigated a steady flame through repeated measurements, using a
variable delay between the laser pulse and camera trigger to obtain
quasi-time-resolved projections. Tomographic two-color pyrometry was
conducted after the fact to estimate the initial bath gas (flame) temper-
ature; beam profilometry was used to characterize the consistency and
attenuation of the laser slab; and LoS extinction measurements were
carried out with a broadband light source and spectrometer to estimate
the optical properties of soot in situ. (See [62] or Section 8.3 for a
discussion of the pyrometry experiment.) Analysis of the particle size
was conducted using the model described in [556], which is similar
to the one used by Hall et al. [67] except that Bauer also neglected
̇Qrad. Bauer and his coworkers assumed monodisperse particles and
constant optical properties in their work, although they note that these
values are likely to vary throughout the flame. Laser slab attenuation of
5%–10% was observed, which could significantly influence estimates
of the soot volume fraction, but dp is more robust to variations in
the fluence than fv. Uncertainties in soot optical properties and laser
heating were considered in a Bayesian analysis, and the authors made
several recommendations for future testing. In particular, uncertainties
could be reduced by using an FBE system in conjunction with MHz-rate
imaging (as in [67]) to conduct two-color time-resolved VLII.

10. Summary and outlook

This paper reviews volumetric emission tomography as applied to
combustion processes. Details of the mathematical formulation, re-
construction algorithms, imaging models, camera calibration methods,

60

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

Estimating an emission source field from a set of image data is an
inherently ill-posed problem. Practitioners are trapped between Scylla
and Charybdis. On the one hand, if a coarse basis is used to represent
a flame, model errors act like noise, leading to artifacts, and the coarse
reconstruction bears little resemblance to the true field. On the other
hand, given a basis with sufficient resolution to capture the flow, the
measurement model will possess a nontrivial null space such that an
infinite set of fields could fully satisfy the data. No matter what, ‘‘prior’’
information must be incorporated into the reconstruction procedure to
obtain a realistic estimate of the source field.

Mainstay algorithms include the iterative ART, MART, and SIRTs.
These are mature methods that deliver acceptable reconstructions in a
reasonable time, provided that the measurement system contains many
cameras spread across a wide arc. However, these algorithms must
be truncated to avoid high-frequency artifacts, which amounts to an
ad hoc form of regularization. Classical regularization techniques and
statistical formulations often improve the quality of reconstructions,
but most of these methods are plagued by lengthy computation times
and generally yield overly-smooth 3D fields with ‘‘steaky’’ artifacts.
Conventional deep learning can be employed to speed-up reconstruc-
tion via well-chosen training data, but curating an appropriate training
set is a major challenge in its own right. Conversely, performing
comprehensive data assimilation with noisy measurements that have
an ambiguous relationship to the quantities of interest is currently
out of reach. Deep learning tools offer an intermediate compromise:
physics-informed neural networks can be used to identify fields that
approximately satisfy the governing physics and reproduce the mea-
sured data. Physics-based workflows of this nature are likely to gain a
foothold among combustion scientists.

While it is desirable to characterize the spatio-temporal-spectral
resolution of an optical sensor, only the latter two aspects are fully
tractable in tomography. The commonplace notion of ‘‘spatial resolu-
tion’’ breaks down in the presence of reconstruction artifacts, which are
inevitable due to noise amplification and the multiplicity of solutions.
These artifacts, or errors, are not akin to limited resolution or blur,
they are simply mistakes in the estimate. Therefore, it is useful to
conduct uncertainty quantification to understand the limitations of a
reconstruction, e.g., using a Bayesian technique that accounts for prior
information, but it is not possible to give a simple account of spatial
resolution. Typical reconstruction errors can be identified through a
well-designed phantom study, in which a CFD simulation of a repre-
sentative flame is used to generate synthetic emission images. Errors
in these reconstructions are indicative of errors in the experiment,
which facilitates qualitative analysis of the results. These practices are
increasingly common, but few studies contain a detailed analysis of
uncertainty.

The considerations listed thus far have been general to emission
tomography. However, interpreting a reconstructed intensity source
field requires an understanding of the emission mechanism. To start,
chemiluminescence and LIF are based on the spontaneous emission of
light by electronically excited radicals. In chemiluminescence, these
radicals are chemically formed in an excited state, whereas in LIF they
are excited by absorbing laser light. Chemiluminescence is a workhorse
combustion diagnostic that can be combined with tomography to visu-
alize and track 3D combustion structures. Some fields can be quantified
using this technique. For instance, the excited state number density
of a target radical can be measured to assess a kinetic mechanism
or estimate a reaction rate, and the local OH*/CH* ratio may be
employed to estimate the local equivalence ratio in certain flames.
Both of these measurements require a correction procedure to subtract
the background continuum, but this step is often overlooked. Another
key application of tomographic chemiluminescence is the study of
thermoacoustic instability, which is made possible by the relationship
between endothermic and chemiluminescent reactions in combustion.
However, this relationship is modulated by turbulence, and few studies
include the strain rate correction needed to accurately map the rate of

heat release. Crucially, most work on CTC neglects self-absorption by
ground state OH located outside the flame brush. While the presence
of ground state OH is well known and visibly apparent in PLIF mea-
surements, the effect of signal trapping on reconstructions has yet to
be characterized. Future work is expected to address these limitations
and utilize quantitative 4D CTC to measure turbulent flames via multi-
spectral and multi-modal data. Such reconstructions could be used in
conjunction with flow decomposition methods to analyze the role of
coherent structures in turbulent combustion.

Laser-induced fluorescence features the same basic photophysics as
chemiluminescence, except that the excited state population is con-
trolled in part by the laser. VLIF carries several advantages over CTC.
First, the probe volume corresponds to the laser slab, which can be
controlled. This enables more accurate reconstructions for a given
camera count because the complexity of the unknown field is reduced
by measuring a subsection of the combustion process as opposed to
the whole field. The accuracy of VLIF has been verified by quasi-
simultaneous PLIF measurements. LIF is also species specific, which
mitigates interference from other radicals, soot precursors, and the
like. Moreover, LIF makes ground state molecules visible, thereby
eliminating a major source of uncertainty in chemiluminescence imag-
ing. Lastly, the excitation and detection schemes can be tailored to
determine the temperature of flame radicals or tracers, e.g., via two-line
thermometry, which is invaluable data for benchmarking numerical
models. There are also several disadvantages to volumetric LIF. To
start, the LIF signal is relatively weak and intensified cameras are
often required. Relatedly, VLIF generally necessitates full optical access
to the probe, and the equipment is relatively expensive compared
to passive setups for CTC or natural incandescence, especially when
conducting 4D measurements. LIF measurements are also sensitive
to spatio-temporal fluctuations in and attenuation of the laser sheet,
which can be compensated in principle although doing so is highly
complex. Nevertheless, the prospect of accurate, quantitative, 4D LIF,
made possible by the controlled excitation scheme and probing volume,
makes it an attractive diagnostic for research on turbulent combustion.
Visible incandescence from a flame is usually produced by hot
particulate matter, principally soot or ash. Since these particles are
very small, they absorb and emit light in a volumetric manner, so
images of incandescence can be tomographically reconstructed. If the
incandescence source field is measured at two or more wavelengths,
then a pyrometric technique can be used to estimate the local temper-
ature. Visible-range flame pyrometry requires knowledge of the optical
properties of soot, many of which are subject to controversy. Moreover,
parameters like the complex refractive index spectrum may evolve
throughout a flame as a function of the local chemical composition
and maturity of soot. Another key concern regards self-absorption
by soot particles. While very small flames may be optically thin,
path lengths of even a centimeter or two can lead to significant at-
tenuation. These effects are often characterized through multi-modal
measurements, e.g., using combined absorption/emission tomography,
and counteracted with an iterative reconstruction algorithm that incor-
porates self-absorption. Incandescence tomography is simple and cheap
and it provides 3D information that might be otherwise inaccessible.
For example, it is difficult to conduct CTC or VLIF in a fuel-rich diffu-
sion flame, whereas incandescence is easily measured in this context.
As incandescence tomography matures, it is likely to yield significant
insight into soot formation in turbulent flames, particularly if combined
with high-speed absorption tomography.

Lastly, VLII is another incandescence technique in which the par-
ticles, generally soot, are heated far above the flame temperature by
a laser slab. These particles rapidly cool, such that the incandescence
signal spikes and then decays exponentially. This curve can be in-
terpreted using a suite of heating and cooling models to estimate
properties such as the volume fraction or primary particle diameter of
soot. LII signals decay very quickly, on the order of tens to hundreds
of nanoseconds, so very rapid measurements are required to conduct

61

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

VLII in a turbulent flame. The need for ultra-high-speed detection limits
one’s ability to track the evolution of turbulent structures in a flame,
although it may be possible to approximate the cooling curve with as
few as two points, such that measurements can be sustained for several
milliseconds. Uncertainties about soot optical properties are larger in
LII than in passive incandescence because these properties may change
in response to laser-based heating, which is an exceedingly difficult
phenomenon to characterize. Moreover, there are numerous mecha-
nisms that influence the signal decay rate, including radiative cooling,
conduction, sublimation, annealing, oxidation, and thermionic emis-
sion, and comprehensive modeling of these effects requires appreciable
spectral–temporal resolution. At the same time, time-resolved cooling
reconstructions are more sensitive to soot aggregate properties, such
as the fractal dimension and primary particle size distribution, than
reconstructions of passive incandescence. Therefore, volumetric LII
could complement passive incandescence tomography when studying
soot in turbulent combustion.

Despite its current limitations, volumetric emission tomography
is an important companion to planar diagnostics when measuring a
combustion process, due to their intrinsically three-dimensional nature.
Physics-informed reconstruction algorithms are on the rise and promise
greater accuracy than existing techniques, and the cameras, lasers,
and computing power needed for volumetric measurement are steadily
increasing in speed and precision. Moreover, high-speed imaging spec-
trometers could enable ‘‘5D’’ (x, y, z, t, λ) measurements that facilitate
the quantification of multiple thermochemical parameters. With these
developments, researchers will push the boundaries of what can be
measured: running diagnostics as fast as possible in extreme conditions
with ever increasing spatio-temporal-spectral resolution. Such infor-
mation will shed light on turbulent combustion as well as high-speed
flows, helping to build understanding and enable clean, next-generation
technologies.

Declaration of competing interest

The authors declare that they have no known competing finan-
cial interests or personal relationships that could have appeared to
influence the work reported in this paper.

Acknowledgments

The authors thank Yair Censor, Gabor Herman, Thomas Dreier,
Bernhard Wieneke, Stefan Will, and Florian Bauer for their thoughtful
comments and critiques. This work was funded by the Ministerium
für Kultur und Wissenschaft des Landes Nordrhein-Westfalen, Germany
and the National Science Foundation of China (grant nos. 52061135108
and 51976122).

References

[1] Warnatz J, Maas U, Dibble RW, Warnatz J. Combustion. Springer; 2006.
[2] Masri A. Challenges for turbulent combustion. Proc Combust Inst 2021;38:121–

55.

[3] Steinberg AM, Hamlington PE, Zhao X. Structure and dynamics of highly
turbulent premixed combustion. Prog Energy Combust Sci 2021;85:100900.

[4] Pope SB. Turbulent flows. Cambridge University Press; 2000.
[5] Eckbreth AC. Laser diagnostics for combustion temperature and species, vol. 3.

CRC Press; 1996.

[6] Smyser ME, Braun EL, Athmanathan V, Slipchenko MN, Roy S, Meyer TR. Dual-
output fs/ps burst-mode laser for megahertz-rate rotational coherent anti-Stokes
Raman scattering. Opt Lett 2020;45:5933–6.

[7] Cutler AD, Magnotti G, Cantu L, Gallo E, Rockwell R, Goyne C. Dual-
pump coherent anti-Stokes Raman spectroscopy measurements in a dual-mode
scramjet. J Propul Power 2014;30:539–49.

[8] Förster F, Crua C, Davy M, Ewart P. Temperature measurements under diesel
engine conditions using laser induced grating spectroscopy. Combust Flame
2019;199:249–57.

[9] De Domenico F, Guiberti TF, Hochgreb S, Roberts WL, Magnotti G. Tracer-free
laser-induced grating spectroscopy using a pulse burst laser at 100 kHz. Opt
Express 2019;27:31217–24.

62

[10] De Domenico F, Guiberti TF, Hochgreb S, Roberts WL, Magnotti G. Temperature
and water measurements in flames using 1064 nm Laser-Induced Grating
Spectroscopy (LIGS). Combust Flame 2019;205:336–44.

[11] Goldenstein CS, Spearrin RM, Jeffries JB, Hanson RK. Infrared laser-absorption
sensing for combustion gases. Prog Energy Combust Sci 2017;60:132–76.
[12] Cai W, Kaminski CF. Tomographic absorption spectroscopy for the study of gas

dynamics and reactive flows. Prog Energy Combust Sci 2017;59:1–31.

[13] Magnotti G, KC U, Varghese P, Barlow R. Raman spectra of methane, ethylene,
ethane, dimethyl ether, formaldehyde and propane for combustion applications.
J Quant Spectrosc Radiat Transfer 2015;163:80–101.

[14] Fuest F, Barlow RS, Magnotti G, Dreizler A, Ekoto IW, Sutton JA. Quan-
titative acetylene measurements in laminar and turbulent flames using 1D
Raman/Rayleigh scattering. Combust Flame 2015;162:2248–55.

[15] Kohse-Höinghaus K, Barlow RS, Aldén M, Wolfrum J. Combustion at the focus:

Laser diagnostics and control. Proc Combust Inst 2005;30:89–123.

[16] Hanson RK. Combustion diagnostics: Planar imaging techniques. In: Symp. int

combust. Elsevier; 1988, p. 1677–91.

[17] Grib SW, Fugger CA, Hsu PS, Jiang N, Roy S, Schumaker SA. Two-dimensional
temperature in a detonation channel using two-color OH planar laser-induced
fluorescence thermometry. Combust Flame 2021;228:259–76.

[18] Schulz C, Sick V. Tracer-LIF diagnostics: Quantitative measurement of fuel
concentration, temperature and fuel/air ratio in practical combustion systems.
Prog Energy Combust Sci 2005;31:75–121.

[19] Johchi A, Pareja J, Böhm B, Dreizler A. Quantitative mixture fraction imaging
of a synthetic biogas turbulent jet propagating into a NO-vitiated air co-flow
using planar laser-induced fluorescence (PLIF). Exp Fluids 2019;60:1–13.
[20] Westerweel J. Fundamentals of digital particle image velocimetry. Meas Sci

Technol 1997;8:1379.

[21] Prasad AK. Stereoscopic particle image velocimetry. Exp Fluids 2000;29:103–16.
[22] Abram C, Fond B, Beyrau F. Temperature measurement techniques for gas
and liquid flows using thermographic phosphor tracer particles. Prog Energy
Combust Sci 2018;64:93–156.

[23] Will S, Schraml S, Leipertz A. Two-dimensional

soot-particle sizing by

time-resolved laser-induced incandescence. Opt Lett 1995;20:2342–4.

[24] Michael JB, Venkateswaran P, Shaddix CR, Meyer TR. Effects of repetitive
pulsing on multi-kHz planar laser-induced incandescence imaging in laminar
and turbulent flames. Appl Opt 2015;54:3331–44.

[25] Kojima J,

Ikeda Y, Nakajima T. Spatially resolved measurement of OH*,
CH*, and C2* chemiluminescence in the reaction zone of laminar methane/air
premixed flames. Proc Combust Inst 2000;28:1757–64.

[26] Raffel M. Background-oriented schlieren (BOS)

techniques. Exp Fluids

2015;56:60.

[27] Zhang M, Wang J, Jin W, Huang Z, Kobayashi H, Ma L. Estimation of 3D
flame surface density and global fuel consumption rate from 2D PLIF images
of turbulent premixed flame. Combust Flame 2015;162:2087–97.

[28] Huang Y, Yang V. Dynamics and stability of lean-premixed swirl-stabilized

combustion. Prog Energy Combust Sci 2009;35:293–364.

[29] Geraedts BD, Arndt CM, Steinberg AM. Rayleigh index fields

in heli-
cally perturbed swirl-stabilized flames using doubly phase conditioned OH*
chemiluminescence tomography. Flow Turbul Combust 2016;96:1023–38.
[30] Yu T, Ruan C, Chen F, Wang Q, Cai W, Lu X. Measurement of the 3D Rayleigh
index field via time-resolved CH* computed tomography. Aerosp Sci Technol
2019;95:105487.

[31] Stark WJ, Pratsinis SE. Aerosol flame reactors for manufacture of nanoparticles.

Powder Technol 2002;126:103–8.

[32] Foo CT, Unterberger A, Menser J, Mohri K. Tomographic imaging using multi-
simultaneous measurements (TIMes) for flame emission reconstructions. Opt
Express 2021;29:244–55.

[33] Foo CT, Unterberger A, Martins FJ, Prenting MM, Schulz C, Mohri K. In-
vestigating spray flames for nanoparticle synthesis via tomographic imaging
using multi-simultaneous measurements (TIMes) of emission. Opt Express
2022;30:15524–45.

[34] Zhou B, Li T, Frank JH, Dreizler A, Böhm B. Simultaneous 10 khz
in a lifted

three-dimensional CH2O and tomographic PIV measurements
partially-premixed jet flame. Proc Combust Inst 2021;38:1675–83.

[35] Yip B, Long MB.

Instantaneous planar measurement of

the complete

three-dimensional scalar gradient in a turbulent jet. Opt Lett 1986;11:64–6.

[36] Yip B, Lam JK, Winter M, Long MB. Time-resolved three-dimensional

concentration measurements in a gas jet. Science 1987;235:1209–11.

[37] Kychakoff G, Paul PH, van Cruyningen I, Hanson RK. Movies and 3-D images of
flowfields using planar laser-induced fluorescence. Appl Opt 1987;26:2498–500.
[38] Island T, Patrie B, Mungal M, Hanson R. Instantaneous three-dimensional flow
visualization of a supersonic mixing layer. Exp Fluids 1996;20:249–56.
[39] Nygren J, Hult J, Richter M, Aldén M, Christensen M, Hultqvist A, Johansson B.
Three-dimensional laser induced fluorescence of fuel distributions in an HCCI
engine. Proc Combust Inst 2002;29:679–85.

[40] Hult J, Omrane A, Nygren J, Kaminski C, Axelsson B, Collin R, Bengtsson P-E,
Aldén M. Quantitative three-dimensional imaging of soot volume fraction in
turbulent non-premixed flames. Exp Fluids 2002;33:265–9.

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

[41] Böhm B, Kittler C, Nauert A, Dreizler A. Diagnostics at high repetition rates:
New insights into transient combustion phenomena. In: Proceedings of the
European combustion meeting 2007; 2007. p. 6.

[42] Thurow BS, Lynch KP. Development of a high-speed three-dimensional flow

visualization technique. AIAA J 2009;47:2857–65.

[43] Cho KY, Satija A, Pourpoint TL, Son SF, Lucht RP. High-repetition-rate three-
dimensional OH imaging using scanned planar laser-induced fluorescence
system for multiphase combustion. Appl Opt 2014;53:316–26.

[44] Thurow B, Jiang N, Lempert W. Review of ultra-high repetition rate laser
diagnostics for fluid dynamic measurements. Meas Sci Technol 2012;24:012002.
[45] McCann H, Wright P, Daun K, Grauer SJ, Chang L, Wagner S. Chemical
species tomography. In: Wang M, editor. Industrial tomography: Systems and
applications. Woodhead Publishing; 2022, p. 155–206.

[46] Mei D, Ding J, Shi S, New TH, Soria J. High resolution volumetric dual-camera

light-field PIV. Exp Fluids 2019;60:132.

[47] Tan ZP, Thurow BS. Time-resolved 3D flow-measurement with a single

plenoptic-camera. In: AIAA scitech 2019 forum; 2019. p. 0267.

[48] Tan ZP, Thurow BS. Perspective on the development and application of
light-field cameras in flow diagnostics. Meas Sci Technol 2021;32:101001.
[49] Liu H, Wang Q, Cai W. Assessment of plenoptic imaging for reconstruction of
3D discrete and continuous luminous fields. J Opt Soc Amer A 2019;36:149–58.
[50] Herzberg G. Molecular spectra and molecular structure. D. van Nostrand; 1945.
[51] Gaydon A. The spectroscopy of flames. Chapman and Hall, London; 1957.
[52] Howell JR, Mengüç MP, Daun K, Siegel R. Thermal radiation heat transfer. CRC

Press; 2020.

[53] Hertz H, Faris G. Emission tomography of

flame radicals. Opt Lett

1988;13:351–3.

[54] Worth NA, Dawson JR. Tomographic reconstruction of OH* chemiluminescence
in two interacting turbulent flames. Meas Sci Technol 2013;24:024013.
[55] Ma L, Wu Y, Lei Q, Xu W, Carter CD. 3D flame topography and curvature
measurements at 5 kHz on a premixed turbulent Bunsen flame. Combust Flame
2016;166:66–75.

[56] Dong R, Lei Q, Chi Y, Song E, Fan W. Analysis of global and local hydro-
dynamic instabilities on a high-speed jet diffusion flame via time-resolved 3D
measurements. Flow Turbul Combust 2021;1–22.

[57] Unterberger A, Röder M, Giese A, Al-Halbouni A, Kempf A, Mohri K. 3D
instantaneous reconstruction of turbulent industrial flames using computed
tomography of chemiluminescence (CTC). J Combust 2018;2018:5373829.
[58] Wu Y, Xu W, Lei Q, Ma L. Single-shot volumetric laser induced fluorescence
flows seeded with iodine. Opt Express

(VLIF) measurements in turbulent
2015;23:33408–18.

[59] Ma L, Lei Q, Ikeda J, Xu W, Wu Y, Carter CD. Single-shot 3D flame diagnostic
based on volumetric laser induced fluorescence (VLIF). Proc Combust Inst
2017;36:4575–83.

[60] Halls BR, Hsu PS, Jiang N, Legge ES, Felver JJ, Slipchenko MN, Roy S,
Meyer TR, Gord JR. kHz-rate four-dimensional fluorescence tomography using
an ultraviolet-tunable narrowband burst-mode optical parametric oscillator.
Optica 2017;4:897–902.

[61] Hossain MM, Lu G, Sun D, Yan Y. Three-dimensional reconstruction of
flame temperature and emissivity distribution using optical tomographic and
two-colour pyrometric techniques. Meas Sci Technol 2013;24:074010.

[62] Yu T, Bauer FJ, Huber FJ, Will S, Cai W. 4D temperature measurements using

tomographic two-color pyrometry. Opt Express 2021;29:5304–15.

[63] Uchiyama H, Nakajima M, Yuta S. Measurement of

flame temperature
distribution by IR emission computed tomography. Appl Opt 1985;24:4111–6.
[64] Zhou H-C, Lou C, Cheng Q, Jiang Z, He J, Huang B, Pei Z, Lu C. Ex-
perimental
investigations on visualization of three-dimensional temperature
distributions in a large-scale pulverized-coal-fired boiler furnace. Proc Combust
Inst 2005;30:1699–706.

[65] Meyer TR, Halls BR, Jiang N, Slipchenko MN, Roy S, Gord JR. High-speed,
three-dimensional tomographic laser-induced incandescence imaging of soot
volume fraction in turbulent flames. Opt Express 2016;24:29547–55.

[66] Bauer FJ, Yu T, Cai W, Huber FJT, Will S. Three-dimensional particle size
determination in a laminar diffusion flame by tomographic laser-induced
incandescence. Appl Phys B 2021;127:1–10.

[67] Hall EM, Halls BR, Richardson DR, Guildenbecher DR, Cenker E, Paciaroni M.
Tomographic time resolved laser induced incandescence. In: AIAA scitech 2020
forum; 2020. p. 2209.

[68] Modest MF. Radiative heat transfer. Elsevier; 2013.
[69] Bertero M, Boccacci P, De Mol C. Introduction to inverse problems in imaging.

CRC Press; 2021.

[70] Matej S, Lewitt RM. Efficient 3D grids

image reconstruction using
spherically-symmetric volume elements. IEEE Trans Nucl Sci 1995;42:1361–70.
[71] Matej S, Lewitt RM. Practical considerations for 3-D image reconstruction
IEEE Trans Med Imaging

for

using spherically symmetric volume elements.
1996;15:68–78.

[72] Atcheson B, Ihrke I, Heidrich W, Tevs A, Bradley D, Magnor M, Seidel H-
P. Time-resolved 3D capture of non-stationary gas flows. ACM Trans Graph
2008;27:1–9.

63

[73] Hansen PC. Rank-deficient and discrete ill-posed problems: numerical aspects

of linear inversion. SIAM; 1998.

[74] Daun KJ, Grauer SJ, Hadwin PJ. Chemical species tomography of turbulent
flows: Discrete ill-posed and rank deficient problems and the use of prior
information. J Quant Spectrosc Radiat Transfer 2016;172:58–74.

[75] Hadamard J. Sur les problèmes aux dérivées partielles et leur signification

physique. Princet Univ Bull 1902;49–52.

[76] Pan X, Sidky EY, Vannier M. Why do commercial CT scanners still em-
ploy traditional, filtered back-projection for image reconstruction? Inv Probl
2009;25:123009.

[77] Samei E, Pelc NJ. Computed tomography: approaches, applications, and

operations. Springer International Publishing; 2020.

[78] Gordon R, Bender R, Herman GT. Algebraic reconstruction techniques (ART)
for three-dimensional electron microscopy and X-ray photography. J Theoret
Biol 1970;29:471–81.

[79] Andersen AH, Kak AC. Simultaneous algebraic reconstruction technique
(SART): A superior implementation of the ART algorithm. Ultrason Imaging
1984;6:81–94.

[80] Levitan E, Herman GT. A maximum a posteriori probability expectation
maximization algorithm for image reconstruction in emission tomography. IEEE
Trans Med Imaging 1987;6:185–92.

[81] Trampert J, Leveque J-J. Simultaneous iterative reconstruction technique: Phys-
ical interpretation based on the generalized least squares solution. J Geophys
Res Solid Earth 1990;95:12553–9.

[82] Daun KJ, Thomson KA, Liu F, Smallwood GJ. Deconvolution of axisymmetric

flame properties using Tikhonov regularization. Appl Opt 2006;45:4638–46.

[83] Åkesson EO, Daun KJ. Parameter selection methods for axisymmetric flame
tomography through Tikhonov regularization. Appl Opt 2008;47:407–16.
[84] Sidky EY, Kao C-M, Pan X. Accurate image reconstruction from few-views and
limited-angle data in divergent-beam CT. J X-Ray Sci Technol 2006;14:119–39.
[85] Cai W, Li X, Li F, Ma L. Numerical and experimental validation of a three-
dimensional combustion diagnostic based on tomographic chemiluminescence.
Opt Express 2013;21:7050–64.

[86] Kaipio J, Somersalo E. Statistical and computational inverse problems, vol. 160.

Springer Science & Business Media; 2006.

[87] Grauer SJ, Unterberger A, Rittler A, Daun KJ, Kempf AM, Mohri K.

In-
stantaneous 3D flame imaging by background-oriented schlieren tomography.
Combust Flame 2018;196:284–99.

[88] Unterberger A, Kempf A, Mohri K. 3D evolutionary reconstruction of scalar

fields in the gas-phase. Energies 2019;12.

[89] Ramachandran G, Lakshminarayanan A. Three-dimensional reconstruction from
radiographs and electron micrographs: Application of convolutions instead of
Fourier transforms. Proc Natl Acad Sci 1971;68:2236–40.

[90] Shepp LA, Logan BF. The Fourier reconstruction of a head section. IEEE Trans

Nucl Sci 1974;21:21–43.

[91] Gao Y, Yang X, Fu C, Yang Y, Li Z, Zhang H, Qi F. 10 kHz simultaneous
PIV/PLIF study of the diffusion flame response to periodic acoustic forcing.
Appl Opt 2019;58:C112–20.

[92] Dasch CJ. One-dimensional tomography: A comparison of Abel, onion-peeling,

and filtered backprojection methods. Appl Opt 1992;31:1146–52.

[93] Hickstein DD, Gibson ST, Yurchak R, Das DD, Ryazanov M. A direct comparison
of high-speed methods for the numerical Abel transform. Rev Sci Instrum
2019;90:065115.

[94] Martin KM. Acoustic Modification of Sooting Combustion [Ph.D.

thesis],

University of Texas at Austin; 2002.

[95] Bordas C, Paulig F, Helm H, Huestis DL. Photoelectron imaging spectrometry:

Principle and inversion method. Rev Sci Instrum 1996;67:2257–68.

[96] Kalal M, Nugent K. Abel inversion using fast Fourier transforms. Appl Opt

1988;27:1956–9.

[97] Ma S, Gao H, Wu L. Modified Fourier–Hankel method based on analysis
inversion using Fourier transform techniques. Appl Opt

of errors in Abel
2008;47:1350–7.

[98] Walsh KT, Fielding J, Long MB. Effect of

light-collection geometry on

reconstruction errors in Abel inversions. Opt Lett 2000;25:457–9.

[99] Sipkens T, Grauer S, Steinberg A, Rogak S, Kirchen P. New transform to
project axisymmetric deflection fields along arbitrary rays. Meas Sci Technol
2021;33:035201.

[100] Floyd J. Computed Tomography of Chemiluminescence: A 3D Time Resolved
Sensor for Turbulent Combustion [Ph.D. thesis], Imperial College London; 2009.
[101] Hounsfield GN. Computerized transverse axial scanning (tomography): Part 1.

Description of system. Br J Radiol 1973;46:1016–22.

[102] Karczmarz S. Angenäherte auflösung von systemen linearer glei-chungen. Bull

Int Acad Pol Sic Let Cl Sci Math Nat 1937;355–7.

[103] Yu T, Tian B, Cai W. Development of a beam optimization method for

absorption-based tomography. Opt Express 2017;25:5982–99.

[104] Herman GT, Lent A. Iterative reconstruction algorithms. Comput Biol Med

1976;6:273–94.

[105] Tanabe K. Projection method for solving a singular system of linear equations

and its applications. Numer Math 1971;17:203–14.

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

[106] Eggermont PPB, Herman GT, Lent A. Iterative algorithms for large partitioned
linear systems, with applications to image reconstruction. Linear Algebra Appl
1981;40:37–67.

[107] Strohmer T, Vershynin R. A randomized Kaczmarz algorithm with exponential

convergence. J Fourier Anal Appl 2009;15:262.

[108] Natterer F. The mathematics of computerized tomography. SIAM; 2001.
[109] Hansen PC, Jørgensen JS. AIR tools II: Algebraic iterative reconstruction
methods, improved implementation. Numer Algorithms 2018;79:107–37.
[110] Elfving T, Nikazad T. Stopping rules for Landweber-type iteration. Inverse Probl

2007;23:1417.

[111] Verhoeven DD. Multiplicative algebraic computed tomographic algorithms
interferometric data. Opt Eng

the reconstruction of multidirectional

for
1993;32:410–20.

[112] Gordon R, Herman G. Three-dimensional reconstruction from projections: A
review of algorithms. In: International review of cytology, vol. 38. Elsevier;
1974, p. 111–51.

[113] Mishra D, Muralidhar K, Munshi P. A robust MART algorithm for tomographic

applications. Numer Heat Transfer B 1999;35:485–506.

[114] Worth N, Nickels T. Acceleration of Tomo-PIV by estimating the initial volume

intensity distribution. Exp Fluids 2008;45:847.

[115] Atkinson C, Soria J. An efficient simultaneous reconstruction technique for

tomographic particle image velocimetry. Exp Fluids 2009;47:553.

[116] Novara M, Batenburg KJ, Scarano F. Motion tracking-enhanced MART for

tomographic PIV. Meas Sci Technol 2010;21:035401.

[117] Lynch K, Scarano F. An efficient and accurate approach to MTE-MART for

time-resolved tomographic PIV. Exp Fluids 2015;56:66.

[118] Scarano F. Tomographic PIV: Principles and practice. Meas Sci Technol

2012;24:012001.

[119] Byrne C. Block-iterative algorithms. Int Trans Oper Res 2009;16:427–63.
[120] Thomas L, Tremblais B, David L. Optimization of the volume reconstruction
for classical Tomo-PIV algorithms (MART, BIMART and SMART): Synthetic and
experimental studies. Meas Sci Technol 2014;25:035303.

[121] Kashyap RL, Mittal MC. Picture reconstruction from projections. IEEE Trans

Comput 1975;100:915–23.

[122] Fox M. Quantum optics: An introduction, vol. 15. Oxford University Press; 2006.
emission
[123] Shepp LA, Vardi Y. Maximum likelihood reconstruction for

tomography. IEEE Trans Med Imaging 1982;1:113–22.
[124] Vardi Y, Shepp L, Kaufman L. A statistical model
tomography. J Amer Statist Assoc 1985;80:8–20.

for positron emission

[125] Lange K, Carson R, et al. EM reconstruction algorithms for emission and

transmission tomography. J Comput Assist Tomogr 1984;8:306–16.

[126] Lim J. Fan beam emission tomography for estimating scalar properties in
laminar flames. In: Third joint meeting of the U.S. sections of the Combustion
Institute; 2003. p. 1–6.

[127] Ishino Y, Ohiwa N. Three-dimensional computerized tomographic reconstruction
of instantaneous distribution of chemiluminescence of a turbulent premixed
flame. JSME Int J B 2005;48:34–40.

[128] Herman GT, Meyer LB. Algebraic reconstruction techniques can be made
computationally efficient (positron emission tomography application).
IEEE
Trans Med Imaging 1993;12:600–9.

[129] Byrne CL. Iterative image reconstruction algorithms based on cross-entropy

minimization. IEEE Trans Image Process 1993;2:96–103.

[130] Verhoeven D. Limited-data computed tomography algorithms for the physical

sciences. Appl Opt 1993;32:3736–54.

[131] Gilbert P. Iterative methods for the reconstruction of three-dimensional objects

from projections. J Theoret Biol 1972;36:105–17.

[132] Goitein M. Three-dimensional density reconstruction from a series of
two-dimensional projections. Nucl Instrum Methods 1972;101:509–18.
[133] Hansen PC, Saxild-Hansen M. AIR tools–a MATLAB package of algebraic

iterative reconstruction methods. J Comput Appl Math 2012;236:2167–78.

[134] Cimmino G. Cacolo approssimato per le soluzioni dei systemi di equazioni

lineari. Ric Sci 1938;1:326–33.

[135] Landweber L. An iteration formula for Fredholm integral equations of the first

kind. Amer. J. Math. 1951;73:615–24.

[136] Censor Y, Gordon D, Gordon R. Component averaging: An efficient iterative
parallel algorithm for large and sparse unstructured problems. Parallel Comput
2001;27:777–808.

[137] Censor Y, Elfving T, Herman GT, Nikazad T. On diagonally relaxed orthogonal

projection methods. SIAM J Sci Comput 2008;30:473–504.

[138] Vogel CR. Computational methods for inverse problems. SIAM; 2002.
[139] Harris CR, Millman KJ, van der Walt SJ, Gommers R, Virtanen P, Cournapeau D,
Wieser E, Taylor J, Berg S, Smith NJ, et al. Array programming with NumPy.
Nat 2020;585:357–62.

[140] Van Aarle W, Palenstijn WJ, Cant J, Janssens E, Bleichrodt F, Dabravolski A,
De Beenhouwer J, Batenburg KJ, Sijbers J. Fast and flexible X-ray tomography
using the ASTRA toolbox. Opt Express 2016;24:25129–47.

[141] Biguri A, Dosanjh M, Hancock S, Soleimani M. TIGRE: A MATLAB-GPU toolbox

for CBCT image reconstruction. Biomed Phys Eng Express 2016;2:055010.

[143] Tikhonov AN.

Solution of

incorrectly

formulated problems

and the

regularization method. Soviet Math 1963;4:1035–8.

[144] Byrne CL. Signal processing: A mathematical approach. CRC Press; 2014.
[145] Wei C, Schwarm KK, Pineda DI, Spearrin RM. Volumetric laser absorption
imaging of temperature, CO and CO2 in laminar flames using 3D masked
Tikhonov regularization. Combust Flame 2021;224:239–47.

[146] González G, Kolehmainen V, Seppänen A.

Isotropic and anisotropic total
variation regularization in electrical impedance tomography. Comput Math Appl
2017;74:564–76.

[147] Behrooz A, Zhou H-M, Eftekhar AA, Adibi A. Total variation regularization for
3D reconstruction in fluorescence tomography: Experimental phantom studies.
Appl Opt 2012;51:8216–27.

[148] Lawson CL, Hanson RJ. Solving least squares problems. SIAM; 1995.
[149] Hansen PC. Analysis of discrete ill-posed problems by means of the L-curve.

SIAM Rev 1992;34:561–80.

[150] Liu H, Yu T, Zhang M, Cai W. Demonstration of 3D computed tomography of
chemiluminescence with a restricted field of view. Appl Opt 2017;56:7107–15.
[151] Goldman R. Curvature formulas for implicit curves and surfaces. Comput Aided

Geom Design 2005;22:632–58.

[152] Nicolas F, Todoroff V, Plyer A, Le Besnerais G, Donjat D, Micheli F, Cham-
pagnat F, Cornic P, Le Sant Y. A direct approach for instantaneous 3D density
field reconstruction from background-oriented schlieren (BOS) measurements.
Exp Fluids 2016;57:13.

[153] Grauer SJ, Steinberg AM. Fast and robust volumetric refractive index mea-
surement by unified background-oriented schlieren tomography. Exp Fluids
2020;61:1–17.

[154] Kaipio J, Seppänen A, Somersalo E, Haario H. Posterior covariance related
optimal current patterns in electrical impedance tomography. Inverse Probl
2004;20:919.

[155] Grauer SJ, Sipkens TA, Hadwin PJ, Daun KJ. Statistical inversion, uncertainty
quantification, and the optimal design of optical experiments. In: Steinberg A,
Roy S, editors. Optical diagnostics for reacting and non-reacting flows: Theory
and practice. AIAA; 2022, p. 1137–204.

[156] Vauhkonen M, Vadasz D, Karjalainen PA, Somersalo E, Kaipio JP. Tikhonov
regularization and prior information in electrical impedance tomography. IEEE
Trans Med Imaging 1998;17:285–93.

[157] Kolehmainen V, Somersalo E, Vauhkonen P, Vauhkonen M, Kaipio J. A Bayesian
approach and total variation priors in 3D electrical impedance tomography. In:
Proceedings of the 20th annual international conference of the IEEE engineering
in medicine and biology society, vol. 2. IEEE; 1998, p. 1028–31.

[158] Barbano R, Zhang C, Arridge S, Jin B. Quantifying model uncertainty in
inverse problems via Bayesian deep gradient descent. 2020, ArXiv preprint.
arXiv:2007.09971.

[159] Molnar JP, Grauer SJ. Flow field tomography with uncertainty quantifica-
tion using a Bayesian physics-informed neural network. Meas Sci Technol
2022;33:065305.

[160] Kaipio JP, Kolehmainen V, Vauhkonen M, Somersalo E. Inverse problems with

structural prior information. Inv Probl 1999;15:713.

[161] Nadir Z, Brown MS, Comer ML, Bouman CA. Gaussian mixture prior models
for imaging of flow cross sections from sparse hyperspectral measurements. In:
2015 IEEE global conference on signal and information processing. IEEE; 2015,
p. 527–31.

[162] Grauer SJ, Hadwin PJ, Daun KJ. Improving chemical species tomography of
turbulent flows using covariance estimation. Appl Opt 2017;56:3900–12.
[163] Emmert J, Wagner S, Daun KJ. Quantifying the spatial resolution of the
maximum a posteriori estimate in linear, rank-deficient, Bayesian hard field
tomography. Meas Sci Technol 2020.

[164] Grauer SJ. Bayesian methods

for gas-phase tomography [Ph.D.

thesis],

University of Waterloo; 2018.

[165] Arridge SR, Kaipio JP, Kolehmainen V, Schweiger M, Somersalo E, Tarvainen T,
Vauhkonen M. Approximation errors and model reduction with an application
in optical diffusion tomography. Inv Probl 2006;22:175.

[166] Grauer SJ, Hadwin PJ, Sipkens TA, Daun KJ. Measurement-based meshing, basis
selection, and prior assignment in chemical species tomography. Opt Express
2017;25:25135–48.

[167] Nocedal J, Wright S. Numerical optimization. Springer Science & Business

Media; 2006.

[168] Molinari M, Cox SJ, Blott BH, Daniell GJ. Comparison of algorithms for
tomography reconstruction. Physiol Meas

non-linear inverse 3D electrical
2002;23:95.

[169] Belkebir K, Chaumet PC, Sentenac A. Influence of multiple scattering on three-
dimensional imaging with optical diffraction tomography. J Opt Soc Amer A
2006;23:586–95.

[170] Maire G, Drsek F, Girard J, Giovannini H, Talneau A, Konan D, Belkebir K,
Chaumet PC, Sentenac A. Experimental demonstration of quantitative imag-
ing beyond Abbe’s limit with optical diffraction tomography. Phys Rev Lett
2009;102:213905.

[142] Kak AC, Slaney M, Wang G. Principles of computerized tomographic imaging.

[171] Fang W. A nonlinear image reconstruction algorithm for electrical capacitance

Med Phys 2002;29:107.

tomography. Meas Sci Technol 2004;15:2124.

64

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

[172] Press WH, William H, Teukolsky SA, Vetterling WT, Saul A, Flannery BP.
Numerical recipes 3rd edition: The art of scientific computing. Cambridge
University Press; 2007.

[173] Cai W, Ma L. Applications of critical temperature in minimizing functions of
continuous variables with simulated annealing algorithm. Comput Phys Comm
2010;181:11–6.

[174] Bousquet A, Louchet J, Rocchisani J-M. Fully three-dimensional tomographic
evolutionary reconstruction in nuclear medicine. In: Artif evol. Springer Berlin
Heidelberg; 2008, p. 231–42.

[175] Rolnik VP, Seleghim Jr. P. A specialized genetic algorithm for the electri-
impedance tomography of two-phase flows. J Braz Soc Mech Sci Eng

cal
2006;28:378–89.

[176] Wu C, Cheng Y, Ding Y, Wei F, Jin Y. A novel X-ray computed tomog-
raphy method for fast measurement of multiphase flow. Chem Eng Sci
2007;62:4325–35.

[177] Kramer O. Genetic algorithms essentials. Springer Nature; 2017.
[178] Corana A, Marchesi M, Martini C, Ridella S. Minimizing multimodal functions
of continuous variables with the ‘‘simulated annealing’’ algorithm. ACM Trans
Math Softw 1987;13:262–80.

[179] Cai W, Ewing DJ, Ma L. Application of simulated annealing for multispectral

tomography. Comput Phys Comm 2008;179:250–5.

[180] de Castro Martins T, de Camargo EDL, Lima RG, Amato MBP, Tsuzuki MdSG.
Image reconstruction using interval simulated annealing in electrical impedance
tomography. IEEE Trans Biomed Eng 2012;59:1861–70.

[181] de Castro Martins T, Tsuzuki MdSG, de Camargo EDLB, Lima RG, de Moura FS,
Amato MBP. Interval simulated annealing applied to electrical impedance to-
mography image reconstruction with fast objective function evaluation. Comput
Math Appl 2016;72:1230–43.

[182] LeCun Y, Bengio Y, Hinton G. Deep learning. Nature 2015;521:436–44.
[183] Higaki T, Nakamura Y, Tatsugami F, Nakaura T, Awai K. Improvement of image

quality at CT and MRI using deep learning. Jpn J Radiol 2019;37:73–80.

[184] Huang J, Liu H, Dai J, Cai W. Reconstruction for limited-data nonlinear
tomographic absorption spectroscopy via deep learning. J Quant Spectrosc
Radiat Transfer 2018;218:187–93.

[185] Bengio Y, Goodfellow I, Courville A. Deep learning. The MIT Press; 2017.
[186] Huang J, Liu H, Wang Q, Cai W. Limited-projection volumetric tomography for
time-resolved turbulent combustion diagnostics via deep learning. Aerosp Sci
Technol 2020;106:106123.

[187] Jin Y, Zhang W, Song Y, Qu X, Li Z, Ji Y, He A. Three-dimensional
rapid flame chemiluminescence tomography via deep learning. Opt Express
2019;27:27308–34.

[188] Wei C, Schwarm KK, Pineda DI, Spearrin RM. Physics-trained neural network
for sparse-view volumetric laser absorption imaging of species and temperature
in reacting flows. Opt Express 2021;29:22553–66.

[189] Wei C, Schwarm KK, Pineda DI, Spearrin RM. Deep neural network inversion
for 3D laser absorption imaging of methane in reacting flows. Opt Lett
2020;45:2447–50.

[190] Huang J, Liu H, Cai W. Online in situ prediction of 3-D flame evolution from
its history 2-D projections via deep learning. J Fluid Mech 2019;875.
[191] Cai W, Huang J, Deng A, Wang Q. Volumetric reconstruction for combustion
diagnostics via transfer learning and semi-supervised learning with limited
labels. Aerosp Sci Technol 2021;110:106487.

[192] Kim P. Convolutional neural network. In: MATLAB deep learning. Springer;

2017, p. 121–47.

[193] Xu K, Zhang M, Li J, Du SS, Kawarabayashi K-i, Jegelka S. How neural networks
extrapolate: From feedforward to graph neural networks. 2020, ArXiv preprint.
arXiv:2009.11848.

[194] Szegedy C, Zaremba W, Sutskever I, Bruna J, Erhan D, Goodfellow I, Fergus R.
Intriguing properties of neural networks. 2013, ArXiv preprint arXiv:1312.6199.
[195] Raissi M, Perdikaris P, Karniadakis GE. Physics-informed neural networks: A
deep learning framework for solving forward and inverse problems involving
nonlinear partial differential equations. J Comput Phys 2019;378:686–707.

[196] Raissi M, Yazdani A, Karniadakis GE. Hidden fluid mechanics: Learning velocity
and pressure fields from flow visualizations. Science 2020;367:1026–30.
[197] Cai S, Wang Z, Fuest F, Jeon YJ, Gray C, Karniadakis GE. Flow over an
espresso cup: Inferring 3-D velocity and pressure fields from tomographic
background oriented schlieren via physics-informed neural networks. J Fluid
Mech 2021;915.

[198] Fathi MF, Perez-Raya I, Baghaie A, Berg P, Janiga G, Arzani A, D’Souza RM.
Super-resolution and denoising of 4D-flow MRI using physics-informed deep
neural nets. Comput Methods Programs Biomed 2020;197:105729.

[199] van Herten RL, Chiribiri A, Breeuwer M, Veta M, Scannell CM. Physics-informed
neural networks for myocardial perfusion MRI quantification. 2020, ArXiv
preprint. arXiv:2011.12844.

[200] Katsevich A. A general scheme for constructing inversion algorithms for cone

beam CT. Int J Math Math Sci 2003;2003.

[201] Calvetti D, Dunlop M, Somersalo E, Stuart A. Iterative updating of model error

for Bayesian inversion. Inverse Problems 2018;34:025008.

[202] Williams A, Barrus S, Morley RK, Shirley P. An efficient and robust ray-box
intersection algorithm. In: ACM SIGGRAPH 2005 courses; 2005. p. 9–es.

[203] Haines E, Günther J, Akenine-Möller T. Precision improvements for ray/sphere

intersection. In: Ray tracing gems. Springer; 2019, p. 87–94.

[204] Thomas L, Vernet R, Tremblais B, David L. Influence of geometric parameters
and image preprocessing on tomo-PIV results. In: Proc. 15th int. symp. on
applications of laser techniques to fluid mechanics; 2010. p. 12.

[205] Ha S, Kumar A, Mueller K. A study of volume integration models for iterative
cone-beam computed tomography. In: Proceedings of the 13th meeting on fully
3D image reconstruction. p. 464–7.

[206] Lamarche F, Leroy C. Evaluation of the volume of intersection of a sphere with
a cylinder by elliptic integrals. Comput Phys Comm 1990;59:359–69.
[207] Born M, Wolf E. Principles of optics: electromagnetic theory of propagation,

interference and diffraction of light. Elsevier; 2013.

[208] Cai W, Li X, Ma L. Practical aspects of

implementing three-dimensional
tomography inversion for volumetric flame imaging. Appl Opt 2013;52:8106–
16.

[209] Schanz D, Gesemann S, Schröder A, Wieneke B, Novara M. Non-uniform
optical transfer functions in particle imaging: Calibration and application to
tomographic reconstruction. Meas Sci Technol 2012;24:024009.

[210] Champagnat F, Cornic P, Cheminet A, Leclaire B, Le Besnerais G, Plyer A.

Tomographic PIV: Particles versus blobs. Meas Sci Technol 2014;25:084002.

[211] Yu T, Liu H, Cai W. On the quantification of

resolution for
three-dimensional computed tomography of chemiluminescence. Opt Express
2017;25:24093–108.

spatial

[212] Zhou G, Li F, Wang K, Lin X, Yu X. Research on a quantitative method
for three-dimensional computed tomography of chemiluminescence. Appl Opt
2020;59:5310–8.

[213] Liu H, Sun B, Cai W. kHz-rate volumetric flame imaging using a single camera.

Opt Commun 2019;437:33–43.

[214] Wang J, Zhang W, Zhang Y, Yu X. Camera calibration for multidirectional flame

chemiluminescence tomography. Opt Eng 2017;56:1–7.

[215] Hartley RI, Zisserman A. Multiple view geometry in computer vision. Cambridge

University Press; 2004.

[216] Soloff SM, Adrian RJ, Liu Z-C. Distortion compensation for generalized

stereoscopic particle image velocimetry. Meas Sci Technol 1997;8:1441–54.

[217] Abdel-Aziz YI, Karara H. Direct

transformation from comparator
linear
coordinates into object space coordinates in close-range photogrammetry.
Photogramm Eng Remote Sens 1971;81:103–7.

[218] Hall EL, Tio JB, McPherson CA, Sadjadi FA. Measuring curved surfaces for robot

vision. Comput 1982;15:42–54.

[219] Calluaud D, David L. Stereoscopic particle image velocimetry measurements of
the flow around a surface-mounted block. Exp Fluids 2004;36:53–61.
[220] Tsai R. A versatile camera calibration technique for high-accuracy 3D machine
vision metrology using off-the-shelf TV cameras and lenses. IEEE J Robot Autom
1987;3:323–44.

[221] Weng J, Cohen P, Herniou M. Camera calibration with distortion models and

accuracy evaluation. IEEE Trans Pattern Anal Mach Intell 1992;14:965–80.

[222] Heikkila J, Silven O. A four-step camera calibration procedure with implicit
image correction. In: Proceedings of IEEE computer society conference on
computer vision and pattern recognition; 1997. p. 1106–12.

[223] Zhang Z. Flexible camera calibration by viewing a plane from unknown
orientations. In: Proceedings of the seventh IEEE international conference on
computer vision. p. 666–73.

[224] Svoboda T, Martinec D, Pajdla T. A convenient multicamera self-calibration for
virtual environments. Teleoperators Virtual Environ. 2005;14:407–22.
[225] Willert CE. Assessment of camera models for use in planar velocimetry

calibration. Exp Fluids 2006;41:135–43.

[226] Scarano F, David L, Bsibsi M, Calluaud D. S-PIV comparative assessment: Image
dewarping+misalignment correction and pinhole+geometric back projection.
Exp Fluids 2005;39:257–66.

[227] Giordano R, Astarita T. Spatial resolution of the stereo PIV technique. Exp

Fluids 2009;46:643–58.

[228] Ohmi K, Joshi B, Panday S. Comparative study of camera calibration mod-
Int J Innov Comput Inf Control

els for 3D particle tracking velocimetry.
2013;9:1971–86.

[229] Elsinga GE, Scarano F, Wieneke B, van Oudheusden BW. Tomographic particle

image velocimetry. Exp Fluids 2006;41:933–47.

[230] Wieneke B.

Improvements for volume self-calibration. Meas Sci Technol

2018;29:084002.

[231] Brown DC. Decentering distortion of lenses. Photogramm Eng Remote Sens

1966.

[232] Brown DC. Close-range camera calibration. Photogramm Eng 1971;37:855–66.
[233] Lin PD, Sung CK. Camera calibration based on Snell’s law. J Dyn Syst Meas

Control 2005;128:548–57.

[234] Lin PD, Sung CK. Comparing two new camera calibration methods with

traditional pinhole calibrations. Opt Express 2007;15:3012–22.

[235] Legarda A, Izaguirre A, Arana N, Iturrospe A. A new method for Scheimpflug
In: 2011 10th international workshop on electronics,

camera calibration.
control, measurement and signals. IEEE; 2011, p. 1–5.

[236] Astarita T. A Scheimpflug camera model for stereoscopic and tomographic PIV.
In: 16th international symposium on applications of laser techniques to fluid
mechanics; 2012. p. 9.

65

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

[237] Belden J. Calibration of multi-camera systems with refractive interfaces. Exp

Fluids 2013;54:1–18.

[238] Louhichi H, Fournel T, Lavest J, Aissia HB. Self-calibration of Scheimpflug

cameras: An easy protocol. Meas Sci Technol 2007;18:2616.

[239] Cornic P, Illoul C, Cheminet A, Le Besnerais G, Champagnat F, Le Sant Y,
Leclaire B. Another look at volume self-calibration: Calibration and self-
calibration within a pinhole model of Scheimpflug cameras. Meas Sci Technol
2016;27:094004.

[240] Bouguet JY. Camera calibration toolbox for MATLAB. 2008, http://www.vision.

caltech.edu/bouguetj/calib_doc/ [Last accessed 25 August 2020].

[272] Yan Y. Three-dimensional visualisation and quantitative characterisation of
fossil fuel flames using digital imaging techniques. Technical report, University
of Kent, BCURA Agreement No: B60; 2005.

[273] Wang Q, Yu T, Liu H, Huang J, Cai W. Optimization of camera arrangement
for volumetric tomography with constrained optical access. J Opt Soc Amer B
2020;37:1231–9.

[274] Obertacke R, Wintrich H, Wintrich F, Leipertz A. A new sensor system for
industrial combustion monitoring and control using UV emission spectroscopy
and tomography. Combust Sci Technol 1996;121:133–51.

[275] Gaydon AG, Wolfhard HG, Penner S. Flames: Their Structure, Radiation and

[241] Bradski G, Kaehler A. Learning OpenCV: computer vision with the OpenCV

Temperature. vol. 4, Chapman and Hall, London; 1978.

library. O’Reilly Media, Inc.; 2008.

[276] Turns S. An introduction to combustion: Concepts

and applications.

[242] Kabsch W. A solution for the best rotation to relate two sets of vectors. Acta

McGraw-Hill; 2012.

Crystallogr A 1976;32:922–3.

[243] Muller K, Hemelrijk C, Westerweel J, Tam D. Calibration of multiple cameras
for large-scale experiments using a freely moving calibration target. Exp Fluids
2020;61:1–12.

[244] Drap P, Lefèvre J. An exact

formula for calculating inverse radial

lens

distortions. Sensors 2016;16:807.

[245] Wieneke B. Stereo-PIV using self-calibration on particle images. Exp Fluids

2005;39:267–80.

[246] Hall EM, Fahringer TW, Guildenbecher DR, Thurow BS. Volumetric calibration

of a plenoptic camera. Appl Opt 2018;57:914–23.

[247] Wieneke B. Volume self-calibration for 3D particle image velocimetry. Exp

Fluids 2008;45:549–56.

[248] Liu N, Lei Q, Wu Y, Ma L. 3D tomography reconstruction improved by

integrating view registration. Appl Opt 2019;58:2596–604.

[249] Treibitz T, Schechner Y, Kunz C, Singh H. Flat refractive geometry. IEEE Trans

Pattern Anal Mach Intell 2011;34:51–65.

[250] Liu H, Paolillo G, Astarita T, Shui C, Cai W. Computed tomography of chemilu-
minescence for the measurements of flames confined within a cylindrical glass.
Opt Lett 2019;44:4793–6.

[251] Paolillo G. Experimental and Numerical

Investigation of Rayleigh–Bénard

Convection [Ph.D. thesis], Università degli Studi di Napoli Federico II; 2018.

[252] Paolillo G, Astarita T. Perspective camera model with refraction correction for
optical velocimetry measurements in complex geometries. Trans Pattern Anal
Mach Intell 2020.

[253] Kotowski R. Phototriangulation in multi-media photogrammetry.

Int. Arch

Photogramm Remote Sens 1988;27:324–34.

[254] Mulsow C. A flexible multi-media bundle approach. Int Arch Photogramm

Remote Sens Spat Inf Sci 2010;38:472–7.

[255] Paolillo G, Astarita T. A novel camera model for calibrating optical systems

including cylindrical windows. In: AIAA scitech 2019 forum; 2019. p. 0273.

[256] Unterberger A, Menser J, Kempf A, Mohri K. Evolutionary camera pose
estimation of a multi-camera setup for computed tomography. In: 2019 IEEE
international conference on image processing; 2019. p. 464–8.

[257] Aggarwal CC, Hinneburg A, Keim DA. On the surprising behavior of distance
metrics in high dimensional space. In: International conference on database
theory. Springer; 2001, p. 420–34.

[258] Mohri K, Görs S, Schöler J, Rittler A, Dreier T, Schulz C, Kempf A. Instanta-
neous 3D imaging of highly turbulent flames using computed tomography of
chemiluminescence. Appl Opt 2017;56:7385–95.

[259] Kazantsev D, Pickalov V, Nagella S, Pasca E, Withers PJ. TomoPhantom,
a software package to generate 2D–4D analytical phantoms for CT image
reconstruction algorithm benchmarks. SoftwareX 2018;7:150–5.

[260] Wirgin A. The inverse crime. 2004, ArXiv preprint. arXiv:math--ph/0401050.
[261] Beets K, Barron DL. Super-sampling anti-aliasing analyzed. Technical report,

Beyond3D; 2000.

[262] Hecht E. Diffraction. 5th ed. Pearson Education Limited; 2017, p. 457–541,

[chapter 10].

[263] Harris JL. Diffraction and resolving power. J Opt Soc Amer 1964;54:931–6.
[264] Rosenfeld A. Picture processing by computer. ACM Comput Surv 1969;1:147–

76.

[265] Frieder G, Herman GT. Resolution in reconstructing objects from electron

micrographs. J Theoret Biol 1971;33:189–211.

[266] Elsinga G, Westerweel J, Scarano F, Novara M. On the velocity of ghost particles

and the bias errors in tomographic-PIV. Exp Fluids 2011;50:825–38.

[267] Bracewell RN, Riddle A. Inversion of fan-beam scans in radio astronomy.

Astrophys J 1967;150:427.

[268] Crowther RA, DeRosier D, Klug A. The reconstruction of a three-dimensional
structure from projections and its application to electron microscopy. Proc R
Soc Lond Ser A Math Phys Eng Sci 1970;317:319–40.

[269] Smith SW. Special imaging techniques. In: The scientist and engineer’s guide
to digital signal processing. 2nd ed. California Technical Publishing; 1997, p.
423–30.

[270] Tsekenis S, Tait N, McCann H. Spatially resolved and observer-free experimental
quantification of spatial resolution in tomographic images. Rec Sci Instrum
2015;86:035104.

[271] Liu H, Wang Q, Cai W. Parametric study on single-camera endoscopic

tomography. J Opt Soc Am B 2020;37:271–8.

[277] Lauer M, Fiala T, Sattelmayer T. On the utilization of chemiluminescence for
combustion diagnostics. In: Steinberg A, Roy S, editors. Optical diagnostics for
reacting and non-reacting flows: Theory and practice. AIAA; 2022, p. 931–1020.
[278] Luque J, Crosley D. Transition probabilities in the A2Σ+ - X2Πi electronic

system of OH. J Chem Phys 1998;109/2:439–48.

[279] Hanson RK, Spearrin RM, Goldenstein CS. Spectroscopy and optical diagnostics

for gases, vol. 1. Springer; 2016.

[280] Dieke G, Crosswhite H. The ultraviolet bands of OH fundamental data. J Quant

Spectrosc Radiat Transfer 1962;2:97–199.

[281] Coxon J, Foster S. Rotational analysis of hydroxyl vibration–rotation emission
bands: Molecular constants for OH x2Π, 6 ≤ ν ≤ 10. Can J Phys 1982;60:41–8.
[282] Coxon JA, Sappey AD, Copeland RA. Molecular constants and term values for
the hydroxyl radical, OH: The X2Π (ν = 8, 12), A2Σ (ν = 4–9), B2Σ (ν = 0, 1),
and C2Σ (ν = 0, 1) states. J Mol Spectrosc 1991;145:41–55.

[283] Chidsey IL, Crosley DR. Calculated rotational transition probabilities for the
A–X system of OH. J Quant Spectrosc Radiat Transfer 1980;23:187–99.
[284] Garland NL, Crosley DR. Relative transition probability measurements in the
AX and BX systems of CH. J Quant Spectrosc Radiat Transfer 1985;33:591–5.
[285] Jeffries JB, Copeland RA, Crosley DR. Transition probabilities in the C2Σ+–X2Π

system of CH. J Quant Spectrosc Radiat Transfer 1987;37:419–23.

[286] Luque J, Crosley DR. Electronic transition moment and rotational transition

probabilities in CH. I. A2Δ–X2Π system. J Chem Phys 1996;104:2146–55.

[287] Luque J, Crosley DR. Electronic transition moment and rotational transition

probabilities in CH. II. B2Σ–X2Π system. J Chem Phys 1996;104:3907–13.

[288] Martin M. C2 spectroscopy and kinetics. J Photochem Photobiol 1992;66:263–

89.

[289] Kokkin DL, Bacskay GB, Schmidt TW. Oscillator strengths and radiative lifetimes
u systems. J Chem Phys

for C2: Swan, Ballik–Ramsay, Phillips, and d3Πg ← c3Σ+
2007;126:084302.

[290] Gordon IE, Rothman LS, Hargreaves RJ, Hashemi R, Karlovets EV, Skinner FM,
Conway EK, Hill C, Kochanov RV, Tan Y, Wcisł o P, Finenko AA, Nelson K,
Bernath PF, Birk M, Boudon V, Campargue A, Chance KV, Coustenis A,
Drouin BJ, Flaud J-M, Gamache RR, Hodges JT, Jacquemart D, Mlawer EJ,
Nikitin AV, Perevalov VI, Rotger M, Tennyson J, Toon GC, Tran H, Tyuterev VG,
Adkins EM, Baker A, Barbe A, Canè E, Császár AG, Dudaryonok A, Egorov O,
Fleisher AJ, Fleurbaey H, Foltynowicz A, Furtenbacher T, Harrison JJ, Hart-
mann J-M, Horneman V-M, Huang X, Karman T, Karns J, Kassi S, Kleiner I,
Kofman V, Kwabia-Tchana F, Lavrentieva NN, Lee TJ, Long DA, Luka-
shevskaya AA, Lyulin OM, Makhnev V, Matt W, Massie ST, Melosso M,
Mikhailenko SN, Mondelain D, Müller HSP, Naumenko OV, Perrin A, Polyan-
sky OL, Raddaoui E, Raston PL, Reed ZD, Rey M, Richard C, Tóbiás R, Sadiek I,
Schwenke DW, Starikova E, Sung K, Tamassia F, Tashkun SA, Vander Auwera J,
Vasilenko IA, Vigasin AA, Villanueva GL, Vispoel B, Wagner G, Yachmenev A,
Yurchenko SN. The HITRAN2020 molecular spectroscopic database. J Quant
Spectrosc Radiat Transfer 2022;277:107949.

[291] Rothman LS, Gordon I, Barber R, Dothe H, Gamache RR, Goldman A,
Perevalov V, Tashkun S, Tennyson J. HITEMP, the high-temperature molecular
spectroscopic database. J Quant Spectrosc Radiat Transfer 2010;111:2139–50.
[292] Lauer MRW. Determination of the heat release distribution in turbulent flames
by chemiluminescence imaging [Ph.D. thesis], Technische Universität München;
2011.

[293] Fiala T, Sattelmayer T, Gröning S, Hardi J, Stützer R, Webster S, Oschwald M.
Comparison between excited hydroxyl radical and blue radiation from hydrogen
rocket combustion. J Propul Power 2017;33:490–500.

[294] Lei Q, Wu Y, Xu W, Ma L. Development and validation of a reconstruction
algorithm for three-dimensional nonlinear tomography problems. Opt Express
2016;24:15912–26.

[295] Yu T, Li Z, Ruan C, Chen F, Lu X, Cai W. Development of an absorption-
corrected method for 3D computed tomography of chemiluminescence. Meas
Sci Technol 2019;30:045403.

[296] Brockhinke A, Krüger J, Heusing M, Letzgus M. Measurement and simulation
of rotationally-resolved chemiluminescence spectra in flames. Appl Phys B
2012;107:539–49.

[297] Fiala T, Sattelmayer T. Modeling of the continuous (blue) radiation in hydrogen

flames. Int J Hydrog Energy 2016;41:1293–303.

[298] Fiala T, Sattelmayer T. Assessment of existing and new modeling strategies
for the simulation of OH* radiation in high-temperature flames. CEAS Space J
2016;8:47–58.

66

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

[299] Serauskas RV, Frenklach MF, Bowman CT, Smith GP, Gardiner WC. GRI-Mech

3.0. 2000, http://combustion.berkeley.edu/gri-mech/.

[300] Cancino L, Fikri M, Oliveira A, Schulz C. Ignition delay times of ethanol-
containing multi-component gasoline surrogates: Shock-tube experiments and
detailed modeling. Fuel 2011;90:1238–44.

[301] Kee RJ, Coltrin ME, Glarborg P. Chemically reacting flow: theory and practice.

John Wiley & Sons; 2005.

[302] Kee RJ, Grcar JF, Smooke MD, Miller JA, Meeks E. PREMIX: a Fortran program
for modeling steady laminar one-dimensional premixed flames. Technical report
SAND85-8249, Sandia National Laboratories; 1985.

[303] Goodwin DG, Speth RL, Moffat HK, Weber BW. Cantera: An object-
oriented software toolkit for chemical kinetics, thermodynamics, and transport
processes. 2021, http://dx.doi.org/10.5281/zenodo.4527812, https://www.
cantera.org. Version 2.5.1.

[304] Ihme M, Pitsch H. Flamemaster, a C++ computer program for 0D combustion
and 1D laminar flame calculations. 2007, https://web.stanford.edu/group/
pitsch/FlameMaster.htm. V3.3.10.

[305] Kathrotia T, Fikri M, Bozkurt M, Hartmann M, Riedel U, Schulz C. Study of
the H + O + M reaction forming OH*: Kinetics of OH* chemiluminescence in
hydrogen combustion systems. Combust Flame 2010;157:1261–73.

[306] Kathrotia T. Reaction kinetics modeling of OH*, CH*, and C2* chemilumines-

cence [Ph.D. thesis], Ruprecht-Karls-Universität Heidelberg; 2011.

[307] Kathrotia T, Riedel U, Seipel A, Moshammer K, Brockhinke A. Experimental
and numerical study of chemiluminescent species in low-pressure flames. Appl
Phys B 2012;107:571–84.

[308] Kopp M, Brower M, Mathieu O, Petersen E, Güthe F. CO2* chemiluminescence

study at low and elevated pressures. Appl Phys B 2012;107:529–38.

[309] Kopp MM, Mathieu O, Petersen EL. Rate determination of the CO2* chemi-
Int J Chem Kinet

luminescence reaction CO + O + M ⇌ CO2* + M.
2015;47:50–72.

[310] Panoutsos C, Hardalupas Y, Taylor A. Numerical evaluation of equivalence
ratio measurement using OH* and CH* chemiluminescence in premixed and
non-premixed methane–air flames. Combust Flame 2009;156:273–91.
[311] Ikeda Y, Kojima J, Nakajima T. Fast Response Local Equivalence Ratio Measure-
ment in Premixed Turbulent Flame. Technical report, Department of Mechanical
Engineering, Kobe University, Japan; 2001.

[312] Ikeda Y, Kojima J, Hashimoto H. Local chemiluminescence spectra measure-
ments in a high-pressure laminar methane/air premixed flame. Proc Combust
Inst 2002;29:1495–501.

[313] Nori V, Seitzman J. Chemiluminescence measurements and modeling in syngas,
methane and Jet-A fueled combustors. In: 45th AIAA aerospace sciences meeting
and exhibit; 2007. p. 466.

[314] Nori VN. Modeling and analysis of chemiluminescence sensing for syngas,
methane and Jet-A combustion [Ph.D. thesis], Georgia Institute of Technology;
2008.

[315] Nori VN, Seitzman JM. CH* chemiluminescence modeling for combustion

diagnostics. Proc Combust Inst 2009;32:895–903.

[316] Smith GP, Luque J, Park C, Jeffries JB, Crosley DR. Low pressure flame
determinations of rate constants for OH(A) and CH(A) chemiluminescence.
Combust Flame 2002;131:59–69.

[317] Smith GP, Park C, Luque J. A note on chemiluminescence in low-pressure
hydrogen and methane–nitrous oxide flames. Combust Flame 2005;140:385–9.
[318] Smith GP, Park C, Schneiderman J, Luque J. C2 Swan band laser-induced fluo-
rescence and chemiluminescence in low-pressure hydrocarbon flames. Combust
Flame 2005;141:66–77.

[319] Zhao M, Buttsworth D, Choudhury R. Experimental and numerical study
of OH* chemiluminescence in hydrogen diffusion flames. Combust Flame
2018;197:369–77.

[320] Najm HN, Paul PH, Mueller CJ, Wyckoff PS. On the adequacy of certain
experimental observables as measurements of flame burning rate. Combust
Flame 1998;113:312–32.

[321] Lauer M, Sattelmayer T. On the adequacy of chemiluminescence as a measure
for heat release in turbulent flames with mixture gradients. J Eng Gas Turbines
Power 2010;132.

[322] Ballester J, García-Armingol T. Diagnostic techniques for the monitoring and
control of practical flames. Prog Energy Combust Sci 2010;36:375–411.
[323] Hardalupas Y, Orain M. Local measurements of the time-dependent heat release
rate and equivalence ratio using chemiluminescent emission from a flame.
Combust Flame 2004;139:188–207.

[324] Guyot D, Guethe F, Schuermans B, Lacarelle A, Paschereit CO. CH*/OH*
chemiluminescence response of an atmospheric premixed flame under varying
operating conditions. In: Turbo expo: Power for land, sea, and air, vol. 43970.
2010, p. 933–44.

[325] Clark TP. Technical note 4266 – studies of OH, CO, CH, and C2 radiation from
laminar and turbulent propane-air and ethylene-air flames. Technical report,
National Advisory Committee for Aeronautics; 1958.

[326] Lauer M, Zellhuber M, Sattelmayer T, Aul CJ. Determination of the heat
release distribution in turbulent flames by a model based correction of OH*
chemiluminescence. J Eng Gas Turbines Power 2011;133.

[327] Fiala T. Radiation from High Pressure Hydrogen–Oxygen Flames and its use in
Assessing Rocket Combustion Instability [Ph.D. thesis], Technische Universität
München; 2015.

[328] Clark TP, Bittker DA. A study of the radiation from laminar and turbulent
open propane-air flames as a function of flame area, equivalence ratio, and
fuel flow rate. Technical report, National Advisory Committee for Aeronautics,
Lewis Flight Propulsion Laboratory; 1954.

[329] John RR, Summerfield M. Effect of turbulence on radiation intensity from

propane-air flames. J Jet Propul 1957;27:169–75.

[330] Hurle I, Price R, Sugden TM, Thomas A. Sound emission from open turbulent
premixed flames. Proc R Soc Lond Ser A Math Phys Eng Sci 1968;303:409–27.
[331] Haber LC, Vandsburger U, Saunders WR, Khanna VK. An examination of the
relationship between chemiluminescent light emissions and heat release rate
under non-adiabatic conditions. In: Turbo expo: power for land, sea, and air,
vol. 78552. American Society of Mechanical Engineers; 2000, V002T02A041.

[332] Haber L, Vandsburger U, Saunders W, Khanna V. An experimental examination
of the relationship between chemiluminescent light emissions and heat-release
rate under non-adiabatic conditions. Technical report, Virginia Polytechnic
Institute and State University; 2001.

[333] Higgins B, McQuay M, Lacas F, Rolon J-C, Darabiha N, Candel S. Systematic
measurements of OH chemiluminescence for fuel-lean, high-pressure, premixed,
laminar flames. Fuel 2001;80:67–74.

[334] Lee J, Santavicca D. Experimental diagnostics for the study of combustion

instabilities in lean premixed combustors. J Propul Power 2003;19:735–50.

[335] Haber LC. An investigation into the origin, measurement and application
of chemiluminescent light emissions from premixed flames [Master’s thesis],
Virginia Tech; 2000.

[336] Diederichsen J, Wolfhard H. Spectrographic examination of gaseous flames at

high pressure. Proc R Soc Lond Ser A Math Phys Eng Sci 1956;236:89–103.

[337] Weinkauff J, Koeser J, Michaelis D, Peterson B, Dreizler A, Böhm B. Volu-
metric flame measurements in a lifted turbulent jet flame using tomographic
reconstruction of chemiluminescence.
In: 17th international symposium on
application of laser techniques to fluid mechanics; 2014. p. 11.

[338] Guiberti TF, Durox D, Schuller T. Flame chemiluminescence from CO2- and
N2-diluted laminar CH4/air premixed flames. Combust Flame 2017;181:110–22.
[339] Wiseman SM, Haghiri A, Brear MJ, Gordon RL, Marusic I. Optical emission
tomography of non-axisymmetric, laminar, premixed flames. In: 19th Australian
fluid mechanics conference; 2014. p. 4.

[340] Moeck JP, Bourgouin J-F, Durox D, Schuller T, Candel S. Tomographic re-
construction of heat release rate perturbations induced by helical modes in
turbulent swirl flames. Exp Fluids 2013;54:1498.

[341] Jin Y, Song Y, Qu X, Li Z, Ji Y, He A. Three-dimensional dynamic measurements
of CH* and C2* concentrations in flame using simultaneous chemiluminescence
tomography. Opt Express 2017;25:4640–54.

[342] Windle CI, Anderson J, Boyd J, Homan B, Korivi V, Ma L. In situ imaging of 4D
fire events in a ground vehicle testbed using customized fiber-based endoscopes.
Combust Flame 2021;224:225–32.

[343] Gilabert G, Lu G, Yan Y. Three-dimensional tomographic reconstruction of
the luminosity distribution of a combustion flame. IEEE Trans Instrum Meas
2007;56:1300–6.

[344] Floyd J, Kempf AM. Computed tomography of chemiluminescence (CTC): High
resolution and instantaneous 3-D measurements of a matrix burner. Proc
Combust Inst 2011;33:751–8.

[345] Floyd J, Geipel P, Kempf AM. Computed tomography of chemiluminescence
(CTC): Instantaneous 3D measurements and phantom studies of a turbulent
opposed jet flame. Combust Flame 2011;158:7376–91.

[346] Anikin NB, Suntz R, Bockhorn H. Tomographic reconstruction of the OH*-
chemiluminescence distribution in premixed and diffusion flames. Appl Phys
B 2010;100:675–94.

[347] Anikin NB, Suntz R, Bockhorn H. Tomographic reconstruction of 2D-OH*-
chemiluminescence distributions in turbulent diffusion flames. Appl Phys B
2012;107:591–602.

[348] Hossain MM, Lu G, Yan Y. Three-dimensional reconstruction of combustion
flames through optical fiber sensing and CCD imaging. In: 2011 IEEE inter-
national instrumentation and measurement technology conference; 2011. p.
1–5.

[349] Hossain MM, Lu G, Yan Y. Optical

fiber

imaging based tomographic

reconstruction of burner flames. IEEE Trans Instrum Meas 2012;61:1417–25.

[350] Hossain MM, Lu G, Yan Y. Three-dimensional reconstruction of flame tempera-
ture and emissivity through tomographic imaging and pyrometric measurement.
In: 2012 IEEE international conference on imaging systems and techniques
proceedings; 2012. p. 13–7.

[351] Kang M, Lei Q, Ma L. Characterization of linearity and uniformity of fiber-based
endoscopes for 3D combustion measurements. Appl Opt 2014;53:5961–8.
[352] Kang M, Wu Y, Ma L. Fiber-based endoscopes for 3D combustion measurements:

View registration and spatial resolution. Combust Flame 2014;161:3063–72.

[353] Ma L, Lei Q, Wu Y, Ombrello TM, Carter CD. 3D measurements of ignition
processes at 20 kHz in a supersonic combustor. Appl Phys B 2015;119:313–8.
[354] Ma L, Lei Q, Wu Y, Xu W, Ombrello TM, Carter CD. From ignition to stable com-
bustion in a cavity flameholder studied via 3D tomographic chemiluminescence
at 20 kHz. Combust Flame 2016;165:1–10.

67

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

[355] Ma L, Wickersham AJ, Xu W, Peltier SJ, Ombrello TM, Carter CD. Multi-angular
flame measurements and analysis in a supersonic wind tunnel using fiber-based
endoscopes. J Eng Gas Turbines Power 2016;138.

[356] Cai W, Liu H, Wang Q, Ju D. Improved calibration model for single-camera
endoscopic tomographic systems. J Opt Soc Amer B 2020;37:2578–85.
[357] Liu H, Wang Y, Yu T, Liu H, Cai W, Weng S. Effect of carbon dioxide content in
biogas on turbulent combustion in the combustor of micro gas turbine. Renew
Energy 2020;147:1299–311.

[358] Wang K, Li F, Zeng H, Zhang S, Yu X. Computed tomography measurement of
3D combustion chemiluminescence using single camera. In: Opt Meas Technol
Instrum. 10155, International Society for Optics and Photonics; 2016, 1015531.
[359] Wang K, Li F, Zeng H, Yu X. Three-dimensional flame measurements with large

field angle. Opt Express 2017;25:21008–18.

[360] Wang K, Kang G, Li F, Yu X. 3D measurements of swirling flame heat release
rate based on CH chemiluminescence. In: Fifth international symposium on
laser interaction with matter, vol. 11046. International Society for Optics and
Photonics; 2019, p. 110462V.

[361] An Q, Kwong WY, Geraedts BD, Steinberg AM. Coupled dynamics of lift-
flames. Combust Flame

off and precessing vortex core formation in swirl
2016;168:228–39.

[362] Stöhr M, Oberleithner K, Arndt CM, Steinberg AM, Meier W. Experimental study
of transient coupling of PVC formation and flame shape transition in a bi-stable
turbulent swirl flame. In: Proceedings of the 7th European Combustion Meeting;
2015. p. 6.

[363] Stöhr M, Oberleithner K, Sieber M, Yin Z, Meier W. Experimental study of
transient mechanisms of bistable flame shape transitions in a swirl combustor.
J Eng Gas Turbines Power 2018;140.

[364] Oberleithner K, Stöhr M, Im SH, Arndt CM, Steinberg AM. Formation and
flame-induced suppression of the precessing vortex core in a swirl combustor:
Experiments and linear stability analysis. Combust Flame 2015;162:3100–14.

[365] Liu C, Cao Z, Lin Y, Xu L, McCann H. Online cross-sectional monitoring
IEEE Trans Instrum Meas

of a swirling flame using TDLAS tomography.
2018;67:1338–48.

[366] Berkooz G, Holmes P, Lumley JL. The proper orthogonal decomposition in the

analysis of turbulent flows. Annu Rev Fluid Mech 1993;25:539–75.

[367] Taira K, Brunton SL, Dawson ST, Rowley CW, Colonius T, McKeon BJ,
Schmidt OT, Gordeyev S, Theofilis V, Ukeiley LS. Modal analysis of fluid flows:
An overview. AIAA J 2017;55:4013–41.

[368] Buhl S, Hartmann F, Hasse C. Identification of large-scale structure fluctuations
in IC engines using POD-based conditional averaging. Oil Gas Sci Technol
2016;71:1.

[369] Chen H, Reuss DL, Hung DL, Sick V. A practical guide for using proper
orthogonal decomposition in engine research. Int J Engine Res 2013;14:307–19.
[370] Samarasinghe J, Peluso S, Szedlmayer M, De Rosa A, Quay B, Santavicca D.
Three-dimensional chemiluminescence imaging of unforced and forced swirl-
stabilized flames in a lean premixed multi-nozzle can combustor. J Eng Gas
Turbines Power 2013;135.

[371] Xu W, Wickersham A, Wu Y, He F, Ma L. 3D flame topography obtained
by tomographic chemiluminescence with direct comparison to planar Mie
scattering measurements. Appl Opt 2015;54:2174–82.

[372] Ma L, Lei Q, Capil T, Hammack SD, Carter CD. Direct comparison of two-
dimensional and three-dimensional laser-induced fluorescence measurements on
highly turbulent flames. Opt Lett 2017;42:267–70.

[373] Li T, Pareja J, Fuest F, Schütte M, Zhou Y, Dreizler A, Böhm B. Tomographic
imaging of OH laser-induced fluorescence in laminar and turbulent jet flames.
Meas Sci Technol 2017;29:015206.

[374] Yu T, Ruan C, Liu H, Cai W, Lu X. Time-resolved measurements of a swirl
flame at 4 kHz via computed tomography of chemiluminescence. Appl Opt
2018;57:5962–9.

[375] Ruan C, Yu T, Chen F, Wang S, Cai W, Lu X. Experimental characteriza-
tion of the spatiotemporal dynamics of a turbulent flame in a gas turbine
model combustor using computed tomography of chemiluminescence. Energy
2019;170:744–51.

[376] Sweeney MS, Hochgreb S, Dunn MJ, Barlow RS. The structure of turbulent
stratified and premixed methane/air flames I: Non-swirling flows. Combust
Flame 2012;159:2896–911.

[377] Sweeney MS, Hochgreb S, Dunn MJ, Barlow RS. The structure of turbulent
stratified and premixed methane/air flames II: Swirling flows. Combust Flame
2012;159:2912–29.

[378] Wiseman SM, Brear MJ, Gordon RL, Marusic I. Measurements from flame
chemiluminescence tomography of forced laminar premixed propane flames.
Combust Flame 2017;183:1–14.

[379] Chi Y, Lei Q, Song E, Fan W, Sha Y. Development and validation of evaluation
methods for 3D flame propagation speed of turbulent non-premixed edge flames
via tomographic chemiluminescence. Flow Turbul Combust 2021;1–19.
[380] Dong R, Lei Q, Zhang Q, Fan W. Dynamics of ignition kernel in a liquid-fueled
gas turbine model combustor studied via time-resolved 3D measurements.
Combust Flame 2021;232:111566.

68

[381] Ishino Y, Takeuchi K, Shiga S, Ohiwa N. Measurement of

instantaneous
3D-distribution of local burning velocity on a turbulent premixed flame by non-
scanning 3D-CT reconstruction. In: 4th european combustion meeting. Citeseer;
2009, p. 14–7.

[382] Ma L, Wu Y, Xu W, Hammack SD, Lee T, Carter CD. Comparison of 2D
and 3D flame topography measured by planar laser-induced fluorescence and
tomographic chemiluminescence. Appl Opt 2016;55:5310–5.

[383] Yu T, Wang Q, Ruan C, Chen F, Cai W, Lu X, Klein M. A quantitative evaluation
method of 3D flame curvature from reconstructed flame structure. Exp Fluids
2020;61:66.

[384] Tyagi A, Boxx I, Peluso S, O’Connor J. Pocket formation and behavior in

turbulent premixed flames. Combust Flame 2020;211:312–24.

[385] Peters N, Terhoeven P, Chen JH, Echekki T. Statistics of flame displacement
speeds from computations of 2-d unsteady methane-air flames. In: Symp. (Int.)
Combust.. Elsevier; 1998, p. 833–9.

[386] Echekki T, Chen JH. Analysis of the contribution of curvature to premixed flame

propagation. Combust Flame 1999;118.

[387] Chakraborty N, Klein M, Cant R. Stretch rate effects on displacement speed
in turbulent premixed flame kernels in the thin reaction zones regime. Proc
Combust Inst 2007;31:1385–92.

[388] Han I, Huh KY. Roles of displacement speed on evolution of flame surface
density for different turbulent intensities and Lewis numbers in turbulent
premixed combustion. Combust Flame 2008;152:194–205.

[389] Ayoola BO, Balachandran R, Frank JH, Mastorakos E, Kaminski CF. Spatially
resolved heat release rate measurements in turbulent premixed flames. Combust
Flame 2006;144:1–16.

[390] Tautschnig G, Hampel B, Hirsch C, Sattelmayer T. Experimental investigation of
OH* and CH* chemiluminescence under varying operating conditions. In: Turbo
expo: power for land, sea, and air, vol. 55119. American Society of Mechanical
Engineers; 2013, V01BT04A062.

[391] Hsu PS, Lauriola D, Jiang N, Miller JD, Gord JR, Roy S. Fiber-coupled,
UV–SWIR hyperspectral imaging sensor for combustion diagnostics. Appl Opt
2017;56:6029–34.

[392] Cheng TS, Wu CY, Li YH, Chao YC. Chemiluminescence measurements of
local equivalence ratio in a partially premixed flame. Combust Sci Technol
2006;178:1821–41.

[393] Docquier N, Belhalfaoui S, Lacas F, Darabiha N, Rolon C. Experimental and
numerical study of chemiluminescence in methane/air high-pressure flames for
active control applications. Proc Combust Inst 2000;28:1765–74.

[394] Docquier N, Lacas F, Candel S. Closed-loop equivalence ratio control of pre-
mixed combustors using spectrally resolved chemiluminescence measurements.
Proc Combust Inst 2002;29:139–45.

[395] Muruganandam T, Kim B-H, Morrell M, Nori V, Patel M, Romig B, Seitzman J.
Optical equivalence ratio sensors for gas turbine combustors. Proc Combust Inst
2005;30:1601–9.

[396] Walsh KT, Fielding J, Smooke MD, Long MB, Liñán A. A comparison of
lift-off heights of coflow laminar diffusion

computational and experimental
flames. Proc Combust Inst 2005;30:357–65.

[397] Giassi D, Cao S, Bennett BAV, Stocker DP, Takahashi F, Smooke MD, Long MB.
Analysis of CH* concentration and flame heat release rate in laminar coflow
diffusion flames under microgravity and normal gravity. Combust Flame
2016;167:198–206.

[398] Kather V, Lückoff F, O. Paschereit C, Oberleithner K. Interaction of equivalence
ratio fluctuations and flow fluctuations in acoustically forced swirl flames. Int
J Spray Combust Dyn 2021;13:72–95.

[399] O’Connor J, Acharya V, Lieuwen T. Transverse combustion instabilities:
fluid mechanic, and flame processes. Prog Energy Combust Sci

Acoustic,
2015;49:1–39.

[400] Strutt

JW. The
1878;18:319–21.

explanation of

certain acoustical phenomena. Nature

[401] Zinn BT. Pulse combustion: Recent applications and research issues. In: Symp.

(Int.) Combust.. Elsevier; 1992, p. 1297–305.

[402] Lauer M, Sattelmayer T, et al. Heat release calculation in a turbulent swirl
flame from laser and chemiluminescence measurements. In: 14th international
symposium on applications of laser techniques to fluid mechanics. Citeseer;
2008, p. 7–10.

[403] Venkataraman K, Preston L, Simons D, Lee B, Lee J, Santavicca D. Mechanism
of combustion instability in a lean premixed dump combustor. J Propul Power
1999;15:909–18.

[404] Kim KT, Lee JG, Quay B, Santavicca D. Response of partially premixed
flames to acoustic velocity and equivalence ratio perturbations. Combust Flame
2010;157:1731–44.

[405] Yi T, Santavicca DA. Combustion instability and flame structure of turbulent

swirl-stabilized liquid-fueled combustion. J Propul Power 2012;28:1000–14.

[406] Bunce NA. Flame transfer function measurements and mechanisms in a single-
thesis], The Pennsylvania State University, State

nozzle combustor [Ph.D.
College, PA; 2013.
[407] Kim KT, Santavicca DA.

Interference mechanisms of acoustic/convective
disturbances in a swirl-stabilized lean-premixed combustor. Combust Flame
2013;160:1441–57.

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

[408] Mordaunt CJ. Dual fuel issues related to performance, emissions, and com-
bustion instability in lean premixed gas turbine systems [Ph.D.
thesis],
Pennsylvania State University; 2005.

[435] Paul P, Durant Jr. J, Gray J, Furlanetto M. Collisional electronic quenching of
OH A2Σ(v′ = 0) measured at high temperature in a shock tube. J Chem Phys
1995;102:8378–84.

[409] Lee J-Y, Lubarsky E, Zinn BT.

‘‘Slow’’ active control of combustion insta-
bilities by modification of liquid fuel spray properties. Proc Combust Inst
2005;30:1757–64.

[410] Cirtwill JM, Saini P, Venkatesan K, Steinberg AM. A semi-empirical time-lag
model for predicting limit-cycle thermoacoustic amplitudes in an aeronautical
gas turbine combustor. In: 53rd AIAA/SAE/ASEE joint propulsion conference;
2017. p. 4777.

[411] Strollo J, Peluso S, O’Connor J. Effect of hydrogen on steady-state and
transient combustion instability characteristics. J Eng Gas Turbines Power
2021;143:071023.

[412] Chterev I, Boxx I. Effect of hydrogen enrichment on the dynamics
of a lean technically premixed elevated pressure flame. Combust Flame
2021;225:149–59.

[413] Lückoff F, Oberleithner K. Excitation of the precessing vortex core by active
flow control to suppress thermoacoustic instabilities in swirl flames. Int J Spray
Combust Dyn 2019;11:1756827719856237.

[414] Palies P, Durox D, Schuller T, Candel S. The combined dynamics of swirler and
turbulent premixed swirling flames. Combust Flame 2010;157:1698–717.
[415] Schimek S, Moeck JP, Paschereit CO. An experimental investigation of the
nonlinear response of an atmospheric swirl-stabilized premixed flame. In: Turbo
expo: power for land, sea, and air, vol. 43970. 2010, p. 665–75.

[416] Hardi J, Hallum WZ, Huang C, Anderson WE. Development of validation
approaches for numerical simulation of combustion instability using flame
imaging. In: 50th AIAA/ASME/SAE/ASEE joint propulsion conference; 2014.
p. 3775.

[417] Arndt CM, Severin M, Dem C, Stöhr M, Steinberg AM, Meier W. Experimental
analysis of
thermo-acoustic instabilities in a generic gas turbine combus-
tor by phase-correlated PIV, chemiluminescence, and laser Raman scattering
measurements. Exp Fluids 2015;56:1–23.

[418] Meier W, Weigand P, Duan XR, Giezendanner-Thoben R. Detailed characteri-
zation of the dynamics of thermoacoustic pulsations in a lean premixed swirl
flame. Combust Flame 2007;150:2–26.

[419] Wang L-Y, Chatterjee S, An Q, Steinberg AM, Gülder ÖL. Soot formation and
flame structure in swirl-stabilized turbulent non-premixed methane combustion.
Combust Flame 2019;209:303–12.

[420] Arndt CM, Dem C, Meier W. Influence of fuel staging on thermo-acoustic
oscillations in a premixed stratified dual-swirl gas turbine model combustor.
Flow Turbul Combust 2021;106:613–29.

[421] Lucht RP, Sweeney DW, Laurendeau NM, Drake MC, Lapp M, Pitz RW.
laser-saturated fluorescence measurements of OH in turbulent

Single-pulse,
nonpremixed flames. Opt Lett 1984;9:90–2.

[422] van Oostendorp DL, Levinsky HB, van der Meij CE, Jacobs RA, Borghols WT.
in one-
imaging. Appl Opt

the photochemical production of oxygen atoms

two-photon laser-induced fluorescence

Avoidance of
dimensional,
1993;32:4636–40.

[423] Kychakoff G, Howe RD, Hanson RK, Drake MC, Pitz RW, Lapp M, Penney CM.
Visualization of turbulent flame fronts with planar laser-induced fluorescence.
Science 1984;224:382–4.

[424] Coriton B, Steinberg AM, Frank JH. High-speed tomographic PIV and OH PLIF

measurements in turbulent reactive flows. Exp Fluids 2014;55:1743.

[425] Watson K, Lyons K, Donbar J, Carter C. Simultaneous Rayleigh imaging
and CH-PLIF measurements in a lifted jet diffusion flame. Combust Flame
2000;123:252–65.

[426] Meyer T, King G, Martin G, Lucht R, Schauer F, Dutton JC. Accuracy and
resolution issues in NO/acetone PLIF measurements of gas-phase molecular
mixing. Exp Fluids 2002;32:603–11.

[427] Hindle F, McCann H, Ozanyan KB. First demonstration of optical fluorescence

auto-projection tomography. Chem Eng J 2000;77:127–35.

[428] Ozanyan KB, McCann H. Efficiency and data correction for OFAPT sensors with

fiber receivers. IEEE Sens J 2005;5:195–202.

[436] Tamura M, Berg PA, Harrington JE, Luque J, Jeffries JB, Smith GP,
Crosley DR. Collisional quenching of CH(A), OH (A), and NO(A) in low pressure
hydrocarbon flames. Combust Flame 1998;114:502–14.

[437] Halls BR, Hsu P, Roy S, Meyer T, Gord J. Two-color volumetric laser-induced
fluorescence for 3D OH and temperature fields in turbulent reacting flows. Opt
Lett 2018;43:2961–4.

[438] McDaniel J, Baganoff D, Byer R. Density measurement in compressible flows

using off-resonant laser-induced fluorescence. Phys Fluids 1982;25:1105–7.

[439] McDaniel J. Nonintrusive pressure measurement with laser-induced iodine

fluorescence. In: 18th thermophysics conference; 1984. p. 1468.

[440] Hiller B, Hanson RK. Simultaneous planar measurements of velocity and
flows using laser-induced fluorescence. Appl Opt

in gas

pressure fields
1988;27:33–48.

[441] Cheng S, Zimmermann M, Miles R. Supersonic-nitrogen flow-field measurements
with the resonant Doppler velocimeter. Appl Phys Lett 1983;43:143–5.
[442] Paul PH, Lee M, Hanson R. Molecular velocity imaging of supersonic flows
using pulsed planar laser-induced fluorescence of NO. Opt Lett 1989;14:417–9.
[443] Liebeskind JG, Hanson RK, Cappelli MA. Laser-induced fluorescence diagnostic
for temperature and velocity measurements in a hydrogen arcjet plume. Appl
Opt 1993;32:6117–27.

[444] Yin Z, Carter CD, Lempert WR. Effects of signal corrections on measurements
of temperature and oh concentrations using laser-induced fluorescence. Appl
Phys B 2014;117:707–21.

[445] Luque J, Smith GP, Crosley DR. Quantitative CH determinations in low-pressure

flames. Symp (Int) Combust 1996;26:959–66.

[446] Luque J, Klein-Douwel R, Jeffries J, Smith G, Crosley D. Quantitative laser-
induced fluorescence of CH in atmospheric pressure flames. Appl Phys B
2002;75:779–90.

[447] Versailles P, Watson GM, Lipardi AC, Bergthorson JM. Quantitative CH mea-
surements in atmospheric-pressure, premixed flames of C1–C4 alkanes. Combust
Flame 2016;165:109–24.

[448] Seitzman JM, Kychakoff G, Hanson RK. Instantaneous temperature field mea-

surements using planar laser-induced fluorescence. Opt Lett 1985;10:439–41.

[449] Laufer G, McKenzie RL, Fletcher DG. Method for measuring temperatures
and densities in hypersonic wind tunnel air flows using laser-induced O2
fluorescence. Appl Opt 1990;29:4873–83.

[450] Zizak G, Omenetto N, Winefordner JD. Laser-excited atomic fluorescence
techniques for temperature measurements in flames: A summary. Opt Eng
1984;23:236749.

[451] Thurber MC, Grisch F, Kirby BJ, Votsmeier M, Hanson RK. Measurements
and modeling of acetone laser-induced fluorescence with implications for
temperature-imaging diagnostics. Appl Opt 1998;37:4963–78.

[452] Thurber MC, Hanson RK. Pressure and composition dependences of acetone
laser-induced fluorescence with excitation at 248, 266, and 308 nm. Appl Phys
B 1999;69:229–40.

[453] Desgroux P, Gasnot L, Pauwels J, Sochet L. Correction of LIF temperature
measurements for laser absorption and fluorescence trapping in a flame. Appl
Phys B 1995;61:401–7.

[454] Luque J, Crosley DR. LIFBASE: Database and spectral simulation program

(Version 1.5). Technical report, SRI International; 1999.

[455] Bülter A, Lenhard U, Rahmann U, Kohse-Höinghaus K, Brockhinke A. LASKIN:
Efficient simulation of spectra affected by energy transfer. In: Laser applications
to chemical and environmental analysis. Optical Society of America; 2004, p.
TuE4.

[456] Bessler WG, Schulz C, Sick V, Daily JW. A versatile modeling tool for nitric
oxide LIF spectra. In: Proceedings of the third joint meeting of the US sections
of the Combustion Institute, vol. 3. p. PI05.

[457] Western CM. PGOPHER: A program for simulating rotational, vibrational and
electronic spectra. J Quant Spectrosc Radiat Transfer 2017;186:221–42.

[458] Siegman AE. Lasers. University Science Books; 1986.
[459] Demtröder W. Laser spectroscopy: basic concepts and instrumentation. Springer

[429] Daily JW. Laser induced fluorescence spectroscopy in flames. Prog Energy

Science & Business Media; 2013.

Combust Sci 1997;23:133–99.

[430] Carter CD, Lee T. LIF theory and practice. In: Steinberg A, Roy S, editors.
Optical diagnostics for reacting and non-reacting flows: theory and practice.
AIAA; 2022, p. 181–254.

[431] Hilborn RC. Einstein coefficients, cross sections, f values, dipole moments, and

all that. Amer J Phys 1982;50:982–6.

[432] Beaud P, Radi PP, Franzke D, Frey H-M, Mischler B, Tzannis A-P, Gerber T.
Picosecond investigation of the collisional deactivation of OH a2Σ+(ν′ = 1,
n′ = 4, 12) in an atmospheric-pressure flame. Appl Opt 1998;37:3354–67.
[433] Brackmann C, Bood J, Nauclér JD, Konnov AA, Aldén M. Quantitative picosec-
ond laser-induced fluorescence measurements of nitric oxide in flames. Proc
Combust Inst 2017;36:4533–40.

[460] Koban W, Koch J, Hanson R, Schulz C. Absorption and fluorescence of toluene
vapor at elevated temperatures. Phys Chem Chem Phys 2004;6:2940–5.
[461] Wermuth N, Sick V. Absorption and fluorescence data of acetone, 3-pentanone,
temperature and

biacetyl, and toluene at engine-specific combinations of
pressure. SAE Trans 2005;14:804–14.

[462] Rosell J, Bai X-S, Sjoholm J, Zhou B, Li Z, Wang Z, Pettersson P, Li Z, Richter M,
Alden M. Multi-species PLIF study of the structures of turbulent premixed
methane/air jet flames in the flamelet and thin-reaction zones regimes. Combust
Flame 2017;182:324–38.

[463] Sjöholm J, Rosell J, Li B, Richter M, Li Z, Bai X-S, Aldén M. Simultaneous
visualization of OH, CH, CH2O and toluene PLIF in a methane jet flame with
varying degrees of turbulence. Proc Combust Inst 2013;34:1475–82.

[434] Dunn M, Masri A. A comprehensive model for the quantification of linear and
nonlinear regime laser-induced fluorescence of OH under A2Σ+ ← X2Π(1, 0)
excitation. Appl Phys B 2010;101:445–63.

[464] Peterson B, Baum E, Böhm B, Sick V, Dreizler A. Evaluation of toluene LIF
thermometry detection strategies applied in an internal combustion engine. Appl
Phys B 2014;117:151–75.

69

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

[465] Kojima H, Takahashi E, Tsujimura T, Furutani H, Kashiwazaki T. Acetone
PLIF measurements of temperature and concentration distributions in a high-
temperature and high-pressure spray.
In: SAE technical paper; 2015. p.
1840.

[466] Braeuer A, Beyrau F, Leipertz A. Laser-induced fluorescence of ketones at
elevated temperatures for pressures up to 20 bars by using a 248 nm
excitation laser wavelength: Experiments and model improvements. Appl Opt
2006;45:4982–9.

[467] Mohri K, Luong M, Vanhove G, Dreier T, Schulz C. Imaging of the oxygen
distribution in an isothermal turbulent free jet using two-color toluene LIF
imaging. Appl Phys B 2011;103:707–15.

[468] Wohler A, Weigand B, Mohri K, Schulz C. Mixing processes in a compressible
accelerated nozzle flow with blunt-body wakes. AIAA J 2014;52:559–68.
[469] Lind S, Zigan L, Trost J, Leipertz A, Will S. Simultaneous two-dimensional
measurement of fuel-air ratio and temperature in a direct-injection spark-
ignition engine using a new tracer-pair laser-induced fluorescence technique.
Int J Engine Res 2016;17:120–8.

[470] Brackmann C, Nygren J, Bai X, Li Z, Bladh H, Axelsson B, Denbratt I, Koop-
mans L, Bengtsson PE, Aldén M. Laser-induced fluorescence of formaldehyde in
combustion using third harmonic Nd:YAG laser excitation. Spectrochim Acta A
2003;59:3347–56.

[471] Jiang N, Patton RA, Lempert WR, Sutton JA. Development of high-repetition
rate CH PLIF imaging in turbulent nonpremixed flames. Proc Combust Inst
2011;33:767–74.

[472] Xu W, Carter CD, Hammack S, Ma L. Analysis of 3D combustion measurements
using CH-based tomographic VLIF (volumetric laser induced fluorescence).
Combust Flame 2017;182:179–89.

[473] Michelsen H, Schulz C, Smallwood G, Will S. Laser-induced incandescence:
Particulate diagnostics for combustion, atmospheric, and industrial applications.
Prog Energy Combust Sci 2015;51:2–48.

[490] Morandini F, Toulouse T, Silvani X, Pieri A, Rossi L. Image-based diagnostic
system for the measurement of flame properties and radiation. Fire Technol
2019;55:2443–63.

[491] Kempema NJ, Long MB. Effect of soot self-absorption on color-ratio pyrometry

in laminar coflow diffusion flames. Opt Lett 2018;43:1103–6.

[492] Wang Q, Legros G, Morin C, Yao M, Cai W, Jiang L. Optical measurements
of temperature fields in sooting flames: Influence of soot self-absorption. Appl
Phys B 2019;125:1–11.

[493] Bockhorn H. Soot formation in combustion: mechanisms and models, vol. 59.

Springer Science & Business Media; 2013.

[494] Lee S, Tien C. Optical constants of soot in hydrocarbon flames. In: Symp. (int.)

combust.. Elsevier; 1981, p. 1159–66.

[495] Stull VR, Plass GN. Emissivity of dispersed carbon particles.

JOSA

1960;50:121–9.

[496] Dalzell W, Sarofim A. Optical constants of soot and their application to heat-flux

calculations. J Heat Transfer 1969;91:100–4.

[497] Howarth C, Foster P, Thring M. The effect of temperature on the extinction
of radiation by soot particles. In: International heat transfer conference digital
library. Begel House Inc.; 1966, p. 122–8.

[498] Chang H-c, Charalampopoulos T. Determination of the wavelength dependence
of refractive indices of flame soot. Proc R Soc Lond Ser A Math Phys Eng Sci
1990;430:577–91.

[499] Felske J, Charalampopoulos T, Hura H. Determination of the refractive indices
of soot particles from the reflectivities of compressed soot pellets. Combust Sci
Technol 1984;37:263–83.

[500] Köylü ÜÖ, Faeth GM. Radiative properties of flame-generated soot. J Heat

Transfer 1993;115:409–17.

[501] Liu L, Mishchenko MI. Scattering and radiative properties of complex soot
and soot-containing aggregate particles. J Quant Spectrosc Radiat Transfer
2007;106:262–73.

[474] Pareja J, Johchi A, Li T, Dreizler A, Böhm B. A study of the spatial and temporal
evolution of auto-ignition kernels using time-resolved tomographic OH-LIF. Proc
Combust Inst 2019;37:1321–8.

[502] Liu F, Smallwood GJ. Radiative properties of numerically generated fractal
soot aggregates: The importance of configuration averaging. J Quant Spectrosc
Radiat Transfer 2010;111:302–8.

[475] Wang Q, Liu H, Liu X, Wang S, Fu C, Wang G, Gao Y, Cai W, Qi F. Three-
dimensional concentration field imaging in a swirling flame via endoscopic
volumetric laser-induced fluorescence at 10-kHz-rate. Sci China Technol Sci
2020;63:2163–8.

[476] Halls BR, Gord JR, Meyer TR, Thul DJ, Slipchenko M, Roy S. 20-kHz-rate three-
dimensional tomographic imaging of the concentration field in a turbulent jet.
Proc Combust Inst 2017;36:4611–8.

[477] Wu Y, Xu W, Ma L. Kilohertz VLIF (volumetric laser induced fluorescence)
measurements in a seeded free gas-phase jet in the transitionally turbulent flow
regime. Opt Lasers Eng 2018;102:52–8.

[478] Halls BR, Jiang N, Meyer TR, Roy S, Slipchenko MN, Gord JR. 4D spatiotempo-
ral evolution of combustion intermediates in turbulent flames using burst-mode
volumetric laser-induced fluorescence. Opt Lett 2017;42:2830–3.

[479] Shimura M, Ueda T, Choi G-M, Tanahashi M, Miyauchi T. Simultaneous
dual-plane CH PLIF, single-plane OH PLIF and dual-plane stereoscopic PIV
measurements in methane–air turbulent premixed flames. Proc Combust Inst
2011;33:775–82.

[480] Hancock RD, Bertagnolli KE, Lucht RP. Nitrogen and hydrogen CARS temper-
ature measurements in a hydrogen/air flame using a near-adiabatic flat-flame
burner. Combust Flame 1997;109:323–31.

[503] Bond TC, Bergstrom RW. Light absorption by carbonaceous particles: An

investigative review. Aerosol Sci Technol 2006;40:27–67.

[504] Millikan RC. Optical properties of soot. JOSA 1961;51:698–9.
[505] Ma B, Long MB. Combined soot optical characterization using 2-D multi-
angle light scattering and spectrally resolved line-of-sight attenuation and its
implication on soot color-ratio pyrometry. Appl Phys B 2014;117:287–303.

[506] Sorensen C. Light scattering by fractal aggregates: A review. Aerosol Sci Technol

2001;35:648–87.

[507] Michelsen HA, Schrader PE, Goulay F. Wavelength and temperature de-
pendences of the absorption and scattering cross sections of soot. Carbon
2010;48:2175–91.

[508] Hunter GB, Allemand CD, Eagar TW. Multiwavelength pyrometry: an improved

method. Opt Eng 1985;24:1081–5.

[509] Araújo A. Multi-spectral

pyrometry—a

review. Meas

Sci

Technol

2017;28:082002.

[510] Huajian W, Zhifeng H, Dundun W, Zixue L, Yipeng S, Qingyan F, Chun L,
Huaichun Z. Measurements on flame temperature and its 3D distribution in a
660 MWe arch-fired coal combustion furnace by visible image processing and
verification by using an infrared pyrometer. Meas Sci Technol 2009;20:114006.
[511] Modest MF, Haworth DC. Radiative heat transfer in turbulent combustion

[481] Dahm WJ, Dimotakis PE. Mixing at large Schmidt number in the self-similar

systems: Theory and applications. Springer; 2016.

far field of turbulent jets. J Fluid Mech 1990;217:299–330.

[512] Pope III CA, Dockery DW. Health effects of fine particulate air pollution: lines

[482] Tacina KM, Dahm WJ. Effects of heat release on turbulent shear flows. Part 1.
A general equivalence principle for non-buoyant flows and its application to
turbulent jet flames. J Fluid Mech 2000;415:23–44.

[483] Li G, Modest MF. Application of composition PDF methods in the investiga-
tion of turbulence–radiation interactions. J Quant Spectrosc Radiat Transfer
2002;73:461–72.

[484] Liu D, Wang F, Cen K, Yan J, Huang Q, Chi Y. Noncontact temperature
measurement by means of CCD cameras in a participating medium. Opt Lett
2008;33:422–4.

that connect. J Air Waste Manage Assoc 2006;56:709–42.

[513] Bond TC, Doherty SJ, Fahey DW, Forster PM, Berntsen T, DeAngelo BJ,
Flanner MG, Ghan S, Kärcher B, Koch D, et al. Bounding the role of black
carbon in the climate system: A scientific assessment. J Geophys Res Atmos
2013;118:5380–552.

[514] Hall RJ, Bonczyk PA. Sooting flame thermometry using emission/absorption

tomography. Appl Opt 1990;29:4590–8.

[515] Cignoli F, De Iuliis S, Manta V, Zizak G. Two-dimensional two-wavelength

emission technique for soot diagnostics. Appl Opt 2001;40:5370–8.

[485] Huang Q, Wang F, Yan J, Chi Y. Simultaneous estimation of the 3-D soot
temperature and volume fraction distributions in asymmetric flames using
high-speed stereoscopic images. Appl Opt 2012;51:2968–78.

[516] Snelling DR, Thomson KA, Smallwood GJ, Guider OL, Weckman EJ, Fraser RA.
flame radiation to determine soot

Spectrally resolved measurement of
temperature and concentration. AIAA J 2002;40:1789–95.

[486] Wang F, Xie Z, Yan J, Cen K. Simultaneous measurement of

three-
dimensional particle temperature, particle concentration, and H2O concen-
tration distributions using multispectral flame images. Combust Sci Technol
2017;189:1891–906.

[487] Lou C, Zhou H-C. Assessment of regularized reconstruction of three-dimensional
temperature distributions in large-scale furnaces. Numer Heat Transfer B
2008;53:555–67.

[488] Liu D, Yan J, Wang F, Huang Q, Chi Y, Cen K. Experimental

re-
constructions of
in laboratory-scale and
large-scale pulverized-coal fired furnaces by inverse radiation analysis. Fuel
2012;93:397–403.

flame temperature distributions

[489] Mason PS, Fleischmann CM, Rogers CB, McKinnon AE, Unsworth K, Spear-
point M. Estimating thermal radiation fields from 3D flame reconstruction. Fire
Technol 2009;45:1–22.

70

[517] Lee W, Na YD. Soot study in laminar diffusion flames at elevated pressure using
two-color pyrometry and Abel inversion. JSME Int J B 2000;43:550–5.
[518] Connelly BC, Kaiser SA, Smooke MD, Long MB. Two-dimensional soot pyrom-
etry with a color digital camera. In: Joint meeting of the US sections of the
Combustion Institute; 2005. p. 6.

[519] Kuhn PB, Ma B, Connelly BC, Smooke MD, Long MB. Soot and thin-filament

pyrometry using a color digital camera. Prof Combust Inst 2011;33:743–50.

[520] Kempema NJ, Long MB. Combined optical and TEM investigations for a detailed
characterization of soot aggregate properties in a laminar coflow diffusion
flame. Combust Flame 2016;164:373–85.

[521] Ma B, Cao S, Giassi D, Stocker DP, Takahashi F, Bennett BAV, Smooke MD,
Long MB. An experimental and computational study of soot formation in a
coflow jet flame under microgravity and normal gravity. Proc Combust Inst
2015;35:839–46.

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

[522] Vicariotto M, Dunn-Rankin D. Temperature profiles and extinction limits
laden methane/air diffusion flame. Exp Fluids

of a coflow water-vapor
2018;59:1–10.

[548] Mansmann R, Terheiden T, Schmidt P, Menser J, Dreier T, Endres T, Schulz C.
LIISim: A modular signal processing toolbox for laser-induced incandescence
measurements. Appl Phys B 2018;124:69.

[523] Dreyer JA, Slavchov RI, Rees EJ, Akroyd J, Salamanca M, Mosbach S, Kraft M.
Improved methodology for performing the inverse Abel transform of flame
images for color ratio pyrometry. Appl Opt 2019;58:2662–70.

[549] Nanthaamornphong A, Carver JC, Morris K, Michelsen HA, Rouson DW.
Building CLiiME via test-driven development: A case study. Comput Sci Eng
2014;16:36–46.

[524] Sankaranarayanan A, Swami U, Sasidharakurup R, Chowdhury A, Kumb-
hakarna N. Investigation of sooting flames by color-ratio pyrometry with a
consumer-grade DSLR camera. Rev Sci Instrum 2021;92:044905.

[550] Michelsen HA. Understanding and predicting the temporal

response of
laser-induced incandescence from carbonaceous particles. J Chem Phys
2003;118:7012–45.

[525] Liu F, Thomson KA, Smallwood GJ. Soot temperature and volume fraction
retrieval
in laminar
axisymmetric coflow diffusion flames: Effect of self-absorption. Combust Flame
2013;160:1693–705.

from spectrally resolved flame emission measurement

[526] De Iuliis S, Barbini M, Benecchi S, Cignoli F, Zizak G. Determination of the soot
volume fraction in an ethylene diffusion flame by multiwavelength analysis of
soot radiation. Combust Flame 1998;115:253–61.

[527] Thomson KA, Gülder ÖL, Weckman EJ, Fraser RA, Smallwood GJ, Snelling DR.
Soot concentration and temperature measurements
in co-annular, non-
premixed CH4/air laminar flames at pressures up to 4 MPa. Combust Flame
2005;140:222–32.

[528] Freeman MP, Katz S. Determination of the radial distribution of brightness
luminous medium with self-absorption. J Opt Soc Amer

in a cylindrical
1960;50:826–30.

[529] Huang Q-x, Wang F, Liu D, Ma Z-y, Yan J-h, Chi Y, Cen K-f. Reconstruction
of soot temperature and volume fraction profiles of an asymmetric flame using
stereoscopic tomography. Combust Flame 2009;156:565–73.

[530] Liu H, Zheng S, Zhou H, Qi C. Measurement of distributions of tempera-
ture and wavelength-dependent emissivity of a laminar diffusion flame using
hyper-spectral imaging technique. Meas Sci Technol 2015;27:025201.
[531] Si M, Cheng Q, Zhang Q, Wang D, Luo Z. Simultaneous reconstruction of the
temperature and inhomogeneous radiative properties of soot in atmospheric and
pressurized ethylene/air flames. Combust Sci Technol 2019;92:1946–62.
[532] Hossain MM, Lu G, Yan Y. Soot volume fraction profiling of asymmetric
diffusion flames through tomographic imaging. In: 2014 IEEE international
conference on imaging systems and techniques (IST) proceedings. IEEE; 2014,
p. 427–31.

[533] Hossain MM, Lu G, Hatem FA, Valera-Medina A, Marsh R, Yan Y. Tempera-
ture measurement of gas turbine swirling flames using tomographic imaging
techniques. In: 2015 IEEE international conference on imaging systems and
techniques. IEEE; 2015, p. 1–5.

[534] Hossain MM, Lu G, Yan Y. Tomographic imaging based measurement of
three-dimensional geometric parameters of a burner flame. In: 2014 IEEE
international instrumentation and measurement technology conference (I2MTC)
Proceedings. Ieee; 2014, p. 1111–4.

[535] Wu Z, Zhou Z, Tian D, Wu W. Reconstruction of three-dimensional flame with

color temperature. Visual Comput 2015;31:613–25.

[551] Sipkens T. Advances

in the modeling of

time-resolved laser-induced

incandescence [Ph.D. thesis], University of Waterloo; 2018.

[552] Liu F, Yang M, Hill FA, Snelling DR, Smallwood GJ. Influence of polydisperse
distributions of both primary particle and aggregate size on soot temperature
in low-fluence LII. Appl Phys B 2006;83:383.

[553] Daun K. Effect of selective accommodation on soot aggregate shielding
in time-resolved laser-induced incandescence experiments. J Heat Transfer
2010;132.

[554] Cenker E, Bennett A, Roberts WL. Investigations of the long-term effects of LII

on soot and bath gas. Aerosol Sci Technol 2017;51:1354–67.

[555] Michelsen HA, Liu F, Kock BF, Bladh H, Boïarciuc A, Charwath M, Dreier T,
Hadef R, Hofmann M, Reimann J, et al. Modeling laser-induced incandescence
of soot: A summary and comparison of LII models. Appl Phys B 2007;87:503–21.
[556] Bauer FJ, Daun KJ, Huber FJT, Will S. Can soot primary particle size
distributions be determined using laser-induced incandescence? Appl Phys B
2019;125:109.

[557] Schraml S, Dankers S, Bader K, Will S, Leipertz A. Soot temperature measure-
ments and implications for time-resolved laser-induced incandescence TIRE-LII.
Combust Flame 4:439–50.

[558] Goulay F, Schrader PE, Nemes L, Dansson MA, Michelsen HA. Photochemical
interferences for laser-induced incandescence of flame-generated soot. Proc
Combust Inst 2009;32:963–70.

[559] Will S, Schraml S, Bader K, Leipertz A. Performance characteristics of soot pri-
mary particle size measurements by time-resolved laser-induced incandescence.
Appl Opt 1998;37:5647–58.

[560] Michelsen HA, Witze PO, Kayes D, Hochgreb S. Time-resolved laser-induced
incandescence of soot: The influence of experimental factors and microphysical
mechanisms. Appl Opt 2003;42:5577–90.

[561] Kock BF, Tribalet B, Schulz C, Roth P. Two-color time-resolved LII applied
to soot particle sizing in the cylinder of a diesel engine. Combust Flame
2006;147:79–92.

[562] Musikhin S, Fortugno P, Corbin JC, Smallwood GJ, Dreier T, Daun KJ, Schulz C.
Characterization of few-layer graphene aerosols by laser-induced incandescence.
Carbon 2020;167:870–80.

[563] Zheng L, Ma X, Wang Z, Wang J. An optical study on liquid-phase penetration,
flame lift-off location and soot volume fraction distribution of gasoline-diesel
blends in a constant volume vessel. Fuel 2015;139:365–73.

[536] Shen L, Zhu D, Nadeem S, Wang Z, Kaufman AE. Radiative transport based
flame volume reconstruction from videos. IEEE Trans Vis Comput Graphics
2017;24:2209–22.

[564] Storch M, Koegl M, Altenhoff M, Will S, Zigan L.

Investigation of soot
formation of spark-ignited ethanol-blended gasoline sprays with single- and
multi-component base fuels. Appl Energy 2016;181:278–87.

[537] Zhaohui W, Xiaobo W, Hong S, Ying L. Acquisition and simulation of dynamic
In: 2017 international conference on

flame with temperature distribution.
virtual reality and visualization. IEEE; 2017, p. 324–31.

[565] Quay B, Lee T-W, Ni T, Santoro R. Spatially resolved measurements of
soot volume fraction using laser-induced incandescence. Combust Flame
1994;97:348–92.

[538] Linhua L, Heping T, Qizheng Y. Inverse radiation problem of temperature field
in three-dimensional rectangular furnaces. Int Commun Heat Mass Transfer
1999;26:239–48.

[566] Geitlinger H, Streibel T, Suntz R, Bockhorn H. Two-dimensional imaging of soot
volume fractions, particle number densities, and particle radii in laminar and
turbulent diffusion flames. Symp (Int) Combust 1998;27:1613–21.

[539] Liu L, Tan H. Inverse radiation problem in three-dimensional complicated
geometric systems with opaque boundaries. J Quant Spectrosc Radiat Transfer
2001;68:559–73.

[540] Zhou H-C, Han S-D, Sheng F, Zheng C-G. Visualization of three-dimensional
temperature distributions in a large-scale furnace via regularized reconstruction
from radiative energy images: Numerical studies. J Quant Spectrosc Radiat
Transfer 2002;72:361–83.

[541] Luo Z, Zhou H. A combustion-monitoring system with 3-D temperature recon-
struction based on flame-image processing technique. IEEE Trans Instrum Meas
2007;56:1877–82.

[542] Walters DV, Buckius RO. Monte Carlo methods for radiative heat transfer in

scattering media. Annu Rev Heat Transfer 1994;5:131–76.

[543] Modest M. Backward Monte Carlo simulations in radiative heat transfer. Trans

ASME J Heat Transfer 2003;125:57–62.

[544] Will S, Schraml S, Leipert A. Comprehensive two-dimensional

soot di-
agnostics based on laser-induced incandescence LII. Symp (Int) Combust
1996;26:2277–84.

[545] Lehre T, Suntz R, Bockhorn H. Time-resolved two-color LII: Size distri-
butions of nano-particles from gas-to-particle synthesis. Proc Combust Inst
2005;30:2585–93.

[546] Michelsen HA. Laser-induced incandescence of

flame-generated soot on a

picosecond time scale. Appl Phys B 2006;83:443–8.

[547] Wright P, McCormick D, Ozanyan K, Johnson M, Black J, Fisher E, Chighine A,
Polydorides N, McCann H, Feng Y, et al. Progress towards non-intrusive
optical measurement of gas turbine exhaust species distributions. In: 2015 IEEE
aerospace conference. IEEE; 2015, p. 1–14.

[567] Hentschel J, Suntz R, Bockhorn H. Soot formation and oxidation in oscillating
methane–air diffusion flames at elevated pressure. Appl Opt 2005;44:6673–81.
[568] Sun Z, Gu D, Nathan G, Alwahabi Z, Dally B. Single-shot, time-resolved planar
laser-induced incandescence (TiRe-LII) for soot primary particle sizing in flames.
Proc Combust Inst 2015;35:3673–80.

[569] Melton LA. Soot diagnostics based on laser heating. Appl Opt 1984;23:2201–8.
[570] Shaddix CR, Smyth KC. Laser-induced incandescence measurements of soot
production in steady and flickering methane, propane, and ethylene diffusion
flames. Combust Flame 1996;107:418–52.

[571] Shaddix CR, Harrington JE, Smyth KC. Quantitative measurements of enhanced
soot production in a flickering methane/air diffusion flame. Combust Flame
1994;99:723–32.

[572] Bladh H, Olofsson N-E, Mouton T, Simonsson J, Mercier X, Faccinetto A, Bengts-
son P-E, Desgroux P. Probing the smallest soot particles in low-sooting premixed
flames using laser-induced incandescence. Proc Combust Inst 2015;35:1843–50.
[573] Snelling DR, Smallwood GJ, Liu F, Gülder ÖL, Bachalo WD. A calibration-
independent laser-induced incandescence technique for soot measurement by
detecting absolute light intensity. Appl Opt 2005;44:6773–85.

[574] Snelling D, Link O, Thomson K, Smallwood G. Measurement of soot morphology

by integrated LII and elastic light scattering. Appl Phys B 2011;104:385–97.

[575] Tian B, Gao Y, Balusamy S, Hochgreb S. High spatial resolution laser cavity
extinction and laser-induced incandescence in low-soot-producing flames. Appl
Phys B 2015;120:469–87.

[576] Hofmann M, Kock BF, Dreier T, Jander H, Schulz C. Laser-induced in-
soot-particle sizing at elevated pressure. Appl Phys B

candescence for
2008;90:629–39.

71

Grauer, Mohri et al.

Progress in Energy and Combustion Science 94 (2023) 101024

und Forshung des Landes Nordrhein-Westfalen to fund her
professorship. Thereon, she established the Tomography
Group at UDE, which is focused on developing and applying
tomographic techniques for energy and process technology.

Tao Yu, King Abdullah University of Science and Tech-
nology (KAUST). Tao Yu is a postdoctoral fellow in the
Clean Combustion Research Center at KAUST. He received
his B.Eng. (2015) at Jilin University followed by a Ph.D.
(2020) at Shanghai Jiao Tong University. From 2018 to
2019, he was a visiting student at Lehrstuhl für Technische
Thermodynamik, Friedrich-Alexander-Universität Erlangen-
Nürnberg. His
include spectroscopic
absorption tomography, emission tomography, and the de-
velopment of advanced, quantitative laser diagnostics with
application to experimental investigations of fundamental
combustion phenomena.

research interests

Hecong Liu, Shanghai Jiao Tong University (SJTU). Hecong
Liu is a Ph.D. student in the Ministry of Educations Key
Laboratory for Power Machinery and Engineering at SJTU.
Mr. Liu completed B.Eng. (2016) and M.Eng. (2019) degrees
in mechanical engineering at SJTU. His research interests
include the application of volumetric emission tomography,
background-oriented schlieren tomography, and plenoptic
imaging to combustion phenomena. He is an author or co-
author on more than 20 publications in journals such as the
Journal of Fluid Mechanics, Optics Express, Optics Letters,
and Applied Physics Letters.

Weiwei Cai, Shanghai Jiao Tong University (SJTU). Weiwei
Cai is a professor in the Ministry of Educations Key Labora-
tory for Power Machinery and Engineering at SJTU. Dr. Cai
obtained a B.Eng. (2007) at Zhejiang University and a Ph.D.
(2010) in mechanical engineering at Clemson University. He
then moved to Virginia Tech as a postdoctoral fellow. Before
joining SJTU as a faculty member, Dr. Cai was a Marie Curie
Fellow in the Department of Chemical Engineering and
Biotechnology at the University of Cambridge from 2013
to 2015. His main research interests include absorption
tomography, emission tomography, miniaturized spectral
imaging, and engine diagnostics. He has published more
than 100 peer-reviewed papers in journals such as Science,
Progress in Energy and Combustion Science, the Journal of
Fluid Mechanics, and Combustion and Flame. He is cur-
rently a guest professor at Friedrich-Alexander-Universität
Erlangen-Nürnberg.

[577] Cenker E, Bruneaux G, Dreier T, Schulz C. Sensitivity analysis for soot particle
size imaging with laser-induced incandescence at high pressure. Appl Phys B
2015;119:745–63.

[578] Cao X, Yue T, Lin X, Lin S, Yuan X, Dai Q, Carin L, Brady DJ. Computational
snapshot multispectral cameras: Toward dynamic capture of the spectral world.
IEEE Signal Process Mag 2016;22:95–108.

[579] Han W, Wang Q, Cai W. Computed tomography imaging spectrometry based

on superiorization and guided image filtering. Opt Lett 2021;46:2208–11.

[580] Yang Z, Albrow-Owen T, Cai W, Hasan T. Miniaturization of optical

spectrometers. Science 2021;371.

[581] Monakhova K, Yanny K, Aggarwal N, Waller L. Spectral DiffuserCam: Lens-
filter array. Optica

imaging with a spectral

snapshot hyperspectral

less
2020;7:1298–307.

Samuel J. Grauer, Pennsylvania State University (PSU).
Samuel Grauer is an assistant professor in the Department
of Mechanical Engineering and a Faculty Fellow at the
Institute for Computational and Data Sciences at PSU. Dr.
Grauer completed a B.Sc. (2014) in mechanical engineering
at the University of Manitoba and a Ph.D. (2018) at the
University of Waterloo. From 2018 to 2020, he was a
postdoctoral fellow in the Ben T. Zinn Combustion Labo-
ratory at the Georgia Institute of Technology. Dr. Grauer’s
research is focused on the application of inverse analysis
to optical diagnostics with an emphasis on Bayesian data
assimilation, scientific machine learning, and uncertainty
quantification. He has conducted work on hyperspectral
laser absorption tomography, background-oriented schlieren
tomography,
laser-induced incandescence, and terahertz
time-domain spectroscopy, among other topics.

Khadijeh Mohri, University of Duisburg-Essen (UDE).
Khadijeh Mohri is a junior professor in the Institute for
Combustion and Gas Dynamics (IVG) under the Chair of
Fluid Dynamics at UDE. Prof. Dr. Mohri obtained an M.Eng.
(Hons) (2004) in aerospace engineering at Queen Mary
University of London. She completed her Ph.D. (2008)
in the same field at Imperial College London, where she
investigated supersonic flow over annular cavities using
computational and experimental methods. She has received
awards from the International Shock Wave Institute, Royal
Aeronautical Society, Drapers Company, King Memorial, and
the Institute for Mechanical Engineers. Her work as a post-
doctoral researcher at UDE was focused on laser diagnostics
and flame tomography. In 2016, Prof. Dr. Mohri received
funding from the Ministerium für Innovation, Wissenschaft

72

1. 概述 (Overview)
1.1. 项目背景
为了高效地构建一个对流体力学领域开发至关重要的基准测试题库 (benchmark)，本项目旨在专注于挖掘和沉淀当前先进模型（如 Qwen-8B）无法正确解答的难题。通过自动化流程，系统将持续生成高质量的流体力学相关问题，利用目标模型进行解答，并筛选出其“知识盲区”或“推理短板”，从而形成一个高价值、有针对性的评测数据集和验证数据集。

1.2. 项目目标

自动化 (Automation): 实现从出题、解题、判题到入库的全流程自动化。

高质量 (High-Quality): 利用强大的出题模型（如 Gemini 2.5 Pro）和动态的 Few-shot 策略，确保题目的挑战性与多样性。

双重资产积累 (Dual Asset Accumulation): 不仅构建包含模型“错题”的核心Benchmark，也同时创建一个“已验证”题库，收录被目标模型正确解答的题目，作为未来模型能力回归测试的验证集。

可扩展 (Extensible): 系统设计应支持未来接入不同的解题模型和判题模型。

易于监控 (Monitorable): 提供一个简洁的界面来追踪成本和进度。

2. 目标用户与使用场景 (Target Users & Scenarios)
AI 研究员与模型开发者:

核心用户: 专注于提升大语言模型（特别是像 Qwen-8B 这样的模型）在流体力学等科学领域能力的开发者。

主要场景:

精准评估: 使用本系统生成的、已被证实对目标模型有挑战性的 benchmark，来精准定位模型的知识盲区和推理短板。

迭代开发: 将题库作为回归测试集，在模型经过微调或架构更新后，检验其是否在特定弱点上有所改进。

竞品分析: 利用此专业题库，横向对比不同模型在解决复杂流体力学问题上的能力差异。

高等教育工作者 (物理/工程领域):

核心用户: 教授大学高年级或研究生课程的教师。

主要场景:

前沿教学: 将题库中“AI也答错的题目”作为高级研讨课的素材，激发学生对复杂问题进行深度思考，探讨当前人工智能的认知边界。

3. 系统架构与流程 (System Architecture & Flow)
系统由四大模块组成，并引入了Few-shot机制以提升出题质量。

工作流程图:

graph TD
    subgraph "循环主体"
        A[从Benchmark错题库随机抽取N个Few-shot样本] --> B{1. 题目生成模块};
        B -- "动态Prompt (含Few-shots)" --> C(Google Gemini 2.5 Pro / DeepSeek);
        C -- "生成题目和标答 (JSON)" --> D[数据对象: QuestionUnit];
        D --> E{2. 模型解题模块};
        E -- "题目文本 (放入任务队列)" --> F(本地 LM Studio 服务);
        F -- "返回答案文本" --> G[更新数据对象: 增加 candidate_answer];
        G --> H{3. 自动判题模块};
        H -- "题目/标答/候选答案" --> I(Google Gemini 2.5 Flash);
        I -- "返回判题结果 (JSON)" --> J[数据对象: GradingResult];
        J --> K<4. 数据持久化决策>;
        K -- "结果错误" --> L[写入Benchmark错题库];
        K -- "结果正确" --> N[写入Validation验证集];
    end
    L -- "更新错题库" --> A;
    N --> O[流程结束/下一批];
    L --> O;
    Start[开始] --> A;

4. 验收指标 (Acceptance Criteria)
功能性:

系统能完整地执行一次从题目生成到数据入库的端到端流程。

能够成功调用所有配置的API（Google/DeepSeek, LM Studio）。

系统能正确地将评判为错误的题目及其元数据存入指定的 benchmark_bank.jsonl 文件中。

系统能正确地将评判为正确的题目及其元数据存入指定的 validation_set.jsonl 文件中。

配置与管理:

所有API密钥通过.env文件加载，代码中无敏感信息。

能够通过config.yaml文件调整并发数和Few-shot数量。

用户界面:

仪表盘能实时（或准实时）显示累计API成本和两个题库的题目数量。
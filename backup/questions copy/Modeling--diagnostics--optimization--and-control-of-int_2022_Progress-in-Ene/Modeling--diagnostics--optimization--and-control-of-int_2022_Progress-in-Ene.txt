Contents lists available at ScienceDirect 

Progress in Energy and Combustion Science 

journal homepage: www.elsevier.com/locate/pecs 

Modeling, diagnostics, optimization, and control of internal combustion 
engines via modern machine learning techniques: A review and 
future directions 

Masoud Aliramezani , Charles Robert Koch , Mahdi Shahbakhti * 

Mechanical Engineering Department, University of Alberta, Edmonton, Canada T6G 1H9   

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Internal combustion engines 
Combustion control 
Optimization 
Artificial intelligence 
Machine learning 
Emissions 
Energy 

1. Introduction 

1.1. Scope of the paper 

A critical review of the existing Internal Combustion Engine (ICE) modeling, optimization, diagnosis, and control 
challenges and the promising state-of-the-art Machine Learning (ML) solutions for them is provided in this paper. 
Some  of  the  major  challenges  include  Real  Driving  Emission  (RDE)  modeling  and  control,  combustion  knock 
detection  and  control,  combustion  mode  transition  in  multi-mode  engines,  combustion  noise  modeling  and 
control, combustion instability and cyclic variability control, costly and time-consuming engine calibration, and 
fault diagnostics of some ICE components. In this paper, conventional ICE modeling approaches are discussed 
along with their limitations for realtime ICE optimization and control. Promising ML approaches to address ICE 
challenges are then classified into three main groups of unsupervised learning, supervised learning, and rein-
forcement learning. The working principles of each approach along with their advantages and disadvantages in 
addressing ICE challenges are discussed. ML-based grey-box approach is proposed as a solution that combines the 
benefits from physics-based and ML-based models to provide robust and high fidelity solutions for ICE modeling 
and control challenges. This review provides in-depth insight into the applications of ML for ICEs and provides 
recommendations for future directions to address ICE challenges.   

Analysis  of  state-of-the-art  machine  learning  (ML)  techniques  to 
address the existing challenges in ICE performance, optimization, and 
controlis the focus of this paper. To this end, the paper includes review 
of models that can be used for real-time engine control and optimization. 
Thus, detailed Computational Fluid Dynamics (CFD) models or the ML 
methods for engine design is outside the scope of this paper. The focus of 
the paper will be mainly on review of ML methods for realtime perfor-
mance optimization, onboard combustion diagnosis, and control of ICEs 
via data-driven and grey-box ML approaches. 

ML  is  a  promising  approach  that  is  rapidly  expanding  to  solve 
different  types  of  problems  including  information  technology  [1], 
medicine  [2],  engineering  [3,4]  and  many  other  applications  [5–9]. 
Employing machine learning provides significant capability of modeling 
complex  systems  with  nonlinear  inputs-output  relations,  particularly 
when the number of inputs, outputs or decision scenarios are high [10]. 

Similar to all other data-driven approaches, the models that are devel-
oped using machine learning do not involve physical understanding of 
the system [11,12] but most of them are still able to predict physical 
phenomena if accurately trained and if sufficient training data is avail-
able [13,14]. 

Building upon our previous studies [15–42] on ML applications for 
ICE  modeling,  control  and  optimization,  a  comprehensive  review  is 
carried out in this paper. 

1.2. Why using machine learning for internal combustion engines? 

The first and the second waves of artificial intelligence (AI) started in 
1970s and 2000s respectively, but we are now amid the third and the 
largest wave of AI [43]. This is partially due to the recent progress in ML 
techniques,  computing  power,  and  the  availability  of  extremely  large 
sets of information. 

Internal combustion engines (ICEs) play an essential role in power 
generation and transportation industries [44]. Therefore modeling and 
subsequent optimal control of ICEs to improve engine performance and 
efficiency  and  to  reduce  harmful  emissions  is  critical  for  the 

* Corresponding author. 

E-mail address: mahdi@ualberta.ca (M. Shahbakhti).  

https://doi.org/10.1016/j.pecs.2021.100967 
Received 12 October 2020; Received in revised form 21 September 2021; Accepted 2 October 2021   

ProgressinEnergyandCombustionScience88(2022)100967Availableonline23October20210360-1285/©2021ElsevierLtd.Allrightsreserved.M. Aliramezani et al.                                                                                                                                                                                                                          

Nomenclature 

Artificial Bee Colony 
Artificial Intelligence 
Action Evaluation Network 
Artificial Neural Network 
auto-regressive exogenous 
Action Selection Network 
Burn Duration 
Back Propagation Algorithm 
Brake Specific Fuel Consumption 
Butanol Volume Percentage 
Crank angle position where 50% of the fuel is burnt 
Computational Fluid Dynamics 
Compression Ignition 
Combustion Noise Level 
Carbon Monoxide 
Control Oriented Model 
Coefficient of Variation 
Connected Vehicles 
Direct Injection 
Distributed Kernel Regression 
Data Management Center 
Data Mining 
Distributed Meta-Regression 
Design of Experiment 
Engine Control Unit 
Exhaust Gas Recirculation 
Extreme Learning Machine 
Expectation Maximization 
Feedback Neural Networks 
Fuzzy C-Means 
Feedforward Neural Network 
Field-Programmable Gate Array 
Fuel Quantity 
Genetic Algorithm 
Grey-box 
Gaussian Mixture Models 
Gaussian Processes 
Homogeneous Charge Compression Ignition 
Hybrid Electric Vehicle 
Hilbert-Huang Transform 
Independent Components Analysis 
Internal Combustion Engine 
Iterative Learning Control 
Indicated Mean Effective Pressure 
Input-Output 

ABC 
AI 
AEN 
ANN 
ARX 
ASN 
BD 
BPA 
BSFC 
BVP 
CA50 
CFD 
CI 
CNL 
CO 
COM 
COV 
CV 
DI 
DKR 
DMC 
DM 
DMR 
DOE 
ECU 
EGR 
ELM 
EM 
FBNN 
FCM 
FFNN 
FPGA 
FQ 
GA 
GB 
GMM 
GP 
HCCI 
HEV 
HHT 
ICA 
ICE 
ILC 
IMEP 
IO 
K-ELM  Kernel-based Extreme Learning Machine 
Linear Discriminant Analysis 
LDA 
Locally Linear Embedding 
LLE 
LM 
Levenberg-Marquardt 
LOLIMO  Local Linear Model 

Machine Learning 
Multilayer Perceptron 
Model Order Reduction 
Model Predictive Control 

Premix Ratio 
Pressure Rise Rate 
Principal Component Analysis 
Particulate Matter 
Radial Basis 
Radial Basis Function 

Linear Parameter Varying 
Low Temperature Combustion 
Least-Squares Support Vector Machine 
Long Short Term Memory 
Learning Vector Quantization 

LPV 
LTC 
LSSVM 
LSTM 
LVQ 
MIMO  Multi Input Multi Output 
ML 
MLP 
MOR 
MPC 
MSAP  Multiple Step Ahead Prediction 
Mean Squared Error 
MSE 
NOx 
Nitrogen Oxides 
Non dominated Sorting Genetic Algorithm 
NSGA 
ODL 
Online Deep Learning 
OS-ELM  Online Sequential Extreme Learning Machine 
PR 
PRR 
PCA 
PM 
RB 
RBF 
RBFNN  Radial Basis Function Neural Network 
RCCI 
RDE 
RI 
RKHS 
RL 
RMSE 
RNN 
RVM 
SAE 
SAM 
SB-ELM  Sparse Bayesian Extreme Learning Machine 
SG-ELM  Stochastic Gradient-based Extreme Learning Machine 
SI 
SID 
SLFN 
SML 
SOC 
SOI 
SOM 
STD 
SVM 
SYID 
THC 
TKM 
TS 
UHC 
UGM 
UML 
V2I 

Spark Ignition 
System Identification 
Single hidden Layer Feedforward Neural Network 
Supervised Machine Learning 
Start of Combustion 
Start of Injection 
Self Organising Map 
Standard Deviation 
Support Vector Machine 
system identification 
Total unburned Hydrocarbons 
Thermokinetics-based model 
Takagi-Sugeno 
Unburned Hydrocarbons 
Unsupervised Gaussian Mixture Model 
Unsupervised Machine Learning 
Vehicle to Infrastructure  

Reactivity controlled compression ignition 
Real Driving Emissions 
Ringing Intensity 
Reproducing Kernel Hilbert Space 
Reinforcement Learning 
Root Mean Squared Error 
Recurrent Neural Network 
Relevance Vector Machine 
Sparse Auto Encoder 
Stochastic Action Modifier 

environment and air quality. ML has also shown promising results for a 
wide  range  of  ICE  applications  including  engine  modeling  [11,12,45, 
46], control [15,16,47,48], and optimization [13,49–51]. 

The highly nonlinear and complex phenomena that take place inside 
an ICE, has made it difficult to predict, control, and optimize them using 
either  conventional  physics-based  or  data-driven  approaches.  These 
phenomena  include:  turbulent  air  and  fuel  flow  mixing  inside  the 
combustion  chamber;  large  number  of  thermo-kinetic  nonlinear  re-
actions that take place in steady state and transient ICE operations; in- 
cylinder  temperature  and  pressure  gradients;  complex  fluid-surface 

interactions;  multi-phase  fluid  interactions;  formation  of  particulate 
matters and gaseous emission; and in-cylinder residual gases from pre-
vious cycles. In addition, ICEs typically have a large range of operating 
conditions  and  controlling  stochastic  cyclic  variability  in  some  ICE 
combustion modes such as homogeneous charge compression ignition 
(HCCI) or reactivity controlled compression ignition (RCCI) is an exist-
ing challenge that has not been completely addressed by conventional 
ICE control approaches. ML can be used to address many of these ICE 
control challenges. One way this can occur is by providing highly ac-
curate  models  that  can  be  utilized  by  conventional  model-based  ICE 

ProgressinEnergyandCombustionScience88(2022)1009672M. Aliramezani et al.                                                                                                                                                                                                                          

control  strategies.  Another  way  is  through  a  wide  range  of  ML-based 
control  strategies  including  reinforcement  learning,  and  deep  model 
predictive control with online learning. The most promising ML-based 
ICE control strategies will be discussed extensively in this paper. 

ML techniques offer powerful solutions to help address the existing 
challenges in ICE modeling, control, and optimization. To significantly 
reducing the time, cost, and effort required for ICE calibration for both 
vehicular and stationary applications ML can be employed. In addition, 
ML  can  be  used  to  develop  augmented  ICE  control  (e.g.  optimal, 

adaptive) methods [52] and can help improving the performance of the 
available  physics-based  models  through  grey-box  (also  called  hybrid) 
modeling approaches [53]. 

Finally,  utilizing  ML  along  with  cloud  computing  and  vehicle  to 
infrastructure  (V2I)  communications  leads  to  further  performance 
improve of ICEs [54]. For example, ML helps developing efficient, ac-
curate,  and  realtime  peer-to-peer  learning  techniques  to  monitor  the 
performance,  collect/process  data,  and  learn  from  a  large  number  of 
similar ICEs connected to a network [54]. This can be used to develop 

Fig. 1. Promising machine learning approaches for internal combustion engines [62, 67].  

ProgressinEnergyandCombustionScience88(2022)1009673M. Aliramezani et al.                                                                                                                                                                                                                          

highly  accurate  and  adaptive  ICE  models,  as  well  as  new  ICE  fault 
detection methods due to the availability of large sizes of training data. 
All of these advantages are explained in this review paper. 

(typically Sigmoid function) to form the desired output. The weighed 
sum of the ANN inputs is the activation function which is schematically 
shown in Fig. 2 and Eqn (1). 

2. State-of-the-art machine learning methods for ICEs 

Before the details of ML applications in ICE are given in Section 3 a 
review of machine learning methods used for ICEs is provided in this 
section.  The  working  principles  along  with  advantages  and  disadvan-
tages of ML methods for ICEs are discussed in this section. 

To  provide  a  better  insight  into  the  most  common  ML  techniques 
used for ICEs, the ML techniques are typically divided into three groups: 
supervised learning, unsupervised learning, and reinforcement learning. 
Promising ML methods for ICE combustion modeling, optimization, and 
control are schematically shown in Fig. 1. In total, 16 ML methods are 
noted in Fig. 1 and they are briefly discussed below in Section 2. 

2.1. Supervised machine learning (SML) 

Supervised  learning  is  the  most  commonly  used  machine  learning 
approach which is designed to learn the input-output relations through 
training. Through the training process, the system inputs are paired with 
the corresponding outputs and the ML algorithm will learn input-output 
patterns  from  the  training  data.  After  training,  a  supervised  learning 
algorithm can predict the corresponding output or class for given unseen 
inputs.  The  main  objective  of  a  supervised  learning  algorithm  is  to 
predict the correct output associated with the unseen given inputs. Su-
pervised learning can be used for regression [76] or classification [77]. 
Different supervised ML approaches have been developed and used for 
ICEs. The most common methods are Artificial Neural Networks (ANN) 
[11,32,46,64,78–81],  Support  Vector  Machines  (SVM)  [57,82,83], 
Extreme  Learning  Machines  (ELM)  [12,51,84–86],  Relevance  Vector 
Machines  (RVM)  [87–90],  and  Gaussian  Processes  (GP)  [60].  Some 
studies  have  used  combinations  of  these  approaches  [58,91,92]  and 
other  methodologies  [84,91,93].  These  commonly  used  supervised 
learning algorithms for ICEs are discussed next. 

2.1.1. Artificial neural network (ANN) 

ANN was originally introduced in the early 1940s [94]. However, it 
took a few decades for ANNs to become practically applicable to solve 
engineering  problems  from  high  precision  input-output  black-box 
models  to  robust  classifiers  and  pattern  recognition  systems  [95,96]. 
Although ANN is used for both supervised and unsupervised learning 
applications  [97],  their  application  for  supervised  ML  is  much  more 
common for ICEs. 

ANN  has  been  used  extensively  for  modeling  and  control  of  ICEs 
[98–109]. These applications include: i) predicting engine performance 
metrics (e.g., IMEP, net indicated thermal efficiency) and emissions (e. 
g.,  NOx,  HC,  CO),  ii)  engine  diagnostics  (e.g.,  misfire  detection),  iii) 
engine  performance optimization, and iv) engine  control. The studies 
[24,25,64,110,111] are examples of ANN models used for compression 
ignition engine control applications. 

Since ANN does not need physical understanding of the system, they 
operate as a “black-box” model. The ANN model learns the input-output 
relationship from a given set of training data, performing a non-linear 
regression.  ANN  is  made  of  many  calculating  nodes  (called  neurons) 
that are connected to each other to simulate complex nonlinear system 
behaviour. Neural networks include input and output layers, as well as 
hidden neighboring layers that are interconnected by different weights. 
Hidden and output layers are made from nonlinear functions [112]. The 
hidden layer processes the information coming from the input layer, and 
then  its  neurons  create  required  combinations  to  reproduce  the  rela-
tionship between the input and output spaces. Then, the output layer 
neurons create the network output to predict the desired variables. 

In an ANN, the input signals are multiplied by the adjustable weights 
and  combined  (summed)  and  then  go  through  a  transfer  function 

(

∑N

)

xiWi

i=1

yj = f

(1) 

Many  different  types  of  ANNs  are  developed  and  used  with  some 
being  more  popular  such  as  multilayer  perceptron  (MLP)  (typically 
trained with the back-propagation of error algorithm) [113], learning 
vector  quantization  (LVQ)  [114],  radial  basis  function  (RBF)  [115], 
Hopfield and Kohonen [116], and others. Some ANN are classified as 
feedforward  [117]  while  others  implement  internal  feedback  [118] 
depending on the data process flow through the network and involving 
system dynamics. 

2.1.2. Extreme learning machine (ELM) 

Extreme  learning  machine  is  a  powerful  and  promising  regression 
and  classification  approach  with  an  extremely  fast  training  speed 
compared  to  conventional  ANN  methods  [119,120].  ELM  is  a 
single-hidden  layer  feedforward  neural  network  (SLFN).  The  hidden 
layer  parameters  of  ELM  are  randomly  initialized  [86].  Unlike  the 
traditional ANNs, ELM analytically calculates the output weights by an 
inversion method called Mooree-Penrose [86]. 

Huang et al. [121] proved that the hidden layer biases and the input 
weights of SLFNs can be selected randomly and then they can be kept 
fixed for the rest of the learning process. The output weights of ELM need 
to  be  determined  through  the  training  process.  Assuming  that  the 
number of hidden  nodes is  equal to N,  the predicted output becomes 
[121]: 

f(x) =

∑N

i=1

βihi(x) =

∑N

i=1

βiA(ai, bi, x) = h(x)β

(2)  

where A is the hidden nodes activation function, bi  is the bias, and ai  is 
the  vector  of  input  weights.  The  input  vector,  x,  is  converted  to  the 
output,  f(x),  through  the  hidden  layer  vector  h(x) = [h1(x), h2(x), … ,
hN(x)]. The hidden layer to output layer weights are included in vector 
β = [β1

(x), … , βN

(x), β2

(x)]T. 

ELM is an efficient learning, regression and classification approach in 
terms of training speed, training accuracy, and generalization capability 
compared  to  other  techniques  [13,122–125].  This  makes  ELM  a 
powerful  method  for  online  learning  for  ICE  input  optimization  and 
calibration [86]. More examples about promising applications of ELM 
for ICEs are provided in Sections 3.2.4 and 3.2.2. 

The input layer parameters of ELM are randomly assigned, therefore, 
unlike the conventional ANN methods, ELM does not require adaptation 
to new data [56,126]. Further, the output layer weights of an ELM are 
analytically calculated using a linear least squares approach as opposed 
to the traditional ANNs that iteratively learn the output weights through 
a  more  time  consuming  process  [127–129].  The  other  advantage  of 
using ELM is its high capability of approximating the global optimum 
without getting trapped in local minima. This is due to its closed form 
solution  that  eliminates  iterative  training  and  also  results  in  higher 
generalization capability [130]. 

2.1.3. Support vector machine (SVM) 

Support Vector Machines (SVM) is a powerful supervised machine 
learning  approach  which  was  introduced  by  Vapnik  et  al.  [131,132]. 
SVM  is  capable  of  generating  highly  accurate  predictions  based  on  a 
relatively  small  training  data  set  and  is  able  to  model  complex  and 
non-linear relations [133,134]. SVM is based  on extension  of line (or 
surface) identification for separating two classes of objects and can be 
extended  to  solve  prediction  problems.  SVM regression  (SVR) is  typi-
cally used to find a correlation between labeled output and the input 
data. For a given training data of inputs ui  and outputs zi, SVR predicts 

ProgressinEnergyandCombustionScience88(2022)1009674M. Aliramezani et al.                                                                                                                                                                                                                          

Fig. 2. Model of an artificial neuron in a feedforward network.  

the output function, y(ui), with maximum error of |ϵ| to be as smooth as 
possible and equal to: 

y(ui) = wT ui + b

(3)  

where w and b are found by solving the corresponding SVR algorithm 
[135]. The smoothness of approximated function is achieved by mini-
mising the second norm of w. 

For a kernel- based SVM Eqn (3) is changed to: 

y =

∑n

i=1

wiK(ui, u) + b

(4)  

where, K(ui, u) is a kernel function and often Gaussian kernel is used for 
SVMs [136,137]. When used for classification, the distinguishing feature 
of the SVM method is that its output prediction function minimises the 
training error to maximise the ‘margin’ between the two classes simul-
taneously [138] which helps avoiding over-fitting and provides a good 
generalization capability. Therefore, SVM regression is an appropriate 
technique  that  can  be  used  for  modeling  complex  combustion  phe-
nomena  such  as  emission  formation  modelling,  ringing  intensity  and 
combustion  noise,  knock,  autoignition,  etc.  In  addition,  SVM  classifi-
cation can provide a powerful tool for complex engine component fault 
diagnostics strategies. 

Despite its many advantages, some disadvantages of SVM are:  

• The number of required support vectors increases as the size of the 

training data set grows.  

• An error/margin trade-off parameter (also called the regularization 
parameter)  is  required  for  SVM  classification  and  regression. 
Defining this regularization parameter requires addition effort to the 
model training and validation process. In addition, SVM regression 
requires the insensitivity parameter ϵ.  

• The Kernel function of SVM has to be a continuous symmetric kernel 
with a non-negative integral (Mercer’s condition) [139]. This limits 
the selection of SVM kernel functions.  

• Estimating  the  conditional  distribution  to  capture  the  prediction 
uncertainty is often useful. However, SVMs make point predictions 
rather than distribution (also called probabilistic) predictions [140]. 

A  more  detailed  discussion  of  SVM  capabilities  and  flaws  in 
addressing different ICE modeling and control challenges is provided in 
Section 3. 

Relevance  Vector  Machine  (RVM)was  formulated  [141].  RVM’s  pre-
diction capability is similar to the SVM, but it also provides a distribu-
tion prediction [138,142]. RVM has a similiar structure to SVM but uses 
Bayesian inference for probabilistic classification and regression [138]. 
The  RVM approach  does  not  have  any of  the  above  limitations  of 
SVM due to its Bayesian framework [138]. RVM benefits from a fully 
probabilistic structure that uses a set of hyperparameters1 for which the 
training  parameters  are  estimated  through  several  iterations.  Due  to 
their distribution (probabilistic) predictions, RVMs require much fewer 
kernel functions than SVMs [138]. 

For a given input-output data set {u, t}, the standard probabilistic 
formulation  is  used  for  predictions  assuming  that the  outputs  are  the 
model prediction with additional noise: 

t = y(u, w) + ϵ

(5)  

where, t, u, w are target, input, and the model “weights” respectively. 
Vector ϵ is the independent samples vector with noise. The process noise 
is assumed to be a zero-mean Gaussian distribution with variance σ2. 
RVMs are used to solve different types of classification and regression 
problems.  The  use  of  RVMs  for  ICEs  is  not  as  widespread  as  ANN  or 
conventional  SVM.  An  adaptive  time-dependent  air  fuel  equivalence 
ratio  (lambda)  model  was  developed  using  RVM  [87].  RVM  was 
designed in another study [88] for diesel engine performance prediction 
and  showed  that  the  RVM  model  accuracy  was  better  than  an  ANN 
approach. 

One disadvantage of RVMs compared to SVMs is that RVMs training 
method is based on an expectation maximization (EM) algorithm and 
consequently its tendency to converge to local minima is relatively high 
compared to SVMs [143]. 

However,  due  to  their  high  capability  of  distribution  predictions, 
RVMs are an ideal choice for ICE data classification, particularly when 
the boundary between classes are narrow [144]. This feature of RVMs 
has been recognized by the ICE researchers for fault diagnostics [89,90, 
145]  and  for  other  applications  such  as  fault  diagnostics  of  hybrid 
electric vehicle components [146] and advanced multi-class classifica-
tion [147]. 

2.1.5. Gaussian processes (GP) 

The Gaussian process is an effective method for Bayesian non-linear 
nonparametric classification and regression [148]. The computational 

2.1.4. Relevance vector machine (RVM) 

In  2000,  a  probabilistic  model  similar  to  the  SVM,  called  the 

1  A hyperparameter is a parameter tuned before the training to improve the 
learning  performance  as  opposed  to  the  other  model  parameters  that  are 
defined through the training process. 

ProgressinEnergyandCombustionScience88(2022)1009675M. Aliramezani et al.                                                                                                                                                                                                                          

cost of GP increases by O (n3) and its storage requirement increases by 
O (n2) (where n is the number of points being interpolated). This leads to 
high computational costs for extremely large data sets [148,149]. A brief 
background of GPs is provided here, but more detailed information can 
be found in  [150–153]. 

n=1 

Consider a system with N input vectors U = {un}N

n=1  of dimension D 
(un ∈ RD) and the corresponding actual system outputs (targets) of T =
{tn}N
(tn ∈ RD). A Gaussian distribution with zero-mean is defined as 
the function to predict f(u) that relates the model input u to the output. 
This results in a multivariate Gaussian function of given variables. For 
instance, by considering N (f|m, V) as a Gaussian function with covari-
ance V and average value of m, the covariance matrix is formed based on 
a  kernel  function,  KN(un, un
′ ).  In  addition,  a  regularization  hyper-
parameter (θ) controls the smoothness of the prediction. 

For a standard GP regression it is also assumed that the noise model 
⃒
⃒
f,σ2I)). The marginal likelihood 

has Gaussian distribution (p(t|f) = N (t
is calculated by integrating the latent function: 

p(t|U, θ) = N

(cid:0)

t

⃒
⃒0, KN + σ2I

)

(6) 

To  train  the  GP,  Eqn  (6)  is  used  to  find  the  maximum  value  for 
predefined values of θ and σ2 (Covariance matrix). One problem of GPs is 
that they do not offer a consistent method to learn hyperparameters of 
the  kernel  function  [148]. GPs  have  been  used for  engine  calibration 
[59], modeling [60,61], and design optimization [154], but are infre-
quently used for ICE applications compared to the other ML methods 
discussed in this paper since GPs are not suitable for large data sets. GP is 
also an effective classification/regression tool for combustion processes 
that  exhibit  Gaussian  distributions.  For  instance,  GP  was  used  in  our 
previous work [155] for classifying the regions of combustion phasing 
(CA50) cyclic variability. 

2.1.6. Distributed meta-regression - reproducing kernel Hilbert space 
(RKHS) 

Meta-learning  is  defined  as  a  process  through  which  the  learner, 
learns “how to learn” i.e. selecting the best methods or the best learning 
parameters  [156].  Meta-learning  has  been  defined  by  various  re-
searchers  based  on  its  applications  [157–160].  A  meta-learning  algo-
rithm (also known as meta-learner) uses accumulated sets of data and 
information to change certain parts of a learning algorithm (also known 
as  base-learner),  to  enhance  the  learning  performance  of  the  original 
learner  [158].  For  instance,  assume  that  you  are  planning  to  learn  a 
complex ICE combustion phenomena (e.g., SI to HCCI mode transition), 
but  there  is  not  enough  information  regarding  the  most  appropriate 
machine  learning  algorithm,  or  you  are  not  sure  what  the  optimal 
hyperparameters  of  the  learning  algorithm  are.  Meta-learning  is  the 
process of finding these unknowns to develop the most accurate learning 
algorithm to simulate complex combustion phenomena. 

In  our  recent  study  [33],  a  Connected  Vehicle  (CV)  based  Data 
Mining (DM) framework is proposed to develop an adaptive dynamic 
ICE fuel consumption modeling through online machine learning and 
knowledge sharing over CVs and a CV remote data center. The proposed 
RKHS-based algorithm efficiently represents system nonlinearities and is 
scalable to include a large number of impact factors such as fuel quality, 
intake air humidity, ambient pressure and temperature that affect ICE 
combustion. 

An RKHS is a special Hilbert space which uses a kernel function that 
reproduces each function via inner product in a bounded point evalua-
tion space. Considering H  as a Hilbert space of real-valued functions 
from a desired set (E), that has a bivariate function (K (x,y)) on space E 
×E and inner product 〈.,.〉, the function K (x, y) is called a non-negative 
definite function if, for any given finite point set {x1, x2, …, xn}⫅E and 
for  any  given  not-all-zero  corresponding  real  numbers  {α1, α2, …,
αn}⫅R, the predicted target (y) is [161]: 

y =

∑n

∑n

i=1

j=1

(

)

αiαjK

xi, yj

≥ 0

(7) 

Then, a non-negative definite K  is called a reproducing kernel. One 
of the most important features of non-negative symmetric definite ker-
nels is that for any non-negative symmetric definite kernel, there is a 
reproducing kernel Hilbert space that can be created based on it [161]. 

2.1.7. Other ML methods and combined algorithms 

The most important ML approaches that have promising character-
istics  to  address  ICE  challenges  were  discussed  above  in  Section  2.1. 
However,  there  are  some  other  ML  algorithms  that  are  also  used  for 
modeling,  optimization,  and  control  of  internal  combustion  engines. 
Most of which can be combined with the ML techniques that are already 
discussed [92] in Section 2.1. For example, some studies have used ge-
netic algorithm (GA) [162], or Artificial Bees Colony (ABC) Algorithm 
[93] as an optimization algorithm to optimize the engine performance 
and  to  reduce  the  engine-out  emissions.  These  methods  are  basically 
different  optimization  algorithms  that  can  be  combined  with  main 
state-of-the-art ML techniques. Some of these combined methods have 
been used to predict the emissions and performance of CI engines fueled 
with  conventional  fuels  and  biodiesel   [50,58,84,91,93].  Augmented 
ELM algorithms such as Weighted Ring-ELM have also shown promising 
performance even in near chaotic ICE operating conditions [84] and is a 
promising future direction. 

2.2. Unsupervised machine learning (UML) 

2.2.1. UML vs SML 

Unlike  supervised  learning  techniques,  unsupervised  learning 
methods do not use the output data for given inputs (also called labeled 
data) to train themselves, but they are designed to recognise the desired 
patterns  from  the  available  set  of  information  [163].  Unsupervised 
learning  is  basically  the  process  of  classifying  data  points  that  have 
similar “properties” to find a pattern [164], to detect anomaly [165], or 
to facilitate further processing of the data [166]. 

Clustering the raw data is particularly useful for big-data exploratory 
pattern-analysis  and  decision-making  scenarios.  This  includes  knowl-
edge  discovery  and  data  mining  [167],  vector  quantization  and  data 
compression  [168],  pattern  recognition  [164],  and  data  classification 
[169]. 

An  example  of  an  unsupervised  ML  for  ICE  data  classification  is 

schematically shown in Fig. 3. 

The process depicted in Fig. 3 is based on the work by Pacella [170] 
that proposed an approach for modeling of multi-channel profile data in 
high-dimensional  spaces  based  on  unsupervised  classification.  This 
approach  also  suggests  principal  component  analysis  (PCA)  as  an 
effective method to reduce the order of the problem before carrying out 
the clustering process.This is done using the multi-channel profile data 
provided by different sensors related to a fault event in a NOx  storage 
catalyst (NSC). Then, the detected fault events are isolated for restricted 
number of scenarios that represent a reference pattern. In the approach 
shown in Fig. 3, all the data is collected from the available sensors under 
normal  and  faulty  operation.  Then  a  Principle  Component  Analysis 
(PCA)  based  feature  reduction  approach  is  used  to  define  the  most 
effective features. Using these features, a reduced order model is then 
utilized for pattern clustering, root-cause analysis and finally for system 
improvement. 

2.2.2. Promising UML techniques for ICEs 

The  k-means  technique  is  a  simple  classic  unsupervised  clustering 
method that is commonly used for many clustering applications due to 
its simple structure. The k-means method requires low computational 
effort and has a straightforward working principle which makes it easy 
to implement. The main input parameter of a k-means algorithm is the 

ProgressinEnergyandCombustionScience88(2022)1009676M. Aliramezani et al.                                                                                                                                                                                                                          

Fig. 3. Schematic illustration of an unsupervised ML example for ICE/vehicle data classification. Reprinted from [170] with permission of Elsevier.  

number  of  clusters  (k)  that  the  data  points  should  be  classified  into 
where the mean values of the clusters are learned iteratively until the 
desired number of groups is achieved [171]. Despite the advantages of 
the  k-means  clustering algorithm,  it is  not always  easy to  predict the 
appropriate number of clusters. In addition, k-means is very sensitive to 
the order and the scale of the training data points. 

Fuzzy  C-Means  (FCM)  is  another  commonly  used  unsupervised 
clustering techniques which unlike k-means can assign one data point to 
more than one cluster using a so-called a “Membership Function” [172] 
which reflects the fuzzy structure of this method. The number of clusters 
(c), the fuzziness exponent, and the termination tolerance are the main 
parameters of FCM that need to be defined before using the algorithm. 
Both k-means and FCM are extensively used for different ICE applica-
tions due to their simple structure and acceptable performance. How-
ever,  they  are  not  suitable  for  clustering  the  data  points  for  complex 
phenomena with high levels of non-linearity. 

Unsupervised  Gaussian  Mixture  (UGM),  also  known  as  Gaussian 
Mixture Model (GMM) is another commonly used unsupervised machine 
learning technique that has shown promising performance for ICEs. A 
Gaussian distribution is allocated to each cluster and the UGM classifies 
the data points that belong to each distribution into the corresponding 
groups which results in soft clustering of the data points. This makes 
UGMs  more  suitable  for  unsupervised  ICE  applications  that  involve 
classes with less distinguishable boundaries such as unsupervised engine 
combustion  diagnostics  using  engine  noise  measurements  [65].  For 
instance, Pontoppidan et al [65] have applied UGM to detect condition 
changes of a large diesel engine via unsupervised learning of the data 
provided by an acoustical emission measurements which resulted in a 
high classification accuracy. 

Although ANNs are mainly known for their supervised learning ca-
pabilities, they can also be utilized for unsupervised learning applica-
tions. The use of ANNs for unsupervised applications provides a more 
powerful classification tool compared with the other techniques listed 
above, but involves a more complex algorithm. ANNs cannot directly be 
used for unsupervised learning since they require labeled training data 
[173].  Instead,  ANNs  can  be  trained  to  map  the  raw  data  points  to 
meaningful  information  and  then  the  resulting  information  can  be 
classified  into  desired  clusters  based  on  their  similarity.  Different 
ANN-based algorithms are developed for clustering and one of the most 
commonly  used  type  of  them  is  Self  Organizing  Maps  (SOM).  The 
fundamental  difference  between  SOM  and  conventional  ANN  is  that 
unlike conventional ANNs that use error reduction cost functions, SOMs 
use  competitive  learning  approaches  to  define  the  most  important 
neurons associated with each input data. More information about the 
SOMs and  their working  principles can be found in [174,175]. These 
classification  methods  can  also  be  combined  and  used  for  ICE 

applications. For instance, SOM and k-means methods are combined in a 
study [71] to detect potential ICE faults of a heavy-duty diesel engine. 
Unsupervised machine learning algorithms such as k-means Clustering, 
SOMs,  and  Fuzzy  C-Means  to  improve  the  accuracy  of  marine  diesel 
engine fault detection by reducing the data size given to a fault detection 
algorithm via selecting sample points that represent a cluster of data is 
described in [66]. Similar to ANNs, SVMs can also be utilized for un-
supervised applications. Due to their powerful classification capabilities, 
SVMs are suitable for clusters with complex nonlinear boundaries. For 
example,  one-class  of  SVMs  have  shown  a  promising  performance  in 
unsupervised anomaly detection [176] and have been used in [177] for 
unsupervised detection of ICE production faults. However, the perfor-
mance of this approach in combustion fault diagnostics needs further 
study. 

2.3. Reinforcement learning (RL) 

2.3.1. RL potentials for ICE control 

Reinforcement learning (RL) is another important class of machine 
learning.  RL  is  about  learning  how  to  take  actions  and  reactions  to 
maximize  a  numerical  “reward”  signal  [178].  This  is  done  using  a 
platform, called “agent” or “learner” that explores, interacts with, and 
learns from the environment. The total reward that an agent can receive 
from a series of actions is typically called “the value” [179]. Therefore, 
the main difference between RL and the other ML approaches such as 
supervised and unsupervised learning is that in RL trial and error also 
plays an important role in the learning process. In addition, unlike SML 
and  UML,  RL  aims  to  provide  decisions  or  actions  instead  of  pure 
modeling or classification. In RL the “agent” is not directly forced to take 
an action, but it is guided to discover the most rewarded actions based 
on a predefined criteria also called “the policy” [180] as schematically 
shown in Fig. 4. 

For instance, if we consider an ICE as the environment, the agent can 
be a software program that observes the engine speed, engine load, and 
engine-out emissions. The agent would receive all these observations and 
take an appropriate action based on the current policy. The environment 
(ICE) also generates a reward (e.g., emission level reduction) that can be 
used  to  update  the  policy  via  the  reinforcement  learning  algorithm. 
Then, the actions can be fuel injection timing, fuel injection amount and 
fuel rail pressure which are selected based the latest policy to maximize 
the rewards. 

One  way  of  classifying  RL  algorithms  is  based  on  the  reward-to- 
action  mapping  structure  which  includes  three  main  categories:  i) 
value function based [181], ii) policy gradient [182], and iii) actor-critic 
mapping  [183,184].  RL  algorithms  can  also  be  divided  into  con-
tinuous-action [185] or discrete-action groups [186]. RL methods can 

ProgressinEnergyandCombustionScience88(2022)1009677M. Aliramezani et al.                                                                                                                                                                                                                          

Fig. 4. Agent-environment interaction in reinforcement learning.  

also be classified based on whether the acting policy is model-free [187], 
or  model-based [188]. To  provide insight into the  promising applica-
tions  of  RL  for  ICE,  RL  approaches  are  divided  into  two  groups  of 
model-based and model-free in this paper. The main difference between 
the model-based and model-free is that in a model-based RL algorithm, a 
trained  and  validated  model  is  developed  in  advance  based  on  the 
experimental system data and physical insights of the environment (ICE) 
working principles. In a model-free RL, there is no available model or 
detailed  understanding  from  the  system  and  the  algorithm  learns  by 
observing the effects of various actions on the environment. These two 
methods are described in more detail next. 

2.3.2. Model-based RL 

Similar  to  other  model-based  control  strategies,  model-based  RL 
takes advantage of a prepared model to make informed decisions and to 
take low-risk actions to achieve the desired outputs. The main advantage 
of using model-based RL is that it provides enough information about 
the environment to reduce the need for high-risk trial and errors. Due to 
having more information about the system in advance, model-based RLs 
are more sample efficient than model-free RL. This feature is extremely 
beneficial for ICEs since it reduces the risk of engine or after treatment 
component damage. Let’s assume an RL algorithm that has an accept-
ably accurate estimation of the engine knock or misfire limits and con-
siders this information in its injection control strategies. This reduces the 
risk of damaging the engine due to knock and also reduces the risk of 
damaging  the  engine  after  treatment  systems  due  to  engine  misfires 
while the RL algorithm is doing trial and errors to find and then take the 
best decision to maximize its value function. Model-based RLs can use 
any type of ICE models including physics-based and data-driven models 
as long as the model complexity, and the model accuracy is compatible 
with their structure. Model-based RL can utilize high fidelity ICE models 
and then be evaluated and improved on ICE test bench under controlled 
operating conditions before being tested under real driving or stationary 
applications. 

If we exclude the computational efforts required to train the model in 
a  model-based  RL  or  use  an  already  available  engine  model,  model- 
based RLs will require less computational efforts while they are being 
used.  This  is  because  model-based  RLs  require  less  trial  and  error 
compared to model-free RL. However, if we consider both training and 
utilizing  model-based  RL,  then  it  should  be  noted  that  developing 
model-based  RLs  require  higher  computational  efforts  and  higher 
memory compared with model-free RLs. In addition, providing a suffi-
ciently  accurate  model  that  works  under  a  wide  range  of  input  and 
environment  variations  can  become  time-consuming  and  sometimes 
impossible.  This  is  mainly  due  to  the  time  and  computational  efforts 

needed to develop a properly trained model for model-based RLs. 

2.3.3. Model-free RL 

Model-free  RL  does  not  require  a  pre-trained  model  and  instead 
learns  as  it  interacts  with  and  observes  the  environment.  Therefore, 
model-free RL requires lower memory and lower computational effort. If 
appropriate learning approaches are used, model-free RL can also cap-
ture  moderate  changes  in  the  environment  and  does  not  suffer  from 
inaccuracies  caused  by  ICE-model  mismatch.  This  characteristic  of 
model-free  RL  algorithms  makes  them  promising  for  ICE  applications 
that require adaptation through continuous learning. 

Most  of  the  studies  carried  out  on  the  applications  of  RL  on  ICEs 
[189–191] are focused on the energy management strategies of hybrid 
electric  vehicles  (HEVs)  rather  than  exclusively  on  ICE  control.  An 
example  of  a  model-free  engine  idle  control  with  RL,  that  uses  an 
ANN-based  policy  is  schematically  shown  in  Fig.  5.  The  algorithm  in 
Fig. 5 includes an Action Evaluation Network (AEN) and an Action Se-
lection Network (ASN) which are the action evaluator and the RL-actor, 
respectively. The AEN output and the ASN output will then go to the 
Stochastic Action Modifier (SAM) that is responsible to take the most 
effective actions by interacting with the environment. The role of the Q 
learning [192] algorithm is rewarding the actions based on the effects on 
the environment. For example for idle control of a port injection SI en-
gine,  these  actions  are  the  spark  timing  and  the  intake  throttle  valve 
position [193], while for a diesel idle speed control, fuel injection timing 
and the amount of injected fuel are the actions [194] to ensure a robust 
idle speed control for a wide range of accessory loads on the engine. 

RL-based adaptive controllers are also used for ICEs and are shown to 
be capable of improving the accuracy and stability of ICE controllers to 
manage emissions and performance [74,75]. The adaptive approach can 
take  advantage  of  both  model-based  and  model-free  RLs  by  using  a 
model  to  provide  a  rough  estimation  of  the  ICE  behavior  and  then 
adapting the policy and the RL algorithm based on new observations. 

A wide range of classic and modern control approaches have been 

Fig.  5. Reinforcement  learning  neural  network  for  idle  speed  control  of  a  SI 
engine. Reprinted from [72]  with permission of Elsevier. 

ProgressinEnergyandCombustionScience88(2022)1009678M. Aliramezani et al.                                                                                                                                                                                                                          

used to control ICEs. These include the use of classic PID approaches 
[195], model predictive control (MPC) [196], sliding mode control [28], 
iterative learning control (ILC) [16], and other techniques. Amongst all 
of  the  conventional control  approaches that  are used  to control  ICEs, 
there are similarities between RL and ILC for a repetitive disturbance as 
they both use a trial and error technique to iteratively remove the error 
between the desired and the actual output [197]. 

2.4. Comparison of different ML techniques 

A summary of the ML methods discussed so far along with advan-
tages, disadvantages, and main ICE applications are given in Table 1. All 
of the methods listed in Table 1 have some advantages that make them 
useful  for  ICE  applications.  Amongst  all  of  the  ML  methods  listed  in 
Table 1, ANN and SVM have the highest capability in capturing the most 
complex and highly non-linear ICE phenomena. SVM and ELM have the 
best performance in converging to global minima while ANN and RVM 
have higher risk of converging to global minima compared to SVM and 
ELM. RVM and GP are the two powerful techniques that provide dis-
tribution  prediction  without  requiring  a  kernel  function.  Another 
important characteristic that should be considered when selecting the 
most appropriate ML approach for modeling ICEs is its computation and 
storage efficiency for large data sets. For example, despite their simple 
structure, GPs are not suitable for large data sizes and their computa-
tional efforts increase by O (n3) and its storage requirement increases by 
O (n2) as explained in Section 2.1.5. Finally, RKHs is the only supervised 
ML  method  used  for  ICEs  that  can  simultaneously  include  multiple 
approximation schemes. 

Amongst  the  unsupervised  learning  methods  listed  in  Table  1,  K- 
means  has  the  simplest  structure  while  UGM  and  FCM  have  a  better 
performance in clustering classes with narrow boundaries. SOM has the 
best performance in low dimension data visualization compared to the 
other approaches. 

Finally,  the  model-free,  model-based,  and  RL-based  adaptive  con-
trollers are listed as the main RL approaches used for ICE control. Ad-
vantages  and  disadvantages  of  model-free  and  model-based  RL  were 
discussed in details in Section 2.3. It should also be noted that RL can be 
used  in  conjunction  with  controllers  to  improve  their  accuracy  and 
robustness in tracking the desired ICE output, particularly to adapt to 

system variations. 

3. ML to address ICE modeling, optimization, control, and 
diagnostics challenges 

An  overview  of  the  current  and  the  potential  impacts  of  machine 
learning on addressing ICE challenges in four areas of modeling, opti-
mization, control, and diagnostics is the focus of this section. 

Understanding the working principle, capacity, advantages and dis-
advantages  of  different  ML  techniques  is  essential  for  selecting,  and 
developing the most appropriate ML-based modeling, optimization and 
calibration, control, and diagnostics approaches for ICEs. In this section, 
promising ICE applications and the capability of each method to address 
the  existing  ICE  challenges  are  discussed  further.  An  overview  of  the 
main applications of ML for ICEs is illustrated in Fig. 6. 

3.1. ML to address ICE modeling challenges 

A  large  number  of  examples  of  research  in  developing  predictive 
models to understand ICE combustion and emissions characteristics are 
[15,30,198–200].  Accurate  ICE  models  are  available  to  predict  IMEP 
[30,198], combustion efficiency [30], combustion phasing (e.g. CA50) 
[15,22,28,196],  ignition  delay  [199,200],  burn  duration  and  heat 
release  shape  [30,198].  However,  the  state-of-art  ICE  research  is  still 
developing solutions for challenges shown in Fig. 7. 

Modeling pollutants formation and engine-out emissions particularly 
for transient conditions is still a major challenge for the ICE combustion 
researchers, particularly for unburned hydrocarbons [201], CO [203], 
soot  [230],  and  particulate  number  [204,205].  Predicting  the  exact 
amount  of  emissions  using  the  currently  available  models  is  quite 
difficult since there are many factors that can affect formation of these 
species inside the combustion chamber of an ICE. These factors include: 
air-fuel  distribution,  combustion  kinetics,  local  fuel-air  equivalence 
ratio, in-cylinder temperature and pressure gradients, flame-wall inter-
action, fuel injection parameters (e.g., injection timing, number of in-
jections,  injection  pressure,  injector  hole  size  and  number  of  holes, 
liquid fuel vaporization), and other factors [230,231]. 

Predicting  engine  cyclic  variability  [155,206–208],  combustion 
stability  and  misfire  [218–221],  knock  [212–215],  auto-ignition 

Table 1 
Summary of advantages, disadvantages and applications of the commonly used machine learning approaches for internal combustion engines.  

Method 

Category 

Advantages 

Disadvantages 

ANN 

ELM 

SL/UL 

SL/UL 

Suitable for parallel processing of complex ICE phenomena; 
Successfully tested for different ICE applications 
Fast and accurate learner; Highly capable of finding the global 
minima 

Requires large training data size; It is likely to 
converge to local minima; Overfitting risk is high 
Can be less accurate than multiple layer ANNs for 
complex systems 

SVM 

SL/UL 

RVM 

GP 

RKHS 

K-Means 
SOM 
UGM 
FCM 
Model-free RL 
Model-based RL 

RL-based 

adaptive 
controllers 

SL/UL 

SL/UL 

SL 

UL 
UL 
UL 
UL 
RL 
RL 

RL 

Suitable for high-precision classification and regression; High 
capability of converging to global minima; Memory efficient; 
Better performance with smaller size of training data compared to 
ANNs 
Provides distribution prediction of ICE phenomena; Appropriate 
for classification of complex boundaries 
Simple implementation; Provides distribution prediction 

Self-adapts to ICE model parameters; Can include multiple 
approximation schemes 
Simple implementation; Guaranteed convergence 
Suitable for data visualization 
Suitable for classes with less distinguished boundaries 
Provides fuzzy classification 
Simple; There is only one source of approximation error 
Saves a lot of learning effort; Makes efficient informed decisions 

Enhances conventional ICE controllers; Adapts to system 
variations 

a Providing prediction functions among the training points. 

Requires defining a regularization and 
insensitivity hyperparameters; Requires kernel 
functions for distribution predictionsa 

Risk of converging to local minima exists 

Not suitable for large data sets; Kernel functions 
and hyperparameters are hard to define 
Not suitable for distributed prediction 

Can be affected by initial values and outliers 
Not suitable for high dimensional data 
Long convergence time for large data sets 
Requires a pre-defined number of clusters 
Needs to learn the system while running 
Requires an ICE model; Requires higher memory 
compared to model-free RL 
Complex structure 

Diagnostics 
Diagnostics 
Diagnostics 
Diagnostics 
Control 
Control 

Control  

ICE Applications 

Modeling and data 
analytics 
Modeling and data 
analytics Online 
calibration 
Modeling and data 
analytics Diagnostics 

Modeling and data 
analytics Diagnostics 
Modeling and data 
analytics Diagnostics 
Regression 

ProgressinEnergyandCombustionScience88(2022)1009679M. Aliramezani et al.                                                                                                                                                                                                                          

Fig.  6. Overview  of  main  applications  of  machine  learning  for  modeling,  optimization,  diagnostics,  and  control  of  internal  combustion  engines.  Undefined 
abbreviated names in the diagram include: Engine Control Unit (ECU), Ringing Intensity (RI), and Combustion Noise Level (CNL). 

[209–211], and combustion mode transition [225–227] are still chal-
lenging  due  to  stochastic  and  the  complex  combustion  phenomena 
involved. Combustion noise [222–224], and ringing intensity [31,228, 
229] are two other engine characteristics that are hard to be accurately 
predicted for broad engine speed and load conditions. This is because 
capturing  all  the  physical  phenomena  that  affect  the  high  frequency 
changes of in-cylinder pressure waves is very complex. 

Current  advancements  in  addressing  these  modeling  challenges 
along  with  the  most  promising  ML  techniques  are  discussed  in  this 
section. 

3.1.1. Conventional modeling approaches for ICE modeling 

As  is  typical  for  modeling,  ICE  models  are  designed  for  different 
purposes such as diagnostics, data analytics, optimization, and control 
to enable high performance and low emission engines. ICE models can 
be divided into three main groups: black-box, physics-based, and grey- 
box  models  as  shown  in  Fig.  8.  The  conventional  physics-based  and 
black-box approaches are explained next. 

Physics-based models Physics-based models capture engine operation 
characteristics by applying physical laws including laws of thermody-
namics, conservation of mass, thermo-kinetic relations to simulate the 

phenomena that take place during an engine cycle. The physical pro-
cesses in ICEs include a wide range of phenomena including transport of 
chemical species, heat transfer, fuel injection and atomization, fuel-air 
mixing,  and  combustion  that  affect  the  engine  emissions  and  perfor-
mance. Depending on the required model outputs and combustion type, 
various types of physics-based ICE models can be used. This includes: i) 
zero-dimensional  first  principle  models,  ii)  multi-zone  combustion 
models  which  simulate  the  combustion  process  by  dividing  the  com-
bustion  chamber  into  several  zones  [254,262,263],  iii)  zero  to  multi 
dimensional CFD models to capture flow dynamics  for intake  charge, 
inside  the  combustion  chamber,  and  the  exhaust  flow,  iv)  detailed 
thermo-kinetic models that are used to simulate dynamics of chemical 
reactions  [245], and  v)  simple  physics-based  control  oriented  models 
(COMs) [37,264–266]. One main advantage of a physics-based model is 
that if a physical phenomenon is included in the model, it can adapt to 
changes in those physical characteristics of the system due to their un-
derlying physics-based understanding of the ICE processes. 

Examples of physics-based ICE models [198,267,268]. For instance, 
a three-zone flame propagation model was developed in [198] to esti-
mate the performance of partially stratified charge SI engine fueled with 
hydrogen  and  natural  gas.  This  model  can  capture  the  changes  in 

ProgressinEnergyandCombustionScience88(2022)10096710M. Aliramezani et al.                                                                                                                                                                                                                          

Fig. 7. ICE combustion modeling and control challenges. Abbreviated terms in the chart stand for: Low temperature combustion (LTC), Unburned hydrocarbons 
(UHC), and Particulate matter (PM), Carbon monoxide (CO), Nitrogen Oxides (NOx), and Spark ignition (SI) [202,216]. 

combustion  chamber  geometry,  the  injector  location,  or  hydrogen  to 
natural  gas  ratio  because  these  characteristics  are  included  in  the 
physics-based  model as inputs. The main model outputs include indi-
cated  mean  effective  pressure  (IMEP),  ICE  output  power,  and  heat 
release rate. Although physics-based models aim to provide a physical 
understanding  of  the  system  behaviour,  they  are  often  limited  in 
capturing complex combustion phenomena of engines. Many of the ICE 
combustion  phenomena,  such  as  in-cylinder  emission  formation, 
auto-ignition, and cyclic variability are extremely complex and have not 
been  accurately  captured  with  state  of  the  art  physics-based  models. 
These models are often limited to the engine speed and the load con-
ditions for which the models have been calibrated. In addition, many of 
the physics-based models are not suitable for real-time control because 
computationally efficient models are required to design control systems 
[253]. 

Zero to multi dimensional models 
Zero-dimensional physics-based ICE models are the simplest physical 
models that can be used to predict engine performance and emissions. 
These models consider only one zone that represents the in-cylinder gas 
and  neglect  the  in-cylinder  gradients  of  temperature,  pressure,  and 
species concentrations. This makes single zone models computationally 
efficient but they have low accuracy for predicting the ICE performance 
and emissions. For instance, a single-zone thermodynamic model that 
was combined with a kinetics-based mechanism to calculate the ignition 
timing of a CI engine was developed in [245]. The main inputs to this 
model  are  inlet  gas  temperature  and  pressure,  equivalence  ratio,  and 
fuel octane number. Despite its relatively simple structure, this model 
was capable of predicting combustion characteristics with low but an 

acceptable accuracy (error< 8.5%). Due to their simple structure, the 
zero-dimensional models do not provide accurate and predictive infor-
mation  about  the  flame  distribution  and  complex  emission  formation 
processes.  However,  they  can  be  still  attractive  for  applications  that 
require less computational time [269]. 

Multi-zone  physics-based  models  include  two  or  more  simulations 
zones with different properties and can capture more details than single 
zone models. These details can include information about combustion 
characteristics,  flame  diffusion  (for  CI),  flame  propagation  (for  SI  en-
gines), burned and unburned regions, etc [198]. The number of zones in 
a multi-zone model can vary from two to a large number of zones. For 
instance, CFD models typically use a large number of cells with different 
thermodynamic and chemical properties. 

CFD takes advantage of the high computing power of computers to 
solve  complex  fluid  dynamics  problems  by  dividing  the  system  into 
sufficiently small cells, and solving the governing equations for each cell 
and linking them to each other. CFD models are capable of simulating 
the behavior of a fluid system by considering a wide range of submodels 
including fuel spray and breakup, turbulence, chemical reactions, heat 
transfer, fluid-surface interactions, multi-phase fluid interactions, etc. In 
addition, due to their cell-by-cell simulation structure, CFD models can 
adapt to complex 3D geometries, and provide useful information about 
the  system  at  different  spatial  locations.  This  includes  temperature/ 
pressure  gradients,  concentration  gradient  of  species  throughout  the 
simulated region, and others. A large number of CFD models have been 
developed by the engine researchers to study the combustion phenom-
ena  of  different types  of  ICEs  and  to predict  engine  performance and 
emissions  [256,270,271].  KIVA  [272],  Ansys  Fluent  [273],  AVL  FIRE 

ProgressinEnergyandCombustionScience88(2022)10096711M. Aliramezani et al.                                                                                                                                                                                                                          

Fig. 8. Classification of existing ICE models to predict combustion and emission characteristics. Abbreviated names in the diagram include: Takagi-Sugeno (TS), 
Autoregressive  with  Extra  Input  (ARX),  Hilbert-Huang transformation(HHT),  local  linear model  (LOLIMO), System  Identification  Number(SID),  Artificial  Neural 
Network (ANN), Extreme Learning Machine (ELM), Relevance Vector Machine (RVM), Support Vector Machine (SVM), Gaussian Processes (GP), and Computational 
Fluid Dynamics (CFD) [234,239–241,244,247–251,255]. 

[274], and Star-CD [275] are some of the commonly used commercial 
CFD programs for engine combustion modeling. Despite the advantage 
of ICE CFD models, their computational time is typically too high for 
online  optimization  and  control  purposes.  In  addition,  due  to  a  high 
number of assumptions (e.g. unknown boundary conditions) and a large 
number  of  required  model  components/submodels,  the  CFD  models 
require  a  complex  validation  process  to  ensure  that  the  results  are 
extendable to other ICE operating conditions or modified ICE designs. 
ML-based  models  and  CFD  models  can  be  compared  from  the 

following perspectives: 

1. CFD as a virtual plant model to provide data for developing ML 
models: CFD can provide training data for ML that results in accurate 
models to understand ICE processes [276]. For instance, CFD prediction 
data for in-cylinder local equivalence ratio can be used as an input to ML 
to  identify/classify  reactivity  gradient  regions  inside  the  combustion 
chamber. This knowledge can then be used for engine optimization or 
control by linking the engine control variables to an optimal reactivity 

gradient inside the combustion chamber. 

2.  ML as an  enhancement for CFD:  The use of  ML to enhance the 
performance  and  to  reduce  the  cost  of  CFD  ICE  models  is  rapidly 
emerging. This includes reducing the scale of combustion mechanism 
using ML-based model order reduction approaches [39], memory usage 
optimization  when  simulating  compressible  and  incompressible  flows 
[277]reacting flows [278], optimizing probability density function table 
and  Large  Eddy  Simulation,  detecting  thermoacoustic  combustion 
oscillation, improving the accuracy and robustness of the optimization 
of CFD sub-processes, etc. [276,279,280]. 

3. ML as a counterpart for CFD: ML-based models and CFD models 
can also be seen as counterparts if they are intended to model exactly the 
same  ICE  phenomena.  The  main  downside  of  ML-based  models 
compared to CFD is that similar to any data-driven models, ML-based 
models are not capable of directly providing a “physical explanation” 
of a phenomenon. In addition, ML-based methods completely depend on 
the availability of sufficient and right training data. On the other hand, if 

ProgressinEnergyandCombustionScience88(2022)10096712M. Aliramezani et al.                                                                                                                                                                                                                          

a  sufficient  amount  of  proper  training  data  is  provided,  ML-based 
models can be used to model an ICE process without worrying about 
the  physical  assumptions,  initial  conditions,  boundary  conditions,  etc 
[281] that can be challenging in CFD models if proper information is not 
available  (e.g.,  not  knowing  cylinder  walls  local  temperatures  as  a 
function of engine speed and load for simulating combustion inside an 
engine).  After  training  is  completed,  the  ML-based  models  will  need 
much less computational resources compared to typical CFD models to 
simulate ICE processes. CFD models can not be used for real-time engine 
control  since  the  available  computation  time  to  estimate  the  engine 
process  is  only  a  couple  of  milliseconds  in  an  ECU,  while  trained 
ML-based models can be used for real-time engine control. 

Thermokinetics-based  models  (TKMs)  Thermokinetics-based 
models  explain  ICE  performance  using  thermodynamic  laws  and 
chemical  reaction  kinetics  principles.  A large  number  of  chemical  re-
actions  take  place during  the combustion  process and  these reactions 
often  depend  on  the  in-cylinder  gas  temperature  and  in-cylinder  gas 
pressure.  High  order  TKMs  try  to  capture  as  many  as  thermo-kinetic 
reactions  to  improve  the  model  accuracy  [245,252].  Reduced  order 
TKMs only include the most dominant reactions to reduce the compu-
tation efforts at the expense of slightly losing the model accuracy [282]. 
A general type of input can include intake temperature, intake pressure, 
air/fuel ratio, injection timing, fuel composition, etc. For example, the 
model proposed in [282] consists of 130 reactions and 41 species. This 
TKM  model  was  able  to  predict  combustion  characteristics  including 
ignition delay, heat release rate, and in-cylinder temperature profile. A 
computational  time  vs  model  accuracy  trade-off  is  typically  done  to 
develop the most appropriate reduced order TKM [282]. Depending on 
the complexity of the phenomena or the required accuracy, TKMs can be 
used  in  zero-dimensional  [245]  or  multi-dimensional  [252]  modeling 
approaches. 

Control-oriented  models  (COMs)  Physics-based  COMs  use  the 
physical  understating  of  ICE  phenomena  to  capture  the  dynamic 
behavior  of  ICEs  and  the  transient  input-output  relationships  [283]. 
These COMs can be used for different ICE applications including real-
time optimization, observer design [246] and control [16]. Depending 
on the complexity of a phenomenon and the availability of data, the base 
model used to develop a COM can be physics-based [283], black-box 
[15], or grey-box [238]. For example, the inputs to the model developed 
in [238] are intake valve close (IVC) timing, injected fuel energy, intake 
temperature,  as  well  as  engine  speed.  The  outputs  are  combustion 
timing,  output  power,  and  maximum  in-cylinder  pressure  rise  rate. 
Cycle-based,  mean-value,  and  event-based  ICE  COMs  can  be  used  to 
predict  the  ICE  transient  behavior.  However,  cycle-based  COMs  are 
generally more appropriate for ICEs since the ICE inputs can be set for 
each  combustion  cycle  and  most  of  the  ICE  operation  metrics  (e.g. 
combustion  phasing,  peak  pressure,  mean  effective  pressure,  etc)  are 
cycle-based [15,238]. 

Conventional  black-box  models  Black-box  ICE  models  provide  data- 
driven representations of the system input-output relations to help un-
derstanding the system behaviour when the phenomena are sufficiently 
complicated that physical models are unavailable or too complex and 
computationally  expensive.  Several  types  of  black-box  models  are 
shown in Fig. 8 and are described below. One of the most common black- 
box modeling approaches for ICEs are input-output system identification 
(SYID) models that can provide a data-driven understanding of the dy-
namic  behaviour  of  the  system  [232,235,236].  Regression  models 
represent  another  group  of  black-box  models  which  have  a  simple 
structure  and  typically  include  polynomial  functions  with  a  few  pa-
rameters that are trained using experimental data [237,238]. 

Empirical models are typically based on the experimental behavior 
of the ICE without including any physics of the system. These models 
have  been  widely  used  to  predict  engine  performance  and  emissions 
[284,285]. Due to their typically simple structure, empirical models can 
predict engine performance with a limited accuracy. They also require 
parameter calibration based on experimental data and, due to lack of 

physical  understanding  of  the  system,  they  do  not  adapt  to  system 
parameter changes without re-calibration. 

Regression models provide a simple input-output relation by finding 
the optimum parameters of any function selected by the user including 
linear, polynomial, logarithmic, exponential. The model parameters are 
defined through minimizing the error between the model and the given 
experimental training data. Although regression models have a simple 
structure,  they  have  limited  capabilities  in  predicting  complex  com-
bustion phenomena. In addition, the model type and parameters must be 
selected and any inappropriate selection of the base regression function 
and model parameters can lead to large model errors particularly when 
the  model  is  used  for  extrapolation.  Another  disadvantage  of  these 
models is that they are not suitable for complex input-output relations 
with  multiple  local  minima.  Due  to  their  simple  structure,  these 
regression models can be used as components of a larger model in the 
absence of a reliable empirical model [237,238]. Given that regression 
models for ICEs are often highly nonlinear, these models can be used 
either by using nonlinear control methods or by linearizing them around 
equilibrium points and using techniques such as gain scheduling [286, 
287]. 

System identification [232,233] is a useful approach that can be used 
to develop model-free dynamic COMs from time series data. An example 
includes  a  linear  auto-regressive  exogenous  (ARX)  model  for  fuel 
transport dynamics in a port fuel injection SI engine in reference [288]. 
COMs can be used for realtime estimation of the desired engine outputs 
(e.g., engine output torque, break mean effective pressure, engine-out 
emissions) based on dynamic system inputs. In addition, COMs can be 
used to design advanced model-based control strategies as well as ICE 
fault detection and isolation strategies. Similar to other model-free ap-
proaches, COMs that are developed via SYID cannot capture design or 
input  range  changes  of  the  system  without  re-parameterization  – 
re-running the SYID. 

Tree-based models are another type of black-box models that, unlike 
regression models, can be used for classification and decision making 
[242,243]. The main application of tree-based models for ICEs is fault 
detection and classification [243]. Another group of black-box models 
include ML based models based on advanced regression and classifica-
tion methods that can be used to model the complex combustion engine 
phenomena [30,84,122]. Conventional black-box models and ML-based 
models are both data-driven black-box models and therefore have some 
overlap in terms of their fundamental functions. Both approaches aim to 
provide predictions based on the available training data. However, there 
are a few characteristics that make ML techniques different from con-
ventional black-box approaches:  

1.  Unlike conventional black box models ML solutions (including the 
ones applicable to ICEs) are not limited to predicting ICE variables or 
modeling a phenomenon. A wide range of ML techniques can be used 
to provide a higher level of intelligence to control ICEs such as the 
solutions  that  are  offered  by  RL  or  other  ML-based  ICE  control 
strategies.  

2.  Modern  ML  techniques  have  significantly  better  performance  in 
handling large and extremely large data sets compared to conven-
tional black-box models [289].  

3.  Modern ML methods are more capable of transfer learning from one 
system to another and also have a better performance in adaptation 
to plant changes or disturbance dynamics [290].  

4.  Modern ML solutions offer much more flexible and powerful feature 
engineering  and  feature  extraction  capabilities  compared  to  con-
ventional black-box approaches [39,291].  

5.  The higher level of intelligence of ML methods and therefore their 
better capability of predicting more complex phenomena, have made 
modern ML methods  more attractive than the  conventional  black- 
box  methods.  Thanks  to  the  wide  range  of  standard,  but  flexible 
ML methods including ANN, SVM, ELM, etc, ML techniques can be 
used to extract much more sophisticated patterns in the input-output 

ProgressinEnergyandCombustionScience88(2022)10096713M. Aliramezani et al.                                                                                                                                                                                                                          

relations from the training data compared to conventional black-box 
techniques. These ML-based models will be explained in detail later. 

Conventional grey-box models 
Grey-box models are formed by combining black-box and physics- 
based  submodels.  Grey-box  models  can  provide  benefits  from  both 
black-box  and  physics-based  (also  called  clear-box)  models,  by 
combining their components [23]. For example, the grey-box model in 
[258]  combines  empirical  and  phenomenological  submodels  by 
extracting the most important physical processes and improving them 
with  physics-based  empirical  components  using  10  scalar  parameters 
that were found based on experimental data. This model was used to 
predict  the  engine-out  NOx  emission  where  the  grey-box  approach 
resulted  in  improving  the  empirical  model  accuracy.  Some  grey-box 
models  have  a  data-driven  structure  for  which  the  internal  variables 
are calculated using physics-based submodels [19,261]. For example, a 
physics-based  model  of  a  CI  engine  was  sequentially  attached  to  two 
feedforward  artificial  neural  network  models  to  predict  combustion 
phasing and indicated mean effective pressure (IMEP) [19]. On the other 
hand,  some  models  have  physics-based  structures  with  black-box 
data-driven  submodels  that  calculate  some  of  the  internal  variables. 
Another grey-box modeling approach to enhance the performance of a 
physics-based diesel engine NOx  model by adding data-driven compo-
nents resulted in improving NOx  emission prediction accuracy [292]. In 
this  paper,  the  term  “conventional”  grey-box  model  is  used  for  the 
grey-box models that have “conventional” black-box submodels. 

3.1.2. Emission formation modeling 

Despite  the  significant  advancements  in  developing  physics-based 
models to predict engine-out emissions and to simulate emissions for-
mation, it is still a challenge to develop an accurate and computationally 
efficient model to predict all of the engine-out emissions for both steady 
state and transient conditions. In addition, with the upcoming stringent 
emission regulations, more complex models are required to optimize the 
engine emissions while maintaining the engine efficiency at an accept-
able level [293]. The trade-off between different emissions is another 
aspect  that  makes  this  modeling  and  optimization  problem  more 
complex. 

ML-based modeling and optimization methods do not require phys-
ical understanding of the system or its complex phenomena and are yet 
able to accurately capture system complexity. This is an essential feature 
that can help ICE researchers to cope with the existing and upcoming 
emission reduction challenges for these complex systems. 

The majority of ML applications for ICEs are focused on modeling 
engine performance and emissions [15,30,78,88,294–297]. As discussed 
in Section 2, ML provides a powerful tool to understand, investigate, and 
predict  the  performance  of  ICEs  based  on  the  available  data.  For 
example, Yusaf et al [100], Roy et al [298], Ghobadian et al [299], and 
others  have  used  ML  to  predict  diesel  engine  performance  and  emis-
sions.  The  performance  and  emissions  of  SI  engines  [98,99,300,301], 
and HCCI engines [25,30,64,302,303] have also been modeled. 

Emission formation modeling using ANN: Capabilities and Challenges 
Among  all  of  the  ML  approaches  used  for  ICE  emission  formation 
modeling, ANN is the most common technique due to its capability to 
model highly nonlinear input-output relations. One possible reason to 
explain the domination of ANN based ICE emission models is simply that 
ANN  based  toolboxes  became  available  to  general  users  earlier  than 
many other ML techniques. Some ANN examples will be given next to 
explain  the  capability  of  different  types  of  ANN  for  ICE  emission 
modeling and the challenges associated with them. 

In  our  prior  study  [30],  a  multi  input  multi  output  (MIMO)  ANN 
model  was  developed  to  predict  heat  release  rate,  IMEP,  engine-out 
emissions,  and  maximum  in-cylinder  pressure.  Feed  Forward  NN 
(FFNN) and Radial Basis Function NN (RBFNN) approaches were both 
used in this study and some details of the work are presented here. 

Similar to other types of ANN, the network structure directly affects 

the  performance  of  an  FFNN.  The  structure  of  FFNNs  can  change  by 
changing the activation function type, the number of hidden layers and 
neuron numbers. These effects were studied in [30] by evaluating the 
effect of the design parameters on a single hidden layer FFNN to predict 
the  engine  emissions  (THC,  NOx,  and  CO)  and  engine  performance 
(IMEP, thermal efficiency, etc.) as schematically shown in Fig. 9. 

An example of FFNN, with two inputs and seven outputs, is shown in 
Fig. 9. The inputs include Butanol Volume Percentage (BVP) and fuel 
equivalence ratio (ϕ). The number of neurons and the number of hidden 
layers depend on the system complexity and the size of available data. 
This ANN model has 15 neurons on a single hidden layer with training 
done by using feedforward back propagation [30]. The results showed 
that the RBFNN and FFNN both have acceptable capability in predicting 
the  engine  emissions  and  performance.  It  was  also  concluded  that 
although  the  FFNN  has  a  simpler  structure,  the  RBFNN  requires  less 
training time. 

In  another  study,  an  ANN  model  to  predict  the  performance  and 
emission of a diesel DI engine that used Exhaust Gas Recirculation (EGR) 
was developed [298]. The their ANN model includes four variables in 
the input layer and five variables in the output layer and was used for 
PM- NOx- BSFC trade-off. 

Different  types  of  ANN  based  algorithms  are  used  to  accurately 
predict  the  ICE  performance  and  emissions  based  on  the  available 
training data [30,46,78]. ANN is capable of learning complex nonlinear 
input-output relationships and is therefore can learn and then predict 
the relation between ICE input variables and engine-out emissions. The 
most important aspect of these ANN models is to avoid overfitting the 
training data while maintaining a high training performance. The most 
important ANN design parameters are: understanding the most effective 
ICE inputs and including them in the input layers, defining the optimum 
number of hidden layers, and the minimum required number of neurons 
in the hidden layers. 

Defining the number of required neurons in the hidden layer of the 
neural network is an important step in ANN model development. As the 
number of neurons increases, the correlation of coefficient (R2) typically 
increases and the normalized root mean square error (RMSE) decreases 
(Fig. 10) as is typical in any regression. This leads to better performance 
of the ANN training but at the expense of increasing the network size and 
computational effort. The results in Fig. 10 are for NOx  emission pre-
diction for a CI engine but the trend is often similar for the other ANN 
based ICE emissions or performance models [30]. On the other hand, as 
the  number  of neurons  and  hidden  layers  increases,  the  likelihood  of 
overfitting increases [58]. 

The  main  challenges  of  developing  an  ANN  are:  determining  the 
input  and  output  variables,  providing  a  sufficiently  high  number  of 
training and test data sets, selecting training parameter values, initial-
izing network weights, and defining training convergence criteria [304]. 
Although there is no generic formula for choosing the parameter values, 
some recommended guidelines from references [305,306] can be used to 
set  the  initial  trial  values.  The  initial  weights  of  an  ANN  play  an 
important role in the convergence of the training process as is typical for 
many optimization problems [304,307]. 

Predicting engine-out emissions with SVM 
SVM regression is another powerful ML technique than has shown 
promising results in accurately predicting emission levels of ICEs as a 
function  of  engine  control  inputs.  The  high  capability  of  SVMs  in 
converging  to  global  minima  along  with  their  compatibility  with 
different types of kernels has made them interesting for a wide range of 
ICE emission prediction applications. These include low order SVMs for 
emission COM [37] to high order SVM based models for virtual plants 
[39]. 

A  SVM  based  exergetic  modelling  of  a  direct  injection  (DI)  diesel 
engine is developed and then compared the results with those from an 
ANN  based  model  [308].  The  results  helped  characterize  combustion 
efficiency  under  different  operating  conditions  and  demonstrated  the 
high  performance  of  the  SVM-based  model.  Their  effort  resulted  in 

ProgressinEnergyandCombustionScience88(2022)10096714M. Aliramezani et al.                                                                                                                                                                                                                          

Fig. 9. FFNN architecture to predict performance of an engine with oxygenated fuel. Reprinted from [30] with permission of Elsevier.  

and  SOI  are  inputs.  Where,  Tsoc  and  Psoc  are  the  in-cylinder  gas  tem-
perature and pressure at start of combustion, respectively. The FQ (mg/ 
cycle),  is  selected  as  the  Linear  Parameter  Varying  (LPV)  scheduling 
variable. Considering 65% of the experimental data for training, the rest 
of data points were allocated for validation. The Least-Squares Support 
Vector  Machine  (LSSVM)  technique  was  used  to  develop  the  model 
coupled with the LPV algorithm. 

The CA50 combustion phasing is estimated for the test data points 
and the results in Fig. 11 show an acceptable accuracy of 1 crank angle 
degree (CAD) for predicting combustion phasing under varying engine 
loads. This is an example where ML was used to develop an accurate 
dynamic engine model for a control application. 

Fig.  10. Normalized  RMSE  and  coefficient  of  correlation  for  predicting  NOx 
concentrations in a Radial basis function neural network (RBFNN). Reprinted 
from [30]  with permission of Elsevier. 

defining  the  best  composition  of  diesel-biodiesel  fuel  while  obtaining 
cost-effective and ecofriendly operating conditions. 

A linear parameter varying state space (LPV-SS) model to study the 
performance of a dual fuel engine fueled with isooctane and n-heptane is 
developed in our previous work in [15]. The following was used [15]: 

X = [ CA50 Tsoc Psoc

IMEP ]⊤,

U = [ PR SOI FQ ]⊤,

Y = [ CA50 ].

(8a)  

(8b)  

(8c)  

with (U) as the model inputs, (X) as the model states, and (Y) as the 
model output. The Premix ratio (PR), injected fuel per engine cycle (FQ) 

Fig.  11. LPV-SS  model  validation  for  predicting  engine  combustion  phasing 
(CA50). Engine conditions: N = 1500 rpm, 273 kPa<IMEP<771 kPa, and fuel 
premix ratio=20. Reprinted from [15] with permission of IEEE. 

ProgressinEnergyandCombustionScience88(2022)10096715M. Aliramezani et al.                                                                                                                                                                                                                          

Transient and steady state ICE emission models with ELM and SVM 
The main advantage of using ELM for emission models is its online 
learning capability which helps to reject disturbances and system vari-
ations. This characteristic has been used by engine researchers to predict 
ICE performance including combustion phasing and IMEP. One example 
is  a  stochastic  gradient-based  ELM  for  stable  online  learning  of  a  CI 
engine [56]. In this work, an online regression and online classification 
of  a  CI  Engine  is  used  to  identify  engine  transient  behaviour  [56]. 
However, the main challenge in developing online emission models is 
the availability of real time transient emission data required for online 
training. Thus, developing fast response emission measurement devices 
is an essential step needed for significant progress in developing online 
emission models. Currently, fast response production NOx  sensors are 
available  but  are  mainly  used  for  feedback  control  of  after  treatment 
systems  such  as  Selective  Catalytic  Reduction  (SCR)  systems  [309]. 
Utilizing  fast  response  emission  sensors  for  ICE  feedback  control  in 
conjunction with ML-based control oriented models is a promising way 
to  improve  engine  efficiency  and  reduce  emissions  [16,37,39].  ELM 
based online learning of ICE emission can provide more robust engine 
performance  and  emissions  control  during  disturbances  and  system 
variations. This will be of great utility for predicting and control of real 
driving emission (RDE) for on-road vehicles. 

Apart from their exceptional capabilities for online learning, ELMs 
are also a good candidate for offline applications such as ICE emission 
prediction. ELM has all of the advantages of a single hidden layer ANN 
while  its  accuracy  can  be  enhanced  through  the  use  of  a  kernel.  For 
example, a Kernel-based Extreme Learning Machine (K-ELM) is devel-
oped and used to evaluate the emissions and performance of a diesel 
engine fueled with blends of bioethanol and biodiesel [55]. The results 
revealed  an  excellent  match  between  the  prediction  results  and  the 
experimental data. 

ML  helps  with  understanding  the  relationship  between  the  inputs 
that  affect  ICE  performance,  and/or  understanding  the  underlying 
physical  phenomenon.  These  inputs  can  include  ICE  operating  condi-
tions and ICE design characteristics. 

Although  ML  is  not  expected  to  directly  explain  the  underlying 
physical justification of a phenomenon beyond the available data, it can 
certainly provide physical insight into ICE operation by recognizing and 
revealing complex but repeated patterns. For example, one can utilize 
ML to delve into the factors that affect combustion cyclic variability in 
an HCCI engine. ML can reveal how late ignition in a combustion cycle 
can result in possible early ignition in the subsequent cycle. In this way, 
ML  assists  an  ICE  researcher  to  identify  an  important  physical  phe-
nomenon.  Then  the  ICE  researcher,  motivated  by  the  detected  phe-
nomenon  via  ML,  can  investigate  this  phenomenon  further  to 
understand this is originally caused by thermal coupling between engine 
cycles via trapped residual gases. The researcher will find out that this 
deterministic  cyclic  relation  is  caused  by  residual  gases  that  link  one 
cycle to the next cycle in an HCCI engine in which the onset of com-
bustion  is  controlled  by  the  air-fuel  mixture  conditions  at  the  intake 
valve closing. 

As  another  example,  one  can  split  a  complex  process  into  smaller 
sub-processes  and  use  ML  to  understand  the  relationship  between  in-
termediate  states,  as  long  as  the  appropriate  data  for  ML  training  is 
available2  For example, one can understand the relation between ICE 
operating conditions and total soot emissions using simply by measuring 
total soot emissions at different ICE and environmental conditions. ML 
can also be potentially used to provide some insights into the effect of 
ICE operating conditions such as injection characteristics, rail pressure, 
number  of  injections,  fuel  spray  surface,  in-cylinder  temperature  and 
pressure,  etc.,  on  soot  generation  stages  such  as  particle  nucleation, 
surface  growth,  Surface  oxidation,  and  Particle  coagulation,  but  only 
when  sufficient  data  that  captures  all  these  inputs  and  stages  are 

2  See Section 4.2 for more details about appropriate data. 

available. 

3.1.3. Combustion knock and auto-ignition detection and prediction 
Conventional auto-ignition prediction methods and challenges 
Auto-ignition includes any type of uncontrolled combustion that is 
not directly initiated with an external control input such as spark igni-
tion, pilot injection, etc. Auto-ignition can be a desired phenomenon or 
extremely  undesired  and  harmful,  depending  on  the  engine  type,  the 
combustion  mode,  and  the  auto-ignition  phasing  [310,311].  For 
instance, auto-ignition is not desired for SI engines while it is a desired 
combustion type for HCCI engines when it is controlled at the right crank 
angle.  Regardless  of  the  combustion  type  predicting  and  controlling 
auto-ignition,  is  still  a  challenge  for  engine  researchers  as  it  involves 
multiple complex phenomena and can be affected by a high number of 
factors  including,  fuel  type,  octane  number,  injection  characteristics, 
intake  air  temperature  and  pressure,  environmental  conditions,  etc 
[213,215]. 

The main objective of engine control is to provide required power 
and  torque  with  minimum  fuel  consumption  and  minimum  harmful 
tailpipe  emissions. For SI  engines, high efficiency engine  operation is 
limited by auto-ignition and resulting engine knock [213]. For safe en-
gine  operation,  knock  detection  and  ignition  timing  control  to  avoid 
knock are essential to allow the engine to run at high efficiency oper-
ating  conditions  close  to  the  knock  threshold  without  causing  knock. 
Understanding,  modeling,  real-time  estimation,  and  preventing 
auto-ignition  are  essential  for  combustion  engines.  Developing  a 
physics-based model that can capture the impact of all effective inputs 
on auto-ignition is difficult. In addition, these models do not fully cap-
ture all engine conditions, environmental conditions, or fuel variations. 

Promising ML-based solutions for knock detection and prediction 
The  use  of  machine  learning  for  knock  detection  was  an  early 
adoption  of engine  fault diagnostics through supervised  [82] and  un-
supervised  [312]  learning.  An  unsupervised  pattern  recognition 
approach for knock detection using the engine block vibration signal is 
proposed in [312] proposed a. The developed algorithm differentiates 
three kinds of engine cycles: absence of knock, increasing knock, and 
heavy  knock.  In  another  work  [82]  a  supervised  SVM  classification 
approach is proposed for knock detection of SI engines. This proposed 
method includes a feature selection step to remove less important sup-
port vectors, a method showing to improve the performance of knock 
detection  approach  in  real  time.  Genetic  Algorithm  (GA)  [313],  and 
ANN [314] are also promising approaches for knock detection [315]. 

Generally,  knock detection  methods  can be  classified in  five  main 
groups:  1.  In-cylinder  pressure  analysis;  2.  Heat  release  analysis;  3. 
Engine block vibration analysis; 4. Exhaust gas temperature analysis and 
5. Intermediate radicals and species analysis [316]. Powerful ML-based 
classification  techniques  particularly  SVM  and  ANN  classification 
methods can be used in conjunction with any of these five methods to 
provide accurate knock detection models. 

Both  ANN  and  SVM  algorithms  have  the  potential  to  be  used  for 
developing  data-driven  models  to  simulate  the  effect  of  knock  on  in- 
cylinder pressure trace. The capability of ML for auto-ignition study is 
not limited to knock detection but can be extended to knock simulation, 
auto-ignition prediction, and auto-ignition control. ANN based or SVM 
based regression models can be used to predict auto-ignition. An SVM 
model is developed to predict the auto-ignition temperature from mo-
lecular structure of organic compound of the fuel [317]. SVM has shown 
significantly better performance in predicting the autoignition temper-
ature  compared  with  conventional  techniques  such  as  multiple  linear 
regression [317]. 

To provide an accurate and reliable knock prediction, the ML-based 
models  should  include  these  essential  features:  ICE  inputs  including 
injection  timing  and  pressure,  boost  pressure,  ignition  timing  (for  SI 
engines); Fuel characteristics including Cetane number, Octane number, 
molecular  structure;  Engine  design  parameters  including  compression 
ratio, injection spray cone angle, piston crown shape. 

ProgressinEnergyandCombustionScience88(2022)10096716M. Aliramezani et al.                                                                                                                                                                                                                          

Like all system identification techniques, it is important to include all 

aspects that influence the input-output relationship. 

3.1.4. Combustion noise modeling 

Existing challenges in combustion noise modeling and control 
Developing physics-based models that can accurately predict com-
bustion noise and ringing intensity based on the engine input variables 
for varying operating conditions is difficult. This is due to the complex 
nonlinear effects of ICE operation variables on the frequency and the 
magnitude of in-cylinder pressure oscillations which directly affect ICE 
combustion  noise  [318].  Developing  predictive  computationally  effi-
cient  combustion  noise  models  is  essential  for  model-based  engine 
control to allow smooth engine operation. 
Predicting combustion noise with ML 
ANN has shown high potential in predicting combustion noise level 
and  ringing  intensity.  An  ANN-based  Combustion  Noise  Level  (CNL) 
model was developed in [32] for a CI engine to predict CNL and also 
engine emissions and performance metrics. The ANN model was used to 
determine  ringing  operating  regions  of  the  engine.  The  ANN-based 
model was capable of predicting CNL with maximum error of 0.5% (in 
dB) (Fig. 12). 

Another example is the comprehensive engine noise study of a diesel 
engine fueled with different types of fuels including biodiesel, natural 
gas, and conventional diesel fuel [319]. An ANN model with one hidden 
layer and four hidden neurons was developed in [319] and was capable 
of predicting ICE noise level with R2=0.995 for training and R2=0.991 
for the test data. This model did not include all of the pertinent engine 
inputs such as injection timings, intake pressure and temperature and 
was still capable of predicting the engine noise level with an acceptable 
accuracy  demonstrating  the  high  potential  of  ANN  to  predict  engine 
noise level and ringing intensity. The model training and test accuracy 
could be increased further by considering the inputs that have a direct 
effect on in-cylinder pressure trace such as injection characteristics, and 
intake charge controllable properties. 

3.2. ML to address ICE optimization and calibration challenges 

3.2.1. Offline calibration 

Engine calibration is a general terminology that is typically used for 
the  process  of  defining  ICE  input-output  function  parameters  [320]. 
These functions include the ICE control strategies whose main objective 
are  to  optimize  engine  performance  while  minimizing  the  engine-out 
emissions.  The  ICE  calibration  process  is  extremely  costly  and  time 
consuming  due  to  the  complexity  of  the  system  and  the  stringent 

Fig. 12. Experimental and ANN simulated combustion noise level (CNL) for 50 
engine operating points. The horizontal dashed lines indicate the misfire and 
the ringing limits. Reprinted from [32] with permission of Elsevier. 

emission requirements. Another disadvantage of the conventional off-
line ICE calibration is that they are mostly carried out conservatively 
with  considering  a  number  of  safety  factors  to  mitigate  the  effect  of 
inputs and environment variations on the engine performance. This can 
result in a non-optimal engine calibration or can significantly increase 
the calibration costs. For instance, although many SI engine controllers 
have on-board knock detection algorithms, ML-based modeling can be 
used to develop an efficient design of experiment (DOE) to expand the 
range of operational and environmental conditions while keeping the 
calibration  cost  within  an  acceptable  limit.  This  can  result  in  a  more 
efficient  calibration  process  that  reduces  the  knock  occurrence  under 
real operating conditions. 

Machine  learning  algorithms  can  be  an  effective  way  of  engine 
calibration by providing accurate data-driven models or virtual plants, 
reducing the overall ICE calibration time and effort. These models can 
provide  insight  into  the  optimum  engine  control  parameters  that  are 
defined through the calibration process. The ML-based models can then 
be  used  to  determine  optimum  number  of  required  test  points  in  the 
engine  calibration  test  matrix.  Apart  from  the  ML-based  models,  ML- 
based techniques can also help with this optimization process. When it 
comes to optimization, genetic algorithms (GA) provide an important 
optimization tool that has been widely used along with regression and 
classification  machine  learning  techniques  [321,322].  Despite  its 
important role in ML, GA is itself not technically an ML algorithm but 
can  be  implemented  in  different  ML  approaches  such  as  GA-based 
clustering  techniques  [323,324],  supervised  learning  [325,326],  and 
reinforcement learning [327]. More detailed information about the GA 
can be found in [328–330]. For example, in our prior study, emissions 
and performance of a CI engine were controlled using an optimum CA50 
trajectory [29]. To do this, a grey-box emission model was developed 
and then combined with a GA technique to find an optimum combustion 
phasing that leads to optimum performance of an ICE at different engine 
speeds and loads. 

3.2.2. Online calibration 

ML  can  facilitate  adaptive  ICE  calibration  by  providing  efficient 
online learning algorithms. These algorithms can be used for adaptive 
optimization of the engine emissions and performance [50,331]. This 
could help to significantly reduce the time and effort required for engine 
calibration.  Online  ML-based  learning  techniques  can  also  provide  a 
robust and powerful tool for realtime optimization to adapt to system 
variations,  unexpected  environmental  changes,  and  deviations  in  ICE 
inputs such as fuel quality variation as detailed below. 

As indicated in Section 2.1.2, ELM is an excellent choice for online 
learning and this has made it a promising approach for online calibra-
tion of ICEs. For example, an engine calibration algorithm is developed 
in [332] using online extreme learning machine. This approach suggests 
a procedure that uses sequential Design of Experiment (DoE) algorithm 
for given ICE operating points. The output signals of different engine 
measurement systems are collected for given actuator commend signals 
and then the results were used through an online ELM technique to learn 
the  relation between  the sensors and  the actuators. Another fast cali-
bration  method  was  proposed  to  calibrate  injection  timing  and  idle 
throttle valve position based on sparse Bayesian extreme learning ma-
chine (SBELM) and meta-heuristic optimization for an SI engine fueled 
with  ethanol  and  gasoline  [333].  ELM  has  increasingly  been  used  to 
predict  the  performance  and  emissions  of  different  types  of  internal 
combustion engines [334–337]. 

A  stochastic  gradient-  based  Extreme  Learning  Machine  (SG-ELM) 
based online calibration algorithm is given in [56]. The SG-ELM algo-
rithm stabilizes the online learning process which guarantees that the 
estimated model parameters stay bounded between specific limits dur-
ing the learning process. In [51], a fast calibration method is developed 
using sparse Bayesian ELM (SBELM) and meta heuristic optimization is 
used to optimize operation of a dual-injection engine. These machine 
learning and meta heuristic optimization results showed promising and 

ProgressinEnergyandCombustionScience88(2022)10096717M. Aliramezani et al.                                                                                                                                                                                                                          

effective  performance  in  calibrating  a  dual-injection  engine.  Another 
example of ML-based ICE online learning is an online ELM-based opti-
mization and modeling technique proposed in [13,338] which was used 
for  engine  calibration  and  showed  a  significant  improvement  in  cali-
bration  efficiency  compared  to  conventional  model-based  calibration 
methods. The proposed algorithm optimises the local model parameters 
to provide the optimal DoE and then determines the optimal parameters 
for each engine operating point as schematically shown in Fig. 13. 

As mentioned above, the online calibration strategies help address 
parameter variations and disturbances on engine emissions and perfor-
mance. Some examples of these include i) Fuel quality variations from 
one gas station to another or from one season to another (e.g., winter vs 
summer),  ii)  ambient  temperature,  particularly  at  extreme  conditions 
for which the ICE is not calibrated, iii) ambient air humidity variations, 
iv) large atmospheric pressure variations, particularly for vehicle oper-
ation at high altitude, v) vehicle aging including exhaust aftertreatment 
systems and vehicle to vehicle variation. 

In  our  prior  study  [33],  a  connected  vehicle  distributed 
meta-regression (CV-DMR) training approach was developed to mitigate 
the effect of fuel quality variation by self-adapting the engine calibra-
tion. The engine was calibrated with a specific fuel (type 1). Then, the 
objective was to let the ICE combustion phasing (CA50) model adapt to 
another fuel (type 2) by applying the CV-DMR algorithm on engine/-
vehicle  performance.  In  addition  to  adapting  for  fuel  variation,  the 
transient engine data for changing operating conditions was utilized to 
evaluate the performance of the meta-learning method [33] for transient 
ICE operation among 206 experimental operating conditions. 

3.2.3. Utilizing RVM identifying for emissions trade-off and engine 
optimization 

One of the main challenges of ICE emission reduction, is identifying 
the optimum trade-off between different types of gaseous and particu-
late matter (PM) emissions. Typically, reducing NOx  emission results in 
an  increase  in  UHC,  or  PM  emissions  [339].  To  obtain  an  optimum 
emission trade-off, a deep understanding of the nonlinear and complex 

relation  between  different  emissions  and  engine  control  inputs  is 
essential. Supervised ML-based regressions can provide a powerful tool 
for  understanding  these  nonlinear  relations.  Due  to  the  narrow  and 
complex decision boundaries for emission trade-off, ML techniques with 
stronger distribution prediction capabilities are desired. RVM provides a 
strong distribution prediction and therefore is a promising candidate for 
ICE emission trade-off and optimization [144]. 

3.2.4. ELM For adaptive combustion noise optimization 

We recommend ELM for adaptive training since it has the advantage 
of  faster  training  time  which  makes  it  more  suitable  for  cycle-based 
analysis that requires processing large size of data over a short period 
of  time  [340].  Providing  the  ICE  inputs  that  directly  affect  the 
in-cylinder  pressure  trace  and  can  capture  high  frequency  pressure 
fluctuations and considering them in the ELM input layer, can improve 
the  accuracy  of  combustion  noise  prediction  as  a  function  of  engine 
operating conditions [86,340]. Augmenting in-cylinder-pressure-based 
combustion  noise  study  with  engine  vibration  sensors  as  additional 
ELM model inputs will help to improve the performance of the adaptive 
model  by  adaptive  calibration  of  the  relation  between  in-cylinder 
pressure trace and engine noise and vibration metrics [32,318]. 

3.3. ML to address ICE control challenges 

3.3.1. Augmenting model-based, model-free, and imitated ICE control with 
ML 

ML  can  be  integrated  into  model-based  ICE  control  via  ML-based: 
offline  learning,  or  adaptive  learning  (online)  models;  or  by  directly 
augmenting  the  ML  in  the  controller  structure.  All  cases  are  briefly 
discussed next and are shown in the upper branch of Fig. 14. 

For  offline  learning,  the  data-driven  model  used  in  model-based 
control  is  first  trained  through  a  separate  learning  process  and  then 
deployed.  This  is  a  one-time  training  process  using  experiments  that 
include inputs to the ICE and the corresponding system responses. Once 
the appropriate ML approach is selected and deployed, the data-driven 

Fig. 13. ELM-based workflow of the point-by-point online engine calibration. Reprinted from [13] with permission of Elsevier.  

ProgressinEnergyandCombustionScience88(2022)10096718M. Aliramezani et al.                                                                                                                                                                                                                          

Fig. 14. Overview of ML enhancements to control strategies applicable to ICEs. Undefined abbreviated names in the diagram include: Reinforcement Learning (RL), 
Support Vector Machine (SVM), Artificial Neural Network (ANN), Extreme Learning Machine (ELM), Genetic Algorithm (GA), Linear Parameter Varying (LPV), Deep 
Neural Network (DNN), Gaussian Processes (GP), Piece-Wise Affine (PWA), Local Linear Model Tree (LOLIMOT), Artificial Bee Colony (ABC), and Model Predictive 
Control (MPC) [257,347–365]. 

model can be used to provide dynamic predictions that can then be used 
by model-based control techniques such as MPC[341–343]. 

In the adaptive learning approach, unlike offline models, one or more 
model  parameters  are  updated  based  on  real-time  ICE  observations. 
These  observations  can  include  direct  measurements  from  sensors 
(including  emission,  temperature,  pressure,  etc.)  or  processed  mea-
surements  and  estimations  (e.g.  knock  occurrence,  estimated  heat 

release rate based on in-cylinder pressure curve, etc). Adaptive models 
are typically initialized through a pre-training process to estimate the 
desired output. The error between the estimated and the actual output is 
then  reduced  or  eliminated  by  continuously  updating  the  model  pa-
rameters[344]. 

As depicted in Fig. 14, the objective of adaptive learning for model- 
based control can vary from capturing the plant dynamic modeling to 

ProgressinEnergyandCombustionScience88(2022)10096719M. Aliramezani et al.                                                                                                                                                                                                                          

modeling disturbances. Depending on the application, both approaches 
can result in a more accurate and more robust ICE control. In both cases, 
the  ML-based  model  can  be  used  as  the  based  model  or  only  as  an 
enhancement  to  another  base  model.  For  example,  an  underlying 
physics-based ICE model can be utilized along with an ML-based model 
mismatch compensation or an ML-based disturbance model. A similar 
approach can be used for model-based RL to address ICE control chal-
lenges  which  are  explained  in  detail  along  with  the  most  promising 
applications. 

ML in the control structure can also be used. Apart from improving 
the performance and accuracy of the models used in model-based con-
trol, ML also can play a significant role in improving the performance of 
conventional model-based controllers. To elaborate this, let’s consider 
an example where ML can be used to enhance the structure of an MPC 
controller. The plant or disturbance dynamic model is a core part of an 
MPC that helps with predicting the system performance over a predic-
tion horizon. For MPCs, the plant and disturbance dynamics are often 
simulated as constraints. Large model uncertainty can adversely impact 
MPC’s performance and its computational cost. In addition, there is al-
ways a trade-off between the performance and computational cost of an 
MPC.  The  computational  cost  is  not  only  related  to  the  type  and  the 
complexity of the main MPC model, but also is related to the approach 
that is taken to formulate MPC constraints. ML can be utilized as a smart 
approach to trade off between the performance and the computational 
cost  of  MPCs  or  any  other  type  of  model-based  controller  with 
constraints. 

To provide more details about how ML can be used to imitate model- 
based  control  strategies,  let’s  consider  the  MPC  example  again.  Con-
ventional  MPC  can  be  used  to  control  the  initial  behavior  of  an  ICE 
controller. Once the ICE starts and more experimental data is available, 
an RL agent can gradually take over the control of the ICE. Although this 
approach  has  not  been  sufficiently  used  for  ICEs,  there  are  multiple 
examples that have shown the promising performance of classic control 
strategies that are imitated using ML [345,346]. 

Model-free ML approaches can have ML as the core approach or as an 
add-on to enhance conventional ICE control strategies, some examples 
for  each  are  mentioned  in  Fig.  14.  Model-free  ML-based  control  is 
explained in Section 2.3.3 and more ICE examples will follow in the next 
sections. 

Combining ML-based control with conventional ICE calibration methods 
All modern ICEs are controlled via electronic ECUs that are designed 
to optimize the engine performance and minimize the engine emissions. 
ECUs traditionally include numerous lookup tables that are calibrated to 
adjust the engine inputs such as injection timing, the amount of injected 
fuel, valve timings, etc, to meet the desired engine output torque and 
speed  and  to  meet  the  stringent  emission  regulations.  Conventional 
control strategies such as PID [195] and modern control strategies such 
as MPC [366] are used to control production ICEs. However, developing 
and tuning such a large number of controllers that can also adapt to new 
operating conditions is both cost and labor intensive. Implementing ML 
techniques  can  facilitate  developing  advanced  ICE  control  strategies. 
Some  applications  of  ML  that  can  enhance  the  performance  of  ICE 
controllers are: i) Using ML for tuning controller gains [73], ii) Using 
ML-based models for model-based ICE controller [367], iii) Using rein-
forcement learning and ML-based adaptive ICE controller [34,72]. 

A continuous action reinforcement learning for online PID tuning for 
idle-speed  control  of  an  SI  engine  is  used  in  [73].  The  results  of  this 
tuning approach are compared with a conventional PID tuning method 
(Zeigler-Nichols) and shown in Fig. 15. The results show an improve-
ment in the engine idle speed controller performance when a 10 Nm step 
change in load is applied to the engine. 

A machine learning based model can be utilized in a model-based 
control design such as MPC for different ICE control applications. For 
example, an MPC based on a neural network model to control the air- 
fuel ratio for an SI engine is developed in [368] and [369]. The MPC 
model  is  adapted  on-line  to  address  the  uncertainty  of  system 

Fig. 15. Comparing engine idle speed controller performance for a 10 N.m step 
change in load. Reprinted from [73] with permission of Elsevier. 

parameters.  Based  on  their  model,  an  adaptive  MPC  was  utilized  to 
control  air-fuel  ratio.  Comparing  their  controller  performance  with  a 
conventional PI controller has a smaller overshoot and a shorter settling 
time which is a significant improvement. 

A neural network based controller using reinforcement learning to 
control the idle speed of an SI engine is developed in [72]. The rein-
forcement  learning  structure  is  schematically  shown  in  Fig.  16.  As 
illustrated in Fig. 16, the idle speed deviation (e) and the reinforcement 
reward  (r)  are  the  inputs  to  an  Action  Selection  Network  (ASN)  that 
plays  as  an  actor  and  the  Action  Evaluation  Network  (AEN)  which 
evaluates the actions that the ASN commands. 

ANN has also shown promising performance in adaptive control of 
nonlinear  systems  for  different  applications  [370–372].  Neural 
network-based  adaptive observers have  also shown high stability and 
relatively fast convergence when used for non-linear systems [373]. 

Due to their powerful self-adapting capabilities, ANN is a promising 
choice for online adaptation strategies [374]. As discussed in previous 
sections, these characteristics can also be used to develop ANN-based 
adaptive combustion control strategies to address challenging ICE con-
trol problems. For instance, smooth variable structure filter based ANN, 
is an ANN-based adaptive training algorithm developed based on sliding 
mode and variable structure theory [375]. This methodhas been used for 
a few ICE applications mainly focused on ICE fault detection and clas-
sification  [372].  Similar  approaches  can  be  used  to  develop  adaptive 
control strategies for ICE combustion control challenges. For example, 
adaptive auto-ignition algorithms can be developed to compensate the 
effect  of  fuel  variation  or  unexpected  environmental  variations  that 
affect the engine combustion. 

In summary, ML can improve the performance of conventional ICE 
control strategies either by tuning controller gains, providing accurate 
models  for  model-based  ICE  control,  or  by  offering  reinforcement 
learning  based  solutions  to  address  ICE  control  challenges  meeting 
optimal operation conditions. 

Fig.  16. Reinforcement  learning  -  based  Idle  speed  control  for  an  SI  engine. 
Reprinted from [72] with permission of IEEE. 

ProgressinEnergyandCombustionScience88(2022)10096720M. Aliramezani et al.                                                                                                                                                                                                                          

3.3.2. Combustion mode transitions in control of multi-mode engines 

Another important ICE challenge is modeling and control of engines 
combustion mode transitions for the engines that work under different 
combustion  modes.  It  is  difficulty  to  predict  engine  cycle-by-cycle 
behaviour  (e.g.,  residual  gas  fraction  and  reactivity  distributions) 
through  these  mode  transitions.  Some  examples  include  combustion 
mode transition from low temperature combustion (LTC) to diesel [227] 
or SI [225,226] as illustrated in Fig. 7. Some of the most promising ML 
techniques  to  address  the  ICE  modeling,  optimization,  and  control 
challenges are discussed next. 

Existing challenges in ICE mode transition methods 
Advanced multi-mode engines take advantage of different combus-
tion  modes  at  different  engine  operating  conditions  to  maximize  the 
engine efficiency and minimize the engine-out emissions. For instance, 
HCCI engines have remarkable characteristics at part load operation but 
offer limited benefits at high loads or during engine cold start [206]. 
Despite the advantages of multi-mode engines, modeling and control of 
combustion  mode  transitions  remains  a  challenge.  The  combustion 
mode transition challenge is a result of the significant differences be-
tween the combustion process for each mode. For example (see Section 
3.1.3),  while  auto-ignition  combustion  is  desired  in  HCCI  mode,  it 
damages  the  engine  in  SI  mode.  In  addition,  it  is  difficult  to  predict 
engine cycle-by-cycle behaviour during these combustion mode transi-
tions by only using physics-based models. Combustion mode transitions 
from low temperature combustion (LTC) to diesel [227] or SI [225,226] 
are examples of existing challenging mode transitions. 

Promising  ML  techniques  for  model-based  combustion  mode  transition 

control 

ML-based  regression  can  capture  the  nonlinear  relation  between 
combustion characteristics and the engine control inputs. However, due 
to the high complexity of a combustion process and its sub-processes, 
developing  such  dynamic  models  are  much  more  complicated  than 
predicting  mean  value  engine  outputs  such  as  steady  state  IMEP  or 
emission levels. 

Powerful ML techniques are required to learn the changes in com-
bustion characteristics throughout the mode transition process. Among 
all ML approaches, deep learning models have recently shown excep-
tional potential in capturing complex combustion characteristics [376, 
377]. Deep learning methods are basically ANNs with multiple hidden 
layers [378]. These multiple hidden layers enable deep learning based 
models to capture the complexities that are hard to capture using con-
ventional  ANNs.  Due  to  the  high  complexity  of  this  problem,  deep 
learning  approach  is  recommended  as  a  promising  method  which 
recently has shown a high potential in capturing cycle-based combustion 
characteristics. However, deep learning models require larger data sets 
for  training  and  their  design  requires  more  effort  and  expertise  than 
conventional ANNs. This is due to the higher number of design param-
eters  such  as  the  optimum  number  of  hidden  layers,  the  number  of 
neurons for each hidden layer, the corresponding activation functions 
needed to provide an accurate performance while avoiding over fitting 
and excessive computation time. To make ECUs more suitable to carry 
out complex ML-based analysis such as deep learning, they require more 
computation power and memory capacity compared to current ECUs. 
Another  approach  that  could  help  utilizing  complex  ML  based  tech-
niques is through ad-hoc cloud computing [379] but this needs more 
investigation for ICE applications. 

ML-based online learning for knock and auto-ignition control 
A promising approach to address knock and auto-ignition challenges 
is using adaptive or online techniques. While offline ML-based methods 
are appropriate for systems with small variations, online methods are 
capable  of  capturing  system  variations.  Due  to  the  extremely  high 
sensitivity  of  auto-ignition  to  uncontrolled  ICE  input  variations 
(including intake air properties variation, fuel variation, and environ-
mental  variations),  employing  online  ML-based  models  that  can 
consider the effect of these variations, will be of great value to allow 
precise auto-ignition control. A physics-based model that captures the 

effect of all these variations on auto-ignition is difficult to develop. To 
date, conventional black-box approaches do not have the appropriate 
and complex enough structure for such online learning application. 

One of the most important ML-based online learning approaches that 
has shown promising results in predicting auto-ignition and combustion 
phasing of ICEs, is ELM. Due to its powerful online learning character-
istics,  ELM  is  capable  of  realtime  capturing  the  effect  of  ICE  control 
inputs  such  as  injection  characteristics  on  auto-ignition  timing.  For 
instance  an  online  ELM  model  is  capable  of  predicting  combustion 
phasing of a compression ignition engine [380]. 

One of the important challenges of developing such online learning 
models is the model stability. This is more challenging for a nonlinear 
and sensitive phenomenon like auto-ignition. Stochastic gradient based 
ELM is shown to be an effective solution for stable online learning [56] 
and  therefore  is  a  promising  method  for  adaptive  modeling  of 
auto-ignition. 

ANN based and SVM based classification are both capable of knock 
detection  through  any  of  the  five  knock  detection  methods  listed  in 
Section 3.1.3.2. SVM has also shown promising performance in offline 
prediction of auto-ignition based on engine inputs and fuel character-
istics. More studies need to be carried out on the online learning of the 
auto-ignition by exploring powerful online ML techniques particularly 
ELM. 

The  majority  of  the  ML  application  for  auto-ignition  analyses  are 
focused  on  knock  detection  techniques  rather  than  auto-ignition  pre-
diction. Developing such accurate ML-based predictions are essential for 
controlling auto-ignition based combustion for HCCI or RCCI modes in 
advanced multi-mode engines [226]. 

Model-based RL for managing mode transitions 
Even when all of the combustion characteristics are accurately pre-
dicted with an ML-based model, the combustion mode transition chal-
lenge cannot be addressed unless an appropriate control strategy selects 
the optimum time varying ICE input variables to carry out combustion 
mode  transition.  Model-based  RL  takes  advantage  of  the  available 
knowledge from the training data and still explores the ICE input vari-
ables  to  find  the  best  actions  to  take  to  maximize  the  corresponding 
value  function.  Utilizing  RL  for  cycle-by-cycle  ICE  control  is  another 
promising approach to address combustion mode transition challenges. 
This  approach  requires  combustion  cyclic  variables  including  in- 
cylinder  pressure  trace,  combustion  phasing,  pressure  rise  rate,  heat 
release rate, etc to define the ICE “states” for the RL algorithm. To ensure 
the combustion process remains stable and minimizes the cyclic com-
bustion variation throughout the engine mode transition, the RL algo-
rithm  rewards  can  be  a  function  of  combustion  stability  metrics  and 
engine output power. 

Although  model-based  RL  is  a  potential  solution  to  address  com-
bustion  mode  transition  challenges,  more  experimental  studies  are 
required to evaluate the performance of the approach and to select the 
most  appropriate  RL  algorithm.  One  major  challenge  of  using  RL  for 
engine  transient  control  is  to  ensure  engine  hard  constraints  (i.e., 
misfire, COVIMEP, Knock) are met during each engine transient. This can 
be addressed by design of rewards and policies in RL; however, this will 
require ICE knowledge and extensive virtual simulations to ensure en-
gine hard constraints are met over broad operating conditions. 

3.3.3. ML For combustion stability control 

SVM-based models for ICE combustion stability control 
Another  example  of  using  ML  to  develop  model-based  controllers 
was  carried  out  in  our  prior  work  [15]  where  we  developed  an 
SVM-based  engine  combustion  phasing  controller  (Fig.  17).  The  MPC 
controller calculates the optimal start of injection (SOI) values based on 
the  state  space  plant  matrices  provided  from  the  trained  SVM-based 
linear  parameter  varying  (LPV)  model.  Input-output  transient  engine 
experimental data was used to determine a state space model to predict 
CA50 for varying engine load conditions. 

The results in [15] show the designed controller tracks the desired 

ProgressinEnergyandCombustionScience88(2022)10096721M. Aliramezani et al.                                                                                                                                                                                                                          

Fig. 17. A designed SVM-based MPC combustion phasing controller along with the engine. The engine control unit (ECU) is loaded with a Kalman filter, an LPV plant 
model, and the MPC controller. This figure is adapted from [15] with permission of IEEE. 

combustion phasing (CA50) with an average error of 0.7 CAD to ensure a 
stable  combustion  with  minimum  cyclic  combustion  variability.  By 
comparing these results with those from the physics-based combustion 
control  [381]  for  the  same  engine,  it  is  shown  that  SVM-based  CA50 
controller (Fig. 17) was successfully able to track the desired combustion 
phasing as accurately as a physics-based approach in [381]. However, 
the  time  spent  to  develop  a  proper  control  oriented  model  for  CA50 
tracking  was  much  less  in  the  data-driven  approach  compared  to  the 
physics-based approach in our prior work in [381]. 

ML-based adaptive methods to control cyclic combustion variability 
Cyclic combustion variability can be caused by “random”  external 
disturbances or cyclic variability of gas-fuel mixture conditions inside 
the cylinder. This is due to different time-varying phenamena inside the 
combustion  chamber  including  flow  turbulence,  fuel  injection  vari-
ability,  mixing  dynamics,  residual  gas  amount  and  temperature 
variability. 

Understanding  the  most  important  phenomena  and  factors  that 
affect the cyclic combustion variability are essential for engine  cyclic 
combustion variability control. Although accurately simulating all the 
combustion subprocesses with a pure physics-based models is extremely 
difficult, including the physical insights into the feature selection pro-
cess is beneficial to the model performance and accuracy. Some effective 
features include EGR rate, fuel properties, air/fuel mass flow rates, ϕ, 
residual gas mass fraction [382]. 

Due to their relatively fast training time, ELM is a preferred choice to 
predict fast changing and chaotic combustion variables such as cyclic 
combustion  variability.  A  related  example  for  a  chaotic  combustion 
modeling used the ELM-based model for real time prediction of com-
bustion  phasing  of  an  HCCI  engine  that  was  developed  in  [84].  A 
schematic overview of this approach is shown in Fig. 18 where the value 
of CA50 at step n is predicted based on a weighted ring buffer of the 
previous steps. 

As the number of previous cycles (steps) included in the buffer in-
creases,  the  predictions  become  less  capable  of  capturing  the  sudden 

changes  in  combustion  characteristics  and  therefore  less  suitable  of 
combustion cyclic variability studies. The trade-off between the model 
response time, model accuracy and model stability must be examined to 
develop the optimum combustion cyclic variation analysis. 

Adaptive ML-based models have the capability of capturing the effect 
of  unexpected  engine,  environment,  or  fuel  variations  on  cyclic  com-
bustion variability if the required cyclic training data are available. For 
example,  an  adaptive  NN-based  reinforcement-learning  controller  (an 
adaptive-critic NN-based controller) is developed in [382] to track the 
desired  objective  of  discrete-time  systems  with  high 
level  of 
non-linearity.  The  RL-based  controller  was  capable  of  providing 
appropriate feedback in the presence of random bounded external dis-
turbances. To decrease the coefficient of variation (COV) of an SI engine 
idle speed under lean operating conditions a controller was designed in 
[382]. Similar studies can be carried out in the future to control cyclic 
combustion  variability  in  ICEs  to  take  advantage  of  the  capability  of 
RL-based  controllers  in  the  presence  of  random  bounded  external 
disturbances. 

3.4. ML to address ICE diagnostics challenges 

3.4.1. SVM-based classification for engine fault detection based on 
combustion noise 

Combustion noise level provides helpful information about the per-
formance and operation of an ICE. Therefore, combustion noise char-
acteristics can also be used as inputs to an ML-based model to evaluate 
engine health and to detect ICE faults. A noise-based algorithm for ICE 
fault  diagnosis  using  a  combined  SVM  and  Hilbert-Huang  transform 
(HHT) algorithms  [68] is  shown in  Fig. 19. This  algorithm  illustrates 
that a supervised learning algorithm can also be used for unsupervised 
learning  purposes.  First,  the  noise  of  a  sample  engine  was  measured 
under  normal  and  fault  states.  The  unsupervised  HHT  technique  was 
then used to extract the most significant features vectors that are related 
to the faults. Then a SVM pattern recognition approach was used to learn 

Fig. 18. Online learning of combustion phasing using ELM. Reprinted from [84] with permission of Elsevier.  

ProgressinEnergyandCombustionScience88(2022)10096722M. Aliramezani et al.                                                                                                                                                                                                                          

Fig.  19. The  designed  scheme  of  the  Hilbert-Huang  transform  (HHT)-SVM  modeling  for  engine  fault  detection  using  engine  noise.  Reprinted  from  [68]  with 
permission of Elsevier. 

the fault diagnostics scenarios which were then utilised for fault detec-
tion as shown in Fig. 19. An unsupervised features extraction method for 
selecting healthy training data and removing the faulty information is 
described  in  [291].  They  used  a  sparse-autoencoder  method  to  learn 
fault features and showed an improvement in the performance of their 
feature extraction algorithm  [170]. 

3.4.2. Combustion instability 

Combustion stability and misfire limits diagnostics 
Securing a complete and stable combustion is an essential step to-
wards improving fuel conversion efficiency and emission reduction of 
ICEs.  Combustion  stability  cannot  be  guaranteed  unless  the  sufficient 
conditions  for  a  complete  combustion  for  each  cycle  are  provided  to 
avoid any misfire or partial burn. This is why detecting the ICE misfire 
limits is essential for improving the combustion stability. Further, if EGR 
is  used,  understanding  of  the  coupling  of  unburned  fuel  and  residual 
gases with future cycles is essential. Defining and identifying instability 
limits  is  still  a  challenge  for  engine  researchers  particularly  for  ultra 
lean, low temperature, and stratified charge combustion engines [217, 
383]. It should also be noted that detecting and controlling misfire limits 
is a necessary step for improving combustion stability but it is not suf-
ficient. To have a stable combustion, in addition to ensuring a complete 
combustion for each cycle, other combustion and heat release charac-
teristics  should  also  be  maintained  at  stable  conditions  to  minimize 
cyclic combustion variability (e.g. COVIMEP ≤ 3%). 

Detecting misfire is very important for combustion engines to meet 
the  required  engine  output  torque  while  protecting  the  engine  after 
treatment system [384]. The following techniques have been employed 
to detect misfire for CI and SI engines: in-cylinder pressure trace [385]; 
engine  speed  [386–388];  oxygen  concentration  in  the  exhaust  gas  or 
exhaust gas temperature [389], and; Breakdown voltage or ionization 
current [390,391]. 

The risk of misfire is relatively high for ultra lean combustion en-
gines, due to their low combustion temperatures. This risk can increase 
if the combustion phasing is too late or if an appropriate fuel is not used. 
Very  few  published  works  are  available  for  physics-based  misfire 
detection  of  HCCI  engines.  ML  has  shown  promising  performance  in 
misfire detection of ICEs [392]. 

Utilizing ANN to predict combustion instability limits 
ANNs have been used to predict combustion instability limit and to 
detect  misfire  events.  An  ANN-based  misfire  detection  method  is 
developed  in [384] by  using engine  speed fluctuation,  showing capa-
bility to detect misfires with more than 98% accuracy [384]. Angular 
acceleration of crankshaft was also used to develop ANN-based misfire 

detection methods [70]. In our prior work [393], an ANN-based misfire 
detection method was  developed. We found that sudden drops of the 
maximum heat release rate is typically a good indication of partial burn 
or misfire. Thus, the values of in-cylinder pressure at TDC, 5, 10, 15, and 
20 degrees after TDC (P0, P5, ..., P20) were considered as the inputs for an 
ANN-based  misfire  detection  method  with  10  neurons  and  4  hidden 
layers and a sigmoid activation function as shown in Fig. 20. The pro-
posed ANN-based model in [393] was capable of misfire detection with 
accuracy of 100% for the cases tested. 

Although predicting combustion instability limits can be formulated 
as a regression problem, misfire detection with ANN is not a regression, 
but a classification problem and therefore the ANN model performance 
should be evaluated by classification metrics. For instance, Jafarian et al 
developed ML-based misfire detection algorithms using multiple vibra-
tion  sensor  inputs.  They  carried  out  feature  selection  and  extraction 
based  on  the  sensor  inputs  and  developed  a  20-feature  model  [394]. 
Their  ANN  model  was  capable  of  misfire  detection  with  accuracy  of 
97.2%, sensitivity of 95.6%, and specificity of 99.1%. Some other re-
searchers  have  used  ANN  for  unsupervised  learning  of  ICEs.  In  [69], 
combustion  characteristics  of  a  CI  engine  fueled  with  waste-cooking 
biodiesel  fuel  was  studied  using  unsupervised  ANN  for  misfire  detec-
tion and in another work [70] an unsupervised ANN was used to detect 
engine misfire. 

3.4.3. ML for ICE component fault diagnostics 

In addition to ICE emission reduction and efficiency optimization, 
ICE calibration also aims to provide accurate ICE component fault di-
agnostics as required by the regulations (e.g. OBD-II standard) [395]. 
Supervised and unsupervised machine learning approaches have been 
used for component fault detection, but the use of unsupervised learning 
is  more  popular  for  this  application.  Different  types  of  classification 
techniques  have  been  used  for  component  fault  diagnostics  of  diesel 
engines [396–399]. This is due to the fact that ML-based unsupervised 
learning algorithms are highly capable of anomaly detection in system 
behaviour. 

For instance, a technique using sparse auto encoders for automated 
unsupervised  fault  diagnostics  based  on  the  ICEs  acoustic  signals  is 
proposed in [291]. By employing unsupervised learning, there is no need 
of any manual feature selection or feature extraction from the raw en-
gine data for fault diagnostics which makes the fault detection process 
more  efficient  and  more  robust  [400].  The  proposed  unsupervised 
technique in reference [291] uses sparse-auto encoder to extract features 
from  the  training  data  through  an  unsupervised  method.  Then  the 
testing and the training data sets are converted through the extracted 

ProgressinEnergyandCombustionScience88(2022)10096723M. Aliramezani et al.                                                                                                                                                                                                                          

Fig. 20. ANN-based misfire detection method using in-cylinder pressure at selected engine crank angles. Reprinted from [393] with permission of Elsevier.  

features, before detecting the potential fault of a random engine. The 
fault diagnostics algorithm is schematically shown in Fig. 21. 

Pontoppidan  et  al  [65]  presented  an  unsupervised  fault  detection 
algorithm that couples probabilistic outlier detection with independent 

Fig.  21. The  unsupervised  fault  diagnostics  algorithm  to  detect  and  classify 
potential  ICE  faults  based  on  sparse  auto  encoders  classifier.  Reprinted  from 
[291] with permission of Springer. 

component modeling. This method uses engine acoustic measurements 
to  detect  unexpected  engine  condition  changes  for  heavy  duty  diesel 
engines through an unsupervised algorithm. They concluded that their 
mean-field  Bayesian  learning  method  has  a  better  performance 
compared to other conventional techniques that use Gaussian mixture 
models (GMM) or principal component analysis (PCA) [65]. 

4. Discussions, recommendations, and future directions 

This section highlights the limitations in ICE modeling, optimization, 
and control by using conventional approaches. Then, the characteristics 
of required appropriate data for application of ML methods for ICEs are 
discussed.  Next,  grey-box  ML-based  modeling  and  control  of  ICE  are 
discussed and seen to capture the advantages of both physics and ML 
methods. Finally, the recommended ML methods to address each spe-
cific ICE challenge are discussed and summarized in this section. 

4.1. Limitations of conventional ICE modeling, optimization, and control 
approaches 

We  identified  six  major  existing  modeling  challenges  for  ICEs:  i) 
engine-out  transient  emissions  prediction,  ii)  combustion  knock  and 
auto-ignition  prediction,  iii)  combustion  noise  and  ringing  intensity 
modeling, iv) combustion mode transition modeling, v) cyclic variability 
prediction,  and  vi)  combustion  instability  and  partial  burn/misfire 
prediction. Many of these modeling challenges result in complexities in 
ICE transient control. For instance, it is still challenging to enable robust 
and optimal control of combustion mode transitions in multi-mode en-
gines. The ICE control challenges are partly due to lack of accurate and 
sufficiently fast combustion models to be used for ICE control. It is also 
partially due to the highly transient and broad operating conditions of 
ICEs in conventional vehicles. Conventional ICE control strategies can 
benefit  from  the  state-of-the-art  machine  learning  and  particularly 
reinforcement  learning  to  improve  their  tracking  and  optimal  perfor-
mance,  stability,  and  robustness  to  disturbances.  However,  more  ICE 
studies are needed to provide a practical understating of the effect of RL 
on improving the performance of ICE control strategies as this work is 
just beginning. 

Conventional  ICE  optimization  and  calibration  methods  also  have 
existing challenges that can be addressed using ML. Conventional ICE 
offline calibration methods need a large number of experimental tests, 
which  is  time  and  cost  intensive.  These  experiments  also  typically 
require  multiple  iterations  to  find  the  optimum  engine  operating  pa-
rameters to meet the emission standards and to minimize engine fuel 
consumption. In addition, to ensure that the combustion characteristics 

ProgressinEnergyandCombustionScience88(2022)10096724M. Aliramezani et al.                                                                                                                                                                                                                          

are within the acceptable range in the presence of environmental or fuel 
variation, the optimizations and calibrations are often constrained from 
the optima. This is done to ensure robust ICE operation for worst case 
conditions; thus, undesired combustion phenomena such as misfire and 
knock are avoided. This results in ICE parameters that are sub optimal. 
Employing  ML  techniques  can  help  mitigate  the  effect  of  these  chal-
lenges  on  ICE  optimization  and  calibration  by  providing  smart  DOE 
platforms and learning-based optimization techniques. 

4.2. Optimum data required for ML-based ICE applications 

The state-of-the-art ML approaches that are discussed in this study 
have their specific advantages and disadvantages when they are used for 
different  ICE  applications.  However,  they  all  share  one  essential 
requirement - the need for appropriate data. Providing appropriate data 
for ML-based modeling, optimization and control is at least as important 
as the design of the ML algorithms. It is essential that the data type and 
data size is appropriate for ML-based ICE studies. This is critical for all 
the types of modeling, optimization, and control applications. 

Both the quality and the size of the data set need to be evaluated to 
make sure it is compatible with the ML method that is being used. Below, 
we  will  provide  a  discussion  about  the  quality  and  the  size  of  an 
appropriate data-set for ICE applications. 

High data quality for ML is data that has valuable information which 
provides  meaningful  insight  into  the  system  behavior  and  the  input- 
output  relations.  For  example,  for  high  quality  data  to  predict  the 
steady state engine-out NOx  emission of a diesel engine, the first step in 
selecting the data is to make sure that it is collected while the engine is 
operating at steady state conditions (steady state ICE coolant tempera-
ture, plateaued exhaust gas temperature, etc). Otherwise, using the data 
for training an ML-based steady state NOx  emission model decreases the 
model accuracy in predicting the desired output. Similarly, for devel-
oping dynamic ML-based models (e.g. for ICE control), the provided data 
must have the required quality to be used for ML. This includes having 
the adequate sampling frequency to capture the dynamic behavior of an 
ICE, considering the sensing lag, measurement delay, etc. Considering 
the  ICE  transient  NOx  prediction,  before  feeding  the  raw  measured 
transient data to a transient ML model to learn the dynamic engine-out 
NOx emission behavior, the emission measurement response time should 
be fast enough to capture the ICE dynamic behavior. In addition, the 
sensor lag, the engine to sensor gas transport delay need to be taken into 
account. All of these factors should be considered in processing the data 
before  being  used  for  developing  a  transient  ICE  emission  model. 
Providing  appropriate  data  for  dynamic  data-driven  models  is  not 
exclusive  to  ML-based  models  and  have  been  studied  in  decades  for 
black-box system identification approaches [401,402]. When it comes to 
data  for  dynamic  data-driven  models,  it  is  particularly  important  to 
determine  the  transient  input  signals  that  are  required  to  properly 
“excite” the ICE during the experiments for training the model [402]. To 
excite  the  ICE,  combinations  of  inputs  with  varying  amplitudes  and 
frequency content tailored to the particular ICE dynamics are required. 
Systematic data cleaning procedures should be carried out to ensure 
the  data  that  is  being  used  for  ML  has  a  sufficiently  high  quality, 
particularly when we are working with extremely large data sets. Two 
commonly  used approaches for  distinguishing the  valuable data from 
random  raw  data  are  feature  extraction  [291]  and  feature  selection 
[403]. These procedures can be carried out in conjunction with devel-
oping  ML-based  ICE  models.  Feature  extraction  is  the  process  of 
exploring the most important features from a larger number of candi-
dates  that  are  available  in  the  raw  data  set  and  typically  includes 
combining the current features to reduce the size of feature set [404]. 
Some  commonly  used  feature  extraction  methods  are  Principal 
Component  Analysis  (PCA)  [405],  Independent  Components  Analysis 
(ICA) [406], Linear Discriminant Analysis (LDA) [407], Locally Linear 
Embedding (LLE) [408], and different types of Autoencoders [409]. 

Feature  selection  is  a  similar  process  that  is  used  to  remove  less 

valuable  features  from  the  raw  data  but  does  not  include  feature 
modification [403]. For instance, in our previous work, we developed a 
correlation  based  model  order  reduction  (MOR)  to  select  the  most 
important features for a BMEP and NOx  control oriented diesel engine 
model [39]. Using this approach, we reduced the order of a 34-feature 
model to a 6-feature and a 9-feature model for BMEP and NOx  respec-
tively, while keeping the model accuracy within an acceptable range. 
Removing the less significant ML features by reducing the order of the 
model makes the data collection, data storage, and data processing more 
efficient as it provides a method for removing less valuable data from the 
large size data sets. 

The other important characteristic that affects the quality of the data 
is the data distribution. The data that is being used for training any ML- 
based model, should cover the whole ICE operating region that the ML 
algorithm  aims  to  model,  optimize,  or  control.  If  the  data  is  not 
distributed properly throughout the feature ranges, i.e. it is concentrated 
only around specific values of features, or does not cover a particular 
range,  it  is  called  imbalanced  data  [410].  Imbalanced  data  is  not 
appropriate for training ML models even if it has a sufficiently large size 
with all of the effective features [411]. 

4.3. Systematic decision tree for use of ML in ICEs 

Now that the most important ICE modeling, optimization, control, 
and  diagnostics  challenges  have  been  discussed  along  with  the  most 
promising  ML  approaches  to  address  them,  a  summary  of  the  main 
criteria and decision factors that can be used as a road map to select the 
most appropriate ML technique will be given. This systematic approach 
can also be used to trade-off performance versus cost and to remove less 
appropriate ML techniques for a specific application. 

First, let’s start with a flow chart shown in Fig. 22 that can be used as 
a systematic overview and a guideline for selecting an appropriate ML 
solution for  ICEs.  Depending on  the  type of  ICE  problem  that  we are 
looking  for  an  ML  solution  for,  one  can  use  supervised  learning  for 
classification  or  regression,  unsupervised  clustering,  reinforcement 
learning, or ML integration into conventional ICE control strategies. For 
example, if  an ICE  researcher is  looking for a  high-fidelity prediction 
model for a highly complex phenomenon (e.g., predicting engine com-
bustion  cyclic variability),  the  researcher can use multi-layer ANN  or 
SVM with a nonlinear kernel, providing a high volume of training data 
and high computational power is available. However, if a solution re-
quires high-speed adaptation to environmental changes (e.g., online ICE 
calibration), then ELM would be a recommended solution. Similarly, if 
someone needs to control an ICE variable while meeting hard constraints 
at the verge of stability (e.g., auto-ignition control of an HCCI engine 
close to its knock limit) ML integration into conventional ICE control 
strategies would be a recommended method over using RL. Particularly 
model-free  RL is  not recommended that requires substantial  trial  and 
error that can make the engine unstable. Now, let’s take a look at some 
important decision factors for selecting or not selecting an ML solution 
for an ICE problem. 

4.3.1. Decision factors 

Application 
As extensively discussed in Sections 2 and 3, the first step in defining 
the most appropriate ML approach to address ICE challenges is identi-
fying the application. Depending on the type of problem (e.g., ICE fault 
detection, performance prediction, or control), one can decide whether 
they  should  use  supervised  regression  or  classification,  unsupervised 
clustering,  or  reinforcement  learning  to  address  ICE  challenges,  as 
schematically summarized in Fig. 22. Once the category of the ML so-
lution is specified,  depending on the availability of  the training data, 
computational  power  of  the  ICE  control  unit,  and  complexity  of  the 
underlying phenomenon one can select a relevant and effective ML so-
lution.  More  detailed  comparison  about  ML  solutions  for  ICEs  is  pro-
vided in Section 2.4 and is summarized in Table  1. The information in 

ProgressinEnergyandCombustionScience88(2022)10096725M. Aliramezani et al.                                                                                                                                                                                                                          

Fig. 22. Systematic decision tree to select the most appropriate ML solutions for ICEs.  

these  sections  can  be  utilized  through  a  decision  algorithm  that  is 
summarized  in  Fig.  22.  For  example,  if  someone  wants  to  accurately 
predict engine-out emission levels, according to Fig. 22, they have to use 
a supervised learning regression and if they have a large enough volume 
of training data, their options will be narrowed down to a single layer or 
a multi layer ANN, SVM, ELM, or RVM. In practice, it can be difficult to 
assess the complexity of the underlying phenomena without evaluating 
the performance of the remained ML technique in predicting the desired 
variable (here, the engine out emission level). One can start with less 
computationally expensive approaches such as single layer ANN, SVM 
with  linear  kernel,  or  ELM  and  then  switch  to  more  computationally 
expensive solutions such as multi layer ANN and SVM with nonlinear 
kernel  if  the  prediction  performance  is  not  adequate.  Some  of  these 
recommended  approaches  for  each  ICE  application  are  explained  in 
more detail in Section 4.5 and summarized in Fig. 25. 

Data 
As discussed in Section 4.2, the most important factor that should be 
considered in selecting the most appropriate ML technique to address an 
ICE problem is the availability of high quality data (see Section 4.2 for 
more details about data quality). After making sure that at least mini-
mum data quality requirements are met, it is essential to make sure the 
data  volume  also  meets  the  requirement  of  the  ML-techniques  candi-
dates and their structure. For example, the available training data vol-
ume  must  be  taken  into  account  for  selecting  the  number  of  hidden 
layers or the type of the activation functions of all types of ANNs [412]. 

Memory 
Memory is another limitation that is dictated by the ECU hardware 
and should be considered as a trade-off factor in designing an ML so-
lution for ICEs. Memory limitations can particularly limit the batch size 
for online learning. For instance, consider an online batch processing 
ELM that is designed to optimally control the injection timing of a diesel 
engine  to  meet  emission  and  power  requirements.  The  batch  size, 
number of model inputs, number of hidden layers, and number of out-
puts, significantly affect the memory required to deploy and run the ML 
solution to address real-time ICE control problems. 

Memory limitation is also a great challenge for some complex non- 
batch  processing techniques.  For example,  one of the most  important 
challenges  in  using  DNNs  is  their  high  memory  requirements  [413] 
which limits the options for an ML designer particularly in addressing 
ICE challenges that are related to more complex phenomena. 

When it comes to selecting the most appropriate ML technique, the 
limitations in deployment on the ICE control unit should also be taken 
into  account.  More  complex  ML  techniques  are  typically  needed  to 
capture  more  complex  ICE  phenomena  which  then  leads  to  higher 
computational costs and memory requirements. However, the required 
accuracy  can  also  vary  depending  on  the  application.  For  example, 
consider  an  ML  technique  that  is  utilized  to  predict  the  in-cylinder 
pressure trace of the next combustion cycle. If the estimated pressure 
trace is used to predict the heat release rate curve or IMEP, the required 
accuracy would be less than the accuracy needed to predict the auto- 
ignition  time  or  knock  occurrence  in  the  next  cycle.  It  is  important 
that the ML method is designed for the required accuracy level in the ICE 
application by selecting a cost-effective approach. 

Deploying  ML  solutions  to  ICE  control  units  becomes  more  chal-
lenging when the phenomenon is complex and the required accuracy is 
also very high. One promising approach to reduce the complexity of ML 
techniques for ICEs is utilizing distributed learning. Through distributed 
learning,  one  can  split  the  training  data  into  smaller  clusters.  These 
clusters can then be utilized to build a global model. This approach will 
also  help  with  model  training  problems  associated  with  unevenly 
distributed data [414]. 

Computational cost 
The computational cost of utilizing ML is another important criterion 
that  has  to  be  considered  as  a  decision  factor  in  selecting  (or  not 
selecting)  an  ML  approach  for  ICEs.  This  factor  is  particularly  chal-
lenging for ICEs due to the computation power limitations of commer-
cial engine control units (ECUs) compared to stationary or cloud-based 
computers  [415]. As  discussed in Section 2.3, most of model-free  ML 
approaches  (including  model-free  RL)  have  high  computational  costs 
compared to model-based techniques due to the need for trial and error 
to find the global optima. The computational cost to run algorithms in 
real-time on the ECUs should be taken into account and these exclude 
the  computational  efforts  required  to  prepare  or  initialize  the  model. 
During  the  development  process,  the  computational  cost  should  be 
considered  as  a  constraint for  designing  the  ML-based  solution.  Typi-
cally, there is a trade-off between the computational constraints that are 
dictated by the hardware limitations and other objectives including the 
desired accuracy, and the acceptable latency [416]. 

4.3.2. When to use/ not use ML 

Complexity of the phenomenon and the required accuracy 

As  discussed  in  the  previous  sections,  many  factors  should  be 

ProgressinEnergyandCombustionScience88(2022)10096726M. Aliramezani et al.                                                                                                                                                                                                                          

considered to select an ML solution for ICEs. Section 4.5 provides a more 
detailed  discussion  and  a  road  map  for  selecting  the  ML  techniques 
based on the ICE applications. Some use cases are difficult to address 
using ML, at least with the current infrastructure and hardware limita-
tions.  To  identify  these  cases,  one  needs  to  consider  the  four  factors 
discussed in Section 4.3.1. If any of the factors such as required data 
quality/volume,  computational  cost  limitations,  memory  limitations, 
and the balance between the phenomena and required accuracy are not 
met  by  a  proposed  ML  solution/method,  then  that  ML  method  is  not 
recommended for ICEs. To provide a deeper insight into the factors listed 
in Section 4.3.1, some examples are provided here. 

Consider  the  following  ICE  modeling  and  diagnostics  challenges: 
Transient emission prediction; Steady state emission modeling; Knock 
prediction, and Knock detection. 

When an ML technique is used for transient emission prediction, it 
involves more complex phenomena compared to predicting the steady 
state  emission  level  at  each  ICE  operating  condition.  Although  the 
required  accuracy  for  each  application  can  be  the  same,  predicting 
transient emissions requires a higher computational effort and memory 
capacity. In another example, the ML approach required to detect knock 
for  the  current  cycle  based  on  the  current  in-cylinder  pressure  curve 
requires less computational cost compared to an ML-based model that is 
supposed  to  predict  knock  occurrences  in  the  next  cycle.  The  main 
reason is that knock detection can take place using a pre-trained model- 
based classification approach with in-cylinder pressure curve as its main 
input.  While  for  knock  prediction,  an  adaptive  model  with  a  higher 
number of inputs is needed which requires a higher computational effort 
and  memory.  Please  see  Section  3.1.3  for  more  details  about  knock 
detection  and  prediction.  Now,  let’s  compare  online  and  offline  cali-
bration as two other examples: 

Many types of offline learning approaches can be used to perform 
offline calibration (see Section 3.2.1), as long as the appropriate training 
data is provided and the ML model is capable of capturing the desired 
input-output relation. The processing time and the computational costs 
associated  with  offline  learning  are  not  limited  by  the  ECU  since  the 
training process can be done in advance and then the trained model is 
loaded on the ECU. However, online ML-based calibration requires more 
computational  effort and  memory compared to offline  ML-based cali-
bration due to the need for continuous training and adaptive learning in 
real-time while the ICE is running. 

4.4. Grey-box ML-based ICE modeling and control platform 

Black-box ML-based models are typically less capable of adapting to 
not-trained system variations or environment disturbances compared to 
physics-based models unless these changes have been considered as ML- 
based model features. In addition, black-box models do not necessarily 
include  the  effect  of  ICE  design  parameters  which  makes  them  less 
capable  of  adapting  to  any  changes  in  the  engine  design  or  the  ICE 
components. For example, a black-box regression model that estimates 
the engine output torque as a function of injected fuel amount, injection 
timings and engine speed, is not capable of capturing the effect of in- 
cylinder geometry changes on the estimated output torque, unless the 
model  is  trained  again  with  the  new  system.  Pure  physics-based  ICE 
models also have challenges in accurately capturing complex combus-
tion phenomena for broad operating conditions as discussed in Section 
3.1.1. Grey-box ICE models can combine the advantages of both physics- 
based models and black-box models [23]. 

Grey-box models can have a black-box structure with a few physics- 
based  components  or  they can benefit  from a  physics-based  structure 
with  a  few  black-box  submodels  to  calculate  internal  variables.  For 
example, most of physics-based phenomenological models have one or 
more tuning parameters that should be calibrated using experimental 
data  points  as  is  the  case  for  these  ICE  models [258–260].  The  other 
group  of  grey-box  models  have  a  data-driven  structure  for  which  the 
internal  variables  are  calculated  using  physics-based  submodels  [19, 

261]. For example, in the grey-box model in [19], a physical CI engine 
model is sequentially combined with two FFNN models to estimate the 
IMEP,  combustion  phasing,  and  the  exhaust  gas  temperature [19].  In 
another  study  [238],  a  physics-based  structure  with  black-box  data--
driven submodels is developed to calculate combustion efficiency as an 
internal  variable.  This  internal  variable  was  then  used  to  develop  a 
grey-box control oriented model for an HCCI engine. 

In one of our previous studies [29], a grey-box model was developed 
to simulate and control an ICE using a sequential grey-box structure. The 
developed  grey-box  model  predicted  combustion  phasing  (CA50p), 
adiabatic flame temperature (Tad), exhaust gas temperature (Texh), and 
IMEPp  by  using  a  physics-based  model.  Then  the  outputs  of  the 
physics-based  model  were  fed  into  ANN-based  models  to  predict 
engine-out emissions (Fig. 23). 

The activation function used in [29] is a hyperbolic-tangent sigmoid. 
The Mean Squared Error (MSE) is selected as the cost function of the 
model for all the outputs. After investigating the training performance 
including  trade-off  between  the  model  complexity  and  accuracy,  25 
neurons and one hidden layer are selected for the ANN section of the 
grey-box  model.  Table  2  shows  the  grey-box  model  performance  in 
comparison with the black-box and the physics-based model. The results 
summary of the three types of models listed in Table 2 demonstrates that 
the  grey-box  model  has  a  better  prediction  performance  for  the 
engine-out  (CO,  NOx,  and  THC)  emissions  compared  to  both 
physics-based and black-box models. As illustrated in Table 2, the RMSE 
of  the  grey-box  model  was  significantly  less  than  the  RMSE  of  the 
black-box and the physics-based models. The grey-box model has also 
shown a more consistent prediction as its standard deviation (STD) of 
prediction error is less than the black-box and physics-based models. 

A multi-objective optimization algorithm including Non-dominated 
Sorting  Genetic  Algorithm  -  NSGA  from  [417]  was  then  used  for  en-
gine calibration through the grey-box structure in [29] to find optimum 
combustion  phasing  for  the  engine  to  minimize  engine-out  emissions 
while providing the required IMEP. 

A computational fluid dynamics (CFD) - based model with ANN is 
used to develop a grey-box model to the gaseous emissions and com-
bustion  efficiency  of  a  CI  engine  [63].  A two  layer  ANN  was  used  to 
predict the ignition delay as a function of engine operating parameters 
including residual gas fraction, air-fuel ratio, in-cylinder gas pressure, 
and in-cylinder gas temperature. The CFD-ANN (KIVA3V-ANN) model is 
then  used  to  predict  in-cylinder  gas  pressure  trace,  combustion  effi-
ciency, as well as the concentration of CO2, CO, HC, and oxygenated 
hydrocarbons  (OHC)  emissions.  They  concluded  that  the  CFD-ANN 
model can provide accurate predictions for a CI engine with only 10% 
more  computational  effort  compared  to  a  conventional  KIVA3V  run 
[63]. 

In these examples the grey-box approach offers better performance 
in  ICE  modeling  compared  to  both  black-box  and  physics-based  ap-
proaches. Therefore, grey-box method is recommended as an efficient 
approach for use in modeling and optimization of ICEs. To provide a 
more clear picture of this recommendation, a sample grey-box platform 
is proposed in Fig. 24 for modeling and control of a compression ignition 
engine. In this platform, first principle models are used to predict engine 
parameters  including burn  duration  (BD), CA50, and  IMEP for  which 
accurate physical models are available. Then the inputs from the phys-
ical models are used along with the engine data to predict the complex 
engine operating parameters such as COVIMEP  and engine-out unburned 
hydrocarbons.  The  proposed  grey-box  model  can  be  modified  and 
generalized for use in different types of ICEs. 

The  grey-box  approach  will  particularly  be  useful  for  control  and 
calibration  applications  as  it  provides  a  combined  physics-based  and 
data-driven  cause-effect  insight  into  the  effective  intermediate  com-
bustion variables that can affect the desired ICE outputs. For instance, 
let’s assume that an ICE control strategy aims to reduce the engine-out 
NOx  emission while keeping other gaseous emissions under an accept-
able range via emission trade-off. This will require accurate monitoring 

ProgressinEnergyandCombustionScience88(2022)10096727M. Aliramezani et al.                                                                                                                                                                                                                          

Fig.  23. Architecture  of  the  grey-box  engine  model  to  predict  engine-out  emissions  and  combustion  related  (CA50,  IMEP)  metrics.  Reprinted  from  [29]  with 
permission of Elsevier. The physics-based submodel calculates the estimated CA50, IMEP, adiabtic flame temperature (Tad), and exhaust gas temperature (Texhp) 
which are then fed to an ANN model to increase the accuracy of CA50 and IMEP predictions. These predictions are then used to predict Texh  and engine-out emissions. 

Table 2 
Summary  of  grey-box,  physics-based,  and  black-box  models  performance  in 
predicting engine emissions, combustion phasing (CA50), exhaust gas temper-
ature (Texh), and IMEP [29].  

Type of Model 

Parameter 

STD of Error 

RMSE  

Clear-box 
(Physics based) 

Black-box only 

Grey-box 

CA50 [CAD] 
IMEP [bar] 
Texh [o C]  

NOx [PPM] 
CO [%] 
THC [PPM] 
CA50 [CAD] 
IMEP [bar] 
Texh [oC]  

NOx [PPM] 
CO [%] 
THC [PPM] 
CA50 [CAD] 
IMEP [bar] 
Texh [oC]  

NOx [PPM] 
CO [%] 
THC [PPM] 

3.1 
1.7 
17.0 

- 
- 
- 
2.9 
0.7 
10.0 

11 
0.14 
1054 
0.8 
0.1 
5.0 

4 
0.03 
333 

4.1  
1.30  
21.0 

- 
-  
-  
2.9  
0.50  
13.3 

12  
0.18  
1210  
0.8  
0.20 
5.3  

4  
0.03  
394  

of emissions via predictive models and control of combustion charac-
teristics, such as combustion phasing, burn duration, and pressure rise 
rate. The grey-box approach in Fig. 24 can provide this information in 
real-time and use it as features of the ML-based model which leads to a 
more reliable and efficient NOx  emission control strategy. 

4.5. Recommendations for using promising ML methods to address ICE 
challenges 

The core parts of the recommended grey-box platform (Section 4.4) 
center on the selection of appropriate ML methods. The ML methods are 
classified into  three main  categories of  supervised, unsupervised, and 
reinforcement learning. Although different ML methods have been used 

for  ICE  applications  in  all three  ML categories, the  main  focus of  the 
literature has been on the supervised learning applications. The unsu-
pervised learning methods are mainly focused on component diagnostics 
while the reinforcement learning approach has not been widely used. 

Amongst all the supervised learning algorithms, ANN is utilized the 
most by the ICE researchers to predict engine performance and emis-
sions. Although ANN provides a powerful tool to learn the most complex 
combustion  engine  phenomenon,  its  disadvantages  (the  risk  of  over-
fitting or converging to local minima) have not been sufficiently studied 
for  ICE  applications.  Benchmark  studies  of  different  ML  methods  to 
address the existing ICE modeling, control and optimization challenges 
are needed. For instance, the performance of ANN, SVM, RVM, GP, and 
RKHS  in  modeling  the  complex  combustion  phenomenon  must  be 
evaluated  for  different  applications  including:  the  required  data  size, 
model training accuracy, model prediction accuracy, required memory 
size,  training/learning  time  and  capability  of  online  learning,  and 
capability of distribution prediction. 

Promising ML approaches used for different ICE applications were 
discussed in this paper along with their advantages and disadvantages 
(Table  1).  Based  on  these  discussions,  the  most  promising  ML  ap-
proaches to address the challenges in ICE modeling, diagnostics, control 
and  calibration  are  summarized  in  Fig.  25  and  explained  in  the 
following. 
Knock 
ANN  based  and  SVM  based  classification  are  both  promising  for 
knock detection. SVM has also shown promising performance in offline 
prediction of auto-ignition by using engine inputs and fuel characteris-
tics. One of the most important SVM design parameters that needs more 
investigation before being used for auto-ignition prediction or detection, 
is  the  kernel  design  parameters.  For  example,  if  a  Gaussian  kernel  is 
being used for auto-ignition detection, the kernel parameters must be 
selected in a way that the decision boundaries are narrow and accurate. 
Too large kernel widths results in reduced decision boundary precision 
as it becomes more difficult to capture the complexity of auto-ignition 
prediction. Too small a kernel width can make the kernels ineffective 
and will increase the chance of over fitting. 

ProgressinEnergyandCombustionScience88(2022)10096728M. Aliramezani et al.                                                                                                                                                                                                                          

Fig. 24. A proposed example for greybox modeling platform for control and calibration of a dual fuel compression ignition engine.  

More  studies  need  to  be  carried  out  on  the  online  learning  of  the 
auto-ignition  using  powerful  online  ML  techniques  particularly  ELM. 
This will help capturing the effect of environmental disturbances such as 
fuel  variations  on  knock  and  auto-ignition.  ELM  should  be  tested  for 
both  online  knock  detection,  and  auto-ignition  characteristics 
prediction. 

It should also be noted that most of the studies carried out on knock 
or  auto-ignition are  more focused on  detection techniques  rather than 
simulating the auto-ignition phenomena or predicting the auto-ignition 
timing. The improvements in knock detection with ML-based techniques 
are useful for SI engine knock control and optimization. Kernel based 
SVM  and  ELM  are  appropriate  choices  for  offline  and  online  auto- 
ignition prediction, respectively. This could be of utility for ICEs that 
rely on controlled auto-ignition such as HCCI engines or for fuels such as 
H2 to avoid unwanted pre-ignition. 

Emission formation 
Three  main  recommendations  for  ML-based  emission  prediction 
include:  i)  ANN,  SVM  regression,  and  kernel  based  ELM  are  the  best 
candidates  for  steady  state  emission  prediction.  ii)  Developing  online 
ELM  based  learning  techniques  trained  with  fast  response  emission 
sensors will be an important step towards emission formation simulation 
and transient emission reduction iii) RVM is a promising approach for 
ICE emission trade-off optimization. 

Combustion noise 
ANNs and SVMs both can capture the nonlinearity between engine 
control inputs and combustion characteristics with an acceptable accu-
racy. Similar ML-based techniques can take combustion noise charac-
teristics as inputs of a supervised or unsupervised classification model. 
The results can be used for engine fault diagnostics. ELM based adaptive 
models can be utilized in the future studies to correlate cyclic combus-
tion  noise  to  important  combustion  characteristics  including  auto- 
ignition and combustion stability. 

Combustion  instability  and  cyclic  combustion  variability 

control 

The  most  promising  ML-based  regression  approaches  to  predict 
combustion instability limits and combustion cyclic variability control 
include  ANN  and  SVM.  Another  approach  that  has  shown  promising 
preliminary results in accurately predicting combustion characteristics 
and  provides  a  potential  solution  for  cyclic  combustion  variability 
control, is the online deep learning (ODL) approach [418]. ODL models 
are  multi-layer  ANNs that  are capable of  learning extremely complex 
input-output  relations.  Utilizing  ODL  for  ICEs  requires  a  high 

computational  effort  that  is  challenging  for  the  available  production 
ECUs [418]. However, as the computation power and memory capacity 
of  ECUs  improve,  they  will  become  more  capable  of  including  more 
complex ML-based techniques. ODLs require larger data size and higher 
computational effort compared with conventional ANNs. Designing an 
efficient  ODL  with  high  accuracy  and  without  over  fitting  requires  a 
deep ML knowledge and further ICE studies. Peer-to-peer ICE learning 
and access to powerful ad-hoc network for data processing can facilitate 
utilizing more complex ML methods such as ODL. 

The summary of recommended ML methods, shown in Fig. 25, pro-
vides an initial road map for ICE researchers who are interested in utilizing 
ML for ICE applications. According to the recommended roadmap shown 
in Fig. 25, ANN, SVM, and RVM methods are capable of modeling the 
most complex ICE phenomenon, if a sufficiently large data set is pro-
vided from the experiments and more importantly if the most effective 
features  are  observed,  selected,  and  included  in  the  training  process. 
However, when it comes to online learning and online engine calibra-
tion, ELM shows promising performance. 

Making smart decisions in selecting the most important features to 
model,  optimize  or  control  the  desired  ICE  phenomena  is  a  first  and 
essential  step  in  machine  learning  of  ICEs  for  accurate  and  reliable 
machine  learning  -  based  prediction  or  control.  Advanced  feature  se-
lection methods can be employed to develop a more efficient machine 
learning model. In addition, the available physical understandings of the 
ICE phenomenon can be used to select the most appropriate features and 
to  improve  the  performance  of  black-box  models  by  combining  ML/ 
Physics in a grey box model. 

5. Summary and conclusions 

Applications of ML to address the existing ICE modeling, optimiza-
tion, control, and diagnostics challenges were discussed in this paper. 
First,  the  conventional  ICE  modeling  approaches  are  explained  along 
with their limitations. To address ICE challenges, particularly to meet 
the upcoming stringent emission regulations and to minimize ICE fuel 
consumption,  new  advanced  methods  are  needed.  State-of-the-art  ML 
techniques for ICEs were explained in Section 2. These methods were 
summarized in Table 1 and categorized in three main groups of super-
vised learning, unsupervised learning, and reinforcement learning. 

Then the ML-based solutions to address a wide range of existing ICE 
modeling, optimization, and control challenges were discussed in detail. 
The  areas  discussed  are:  1)  Combustion  knock  and  auto-ignition 

ProgressinEnergyandCombustionScience88(2022)10096729M. Aliramezani et al.                                                                                                                                                                                                                          

Fig.  25. Recommendations  on  the  best  ML  approaches  to  address  ICE  combustion  modelling  and  control  challenges.  Solid  blocks:  Challenges,  Dashed  blocks: 
Recommended methods. 

detection and control; 2) Emission formation modeling and optimiza-
tion;  3)  Combustion  mode  transition  in  multi-mode  engines;  4)  Com-
bustion noise modeling and control; 5) Combustion instability and cyclic 
combustion variability control; 6) ICE optimization and calibration with 
ML; 7) ICE component fault diagnostics. The most promising ML-based 
techniques for each of these seven areas were described. This was done 
to  provide  insight  into  possible  methods  that  can  be  utilized  in  the 
future. 

For  many  ICE  applications,  a  grey-box  modeling  approach  is  rec-
ommended. This is a promising method to address the challenges of ICE 
modeling and control. A grey-box platform is advantageous over a black- 
box (data-driven) platform since existing accurate physical models to be 
used but extends them for increased fidelity of the engine modeling and 
its operation range. Details were provided in Section 4.4. 

ML  has  a  high  potential  to  further  enhance  the  performance  and 
reduce the emissions of ICEs. The approaches, limitations, and oppor-
tunities that were discussed in this study provide an insight into future 

directions of utilizing ML for ICEs. The use of these techniques requires 
knowledge of both machine learning and ICE engine physics and oper-
ation. Future study is required to quantify the total benefits of ML for 
production ICEs to reduce the development and calibration efforts, and 
to  enable  fully  optimal  and  robust  ICE  operation  for  broad  operating 
conditions. 

CRediT authorship contribution statement 

Masoud Aliramezani: Conceptualization, Writing –  original draft, 
Data curation, Visualization. Charles Robert Koch: Writing – review & 
editing.  Mahdi  Shahbakhti:  Supervision,  Conceptualization,  Data 
curation, Visualization, Writing – review & editing. 

Declaration of Competing Interest 

None. 

ProgressinEnergyandCombustionScience88(2022)10096730M. Aliramezani et al.                                                                                                                                                                                                                          

References 

[1] Mahdavinejad M, Rezvan M, Barekatain M, Adibi P, Barnaghi P, Sheth A. 
Machine learning for internet of things data analysis: a survey. Digital 
Communications and Networks 2018;4(3):161–75. 

[2] Cabitza F, Rasoini R, Gensini G. Unintended consequences of machine learning in 
medicine. JAMA 2017;318(6):517–8.https://jamanetwork.com/journals/jama/a 
rticlepdf/2645762/jama_cabitza_2017_vp_170094.pdf 

[3] Bishop C. Pattern recognition and machine learning. chapter 6. Springer; 2006. 
[4] Witten I, Frank E, Hall MA, Pal C. Data mining: practical Machine Learning Tools 

and techniques. Chapters 6 and 7. Morgan Kaufmann; 2016. 

[5] Baker R. Data mining for education. International encyclopedia of education 

2010;7(3):112–8. 

[6] Heaton J, Polson N, Witte J. Deep learning for finance: deep portfolios. Appl 

Stoch Models Bus Ind 2017;33(1):3–12. 

[7] Bose I, Mahapatra R. Business data mining a machine learning perspective. 

Information & management 2001;39(3):211–25. 

[8] Chen F, Ou T. Sales forecasting system based on Gray extreme learning machine 

with taguchi method in retail industry. Expert Syst Appl 2011;38(3):1336–45. 

[9] Rafiei M, Adeli H. A novel machine learning model for estimation of sale prices of 

real estate units. J Constr Eng Manag 2015;142(2):04015066. 

[10] Thangaraja J, Kannan C. Effect of exhaust gas recirculation on advanced diesel 
combustion and alternate fuels - a review. Appl Energy 2016;180:169–84. 
[11] Yusri I, Majeed AA, Mamat R, Ghazali M, Awad OI, Azmi W. A review on the 
application of response surface method and artificial neural network in engine 
performance and exhaust emissions characteristics in alternative fuel. Renewable 
Sustainable Energy Rev 2018;90:665–86. https://doi.org/10.1016/j. 
rser.2018.03.095.http://www.sciencedirect.com/science/article/pii/S1364032 
118301916 

[12] Silitonga A, Masjuki H, Ong HC, Sebayang A, Dharma S, Kusumo F, et al. 
Evaluation of the engine performance and exhaust emissions of biodiesel- 
bioethanol-diesel blends using kernel-based extreme learning machine. Energy 
2018;159:1075–87. https://doi.org/10.1016/j.energy.2018.06.202.http://www. 
sciencedirect.com/science/article/pii/S0360544218312672 

[13] Wong P, Gao X, Wong K, Vong CM. Online extreme learning machine based 

modeling and optimization for point-by-point engine calibration. 
Neurocomputing 2018;277:187–97. 

[14] Wong PK, Wong KI, Vong CM, Cheung CS. Modeling and optimization of biodiesel 

engine performance using kernel-based extreme learning machine and cuckoo 
search. Renew Energy 2015;74:640–7. https://doi.org/10.1016/j. 
renene.2014.08.075.http://www.sciencedirect.com/science/article/pii/ 
S096014811400545X 

[15] Irdmousa BK, Rizvi SZ, Velni JM, Naber JD, Shahbakhti M. Data-driven modeling 
and predictive control of combustion phasing for RCCI engines. American Control 
Conference 2019. 

[16] Norouzi A, Gordon D, Aliramezani M, Koch CR. Machine learning-based diesel 

engine-out NOx reduction using a plug-in PD-type iterative learning control. 4th 
IEEE Conference on Control Technology and Applications (CCTA 2020) 2020. 

[17] Cranmer A, Shahbakhti M, Hedrick J. Grey-box modeling architectures for 
rotational dynamic control in automotive engines. 2012 American Control 
Conference (ACC). IEEE; 2012. p. 1278–83. 

[18] Bahri B, Aziz AA, Shahbakhti M, Said MM. Artificial neural network model for 
predicting exhaust temperature of an ethanol-Fueled HCCI engine. May 23–25 
JSAE Annual Congress, Yokohama, Japan 2012. 

[19] Bidarvatan M, Shahbakhti M. Gray-box modeling for performance control of an 
HCCI engine with blended fuels. J Eng Gas Turbine Power 2014;136(10):101510. 
[20] Bidarvatan M, Thakkar V, Shahbakhti M. Grey-box modeling and control of HCCI 

engine emissions. 2014 American Control Conference. IEEE; 2014. p. 837–42. 

[21] Ghazimirsaied A, Shahbakhti M, Koch C. HCCI Engine combustion phasing 

prediction using a symbolic-Statistics approach. J Eng Gas Turbine Power 2010; 
132(8). https://doi.org/10.1115/1.4000297.http://link.aip.org/link/?GTP/132 
/082805/1 

[22] Bidarvatan M, Shahbakhti M, Jazayeri SA. Model-based control of combustion 

phasing in an HCCI engine. SAE Int J Engines 2012;5(3):1163–76. 
[23] Bidarvatan M, Shahbakhti M. Grey-box modeling for HCCI engine control. 

Proceedings of the ASME 2013 Internal Combustion Engine Division Fall 
Technical Conference, ASME Paper No ICEF2013-19097 2013. 

[24] Bahri B, Aziz A, Shahbakhti M, Muhamad Said M. Understanding and detecting 

misfire in an HCCI engine fuelled with ethanol. Appl Energy 2013;108:24–33. 

[25] Bahri B, Aziz A, Shahbakhti M, Muhamad Said M. Analysis and modeling of 

exhaust gas temperature in an ethanol fuelled HCCI engine. J Mech Sci Technol 
2013;27(11):3531–9. 

[26] Fathi M, Jahanian O, Shahbakhti M. Modeling and controller design architecture 
for cycle-by-cycle combustion control of homogeneous charge compression 
ignition (HCCI) engines–a comprehensive review. Energy Convers Manage 2017; 
139:1–19. 

[27] Bidarvatan M, Shahbakhti M. Two-input two-output control of blended fuel HCCI 

engines 2013;SAE Paper 2013-01-1663. 

[28] Bidarvatan M, Shahbakhti M, Jazayeri S, Koch C. Cycle-to-cycle modeling and 
sliding mode control of blended-fuel HCCI engine. Control Eng Pract 2014;24: 
79–91. 

[29] Bidarvatan M, Thakkar V, Shahbakhti M, Bahri B, Aziz A. Grey-box modeling of 

HCCI engines. Appl Therm Eng 2014;70:397–409. 

[30] Rezaei J, Shahbakhti M, Bahri B, Aziz A. Performance prediction of HCCI engines 

with oxygenated fuels using artificial neural networks. Appl Energy 2015;138: 
460–73. 

[31] Bahri B, Shahbakhti M, Kannan K, Aziz AA. Identification of ringing operation for 

low temperature combustion engines. Appl Energy 2016;171:142–52. 

[32] Bahri B, Shahbakhti M, Aziz A. Real-time modeling of ringing in HCCI engines 
using artificial neural networks. Energy 2017;125:509–18. https://doi.org/ 
10.1016/j.energy.2017.02.137.http://www.sciencedirect.com/science/article/ 
pii/S0360544217303201 

[33] Ma X, Chigan T, Shahbakhti M. Connected vehicle based distributed meta- 

learning for online adaptive engine/powertrain fuel consumption modeling. IEEE 
Trans Veh Technol 2020:1. 

[34] Basina L, Irdmousa B, Velni JM, Naber J, Borhan H, Shahbakhti M. Support vector 
machine based data driven modeling and adaptive control of maximum pressure 
rise rate in RCCI engines. IEEE Conference on Control Technology and 
Applications (CCTA 2020) 2020. 

[35] Basina LA, Irdmousa B, Velni JM, Borhan H, Naber J, Shahbakhti M. Data-driven 
modeling and predictive control of maximum pressure rise rate in RCCI engines. 
The 4th IEEE Conference on Control Technology and Applications (CCTA) 2020. 

[36] Bao Y, Velni JM, Basina A, Shahbakhti M. Identification of state-space linear 
parameter-varying models using artificial neural networks. International 
Federation of Automatic Control (IFAC) World Congress 2020. 

[37] Aliramezani M, Norouzi A, Koch CR. Support vector machine for a diesel engine 
performance and NOx emission control-oriented model. 21st IFAC World 
Congress in Berlin, Germany 2020. 

[38] Aliramezani M, Norouzi A, Koch C. A grey-box machine learning based model of 
an electrochemical gas sensor. Sens Actuators, B 2020;321:128414. https://doi. 
org/10.1016/j.snb.2020.128414.http://www.sciencedirect.com/science/article/ 
pii/S0925400520307590 

[39] Norouzi A, Aliramezani M, Koch CR. A correlation based model order reduction 
approach for a diesel engine NOx and BMEP dynamic model using machine 
learning. Int J Engine Res 2020. 

[40] Batool S, Naber J, Shahbakhti M. Data-Driven modeling and control of cyclic 

variability of an engine operating in low temperature combustion modes. IFAC 
Modeling, Estimation and Control Conference (MECC), Austin, TX, USA 2021. 

[41] Shahpouri S, Norouzi A, Hayduk C, Rezaei R, Shahbakhti M, Koch C. Soot 

emission modeling of a compression ignition engine using machine learning. IFAC 
Modeling, Estimation and Control Conference (MECC), Austin, TX, USA 2021. 
[42] Irdmousa BK, Naber J, Velni JM, Borhan H, Shahbakhti M. Input-output Data- 
driven Modeling and MIMO Predictive Control of an RCCI Engine Combustion. 
IFAC Modeling, Estimation and Control Conference (MECC), Austin, TX, USA 
2021. 

[43] Makridakis S. The forthcoming artificial intelligence (AI) revolution: its impact on 

society and firms. Futures 2017;90:46–60. 

[44] Reitz R.D., Ogawa H., Payri R., Fansler T., Kokjohn S., Moriyoshi Y., et al. IJER 

editorial: the future of the internal combustion engine. 2020. 

[45] Paul A, Bhowmik S, Panua R, Debroy D. Artificial neural network-based 

prediction of performances-exhaust emissions of diesohol piloted dual fuel diesel 
engine under varying compressed natural gas flowrates. J Energy Resour Technol 
2018;140(11):112201. 

[46] Bhowmik S, Paul A, Panua R, Ghosh SK, Debroy D. Performance-exhaust emission 

prediction of diesosenol fueled diesel engine: an ANN coupled MORSM based 
optimization. Energy 2018;153:212–22. 

[47] Bouselham L, Hajji M, Hajji B, Bouali H. A new MPPT-based ANN for photovoltaic 
system under partial shading conditions. Energy Procedia 2017;111:924–33. 
https://doi.org/10.1016/j.egypro.2017.03.255.8th International Conference on 
Sustainability in Energy and Buildings, SEB-16, 11–13 September 2016, Turin, 
Italy 

[48] Azman M, Aris J, Hussain Z, Samat A, Nazelan A. A comparative study of fuzzy 
logic controller and artificial neural network in speed control of separately 
excited dc motor. 2017 7th IEEE international conference on control system, 
computing and engineering (ICCSCE). IEEE; 2017. p. 336–41. 

[49] Turkson RF, Yan F, Ali M, Hu J. Artificial neural network applications in the 

calibration of spark-ignition engines: an overview. Engineering Science and 
Technology, an International Journal 2016;19(3):1346–59. 

[50] Malikopoulos AA, Papalambros PY, Assanis DN. A learning algorithm for optimal 

internal combustion engine calibration in real time. ASME 2007 international 
design engineering technical conferences and computers and information in 
engineering conference. American Society of Mechanical Engineers Digital 
Collection; 2009. p. 91–100. 

[51] Wong KI, Wong PK. Optimal calibration of variable biofuel blend dual-injection 
engines using sparse Bayesian extreme learning machine and metaheuristic 
optimization. Energy Convers Manage 2017;148:1170–8. 

[52] Bao Y, Velni JM, Shahbakhti M. Epistemic uncertainty quantification in state- 
space LPV model identification using Bayesian neural networks. IEEE Control 
Systems Letters 2020;5(2):719–24. 

[53] Rezaei R, Hayduk C, Alkan E, Kemski T, Delebinski T, Bertram C. Hybrid 
phenomenological and mathematical-based modeling approach for diesel 
emission prediction. Tech. Rep. SAE Technical Paper; 2020. 

[54] Afonso JA, Sousa RA, Ferreira JC, Monteiro V, Vitor P, Pedrosa D, Afonso JL. IoT 

system for anytime/anywhere monitoring and control of vehicles’ parameters. 
2017 IEEE international conference on service operations and logistics, and 
informatics (SOLI). IEEE; 2017. p. 193–8. 

[55] Silitonga AS, Masjuki HH, Ong HC, Sebayang AH, Dharma S, Kusumo F, et al. 
Evaluation of the engine performance and exhaust emissions of biodiesel- 
bioethanol-diesel blends using kernel-based extreme learning machine. Energy 
2018;159:1075–87. 

ProgressinEnergyandCombustionScience88(2022)10096731M. Aliramezani et al.                                                                                                                                                                                                                          

[56] Janakiraman VM, Nguyen X, Assanis D. Stochastic gradient based extreme 

learning machines for stable online learning of advanced combustion engines. 
Neurocomputing 2016;177:304–16. 

[57] Janakiraman VM, Nguyen X, Sterniak J, Assanis D. A system identification 

framework for modeling complex combustion dynamics using support vector 
machines. Cham: Springer International Publishing; 2014, ISBN 978-3-319- 
03500-0. p. 297–313. 

[58] Wong KI, Wong PK, Cheung CS, Vong CM. Modelling of diesel engine 

performance using advanced machine learning methods under scarce and 
exponential data set. Appl Soft Comput 2013;13(11):4428–41. https://doi.org/ 
10.1016/j.asoc.2013.06.006.http://www.sciencedirect.com/science/article/pii/ 
S1568494613001956 

[59] Berger B, Rauscher F. Robust gaussian process modelling for engine calibration. 

IFAC Proceedings Volumes 2012;45(2):159–64. 

[60] Berger B, Rauscher F, Lohmann B. Analysing gaussian processes for stationary 

black-box combustion engine modelling. IFAC Proceedings Volumes 2011;44(1): 
10633–40. 

[61] Castric S, Denis-Vidal L, Cherfi Z, Blanchard GJ, Boudaoud N. Modeling pollutant 
emissions of diesel engine based on kriging models: a comparison between 
geostatistic and gaussian process approach. IFAC Proceedings Volumes 2012;45 
(6):1708–15. 

[62] Choi Y, Chen J-Y. Fast prediction of start-of-combustion in HCCI with combined 
artificial neural networks and ignition delay model. Proc Combust Inst 2005;30 
(2):2711–8. 

[63] Aceves SM, Flowers DL, Chen J-Y, Babajimopoulos A. Fast prediction of HCCI 
combustion with an artificial neural network linked to a fluid mechanics code. 
Tech. Rep. SAE Technical Paper; 2006. 

[64] Janakiraman VM, Nguyen X, Assanis D. Nonlinear identification of a gasoline 

HCCI engine using neural networks coupled with principal component analysis. 
Appl Soft Comput 2013;13(5):2375–89. 

[65] Pontoppidan NH, Larsen J. Unsupervised condition change detection in large 

diesel engines. 2003 IEEE XIII workshop on neural networks for signal processing 
(IEEE Cat. No. 03TH8718). IEEE; 2003. p. 565–74. 

[66] Chan T, Chin C. Data analysis to predictive modeling of marine engine 

performance using machine learning. 2016 IEEE region 10 conference (TENCON). 
IEEE; 2016. p. 2076–80. 

[67] Laukonen E, Passino K, Krishnaswami V, Luh G, Rizzoni G. Fault detection and 
isolation for an experimental internal combustion engine via fuzzy identification. 
IEEE Trans Control Syst Technol 1995;3(3):347–55. 

[68] Wang Y, Ma Q, Zhu Q, Liu X, Zhao L. An intelligent approach for engine fault 

diagnosis based on hilbert–huang transform and support vector machine. Applied 
acoustics 2014;75:1–9. 

[81] Shin S, Lee Y, Kim M, Park J, Lee S, Min K. Deep neural network model with 
Bayesian hyperparameter optimization for prediction of NOx at transient 
conditions in a diesel engine. Eng Appl Artif Intell 2020;94:103761. 

[82] Rychetsky M, Ortmann S, Glesner M. Support vector approaches for engine knock 
detection. IJCNN’99. International Joint Conference on Neural Networks. 
Proceedings (Cat. No.99CH36339). 2; 1999969–974 vol.2. https://doi.org/ 
10.1109/IJCNN.1999.831085. 

[83] Widodo A, Yang B-S. Support vector machine in machine condition monitoring 
and fault diagnosis. Mech Syst Signal Process 2007;21(6):2560–74. https://doi. 
org/10.1016/j.ymssp.2006.12.007.http://www.sciencedirect.com/science/artic 
le/pii/S0888327007000027 

[84] Vaughan A, Bohac S. Real-time, adaptive machine learning for non-stationary, 

near chaotic gasoline engine combustion time series. Neural Networks 2015;70: 
18–26. https://doi.org/10.1016/j.neunet.2015.04.007.http://www.sciencedirec 
t.com/science/article/pii/S0893608015000878 

[85] Sebayang A, Masjuki H, Ong HC, Dharma S, Silitonga A, Kusumo F, et al. 

Prediction of engine performance and emissions with manihot glaziovii 
bioethanol - gasoline blended using extreme learning machine. Fuel 2017;210: 
914–21. https://doi.org/10.1016/j.fuel.2017.08.102.http://www.sciencedirect. 
com/science/article/pii/S0016236117310980 

[86] Janakiraman VM, Nguyen X, Assanis D. Stochastic gradient based extreme 

learning machines for stable online learning of advanced combustion engines. 
Neurocomputing 2016;177:304–16. https://doi.org/10.1016/j. 
neucom.2015.11.024.http://www.sciencedirect.com/science/article/pii/ 
S0925231215017439 

[87] Wong H, Wong P, Vong C. Model predictive engine air-ratio control using online 
sequential relevance vector machine. Journal of Control Science and Engineering 
2012;2012:2. 

[88] Wong KI, Wong PK, Cheung CS. Modelling and prediction of diesel engine 

performance using relevance vector machine. Int J Green Energy 2015;12(3): 
265–71. 

[89] Liu Y, Zhang J, Ma L. A fault diagnosis approach for diesel engines based on self- 

adaptive WVD, improved FCBF and PECOC-RVM. Neurocomputing 2016;177: 
600–11. 

[90] Liu Y, Zhang J, Qin K, Xu Y. Diesel engine fault diagnosis using intrinsic time- 
scale decomposition and multistage adaboost relevance vector machine. 
Proceedings of the Institution of Mechanical Engineers, Part C: Journal of 
Mechanical Engineering Science 2018;232(5):881–94. 

[91] Wong K, Wong P, Cheung C, Vong C. Modeling and optimization of biodiesel 

engine performance using advanced machine learning methods. Energy 2013;55: 
519–28. https://doi.org/10.1016/j.energy.2013.03.057.http://www.sciencedi 
rect.com/science/article/pii/S0360544213002533 

[69] Najafi G, Ghobadian B, Yusaf T, Rahimi H. Combustion analysis of a ci engine 

[92] Alonso JM, Alvarruiz F, Desantes JM, Hernandez L, Hernandez V, Molto G. 

performance using waste cooking biodiesel fuel with an artificial neural network 
aid. Am J Appl Sci 2007;4(10):756–64. 

[70] Nareid H, Lightowler N. Detection of engine misfire events using an artificial 

neural network. Tech. Rep. SAE Technical Paper; 2004. 

[71] Morgan I, Liu H, Turnbull G, Brown D. Predictive unsupervised organisation in 
marine engine fault detection. 2008 IEEE international joint conference on neural 
networks (IEEE world congress on computational intelligence). IEEE; 2008. 
p. 249–56. 

[72] Xue J, Gao Q, Ju W. Reinforcement learning for engine idle speed control. 2010 
international conference on measuring technology and mechatronics automation. 
2. IEEE; 2010. p. 1008–11. 

Combining neural networks and genetic algorithms to predict and reduce diesel 
engine emissions. IEEE Trans Evol Comput 2007;11(1):46–55. https://doi.org/ 
10.1109/TEVC.2006.876364. 

[93] Shirneshan A, Samani BH, Ghobadian B. Optimization of biodiesel percentage in 
fuel mixture and engine operating conditions for diesel engine performance and 
emission characteristics by artificial bees colony algorithm. Fuel 2016;184: 
518–26. https://doi.org/10.1016/j.fuel.2016.06.117.http://www.sciencedirect. 
com/science/article/pii/S0016236116305804 

[94] McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous 
activity. Bull Math Biophys 1943;5(4):115–33. https://doi.org/10.1007/ 
BF02478259. 

[73] Howell MN, Best MC. On-line PID tuning for engine idle-speed control using 

[95] Pancioni L. Artificial neural networks in pattern recognition11081. Springer; 

continuous action reinforcement learning automata. Control Eng Pract 2000;8(2): 
147–54. 

[74] Shih P, Kaul BC, Jagannathan S, Drallmeier JA. Reinforcement-learning-based 
output-feedback control of nonstrict nonlinear discrete-time systems with 
application to engine emission control. IEEE Transactions on Systems, Man, and 
Cybernetics, Part B (Cybernetics) 2009;39(5):1162–79. https://doi.org/10.1109/ 
TSMCB.2009.2013272. 

[75] Shih P, Kaul BC, Jagannathan S, Drallmeier JA. Reinforcement-learning-based 

dual-control methodology for complex nonlinear discrete-time systems with 
application to spark engine EGR operation. IEEE Trans Neural Networks 2008;19 
(8):1369–88. https://doi.org/10.1109/TNN.2008.2000452. 

[76] Caruana R, Niculescu-Mizil A. An empirical comparison of supervised learning 
algorithms. Proceedings of the 23rd international conference on machine 
learning. ACM; 2006. p. 161–8. 

[77] Graves A. Supervised sequence labelling. Supervised sequence labelling with 

recurrent neural networks. Springer; 2012. p. 5–13. 

[78] Sebayang A, Masjuki H, Ong HC, Dharma S, Silitonga A, Kusumo F, et al. 

Optimization of bioethanol production from sorghum grains using artificial 
neural networks integrated with ant colony. Ind Crops Prod 2017;97:146–55. 
https://doi.org/10.1016/j.indcrop.2016.11.064.http://www.sciencedirect.com/ 
science/article/pii/S0926669016308287 

[79] Domínguez-S´aez A, Ratt´a GA, Barrios CC. Prediction of exhaust emission in 
transient conditions of a diesel engine fueled with animal fat using artificial 
neural network and symbolic regression. Energy 2018;149:675–83. https://doi. 
org/10.1016/j.energy.2018.02.080.http://www.sciencedirect.com/science/artic 
le/pii/S0360544218303086 

[80] Uslu S, Celik MB. Prediction of engine emissions and performance with artificial 
neural networks in a single cylinder diesel engine using diethyl ether. Engineering 
Science and Technology, an International Journal 2018;21(6):1194–201. https:// 
doi.org/10.1016/j.jestch.2018.08.017.http://www.sciencedirect.com/science/ 
article/pii/S2215098618308085 

2018. 

[96] Gürgen S, Ünver B, Altın ˙I. Prediction of cyclic variability in a diesel engine fueled 
with n-butanol and diesel fuel blends using artificial neural network. Renew 
Energy 2018;117:538–44. 

[97] Thekumparampil KK, Wang C, Oh S, Li L-J. Attention-based graph neural network 

for semi-supervised learning. arXiv:180303735 2018. 

[98] Najafi G, Ghobadian B, Tavakoli T, Buttsworth D, Yusaf T, Faizollahnejad M. 

Performance and exhaust emissions of a gasoline engine with ethanol blended 
gasoline fuels using artificial neural network. Appl Energy 2009;86(5):630–9. 
[99] Togun NK, Baysec S. Prediction of torque and specific fuel consumption of a 
gasoline engine by using artificial neural networks. Appl Energy 2010;87(1): 
349–55. 

[100] Yusaf TF, Buttsworth D, Saleh KH, Yousif B. CNG-diesel engine performance and 
exhaust emission analysis with the aid of artificial neural network. Appl Energy 
2010;87(5):1661–9. 

[101] Sharma A, Sahoo PK, Tripathi R, Meher LC. Artificial neural network based 

prediction of performance and emission characteristics of a variable compression 
ratio CI engine using WCO as a biodiesel at different injection timings. Appl 
Energy 2011;88(7):2344–54. 

[102] Ismail HM, Ng HK, Queck CW, Gan S. Artificial neural networks modelling of 

engine-out responses for a light-duty diesel engine fuelled with biodiesel blends. 
Appl Energy 2012;92:769–77. 

[103] Golcu M, Sekmen Y, Erduranlí P, Salman MS. Artificial neural-network based 

modeling of variable valve-timing in a spark-ignition engine. Appl Energy 2005; 
81(2):187–97. 

[104] Parlak A, Islamoglu Y, Yasar H, Egrisogut A. Application of artificial neural 

network to predict specific fuel consumption and exhaust temperature for a diesel 
engine. Appl Therm Eng 2006;26(8):824–8. 

[105] Sayin C, Ertunc H, Hosoz M, Kilicaslan I, Canakci M. Performance and exhaust 
emissions of a gasoline engine using artificial neural network. Appl Therm Eng 
2007;27(1):46–54. 

ProgressinEnergyandCombustionScience88(2022)10096732M. Aliramezani et al.                                                                                                                                                                                                                          

[106] Kara Togun N, Baysec S. Prediction of torque and specific fuel consumption of a 

[137] Keerthi SS, Lin C-J. Asymptotic behaviors of support vector machines with 

gasoline engine by using artificial neural networks. Appl Energy 2010;87(1): 
349–55. 

[107] Porteiro J, Collazo J, Pati˜no D, Míguez J. Diesel engine condition monitoring 

using a multi-net neural network system with nonintrusive sensors. Appl Therm 
Eng 2011;31(17):4097–105. 

[108] Çay AY, Çiçek FK, Sa˘giro˘glu S. Prediction of engine performance for an 

alternative fuel using artificial neural network. Appl Therm Eng 2012;37:217–25. 

[109] Liu B, Zhao C, Zhang F, Cui T, Su J. Misfire detection of a turbocharged diesel 

engine by using artificial neural networks. Appl Therm Eng 2013;55:26–32. 
[110] Choi Y, Chen J-Y. Fast prediction of start-of-combustion in HCCI with combined 
artificial neural networks and ignition delay model. Proc Combust Inst 2005;30 
(2):2711–8. 

[111] Mirhassani M, Chen X, Tahmasebi A, Ahmadi M. On control of HCCI combustion- 
neural network approach. Proceeding of the 2006 IEEE international conference 
on control applications. 2006. p. 1669–74. 

[112] Haykin S, Network N. A comprehensive foundation. Neural networks 2004;2 

(2004):41. 

[113] Pham BT, Bui DT, Prakash I, Dholakia M. Hybrid integration of multilayer 
perceptron neural networks and machine learning ensembles for landslide 
susceptibility assessment at Himalayan area (India) using GIS. Catena 2017;149: 
52–63. 

[114] Song K, Li F, Hu X, He L, Niu W, Lu S, et al. Multi-mode energy management 

strategy for fuel cell electric vehicles based on driving pattern identification using 
learning vector quantization neural network algorithm. J Power Sources 2018; 
389:230–9. 

[115] Pham BT, Shirzadi A, Bui DT, Prakash I, Dholakia M. A hybrid machine learning 
ensemble approach based on a radial basis function neural network and rotation 
forest for landslide susceptibility modeling: a case study in the himalayan area, 
india. Int J Sediment Res 2018;33(2):157–70. 

[116] Ettaouil M, Lazaar M, Elmoutaouakil K, Haddouch K. A new algorithm for 

Gaussian kernel. Neural Comput 2003;15(7):1667–89. 

[138] Tipping ME. Sparse bayesian learning and the relevance vector machine. Journal 

of machine learning research 2001;1(Jun):211–44. 

[139] Suykens JA, Vandewalle J. Least squares support vector machine classifiers. 

Neural processing letters 1999;9(3):293–300. 

[140] Bishop C, Tipping M. Variational relevance vector machines. Proceedings of the 
sixteenth conference on uncertainty in artificial intelligence. Morgan Kaufmann 
Publishers Inc; 2000. p. 46–53. 

[141] Tipping ME. The relevance vector machine. Advances in neural information 

processing systems. 2000. p. 652–8. 

[142] Widodo A, Kim EY, Son J-D, Yang B-S, Tan AC, Gu D-S, et al. Fault diagnosis of 
low speed bearing based on relevance vector machine and support vector 
machine. Expert Syst Appl 2009;36(3):7252–61. 

[143] Xiang-min X, Yun-feng M, Jia-ni X, Feng-le Z. Classification performance 

comparison between RVM and SVM. 2007 international workshop on anti- 
counterfeiting, security and identification (ASID). IEEE; 2007. p. 208–11. 

[144] Demir B, Erturk S. Hyperspectral image classification using relevance vector 

machines. IEEE Geosci Remote Sens Lett 2007;4(4):586–90. 

[145] Yang B, Song G, Shen L, Ghuktomova Y, Xu J. Fault diagnosis method for internal 

combustion engines based on IHS-RVM model. Journal of Mechanical 
Engineering Research and Developments 2017;40(1):64–71. 

[146] Fan J, Wang F, Sun Q, Bin F, Liang F, Xiao X. Hybrid RVM–ANFIS algorithm for 
transformer fault diagnosis. IET Generation, Transmission & Distribution 2017;11 
(14):3637–43. 

[147] Wu K, Kang J, Chi K. Research on fault diagnosis method using improved multi- 
class classification algorithm and relevance vector machine. International Journal 
of Information Technology and Web Engineering (IJITWE) 2015;10(3):1–16. 

[148] Snelson E, Ghahramani Z. Sparse gaussian processes using pseudo-inputs. 

Advances in neural information processing systems. 2006. p. 1257–64. 
[149] Wilson A, Nickisch H. Kernel interpolation for scalable structured Gaussian 

optimization of the Kohonen network architectures using the continuous hopfield 
networks. wseas transactions on computers 2013;12(4). 

processes (KISS-GP). International conference on machine learning. 2015. 
p. 1775–84. 

[117] Ehlers R. Formal verification of piece-wise linear feed-forward neural networks. 
International symposium on automated technology for verification and analysis. 
Springer; 2017. p. 269–86. 

[118] Pan Y, Yu H. Biomimetic hybrid feedback feedforward neural-network learning 

control. IEEE Trans Neural Netw Learn Syst 2016;28(6):1481–7. 
[119] Huang G-B, Zhu Q-Y, Siew C-K. Extreme learning machine: theory and 

applications. Neurocomputing 2006;70(1):489–501.Neural Networks 

[150] MacKay DJ. Introduction to gaussian processes. NATO ASI Series F Computer and 

Systems Sciences 1998;168:133–66. 

[151] Williams CK, Rasmussen CE. Gaussian processes for regression. Advances in 

neural information processing systems. 1996. p. 514–20. 

[152] Rasmussen CE. Evaluation of gaussian processes and other methods for non-linear 

regression. Doctoral dissertation. University of Toronto; 1999. 

[153] Gibbs MN. Bayesian gaussian processes for regression and classification. Citeseer; 

[120] Huang G-B, Zhou H, Ding X, Zhang R. Extreme learning machine for regression 

1998. 

and multiclass classification. IEEE Transactions on Systems, Man, and 
Cybernetics, Part B: Cybernetics 2012;42(2):513–29.Cited By 2885 

[121] Huang G-B, Zhou H, Ding X, Zhang R. Extreme learning machine for regression 

and multiclass classification. IEEE Transactions on Systems, Man, and 
Cybernetics, Part B (Cybernetics) 2011;42(2):513–29. 

[122] Wong PK, Wong KI, Vong CM, Cheung CS. Modeling and optimization of biodiesel 

engine performance using kernel-based extreme learning machine and cuckoo 
search. Renew Energy 2015;74:640–7. https://doi.org/10.1016/j. 
renene.2014.08.075.http://www.sciencedirect.com/science/article/pii/ 
S096014811400545X 

[123] Zou H, Lu X, Jiang H, Xie L. A fast and precise indoor localization algorithm based 
on an online sequential extreme learning machine. Sensors 2015;15(1):1804–24. 

[154] Zhou J, Li M, Xu M. Multi-disciplinary tolerance optimization for internal 

combustion engines using gaussian process and sequential mdo method. SAE 
International Journal of Materials and Manufacturing 2016;9(2):410–8. 
[155] Shahbakhti M, Ghazimirsaied A, Koch CR. Modeling ranges of cyclic variability 
for HCCI ignition timing control. Proceedings of the ASME 2011 Dynamic Systems 
and Control Conference 2011;6118. 

[156] Maudsley DB. A theory of meta-learning and principles of facilitation: an 

organismic perspective. 1980. 

[157] Brazdil P, Carrier CG, Soares C, Vilalta R. Metalearning: applications to data 

mining. Springer Science & Business Media; 2008. 

[158] Schaul T, Schmidhuber J. Metalearning. 2010.Available: http://www.scholarp 

edia.org/article/Metalearning 

[124] Lan Y, Soh YC, Huang G-B. Ensemble of online sequential extreme learning 

[159] Stolfo SJ, Prodromidis AL, Tselepis S, Lee W, Fan DW, Chan PK. JAM: Java agents 

machine. Neurocomputing 2009;72(13–15):3391–5. 

for meta-learning over distributed databases. in KDD 1997;97:74–81. 

[125] Wong KI, Vong CM, Wong PK, Luo J. Sparse bayesian extreme learning machine 

[160] Prodromidis AL, Stolfo SJ, Tselepis S, Truta T, Sherwin J, Kalina D. Distributed 

and its application to biofuel engine performance prediction. Neurocomputing 
2015;149:397–404. https://doi.org/10.1016/j.neucom.2013.09.074.Advances in 
neural networks Advances in Extreme Learning Machines 

[126] Wong PK, Wong KI, Vong CM, Cheung CS. Modeling and optimization of biodiesel 

engine performance using kernel-based extreme learning machine and cuckoo 
search. Renew Energy 2015;74:640–7. 

[127] Deo RC, S¸ ahin M. Application of the extreme learning machine algorithm for the 

prediction of monthly effective drought index in eastern australia. Atmos Res 
2015;153:512–25. 

[128] Sajjadi S, Shamshirband S, Alizamir M, Yee L, Mansor Z, Manaf AA, et al. Extreme 
learning machine for prediction of heat load in district heating systems. Energy 
Build 2016;122:222–7. 

[129] Aghbashlo M, Shamshirband S, Tabatabaei M, Yee L, Larimi YN. The use of ELM- 

WT (extreme learning machine with wavelet transform algorithm) to predict 
exergetic performance of a DI diesel engine running on diesel/biodiesel blends 
containing polymer waste. Energy 2016;94:443–56. 

[130] Ding S, Zhao H, Zhang Y, Xu X, Nie R. Extreme learning machine: algorithm, 

theory and applications. Artif Intell Rev 2015;44(1):103–15. 

[131] Vapnik VN. An overview of statistical learning theory. IEEE Trans Neural 

Networks 1999;10(5):988–99. 

[132] Vapnik V. The nature of statistical learning theory. Springer science & business 

media; 2013. 

data mining: the JAM system architecture. 2001. 

[161] Xu J-W, Paiva AR, Park I, Principe JC. A reproducing kernel hilbert space 

framework for information-theoretic learning. IEEE Trans Signal Process 2008;56 
(12):5891–902. 

[162] Senecal PK, Reitz RD. Simultaneous reduction of engine emissions and fuel 

consumption using genetic algorithms and multi-dimensional spray and 
combustion modeling. SAE Trans 2000:1378–90. 

[163] Coates A, Carpenter B, Case C, Satheesh S, Suresh B, Wang T, et al. Text detection 

and character recognition in scene images with unsupervised feature learning. 
ICDAR. 11; 2011. p. 440–5. 

[164] Chen C-C, Juan H-H, Tsai M-Y, Lu HH-S. Unsupervised learning and pattern 
recognition of biological data structures with density functional theory and 
machine learning. Sci Rep 2018;8(1):557. 

[165] Eskin E, Arnold A, Prerau M, Portnoy L, Stolfo S. A geometric framework for 

unsupervised anomaly detection. Applications of data mining in computer 
security. Springer; 2002. p. 77–101. 

[166] Yu W, Zhao F, Yang W, Xu H. Integrated analysis of cfd simulation data with k- 
means clustering algorithm for soot formation under varied combustion 
conditions. Appl Therm Eng 2019;153:299–305. 

[167] Thomas MC, Zhu W, Romagnoli JA. Data mining and clustering in chemical 

process databases for monitoring and knowledge discovery. J Process Control 
2018;67:160–75. 

[133] Tanveer M. Robust and sparse linear programming twin support vector machines. 

[168] Yang S, Wu R, Wang M, Jiao L. Evolutionary clustering based vector quantization 

Cognit Comput 2015;7(1):137–49. 

[134] Xu Y, Guo R, Wang L. A twin multi-class classification support vector machine. 

Cognit Comput 2013;5(4):580–8. 

[135] Cortes C, Vapnik V. Support-vector networks. Mach Learn 1995;20(3):273–97. 
[136] Wang W, Xu Z, Lu W, Zhang X. Determination of the spread parameter in the 

gaussian kernel for classification and regression. Neurocomputing 2003;55(3–4): 
643–63. 

and spiht coding for image compression. Pattern Recognit Lett 2010;31(13): 
1773–80. 

[169] Liu Y, Zhou S, Chen Q. Discriminative deep belief networks for visual data 

classification. Pattern Recognit 2011;44(10–11):2287–96. 

[170] Pacella M. Unsupervised classification of multichannel profile data using PCA: an 
application to an emission control system. Computers & Industrial Engineering 
2018;122:161–9. 

ProgressinEnergyandCombustionScience88(2022)10096733M. Aliramezani et al.                                                                                                                                                                                                                          

[171] Likas A, Vlassis N, Verbeek JJ. The global k-means clustering algorithm. Pattern 

[200] An Y-z, Pei Y-q, Qin J, Zhao H, Teng S-p, Li B, et al. Development of a PAH 

Recognit 2003;36(2):451–61. 

[172] Flores-Sintas A, Cadenas J, Martin F. Membership functions in the fuzzy c-means 

algorithm. Fuzzy Sets Syst 1999;101(1):49–58. 

(polycyclic aromatic hydrocarbon) formation model for gasoline surrogates and 
its application for GDI (gasoline direct injection) engine CFD (computational fluid 
dynamics) simulation. Energy 2016;94:367–79. 

[173] Agatonovic-Kustrin S, Beresford R. Basic concepts of artificial neural network 

[201] Azad NL, Sanketi PR, Hedrick JK. Determining model accuracy requirements for 

(ann) modeling and its application in pharmaceutical research. J Pharm Biomed 
Anal 2000;22(5):717–27. 

automotive engine coldstart hydrocarbon emissions control. J Dyn Syst Meas 
Control 2012;134(5):051002. 

[174] Kaski S. Data exploration using self-organizing maps. Acta polytechnica 

[202] Kozarac D, Taritas I, Vuilleumier D, Saxena S, Dibble RW. Experimental and 

scandinavica: mathematics, computing and management in engineering series no. 
82. Citeseer; 1997. 

numerical analysis of the performance and exhaust gas emissions of a biogas/n- 
heptane fueled hcci engine. Energy 2016;115:180–93. 

[175] Kohonen T. Exploration of very large databases by self-organizing maps. 

[203] Karvountzis-Kontakiotis A, Ntziachristos L. Improvement of NO and CO 

Proceedings of international conference on neural networks (ICNN’97). 1. IEEE; 
1997PL1–6. 

predictions for a homogeneous combustion SI engine using a novel emissions 
model. Appl Energy 2016;162:172–82. 

[176] Amer M, Goldstein M, Abdennadher S. Enhancing one-class support vector 

[204] Jiao Q, Reitz RD. Modeling of equivalence ratio effects on particulate formation in 

machines for unsupervised anomaly detection. Proceedings of the ACM SIGKDD 
workshop on outlier detection and description. New York, NY, USA: Association 
for Computing Machinery; 2013, ISBN 9781450323352. p. 8–15. https://doi.org/ 
10.1145/2500853.2500857. 

[177] Leitner L, Lagrange A, Endisch C. End-of-line fault detection for combustion 
engines using one-class classification. 2016 IEEE international conference on 
Advanced Intelligent Mechatronics (AIM). IEEE; 2016. p. 207–13. 

[178] Dayan P, Balleine BW. Reward, motivation, and reinforcement learning. Neuron 

2002;36(2):285–98. 

[179] Doya K, Samejima K, Katagiri K-i, Kawato M. Multiple model-based reinforcement 

learning. Neural Comput 2002;14(6):1347–69. 

[180] Sutton RS, Barto AG. Reinforcement learning: an introduction. Chapter 9. MIT 

press; 2018. 

[181] Szepesv´ari C, Littman ML. A unified analysis of value-function-based 

reinforcement-learning algorithms. Neural Comput 1999;11(8):2017–60. 

[182] Kohl N, Stone P. Policy gradient reinforcement learning for fast quadrupedal 
locomotion. IEEE international conference on robotics and automation, 2004. 
Proceedings. ICRA’04. 2004. 3. IEEE; 2004. p. 2619–24. 

[183] Nachum O, Norouzi M, Xu K, Schuurmans D. Bridging the gap between value and 
policy based reinforcement learning. Advances in neural information processing 
systems. 2017. p. 2775–85. 

[184] Grondman I, Busoniu L, Lopes GA, Babuska R. A survey of actor-critic 

a spark-ignition engine under premixed conditions. Tech. Rep. SAE Technical 
Paper; 2014. 

[205] Leach F, Stone R, Richardson D. The influence of fuel properties on particulate 

number emissions from a direct injection spark ignition engine. SAE International 
2013;2. 

[206] Shahbakhti M, Koch C. Characterizing the cyclic variability of ignition timing in a 

homogeneous charge compression ignition engine fuelled with n-heptane/iso- 
octane blend fuels. Int J Engine Res 2008;9(5):361–97. 

[207] Ghazimirsaied A, Koch CR. Controlling cyclic combustion timing variations using 
a symbol-statistics predictive approach in an HCCI engine. Appl Energy 2012;92 
(0):133–46. https://doi.org/10.1016/j.apenergy.2011.09.018.http://www.scienc 
edirect.com/science/article/pii/S0306261911005897 

[208] Grünefeld G., Beushausen V., Andresen P., Hentschel W.. A major origin of cyclic 
energy conversion variations in SI engines: cycle-by-cycle variations of the 
equivalence ratio and residual gas of the initial charge. 1994.. 10.4271/941880. 

[209] Duarte J, Amador G, Garcia J, Fontalvo A, Padilla RV, Sanjuan M, et al. Auto- 

ignition control in turbocharged internal combustion engines operating with 
gaseous fuels. Energy 2014;71:137–47. 

[210] Amador G, Forero JD, Rincon A, Fontalvo A, Bula A, Padilla RV, et al. 

Characteristics of auto-ignition in internal combustion engines operated with 
gaseous fuels of variable methane number. J Energy Resour Technol 2017;139(4): 
042205. 

reinforcement learning: standard and natural policy gradients. IEEE Transactions 
on Systems, Man, and Cybernetics, Part C (Applications and Reviews) 2012;42(6): 
1291–307. 

[211] Wu Z, Kang Z, Deng J, Hu Z, Li L. Effect of oxygen content on n-heptane auto- 
ignition characteristics in a HCCI engine. Appl Energy 2016;184:594–604. 
[212] Yoshimura K., Tokunaga Y., Hashimoto D., Sakurai H.. Knock and misfire 

[185] Van Hasselt H, Wiering MA. Reinforcement learning in continuous action spaces. 
2007 IEEE international symposium on approximate dynamic programming and 
reinforcement learning. IEEE; 2007. p. 272–9. 

[186] Dulac-Arnold G, Evans R, van Hasselt H, Sunehag P, Lillicrap T, Hunt J, et al. 
Deep reinforcement learning in large discrete action spaces. arXiv:151207679 
2015. 

[187] Strehl AL, Li L, Wiewiora E, Langford J, Littman ML. Pac model-free 

reinforcement learning. Proceedings of the 23rd international conference on 
Machine learning. ACM; 2006. p. 881–8. 

[188] Doll BB, Simon DA, Daw ND. The ubiquity of model-based reinforcement 

learning. Curr Opin Neurobiol 2012;22(6):1075–81. 

[189] Johri R, Salvi A, Filipi Z. Optimal energy management for a hybrid vehicle using 
neuro-dynamic programming to consider transient engine operation. ASME 2011 
dynamic systems and control conference and Bath/ASME symposium on fluid 
power and motion control. American Society of Mechanical Engineers Digital 
Collection; 2011. p. 279–86. 

[190] Hu Y, Li W, Xu K, Zahid T, Qin F, Li C. Energy management strategy for a hybrid 
electric vehicle based on deep reinforcement learning. Applied Sciences 2018;8 
(2):187. 

[191] Qi X, Wu G, Boriboonsomsin K, Barth MJ. A novel blended real-time energy 
management strategy for plug-in hybrid electric vehicle commute trips. 2015 
IEEE 18th international conference on intelligent transportation systems. IEEE; 
2015. p. 1002–7. 

[192] Smith AJ. Applications of the self-organising map to reinforcement learning. 

Neural networks 2002;15(8–9):1107–24. 

[193] Czarnigowski J. A neural network model-based observer for idle speed control of 

ignition in si engine. Eng Appl Artif Intell 2010;23(1):1–7. 

[194] Rahman SA, Masjuki H, Kalam M, Abedin M, Sanjid A, Sajjad H. Impact of idling 
on fuel consumption and exhaust emissions and available idle-reduction 
technologies for diesel vehicles–a review. Energy Convers Manage 2013;74: 
171–82. 

[195] Ying H, Fujun Z, Fushui L, Yunshan G, Yebao S. Gasoline engine idle speed control 

system development based on PID algorithm. Proceedings of the IEEE 
international vehicle electronics conference (IVEC’99)(Cat. No. 99EX257). IEEE; 
1999. p. 30–3. 

[196] Widd A, Ekholm K, Tunestål P, Johansson R. Physics-based model predictive 

control of HCCI combustion phasing using fast thermal management and VVA. 
IEEE Trans Control Syst Technol 2012;20(3):688–99. 

detection using ion current measurement for ultra lean burn medium speed gas 
engine. 2007.. 10.4271/2007-01-2078. 

[213] Wang Z, Liu H, Reitz RD. Knocking combustion in spark-ignition engines. Prog 

Energy Combust Sci 2017;61:78–112. 

[214] Luo Q-h, Sun B-g. Inducing factors and frequency of combustion knock in 

hydrogen internal combustion engines. Int J Hydrogen Energy 2016;41(36): 
16296–305. 

[215] Wang Z, Qi Y, He X, Wang J, Shuai S, Law CK. Analysis of pre-ignition to super- 
knock: hotspot-induced deflagration to detonation. Fuel 2015;144:222–7. 
[216] Yun H, Wermuth N, Najt P. Extending the high load operating limit of a naturally- 
aspirated gasoline HCCI combustion engine. SAE Int J Engines 2010;3(1):681–99. 
[217] Li H, Neill WS, Chippior WL. An experimental investigation of HCCI combustion 
stability using n-heptane. J Energy Resour Technol 2012;134(2):022204. 
[218] Wu Z.J., Lee A.. Misfire detection using a dynamic neural network with output 

feedback. 1998.. 10.4271/980515. 

[219] Abadi MKB, Hajnayeb A, Hosseingholizadeh A, Ghasemloonia A. Single and 

multiple misfire detection in internal combustion engines using Vold-Kalman 
filter order-tracking. 2011. https://doi.org/10.4271/2011-01-1536. 
[220] Ponti F. Development of a torsional behavior powertrain model for multiple 

misfire detection. J Eng Gas Turbine Power 2008;130(2). https://doi.org/ 
10.1115/1.2770486.http://link.aip.org/link/?GTP/130/022803/1 

[221] da Silveira A.M., Ramos D., Domahovski S.C., Castro A.. Misfire diagnostic for flex 

vehicles - a case study. 2009.. 10.4271/2009-36-0247. 

[222] Giakoumis EG, Rakopoulos DC, Rakopoulos CD. Combustion noise radiation 
during dynamic diesel engine operation including effects of various biofuel 
blends: a review. Renewable Sustainable Energy Rev 2016;54:1099–113. 

[223] Ihme M. Combustion and engine-core noise. Annu Rev Fluid Mech 2017;49: 

277–310. 

[224] Satsangi DP, Tiwari N. Experimental investigation on combustion, noise, 

vibrations, performance and emissions characteristics of diesel/n-butanol blends 
driven genset engine. Fuel 2018;221:44–60. 

[225] Zhang Y, Xie H, Zhao H. Investigation of SI-HCCI hybrid combustion and control 
strategies for combustion mode switching in a four-stroke gasoline engine. 
Combust Sci Technol 2009;181(5):782–99. 

[226] Yang X, Zhu G. SI and HCCI combustion mode transition control of an HCCI 

capable SI engine. IEEE Trans Control Syst Technol 2012;21(5):1558–69. 
[227] Fang C, Yang F, Ouyang M, Gao G, Chen L. Combustion mode switching control in 

a HCCI diesel engine. Appl Energy 2013;110:190–200. 

[197] Roveda L, Pallucca G, Pedrocchi N, Braghin F, Tosatti LM. Iterative learning 

[228] Maurya RK, Saxena MR. Characterization of ringing intensity in a hydrogen- 

procedure with reinforcement for high-accuracy force tracking in robotized tasks. 
IEEE Trans Ind Inf 2017;14(4):1753–63. 

[198] Aliramezani M, Chitsaz I, Mozafari AA. Thermodynamic modeling of partially 

stratified charge engine characteristics for hydrogen-methane blends at ultra-lean 
conditions. Int J Hydrogen Energy 2013;38(25):10640–7. 

[199] Mehl M, Chen J-Y, Pitz WJ, Sarathy SM, Westbrook CK. An approach for 

fueled hcci engine. Int J Hydrogen Energy 2018;43(19):9423–37. 

[229] Ge H, Cho NH. Effects of numerical models on prediction of cylinder pressure 
ringing in a DI diesel engine. Tech. Rep. SAE Technical Paper; 2018. 
[230] Mosbach S, Celnik MS, Raj A, Kraft M, Zhang HR, Kubo S, et al. Towards a 

detailed soot model for internal combustion engines. Combust Flame 2009;156 
(6):1156–65. 

formulating surrogates for gasoline with application toward a reduced surrogate 
mechanism for cfd engine modeling. Energy & Fuels 2011;25(11):5215–23. 

[231] Guzzella L, Onder C. Introduction to modeling and control of internal combustion 

engine systems. Springer Science & Business Media; 2009. 

ProgressinEnergyandCombustionScience88(2022)10096734M. Aliramezani et al.                                                                                                                                                                                                                          

[232] Audet A, Koch C. Actuator comparison for closed loop control of HCCI 

[264] Tandra V, Srivastava N. Optimal peak pressure and exhaust temperature tracking 

combustion timing 2009;SAE Paper 2009-01-1135. 

[233] Iwadare M, Ueno M, Adachi S. Multi-variable air-path management for a clean 

diesel engine using model predictive control. SAE Int J Engines 2009;2(1): 
764–73. 

[234] Boz T, Unel M, Aran V, Yilmaz M, Gurel C, Bayburtlu C, Koprubasi K. Diesel 

engine NOx emission modeling with airpath input channels. IECON 2015-41st 
annual conference of the IEEE industrial electronics society. IEEE; 2015. 
p. 003382–7. 

[235] Haraldsson G, Tunestål P, Johansson B. Transient control of a multi cylinder HCCI 

engine during a drive cycle 2005;SAE Paper 2005-01-0153. 

[236] Bengtsson J, Strandh P, Johansson R, Tunestål P, Johansson B. Hybrid modeling 
of homogeneous charge compression ignition (HCCI) engine dynamics - a survey. 
Int J of Control 2007;80(11):1814–47. 

[237] Strandh P, Bengtsson J, Johansson R, Tunestål P, Johansson B. Variable valve 
actuation for timing control of a HCCI engine 2005;SAE Paper 2005-01-0147. 

[238] Ebrahimi K, Aliramezani M, Koch C. An HCCI control oriented model that 

includes combustion efficiency. IFAC-PapersOnLine 2016;49(11):327–32.8th 
IFAC Symposium on Advances in Automotive Control AAC 2016 

[239] Martínez-Morales J, Palacios E, Carrillo G. Modeling of internal combustion 

engine emissions by LOLIMOT algorithm. Procedia Technol 2012;3:251–8. 

[240] Macek J, Pol´aˇsek M, 

ˇ
Sika Z, Val´aˇsek M, Flori´an M, Vítek O. Transient engine 
model as a tool for predictive control. Tech. Rep. SAE Technical Paper; 2006. 

[241] Isermann R, Müller N. Design of computer controlled combustion engines. 

Mechatronics 2003;13(10):1067–89. 

[242] Chuntao W, Jinming L. Fault diagnosis of diesel engine based on HHT marginal 
spectrum [J]. Journal of Vibration, Measurement & Diagnosis 2010;4. 
[243] Chun-tao W, Hai-gang LJ-mZ. Fault diagnosis of diesel engine based on HHT 
marginal spectrum and SVM method. Ship & Ocean Engineering 2010;(3):21. 

[244] Khiar D, Lauber J, Floquet T, Colin G, Guerra T, Chamaillard Y. Robust 

Takagi–Sugeno fuzzy control of a spark ignition engine. Control Eng Pract 2007; 
15(12):1446–56. 

[245] Kirchen P, Shahbakhti M, Koch C. A skeletal kinetic mechanism for PRF 

combustion in HCCI engines. Combust Sci Technol 2007;179(6):1059–83. 
[246] Chiang C-J, Stefanopoulou A, Jankovic M. Nonlinear observer-based control of 

load transitions in homogeneous charge compression ignition engines. IEEE Trans 
Control Syst Technol 2007;15(3):438–48. 

[247] Chiang C-J, Huang C-C, Jankovic M. Discrete-time cross-term forwarding design 
of robust controllers for HCCI engines 2010;2010 American Control Conference: 
2218–23. 

[248] Ravi N, Roelle MJ, Liao H-H, Jungkunz AF, Chang C-F, Park S, et al. Model-based 

control of HCCI engines using exhaust recompression. IEEE Trans Control Syst 
Technol 2010;18(6):1289–302. 

[249] Ravi N, Liao H-H, Jungkunz A, Widd A, Gerdes J. Model predictive control of 

HCCI using variable valve actuation and fuel injection. Control Eng Pract 2012;20 
(4):421–30. 

[250] Shaver GM, Gerdes JC, Roelle M. Physics-based closed-loop control of phasing, 

peak pressure and work output in HCCI engines utilizing variable valve actuation 
2004;Proceeding of the 2004 American Control Conference:150–5. 

[251] Nikzadfar K, Shamekhi AH. An extended mean value model (EMVM) for control- 

control for a two-zone HCCI engine model with mean burn duration 2009;SAE 
Paper 2009-01-1130. 

[265] HCCI Combustion timing control with variable valve timing 2013;2013 American 

Control Conference:4429–34. 

[266] Razmara M, Bidarvatan M, Shahbakhti M, Robinett III R. Optimal exergy-based 
control of internal combustion engines. Appl Energy 2016;183:1389–403. 
[267] Shaver G, Gerdes J, Roelle M. Physics-based modeling and control of residual- 
affected HCCI engines. ASME Journal of Dynamic Systems, Measurement, and 
Control 2009;131(2). 

[268] Ravi N, Liao H-H, Jungkunz A, Chang C-F, Song H-H, Gerdes J. Modeling and 

control of an exhaust recompression hcci engine using split injection. ASME 
Journal of Dynamic Systems, Measurement, and Control 2012;134(1). 
[269] Feng H, Zhang C, Wang M, Liu D, Yang X, Lee C-f. Availability analysis of n- 
heptane/iso-octane blends during low-temperature engine combustion using a 
single-zone combustion model. Energy Convers Manage 2014;84:613–22. 
[270] Costa M, Sorge U, Allocca L. CFD Optimization for GDI spray model tuning and 
enhancement of engine performance. Adv Eng Software 2012;49:43–53. 
[271] Badra J, Khaled F, Tang M, Pei Y, Kodavasal J, Pal P, et al. Engine Combustion 
System Optimization Using CFD and Machine Learning: A Methodological 
Approach. Internal combustion engine division fall technical conference. 59346. 
American Society of Mechanical Engineers; 2019.V001T06A007 

[272] K¨arrholm FP, Tao F, Nordin N. Three-dimensional simulation of diesel spray 

ignition and flame lift-off using OpenFOAM and KIVA-3V CFD codes. Tech. Rep. 
SAE Technical Paper; 2008. 

[273] Pandey K, Sivasakthivel T. CFD Analysis of a hydrogen fueled mixture in scramjet 
combustor with a strut injector by using fluent software. International Journal of 
Engineering and Technology 2011;3(2):109. 

[274] Jamrozik A. CFD Modelling of combustion in HCCI engine using AVL fire 

software. ECONTECHMOD: An International Quarterly Journal on Economics of 
Technology and Modelling Processes 2012;1:51–5. 

[275] Riegler UG, Bargende M. Direct coupled 1D/3D-CFD-computation (GT-Power/ 

star-CD) of the flow in the switch-over intake system of an 8-cylinder SI engine 
with external exhaust gas recirculation. SAE Trans 2002:1554–65. 

[276] Badra JA, Khaled F, Tang M, Pei Y, Kodavasal J, Pal P, et al. Engine combustion 
system optimization using computational fluid dynamics and machine learning: A 
Methodological approach. J Energy Resour Technol 2021;143(2):022306. 
[277] Despr´es B, Jourdren H. Machine learning design of volume of fluid schemes for 

compressible flows. J Comput Phys 2020;408:109275. 

[278] Popov PP, Buchta DA, Anderson MJ, Massa L, Capecelatro J, Bodony DJ, et al. 
Machine learning-assisted early ignition prediction in a complex flow. Combust 
Flame 2019;206:451–66. 

[279] Zheng Z, Lin X, Yang M, He Z, Bao E, Zhang H, et al. Progress in the application of 
machine learning in combustion studies. ES Energy & Environment 2020;9:1–14. 

[280] Badra J, Sim J, Pei Y, Viollet Y, Pal P, Futterer C, et al. Combustion system 

optimization of a light-duty GCI engine using CFD and machine learning. Tech. 
Rep. SAE Technical Paper; 2020. 

[281] Hwang J, Lee P, Mun S, Karathanassis IK, Koukouvinis P, Pickett LM, et al. 
Machine-learning enabled prediction of 3D spray under engine combustion 
network spray g conditions. Fuel 2021;293:120444. 

oriented modeling of diesel engines transient performance and emissions. Fuel 
2015;154:275–92. 

[282] Ra Y, Reitz RD. A reduced chemical kinetic model for IC engine combustion 

simulations with primary reference fuels. Combust Flame 2008;155(4):713–38. 

[252] Kong S-C, Reitz RD. Use of detailed chemical kinetics to study HCCI engine 

[283] Shahbakhti M, Koch C. Physics based control oriented model for HCCI 

combustion with consideration of turbulent mixing effects. J Eng Gas Turbines 
Power 2002;124(3):702–7. 

combustion timing. AMSE Journal of Dynamic Systems, Measurement, and 
Control 2010;132(2). 

[253] Ebrahimi K, Koch C, Schramm A. A control oriented model with variable valve 

[284] Grill M, Bargende M, Rether D, Schmid A. Quasi-dimensional and empirical 

timing for HCCI combustion timing control 2013;SAE Paper 2013-01-0588. 
[254] Komninos N, Hountalas D, Kouremenos D. Description of in-cylinder combustion 
processes in HCCI engines using a multi-zone model 2005;SAE Paper No. 2005- 
01-0171. 

[255] Zhang S, Zhu G, Yoon Y, Sun Z. A control oriented charge mixing and HCCI 

combustion model for internal combustion engines. ASME Journal of Dynamic 
Systems, Measurement, and Control 2012;2. 

modeling of compression-ignition engine combustion and emissions. Tech. Rep. 
SAE Technical Paper; 2010. 

[285] Sandoval D, Heywood JB. An improved friction model for spark-ignition engines. 

SAE Trans 2003:1041–52. 

[286] Piltan F, Sulaiman N, AsadiTalooki I. Evolutionary design on-line sliding fuzzy 
gain scheduling sliding mode algorithm: applied to internal combustion engine. 
International Journal of Engineering Science and Technology 2011;3(10):7301–8. 

[256] Reitz R, Rutland C. Development and testing of diesel engine cfd models. Prog 

[287] Arora JK, Shahbakhti M. Real-time closed-loop control of a light-duty RCCI 

Energy Combust Sci 1995;21(2):173–96. 

[257] Abani N, Kokjohn S, Park SW, Bergin M, Munnannur A, Ning W, et al. An 

improved spray model for reducing numerical parameter dependencies in diesel 
engine CFD simulations. SAE World Congress & Exhibition. SAE International; 
2008. 

[258] Asprion J, Chinellato O, Guzzella L. A fast and accurate physics-based model for 

the NOx emissions of diesel engines. Appl Energy 2013;103:221–33. 
[259] Grasreiner S, Neumann J, Wensing M, Hasse C. Model-based virtual engine 

calibration with the help of phenomenological methods for spark-ignited engines. 
Appl Therm Eng 2017;121:190–9. 

[260] Aithal S. Modeling of NOx formation in diesel engines using finite-rate chemical 

kinetics. Appl Energy 2010;87(7):2256–65. 

[261] Benz M, Onder CH, Guzzella L. Engine emission modeling using a mixed physics 
and regression approach. J Eng Gas Turbine Power 2010;132(4):042803. 
[262] Flowers D, Aceves S, Martinez-Frias J, Dibble R. Prediction of carbon monoxide 
and hydrocarbon emissions in isooctane HCCI engine combustion using multizone 
simulations. Proc Combust Inst 2002;29(1):687–94. 

[263] Sommer DE, Kirchen P. Towards improved partial oxidation product yield in 

mixed ionic-electronic membrane reactors using CSTR and CFD modelling. Chem 
Eng Sci 2019;195:11–22. 

engine during transient operations. SAE International 2017.Paper No. 2017-01- 
0767 

[288] Shahbakhti M, Ghafuri M, Aslani AR, Sahraeian A, Jazayeri SA, Azadi S. A method 

to determine fuel transport dynamics model parameters in port fuel injected 
gasoline engines during cold start and warm-Up conditions. J Eng Gas Turbine 
Power 2010;132(7). 

[289] Fan W, Bifet A. Mining big data: current status, and forecast to the future. ACM 

sIGKDD Explorations Newsletter 2013;14(2):1–5. 

[290] Hanuschkin A, Schober S, Bode J, Schorr J, B¨ohm B, Krüger C, et al. Machine 
learning–based analysis of in-cylinder flow fields to predict combustion engine 
performance. Int J Engine Res 2021;22(1):257–72. 

[291] Chopra P, Yadav SK. Fault detection and classification by unsupervised feature 
extraction and dimensionality reduction. Complex & Intelligent Systems 2015;1 
(1–4):25–33. 

[292] Hirsch M, Alberer D, Del Re L. Grey-box control oriented emissions models. IFAC 

Proceedings Volumes 2008;41(2):8514–9. 

[293] Pan Y, Chen S, Qiao F, Ukkusuri SV, Tang K. Estimation of real-driving emissions 
for buses fueled with liquefied natural gas based on gradient boosted regression 
trees. Sci Total Environ 2019;660:741–50. 

[294] Dharma S, Hassan MH, Ong HC, Sebayang AH, Silitonga AS, Kusumo F, et al. 

Experimental study and prediction of the performance and exhaust emissions of 

ProgressinEnergyandCombustionScience88(2022)10096735M. Aliramezani et al.                                                                                                                                                                                                                          

mixed Jatropha curcas-Ceiba pentandra biodiesel blends in diesel engine using 
artificial neural networks. J Clean Prod 2017;164:618–33. 

[295] O˘guz H, Sarıtas I, Baydan HE. Prediction of diesel engine performance using 
biofuels with artificial neural network. Expert Syst Appl 2010;37(9):6579–86. 

[325] Karegowda AG, Manjunath A, Jayaram M. Application of genetic algorithm 
optimized neural network connection weights for medical diagnosis of pima 
indians diabetes. International Journal on Soft Computing 2011;2(2):15–23. 

[326] Vishwakarma MDD. Genetic algorithm based weights optimization of artificial 

[296] Javed S, Murthy YS, Baig RU, Rao DP. Development of ann model for prediction 
of performance and emission characteristics of hydrogen dual fueled diesel engine 
with jatropha methyl ester biodiesel blends. J Nat Gas Sci Eng 2015;26:549–57. 

neural network. International Journal of Advanced Research in Electrical, 
Electronics and Instrumentation Engineering 2012;1(3):206–11. 
[327] Such FP, Madhavan V, Conti E, Lehman J, Stanley KO, Clune J. Deep 

[297] Le Cornec CM, Molden N, van Reeuwijk M, Stettler ME. Modelling of 

instantaneous emissions from diesel vehicles with a special focus on NOx: insights 
from machine learning techniques. Sci Total Environ 2020:139625. 

[298] Roy S, Banerjee R, Bose P. Performance and exhaust emissions prediction of a 

neuroevolution: genetic algorithms are a competitive alternative for training deep 
neural networks for reinforcement learning. arXiv:171206567 2017. 

[328] Whitley D. A genetic algorithm tutorial. Stat Comput 1994;4(2):65–85. 
[329] Kumar M, Husian M, Upreti N, Gupta D. Genetic algorithm: review and 

CRDI assisted single cylinder diesel engine coupled with EGR using artificial 
neural network. Appl Energy 2014;119:330–40. 

application. International Journal of Information Technology and Knowledge 
Management 2010;2(2):451–4. 

[299] Ghobadian B, Rahimi H, Nikbakht A, Najafi G, Yusaf T. Diesel engine performance 
and exhaust emission analysis using waste cooking biodiesel fuel with an artificial 
neural network. Renew Energy 2009;34(4):976–82. 

[300] Kiani MKD, Ghobadian B, Tavakoli T, Nikbakht A, Najafi G. Application of 

artificial neural networks for the prediction of performance and exhaust emissions 
in si engine using ethanol-gasoline blends. Energy 2010;35(1):65–9. 

[301] Kapusuz M, Ozcan H, Yamin JA. Research of performance on a spark ignition 
engine fueled by alcohol–gasoline blends using artificial neural networks. Appl 
Therm Eng 2015;91:525–34. 

[302] Bendu H, Deepak B, Murugan S. Application of GRNN for the prediction of 

performance and exhaust emissions in HCCI engine using ethanol. Energy 
Convers Manage 2016;122:165–73. 

[303] Janakiraman VM, Nguyen X, Sterniak J, Assanis D. Identification of the dynamic 
operating envelope of HCCI engines using class imbalance learning. IEEE Trans 
Neural Netw Learn Syst 2014;26(1):98–112. 

[304] Meireles MR, Almeida PE, Sim˜oes MG. A comprehensive review for industrial 
applicability of artificial neural networks. IEEE Trans Ind Electron 2003;50(3): 
585–601. 

[305] Dowell JA, Hussain A, Devane J, Young D. Artificial neural networks applied to 
the in vitro-in vivo correlation of an extended-release formulation: initial trials 
and experience. J Pharm Sci 1999;88(1):154–60. 

[306] Giustolisi O, Simeone V. Optimal design of artificial neural networks by a multi- 
objective strategy: groundwater level predictions. Hydrol Sci J 2006;51(3): 
502–23. 

[307] Yao X, Liu Y. Evolving artificial neural networks through evolutionary 

programming. Evolutionary programming. 1996. p. 257–66. 

[308] Shamshirband S, Tabatabaei M, Aghbashlo M, Yee L, Petkovi´c D. Support vector 

machine-based exergetic modelling of a DI diesel engine running on 
biodiesel–diesel blends containing expanded polystyrene. Appl Therm Eng 2016; 
94:727–47. 

[309] Aliramezani M, Koch C, Hayes R. Estimating tailpipe NOx concentration using a 
dynamic NOx/ammonia cross sensitivity model coupled to a three state control 
oriented SCR model. IFAC-PapersOnLine 2016;49(11):8–13. 

[310] Zhao H., Homogeneous charge compression ignition (HCCI) and controlled auto 
ignition (CAI) engines for the automotive industry. Woodhead Publishing Limited 
2007 (CRC) Press, Boca Raton, Florida. 

[311] Zhao H. Homogeneous charge compression ignition (HCCI) and controlled auto 
ignition (CAI) engines for the automotive industry. Brunel University: Woodhead 
Publishing Limited; 2007. 

[312] Thomas J-H, Dubuisson B, Dillies-Peltier M-A. Engine knock detection from 

vibration signals using pattern recognition. Meccanica 1997;32(5):431–9. 
[313] El-Dahshan E-SA. Genetic algorithm and wavelet hybrid scheme for ECG signal 

denoising. Telecommun Syst 2011;46(3):209–15. 

[330] Kramer O. Genetic algorithm essentials679. Springer; 2017. 
[331] Malikopoulos AA, Assanis DN, Papalambros PY. Real-time self-learning 

optimization of diesel engine calibration. J Eng Gas Turbine Power 2009;131(2): 
022803. 

[332] Wong PK, Gao XH, Wong KI, Vong CM. Efficient point-by-point engine calibration 
using machine learning and sequential design of experiment strategies. J Franklin 
Inst 2018;355(4):1517–38. 

[333] Wong KI, Wong PK. Optimal calibration of variable biofuel blend dual-injection 

engines using sparse Bayesian extreme learning machine and metaheuristic 
optimization. Energy Convers Manage 2017;148:1170–8. 

[334] Sebayang A, Masjuki H, Ong HC, Dharma S, Silitonga A, Kusumo F, et al. 

Prediction of engine performance and emissions with Manihot glaziovii 
bioethanol- Gasoline blended using extreme learning machine. Fuel 2017;210: 
914–21. 

[335] Mariani VC, Och SH, dos Santos Coelho L, Domingues E. Pressure prediction of a 
spark ignition single cylinder engine using optimized extreme learning machine 
models. Appl Energy 2019;249:204–21. 

[336] Wong PK, Huang W, Vong CM, Yang Z. Adaptive neural tracking control for 

automotive engine idle speed regulation using extreme learning machine. Neural 
Computing and Applications 2019:1–11. 

[337] Vaughan A.. Adaptive machine learning method to predict and control engine 

combustion. 2018. US Patent 10,030,602. 

[338] Wong PK, Gao XH, Wong KI, Vong CM. Efficient point-by-point engine calibration 
using machine learning and sequential design of experiment strategies. J Franklin 
Inst 2018;355(4):1517–38. https://doi.org/10.1016/j.jfranklin.2017.02.006. 
Special Issue on Recent advances in machine learning for signal analysis and 
processing 

[339] Kumar BR, Saravanan S, Sethuramasamyraja B, Rana D. Screening oxygenates for 
favorable NOx/smoke trade-off in a DI diesel engine using multi response 
optimization. Fuel 2017;199:670–83. 

[340] Wong SY, Yap KS, Yap HJ. A constrained optimization based extreme learning 
machine for noisy data regression. Neurocomputing 2016;171:1431–43. 
[341] Smarra F, Jain A, de Rubeis T, Ambrosini D, D’Innocenzo A, Mangharam R. Data- 
driven model predictive control using random forests for building energy 
optimization and climate control. Appl Energy 2018;226:1252–72. 

[342] Wu Z, Tran A, Ren YM, Barnes CS, Chen S, Christofides PD. Model predictive 

control of phthalic anhydride synthesis in a fixed-bed catalytic reactor via 
machine learning modeling. Chem Eng Res Des 2019;145:173–83. 

[343] Chen Y, Tong Z, Zheng Y, Samuelson H, Norford L. Transfer learning with deep 
neural networks for model predictive control of HVAC and natural ventilation in 
smart buildings. J Clean Prod 2020;254:119866. 

[344] Lepird JR. Multi-objective optimization of next-generation aircraft collision 

avoidance software. Massachusetts Institute of Technology; 2015. 

[314] Lazarescu D, Lazarescu V, Ungureanu M. Knock detection based on SOM. 7th 

[345] Negenborn RR, De Schutter B, Wiering MA, Hellendoorn H. Learning-based model 

seminar on neural network applications in electrical engineering, 2004. NEUREL 
2004. 2004. IEEE; 2004. p. 117–20. 

predictive control for markov decision processes. IFAC Proceedings Volumes 
2005;38(1):354–9. 

[315] Witwit AR, Yasin A, Abas MA, Gitano H. Modern methods in engine knock signal 

detection. Procedia Technol 2013;11:40–50. 

[316] Zhen X, Wang Y, Xu S, Zhu Y, Tao C, Xu T, et al. The engine knock analysis–an 

overview. Appl Energy 2012;92:628–36. 

[317] Pan Y, Jiang J, Wang R, Cao H, Cui Y. Predicting the auto-ignition temperatures of 

organic compounds from molecular structure using support vector machine. 
J Hazard Mater 2009;164(2–3):1242–9. 

[318] Aliramezani M, Khademnahvi M, Delkhosh M. Optimal energy management 

strategy of a hybrid electric vehicle considering engine noise. J Vib Control 2018; 
24(23):5546–55. 

[319] Çelebi K, Uludamar E, Tosun E, Yıldızhan S¸ , Aydın K, 

¨
Ozcanlı M. Experimental 
and artificial neural network approach of noise and vibration characteristic of an 
unmodified diesel engine fuelled with conventional diesel, and biodiesel blends 
with natural gas addition. Fuel 2017;197:159–73. 

[346] Zhong M, Johnson M, Tassa Y, Erez T, Todorov E. Value function approximation 
and model predictive control. 2013 IEEE symposium on adaptive dynamic 
programming and reinforcement learning (ADPRL). IEEE; 2013. p. 100–7. 
[347] García JJV, Garay VG, Gordo EI, Fano FA, Sukia ML. Intelligent multi-objective 
nonlinear model predictive control (IMO-NMPC): towards the ‘on-line’ 
optimization of highly complex control problems. Expert Syst Appl 2012;39(7): 
6527–40. 

[348] Babaie M, Sharifzadeh M, Mehrasa M, Chouinard G, Al-Haddad K. Supervised 
learning model predictive control trained by abc algorithm for common mode 
voltage suppression in npc inverter. IEEE J Emerg Sel Top Power Electron 2020. 
[349] Gao B, Cai K, Qu T, Hu Y, Chen H. Personalized adaptive cruise control based on 

online driving style recognition technology and model predictive control. IEEE 
Trans Veh Technol 2020. 

[350] Sindareh-Esfahani P. Machine learning modeling and robust model predictive 

[320] Turkson RF, Yan F, Ali MKA, Hu J. Artificial neural network applications in the 

control of a wind turbine. 2019. 

calibration of spark-ignition engines: an overview. Engineering Science and 
Technology, an International Journal 2016;19(3):1346–59. 

[321] Goldberg DE, Holland JH. Genetic algorithms and machine learning. chapter 5. 

1988. 

[322] Moiz AA, Pal P, Probst D, Pei Y, Zhang Y, Som S, et al. A machine learning-genetic 

algorithm (ML-GA) approach for rapid optimization using high-performance 
computing. SAE Int J Commer Veh 2018;11(2018-01–0190):291–306. 
[323] Maulik U, Bandyopadhyay S. Genetic algorithm-based clustering technique. 

Pattern Recognit 2000;33(9):1455–65. 

[324] Krishna K, Murty MN. Genetic k-means algorithm. IEEE Transactions on Systems, 

Man, and Cybernetics, Part B (Cybernetics) 1999;29(3):433–9. 

[351] Miao Q, Wang S-F. Nonlinear model predictive control based on support vector 
regression. Proceedings. international conference on machine learning and 
cybernetics. 3. IEEE; 2002. p. 1657–61. 

[352] Yin X, Zhao X, Lin J, Karcanias A. Reliability aware multi-objective predictive 
control for wind farm based on machine learning and heuristic optimizations. 
Energy 2020:117739. 

[353] Bradford E, Imsland L, Zhang D, del Rio Chanona EA. Stochastic data-driven 

model predictive control using gaussian processes. Computers & Chemical 
Engineering 2020;139:106844. 

[354] Yang S, Wan MP, Chen W, Ng BF, Dubey S. Model predictive control with 
adaptive machine-learning-based model for building energy efficiency and 
comfort optimization. Appl Energy 2020;271:115147. 

ProgressinEnergyandCombustionScience88(2022)10096736M. Aliramezani et al.                                                                                                                                                                                                                          

[355] Bieker K, Peitz S, Brunton SL, Kutz JN, Dellnitz M. Deep model predictive flow 
control with limited sensor data and online learning. Theor Comput Fluid Dyn 
2020:1–15. 

[356] Wu Z, Rincon D, Christofides PD. Real-time adaptive machine-learning-based 
predictive control of nonlinear processes. Industrial & Engineering Chemistry 
Research 2019;59(6):2275–90. 

[386] Rizzoni G. Fast transforms for rapid isolation of misfiring cylinders. SAE Paper 

871915. 1987. 

[387] Azzoni P, Moro D, Porceddu-cilione CM, Rizzoni G. Misfire detection in a high- 
performance engine by the principal component analysis approach. SAE Paper 
960622. 1996. 

[388] Moro D, Azzoni P, Minelly G. Misfire pattern recognition in high-performance SI 

[357] Bao Y, Velni JM, Shahbakhti M. An online transfer learning approach for 

12-cylinder engine. SAE Paper 980521. 1998. 

identification and predictive control design with application to RCCI engines. 
ASME 2020 Dynamic Systems and Control Conference 2020. 

[358] Shin J, Kim HJ, Park S, Kim Y. Model predictive flight control using adaptive 

support vector regression. Neurocomputing 2010;73(4–6):1031–7. 

[359] Shin C, Ferguson PW, Pedram SA, Ma J, Dutson EP, Rosen J. Autonomous tissue 

manipulation via surgical robot using learning based model predictive control. 
2019 international conference on robotics and automation (ICRA). IEEE; 2019. 
p. 3875–81. 

[389] Chung Y, Bae C, Choi S, Yoon K. Application of a wide range oxygen sensor for the 

misfire detection. SAE Paper 1999-01-1485. 1999. 

[390] Yoshimura K, Tokunaga Y, Hashimoto D, Sakurai H. SAE Paper 2007-01-2078. 
2007.Knock and misfire detection using ion current measurement for ultra lean 
burn medium speed gas engine 

[391] Lee A, Pyko JS. Engine misfire detection by ionization current monitoring. Tech. 

Rep. SAE Technical Paper; 1995. 

[392] YKirkham C, Cambio R. Misfire detection including confidence indicators using a 

[360] Kuo C-Y, Cui Y, Matsubara T. Sample-and-computation-efficient probabilistic 

hardware neural network. SAE Paper 2006-01-1349. 2006. 

model predictive control with random features. 2020 IEEE international 
conference on robotics and automation (ICRA). IEEE; 2020. p. 307–13. 
[361] Ong CJ, Sui D, Gilbert EG. Enlarging the terminal region of nonlinear model 

predictive control using the support vector machine method. Automatica 2006;42 
(6):1011–6. 

[362] Le K, Bourdais R, Gu´eguen H. From hybrid model predictive control to logical 
control for shading system: a support vector machine approach. Energy Build 
2014;84:352–9. 

[363] Georges D. A simple machine learning technique for model predictive control. 
2019 27th mediterranean conference on control and automation (MED). IEEE; 
2019. p. 69–74. 

[364] Novak M, Dragicevic T. Supervised imitation learning of finite set model 

[393] Bahri B, Aziz AA, Shahbakhti M, Said MFM. Understanding and detecting misfire 
in an HCCI engine fuelled with ethanol. Appl Energy 2013;108:24–33. 
[394] Jafarian K, Mobin M, Jafari-Marandi R, Rabiei E. Misfire and valve clearance 
faults detection in the combustion engines based on a multi-sensor vibration 
signal monitoring. Measurement 2018;128:527–36. 

[395] Baltusis P. On board vehicle diagnostics. Tech. Rep. SAE Technical Paper; 2004. 
[396] Zhan Y-L, Shi Z-B, Shwe T, Wang X-Z. Fault diagnosis of marine main engine 

cylinder cover based on vibration signal. 2007 international conference on 
machine learning and cybernetics. 2. IEEE; 2007. p. 1126–30. 

[397] Moosavian A, Ahmadi H, Tabatabaeefar A. Fault diagnosis of main engine journal 

bearing based on vibration analysis using Fisher linear discriminant, K-nearest 
neighbor and support vector machine. journal of vibroengineering 2012;14(2). 

predictive control systems for power electronics. IEEE Trans Ind Electron 2020. 

[398] WU Z-y, YUAN H-q. Fault diagnosis of an engine with ant colony support vector 

[365] Chen S, Saulnier K, Atanasov N, Lee DD, Kumar V, Pappas GJ, et al. 

machine. Journal of Vibration and Shock 2009;3. 

Approximating explicit model predictive control using constrained neural 
networks. 2018 Annual American Control Conference (ACC). IEEE; 2018. 
p. 1520–7. 

[399] Li Z, Yan X, Yuan C, Peng Z. Intelligent fault diagnosis method for marine diesel 

engines using instantaneous angular speed. J Mech Sci Technol 2012;26(8): 
2413–23. 

[366] Maasoumy M, Razmara M, Shahbakhti M, Vincentelli A. Handling model 

[400] Hendrycks D, Mazeika M, Kadavath S, Song D. Using self-supervised learning can 

uncertainty in model predictive control for energy efficient buildings. Energy 
Build 2014;77:377–92. 

[367] Afram A, Janabi-Sharifi F, Fung AS, Raahemifar K. Artificial neural network 

improve model robustness and uncertainty. Advances in neural information 
processing systems. 2019. p. 15637–48. 

[401] Åstr¨om KJ, Eykhoff P. System identification-a survey. Automatica 1971;7(2): 

(ANN) based model predictive control (MPC) and optimization of HVAC systems: 
a state of the art review and case study of a residential HVAC system. Energy 
Build 2017;141:96–113. https://doi.org/10.1016/j.enbuild.2017.02.012.http:// 
www.sciencedirect.com/science/article/pii/S0378778816310799 

[368] Zhai Y-J, Yu D-L. Neural network model-based automotive engine air/fuel ratio 

control and robustness evaluation. Eng Appl Artif Intell 2009;22(2):171–80. 

[369] Wang S, Yu D, Gomm J, Page G, Douglas S. Adaptive neural network model based 
predictive control for air–fuel ratio of SI engines. Eng Appl Artif Intell 2006;19(2): 
189–200. 

123–62. 

[402] Ljung L. System identification. Wiley encyclopedia of electrical and electronics 

engineering 1999:1–19. 

[403] Li J, Cheng K, Wang S, Morstatter F, Trevino RP, Tang J, et al. Feature selection: a 

data perspective. ACM Computing Surveys (CSUR) 2017;50(6):1–45. 

[404] Nixon M, Aguado A. Feature extraction and image processing for computer vision. 

chapter 6. Academic Press; 2019. 

[405] Zou H, Hastie T, Tibshirani R. Sparse principal component analysis. Journal of 

Computational and Graphical Statistics 2006;15(2):265–86. 

[370] Chaoui H, Sicard P, Gueaieb W. ANN-based adaptive control of robotic 

[406] Wang J, Chang C-I. Independent component analysis-based dimensionality 

manipulators with friction and joint elasticity. IEEE Trans Ind Electron 2009;56 
(8):3174–87. 

reduction with applications in hyperspectral image analysis. IEEE Trans Geosci 
Remote Sens 2006;44(6):1586–600. 

[371] Ahmed M. Neural-net-based direct adaptive control for a class of nonlinear plants. 

[407] Lu J, Plataniotis KN, Venetsanopoulos AN. Face recognition using LDA-based 

IEEE Trans Automat Contr 2000;45(1):119–24. 

algorithms. IEEE Trans Neural Networks 2003;14(1):195–200. 

[372] Ahmed R, El Sayed M, Gadsden SA, Tjong J, Habibi S. Automotive internal- 

[408] Roweis ST, Saul LK. Nonlinear dimensionality reduction by locally linear 

combustion-engine fault detection and classification using artificial neural 
network techniques. IEEE Trans Veh Technol 2014;64(1):21–33. 

[373] Yedavalli RK. Robust estimation and fault diagnostics for aircraft engines with 

uncertain model data. 2007 American Control Conference. IEEE; 2007. p. 2822–7. 

[374] Cybenko G. Approximation by superpositions of a sigmoidal function. 
Mathematics of control, signals and systems 1989;2(4):303–14. 

[375] Habibi S. The smooth variable structure filter. Proc IEEE 2007;95(5):1026–59. 
[376] Cho S, Park J, Song C, Oh S, Lee S, Kim M, et al. Prediction modeling and analysis 
of knocking combustion using an improved 0D RGF model and supervised deep 
learning. Energies 2019;12(5):844. 

[377] Gangopadhyay T, Locurto A, Michael JB, Sarkar S. Deep learning algorithms for 

detecting combustion instabilities. Singapore: Springer Singapore; 2020, ISBN 
978-981-15-0536-2. p. 283–300. 

[378] Goodfellow I, Bengio Y, Courville A. Deep learning. MIT press; 2016. 
[379] McGilvary GA, Barker A, Atkinson M. Ad hoc cloud computing. 2015 IEEE 8th 
international conference on cloud computing. IEEE; 2015. p. 1063–8. 

embedding. Science 2000;290(5500):2323–6. 

[409] Vincent P, Larochelle H, Bengio Y, Manzagol P-A. Extracting and composing 
robust features with denoising autoencoders. Proceedings of the 25th 
international conference on Machine learning. 2008. p. 1096–103. 

[410] Bekkar M, Alitouche TA. Imbalanced data learning approaches review. 

International Journal of Data Mining & Knowledge Management Process 2013;3 
(4):15. 

[411] Gonz´alez Palacios CR. Optimal data distributions in machine learning. California 

Institute of Technology; 2015. 

[412] Karsoliya S. Approximating number of hidden layer neurons in multiple hidden 
layer BPNN architecture. International Journal of Engineering Trends and 
Technology 2012;3(6):714–7. 

[413] Modnn: memory optimal dnn training on gpus. 
[414] Park J, Samarakoon S, Elgabli A, Kim J, Bennis M, Kim S-L, et al. Communication- 
efficient and distributed learning over wireless networks: principles and 
applications. Proc IEEE 2021. 

[380] Janakiraman VM, Nguyen X, Assanis D. An ELM based predictive control method 

[415] Moon JY, Kim JH, Jeon JW, et al. The migration of engine ECU software from 

for HCCI engines. Eng Appl Artif Intell 2016;48:106–18. 

single-core to multi-core. IEEE Access 2021;9:55742–53. 

[381] Raut A, Khoshbakht Irdmousa B, Shahbakhti M. Dynamic modeling and model 
predictive control of an RCCI engine. Control Eng Pract 2018;81:129–44. 
[382] Shih P, Kaul BC, Jagannathan S, Drallmeier JA. Reinforcement-learning-based 

output-feedback control of nonstrict nonlinear discrete-time systems with 
application to engine emission control. IEEE Transactions on Systems, Man, and 
Cybernetics, Part B (Cybernetics) 2009;39(5):1162–79. 

[383] Kokjohn SL, Musculus MP, Reitz RD. Evaluating temperature and fuel 

stratification for heat-release rate control in a reactivity-controlled compression- 
ignition engine using optical diagnostics and chemical kinetics modeling. 
Combust Flame 2015;162(6):2729–42. 

[384] Wu Z, Lee A. Misfire detection using a dynamic neural network with output 

feedback. SAE Paper 980515. 1998. 

[385] Komachiya M, Kurihara N, Kodama A, Sakaguchi T, Fumino T, Watanabe S. 

A method of misfire detection by superposing outputs of combustion pressure 
sensors. SAE Paper 982588. 1998. 

[416] Padmanabha Iyer A, Erran Li L, Chowdhury M, Stoica I. Mitigating the latency- 

accuracy trade-off in mobile data analytics systems. Proceedings of the 24th 
annual international conference on mobile computing and networking. 2018. 
p. 513–28. 

[417] Deb K, Pratap A, Agarwal S, Meyarivan T. A fast and elitist multiobjective genetic 
algorithm: NSGA-II. Evolutionary Computation, IEEE Transactions on 2002;6(2): 
182–97. 

[418] Thiele JC, Bichler O, Dupret A. Event-based, timescale invariant unsupervised 
online deep learning with STDP. Front Comput Neurosci 2018;12:46. 

Masoud Aliramezani received the B.S. degree in mechanical engineering from K. N. Toosi 
University of Technology, Tehran, Iran in 2010, the M.S. degree in mechanical engineering 
from Sharif University of Technology, Tehran, Iran in 2012, and the Ph.D. degree in me-
chanical engineering from the University of Al- berta (UofA), Edmonton, Canada in 2019. 
He has been working on modeling and control of internal combustion engines (ICE)s for 
more than 10 years both in the automotive industry and in academia. His research has 

ProgressinEnergyandCombustionScience88(2022)10096737M. Aliramezani et al.                                                                                                                                                                                                                          

been focused on developing physics-based and machine-learning based models for internal 
combustion engines, aftertreatment systems and emission sensors. He was with Irankhodro 
powertrain  Co  (IPCO)  from  2009  to  2010  and  from  2012  to  2014  working  on  engine 
calibration and emission reduction of light-duty spark igni- tion and diesel engines, as well 
as energy management of hybrid electric vehicles. He had been a graduate research and 
teaching  assistant  from  2014  to  2019  working  on  advanced  ICE  modeling  and  control 
strategies  focused  on  electrchemical  sensors  for  realtime  emission  measurement  and 
feedback  control  of  ICE  gaseous  emissions.  Since  2019  he  has  been  a  lecturer  at  UofA 
departments of mechanical engineering and chem- ical engineering, teaching core engi-
neering  courses  including  applied  thermodynamics  and  process  control.  He  is  now  a 
postdoctoral fellow of mechanical engineering at the UofA working on advanced machine 
learning  techniques  to  model  and  control  ICEs.  He  had  also  been  a  member  of  UofA 
research  policy  committee,  Chair  of  Faculty  of  Graduate  Studies  and  Research  (FGSR) 
council caucus, and Chair of General Faculties Council (GFC) Caucus. 

C.R.  Koch  received  his  B.S.  degree  in  mechanical  engineering  from  the  University  of 
Alberta, Edmonton, Canada in 1985, and his M.S. and Ph.D. degrees from Stanford Uni-
versity, Palo Alto, CA, in 1986 and 1991, respectively. From 1991 to 1992 and from 1994 
to 2001 he worked at Daimler-Benz DaimlerChrysler in Stuttgart Germany in advanced 
internal combustion engines. During 1992 to 1994 he worked for General Motors. From 
this work he holds 7 US patents and 5 German patents. In 2001, he joined the Mechanical 
Engineering Department of the University of Alberta, Edmonton, Canada, where he is a 
Professor.  He  teaches  in  the  areas  of  fluid  mechanics  and  controls  and  has  been  the 
associate chair research and of the undergraduate program. He has been on sabbatical at 
the Technical University of Berlin in 2016 (hosted by Rudi King) and at the University of 
Stuttgart in 2007 (host by Frank Allgoewer). His research interests include combustion 
engines,  sensors  for  emission  measurement  during  driving,  advanced  powertrains  and 
control  of  fluid  systems.  Control  of  Distributed  Parameter  Systems  particularly  as  they 
pertain to reacting and non-reacting flows are also an active research area. He is currently 
an  Associate  Editor  for  the  Mechatronics  Journal  (Elsevier)  and  Control  Engineering 
Practice. He has more than 30 years of experience in conducting numerous research-based 

projects that include developing physics-based and data-driven models for internal com-
bustion  engines  (ICE)s  and  advanced  ICE  control  strategies.  He  has  also  been  leading 
research projects on machine-learning based modeling and control of ICEs using Artificial 
Neural  Network  (ANN),  Support  Vector  Machine  (SVM),  Extreme  Learning  Machine 
(ELM), and other state-of-the-art machine learning techniques. He  is particularly inter-
ested in connecting modern control strategies such as adaptive control, model predictive 
control and iterative learning control with advanced machine learning based and rein-
forcement learning based control approaches. 

Mahdi Shahbakhti is an Associate Professor of Mechanical Engineering at the University 
of Alberta and a Research Associate Professor of Mechanical Engineering at Michigan Tech 
University.  He  was  a  post-doctoral  scholar  at  the  University  of  California-Berkeley 
(2010–2012)  and  received  his  PhD  in  Mechanical  Engineering  from  the  University  of 
Alberta in 2009. He worked several years on modeling and control of dynamic systems in 
the automotive (2001–2004), robotic (2000–2001), and HVAC (1998–2000) industries. 
He has over 20 years of academic and industry research experience on internal combustion 
engines  (ICEs).  His  ICE  research  has  centered  on  experimental  combustion  studies, 
developing  physical  and  data-driven  dynamical  models,  and  model-based  combustion 
control techniques. He has co-authored more than 120 peer-reviewed publications in the 
field of modeling and control of ICEs and automotive powertrains. Over the past 8 years, 
his research group has successfully applied different artificial intelligence and machine 
learning  techniques  for  modeling,  diagnostics,  optimization,  and  control  of  ICEs.  His 
research has been funded by, among others, Ford Motor Company, General Motors, Toyota 
Motor Company, the US National Science Foundation, ARPA-E and the US Department of 
Energy, and Natural Sciences and Engineering Research Council of Canada. Dr. Shahbakhti 
is  the  vice-chair  of  ASME  Dynamic  Systems  Control  Division  (DSCD)  Automotive  and 
Transportation  Systems  Technical  Committee  and  former  chair  (2018–2020)  of  ASME- 
DSCD Energy Systems Technical Committee. He serves as the Associate Editor for ASME 
Journal  of  Dynamic  Systems,  Measurement,  and  Control,  and  also  Associate  Editor 
(2014–2020) for International Journal of Powertrains. 

ProgressinEnergyandCombustionScience88(2022)10096738
#!/usr/bin/env python3
"""
Milestone 1 Insights Pro Generator
ç”Ÿæˆé«˜è´¨é‡çš„é¢†åŸŸæ´å¯Ÿï¼Œå¼ºè°ƒç†è§£è¿‡ç¨‹è€Œéç®€å•é™ˆè¿°äº‹å®
æ¯ç¯‡è®ºæ–‡ç”Ÿæˆ5æ¡æ·±åº¦æ´å¯Ÿ
"""

import json
import logging
import sys
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Tuple
import difflib
from litellm import completion

# å¯¼å…¥å·²æœ‰æ¨¡å—
from src.utils import setup_logging, load_env_variables

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# æ–‡ä»¶è·¯å¾„
PAPER_FILE = Path("main.txt")
OUTPUT_FILE = Path("data/milestone1_insights_pro.jsonl")
REPORT_FILE = Path("data/milestone1_insights_pro_report.md")

# æ¨¡å‹é…ç½®
GENERATION_MODEL = "openai/deepseek-ai/DeepSeek-V3"
CITATION_THRESHOLD = 0.85


def load_paper_data() -> Dict[str, Any]:
    """åŠ è½½è®ºæ–‡å…¨æ–‡"""
    logger.info(f"Loading paper from: {PAPER_FILE}")
    with open(PAPER_FILE, 'r', encoding='utf-8') as f:
        entire_text = f.read()
    logger.info(f"  Text length: {len(entire_text)} chars")
    return {
        "title": "Combustion Science Review",
        "entire_text": entire_text
    }


def build_generation_prompt(seed_data: Dict[str, Any]) -> str:
    """
    æ„å»ºç”Ÿæˆæ´å¯Ÿçš„prompt
    å¼ºè°ƒç†è§£è¿‡ç¨‹ï¼šä¸ºä»€ä¹ˆâ†’æ€ä¹ˆæ ·â†’æ„å‘³ç€ä»€ä¹ˆ
    """
    # æˆªå–å‰50000å­—ç¬¦ä»¥é¿å…è¶…é•¿context
    text_excerpt = seed_data['entire_text'][:50000]
    
    prompt = f"""ä½ æ˜¯ä¸€ä½ç‡ƒçƒ§ç§‘å­¦å’ŒCFDé¢†åŸŸçš„èµ„æ·±ä¸“å®¶ã€‚ä½ åˆšåˆšä»”ç»†é˜…è¯»äº†è¿™ç¯‡è®ºæ–‡çš„æ ¸å¿ƒå†…å®¹ï¼Œå¹¶ä»ä¸­è·å¾—äº†æ·±åˆ»çš„é¢†åŸŸç†è§£ã€‚

**è®ºæ–‡æ ‡é¢˜**: {seed_data['title']}

**è®ºæ–‡å†…å®¹æ‘˜å½•** (å‰50000å­—ç¬¦):
{text_excerpt}

---

## ä»»åŠ¡è¦æ±‚

è¯·ç”Ÿæˆ **5æ¡é«˜è´¨é‡çš„é¢†åŸŸæ´å¯Ÿ**ï¼Œæ¯æ¡æ´å¯Ÿå¿…é¡»ï¼š

### 1. å†…å®¹è¦æ±‚
- **èšç„¦é¢†åŸŸ**: å¿…é¡»å…³äºç‡ƒçƒ§ã€ä¼ çƒ­ã€æµä½“åŠ›å­¦ã€CFDã€èƒ½æºåº”ç”¨ï¼ˆä¸è¦çº¯ML/CSæ–¹æ³•å¯¹æ¯”ï¼‰
- **å±•ç¤ºç†è§£è¿‡ç¨‹**ï¼ˆé‡è¦ï¼ï¼‰ï¼š
  - âŒ é”™è¯¯ç¤ºä¾‹ï¼ˆä»…é™ˆè¿°äº‹å®ï¼‰ï¼š"ç°ç›’æ¨¡å‹ç»“åˆç‰©ç†å’Œæ•°æ®é©±åŠ¨æ–¹æ³•"
  - âœ… æ­£ç¡®ç¤ºä¾‹ï¼ˆå±•ç¤ºç†è§£ï¼‰ï¼š"ç°ç›’æ¨¡å‹çš„å…³é”®åˆ›æ–°åœ¨äº**åœ¨ç‰©ç†çº¦æŸä¸‹å­¦ä¹ æ•°æ®æ¨¡å¼**ï¼Œè¿™è§£å†³äº†çº¯MLæ¨¡å‹åœ¨å°æ ·æœ¬ç‡ƒçƒ§æ•°æ®ä¸Šçš„è¿‡æ‹Ÿåˆé—®é¢˜ï¼ŒåŒæ—¶é¿å…äº†CFDçš„è®¡ç®—ç“¶é¢ˆ"

### 2. æ´å¯Ÿç»“æ„ï¼ˆä¸‰æ®µå¼ï¼‰
æ¯æ¡æ´å¯Ÿåº”åŒ…å«ï¼š
1. **æ ¸å¿ƒå‘ç°**ï¼ˆWhatï¼‰ï¼šè¿™ä¸ªé¢†åŸŸçŸ¥è¯†çš„æœ¬è´¨æ˜¯ä»€ä¹ˆ
2. **ç†è§£è¿‡ç¨‹**ï¼ˆWhy/Howï¼‰ï¼šä¸ºä»€ä¹ˆè¿™å¾ˆé‡è¦ï¼Ÿå®ƒå¦‚ä½•è§£å†³é—®é¢˜ï¼ŸèƒŒåçš„æœºç†æ˜¯ä»€ä¹ˆï¼Ÿ
3. **é¢†åŸŸæ„ä¹‰**ï¼ˆImpactï¼‰ï¼šå¯¹ç‡ƒçƒ§/CFD/èƒ½æºé¢†åŸŸæ„å‘³ç€ä»€ä¹ˆ

ç¤ºä¾‹æ ¼å¼ï¼š
"[æ ¸å¿ƒå‘ç°]ã€‚è¿™æ˜¯å› ä¸º[ç†è§£è¿‡ç¨‹/æœºç†è§£é‡Š]ï¼Œä»è€Œ[é¢†åŸŸæ„ä¹‰/è§£å†³çš„é—®é¢˜]ã€‚"

### 3. å¼•ç”¨è¦æ±‚
- æ¯æ¡æ´å¯Ÿå¿…é¡»å¼•ç”¨è®ºæ–‡åŸæ–‡ä¸­çš„ **2æ®µå…·ä½“æ–‡å­—**
- å¼•ç”¨æ–‡å­—å¿…é¡»æ˜¯åŸæ–‡çš„**ç²¾ç¡®ç‰‡æ®µ**ï¼ˆä¸è¦æ”¹å†™ï¼‰
- å¼•ç”¨é•¿åº¦ï¼šæ¯æ®µ50-200å­—ç¬¦

### 4. ç¦æ­¢å†…å®¹
- âŒ ç®€å•ç½—åˆ—äº‹å®ï¼ˆå¦‚"XXæ–¹æ³•æ¯”YYå¿«"ï¼‰
- âŒ çº¯MLæ–¹æ³•å¯¹æ¯”ï¼ˆå¦‚"SVM vs ANN"ï¼‰
- âŒ ç¼ºå°‘æœºç†è§£é‡Šçš„é™ˆè¿°
- âŒ æ—¶æ•ˆæ€§å†…å®¹ï¼ˆå¦‚"è¿‘å¹´æ¥"ã€"æœªæ¥å°†"ï¼‰
- âŒ è¿‡äºå®½æ³›çš„é€šç”¨çŸ¥è¯†

---

## è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼JSONï¼‰

```json
{{
  "insights": [
    {{
      "insight_text": "[æ ¸å¿ƒå‘ç°]ã€‚[ç†è§£è¿‡ç¨‹/æœºç†è§£é‡Š]ï¼Œ[é¢†åŸŸæ„ä¹‰]ã€‚",
      "original_text": {{
        "1": "åŸæ–‡ç²¾ç¡®å¼•ç”¨1ï¼ˆ50-200å­—ç¬¦ï¼‰",
        "2": "åŸæ–‡ç²¾ç¡®å¼•ç”¨2ï¼ˆ50-200å­—ç¬¦ï¼‰"
      }},
      "domain": "combustion_modeling|combustion_control|engine_diagnostics|emission_modeling|turbulence_combustion|combustion_dynamics",
      "tags": ["tag1", "tag2", "tag3"]
    }}
  ]
}}
```

è¯·ç”Ÿæˆ5æ¡ç¬¦åˆè¦æ±‚çš„æ´å¯Ÿã€‚
"""
    return prompt


def verify_citations(
    original_text_dict: Dict[str, str],
    entire_text: str,
    threshold: float = CITATION_THRESHOLD
) -> Tuple[bool, Dict[str, Any]]:
    """
    éªŒè¯å¼•ç”¨æ˜¯å¦åœ¨åŸæ–‡ä¸­å­˜åœ¨
    
    Args:
        original_text_dict: å¼•ç”¨æ–‡æœ¬å­—å…¸
        entire_text: è®ºæ–‡å…¨æ–‡
        threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
    
    Returns:
        (æ˜¯å¦å…¨éƒ¨é€šè¿‡, è¯¦ç»†ç»“æœ)
    """
    entire_lower = entire_text.lower()
    entire_lower = ''.join(c for c in entire_lower if c.isalnum() or c.isspace())
    
    results = {}
    verified_count = 0
    failed_citations = []
    
    for cite_id, cite_text in original_text_dict.items():
        cite_clean = cite_text.lower()
        cite_clean = ''.join(c for c in cite_clean if c.isalnum() or c.isspace())
        
        # å¿«é€Ÿæ£€æŸ¥ï¼šåœ¨åŸæ–‡ä¸­æŸ¥æ‰¾å€™é€‰ä½ç½®
        words = cite_clean.split()[:5]  # å‰5ä¸ªè¯
        search_term = ' '.join(words)
        
        candidate_positions = []
        start_pos = 0
        while True:
            pos = entire_lower.find(search_term, start_pos)
            if pos == -1:
                break
            candidate_positions.append(pos)
            start_pos = pos + 1
        
        # åœ¨å€™é€‰ä½ç½®é™„è¿‘ç²¾ç¡®åŒ¹é…
        best_similarity = 0.0
        best_snippet = ""
        
        for pos in candidate_positions:
            # æå–å€™é€‰ç‰‡æ®µï¼ˆå‰åå„50%é•¿åº¦ï¼‰
            start = max(0, pos - len(cite_clean) // 2)
            end = min(len(entire_lower), pos + len(cite_clean) + len(cite_clean) // 2)
            candidate = entire_lower[start:end]
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = difflib.SequenceMatcher(None, cite_clean, candidate).ratio()
            if similarity > best_similarity:
                best_similarity = similarity
                best_snippet = entire_lower[pos:pos+100]
        
        verified = best_similarity >= threshold
        if verified:
            verified_count += 1
        else:
            failed_citations.append({
                "citation_id": cite_id,
                "text": cite_text[:100] + "...",
                "similarity": best_similarity
            })
        
        results[cite_id] = {
            "text": cite_text,
            "similarity": best_similarity,
            "verified": verified,
            "matched_snippet": best_snippet
        }
    
    all_verified = verified_count == len(original_text_dict)
    
    return all_verified, {
        "verified": all_verified,
        "total_citations": len(original_text_dict),
        "verified_citations": verified_count,
        "failed_citations": failed_citations,
        "details": results
    }


def generate_insights(seed_data: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    ç”Ÿæˆ5æ¡é«˜è´¨é‡æ´å¯Ÿ
    """
    logger.info("=" * 60)
    logger.info("Generating Insights Pro")
    logger.info("=" * 60)
    
    # æ„å»ºprompt
    prompt = build_generation_prompt(seed_data)
    
    # è°ƒç”¨æ¨¡å‹ç”Ÿæˆ
    logger.info(f"Calling {GENERATION_MODEL}...")
    response = completion(
        model=GENERATION_MODEL,
        messages=[{"role": "user", "content": prompt}],
        api_base="https://api.siliconflow.cn/v1",
        api_key=os.environ.get('SILICONFLOW_API_KEY'),
        response_format={"type": "json_object"},
        max_tokens=25000,
        temperature=0.7
    )
    
    response_text = response.choices[0].message.content
    logger.info(f"âœ“ Got response: {len(response_text)} chars")
    
    # è§£æJSON
    try:
        data = json.loads(response_text)
        insights = data.get("insights", [])
        logger.info(f"âœ“ Parsed {len(insights)} insights")
        return insights
    except json.JSONDecodeError as e:
        logger.error(f"JSON decode error: {e}")
        logger.error(f"Response: {response_text[:500]}")
        return []


def verify_all_citations(
    insights: List[Dict[str, Any]],
    entire_text: str
) -> List[Dict[str, Any]]:
    """
    éªŒè¯æ‰€æœ‰æ´å¯Ÿçš„å¼•æ–‡
    """
    logger.info("=" * 60)
    logger.info("Citation Verification")
    logger.info(f"Threshold: {CITATION_THRESHOLD * 100}%")
    logger.info("=" * 60)
    
    verified_count = 0
    
    for i, insight in enumerate(insights, 1):
        logger.info(f"Verifying citations for insight {i}/{len(insights)}...")
        
        original_text = insight.get("original_text", {})
        if not original_text:
            logger.warning(f"  âš  No citations found")
            insight["citation_verification"] = {
                "verified": False,
                "total_citations": 0,
                "verified_citations": 0,
                "failed_citations": [],
                "details": {}
            }
            continue
        
        # éªŒè¯å¼•æ–‡
        all_verified, verification_result = verify_citations(
            original_text, entire_text, CITATION_THRESHOLD
        )
        
        insight["citation_verification"] = verification_result
        
        if all_verified:
            logger.info(f"  âœ… All {verification_result['total_citations']} citations verified")
            verified_count += 1
        else:
            logger.warning(f"  âŒ {len(verification_result['failed_citations'])} citation(s) failed verification")
            for failed in verification_result['failed_citations']:
                logger.warning(f"     - Citation {failed['citation_id']}: {failed['similarity']*100:.1f}% similarity")
    
    logger.info(f"Citation Verification: {verified_count}/{len(insights)} insights passed")
    return insights


def add_metadata(insights: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """æ·»åŠ å…ƒæ•°æ®"""
    logger.info("=" * 60)
    logger.info("Adding Metadata")
    logger.info("=" * 60)
    
    for insight in insights:
        # ç”Ÿæˆå”¯ä¸€ID
        import hashlib
        text_hash = hashlib.md5(insight['insight_text'].encode()).hexdigest()[:8]
        insight['insight_id'] = f"insight_pro_{text_hash}"
        
        # æ·»åŠ æ¥æºä¿¡æ¯
        insight['source'] = {
            "type": "with_reference",
            "paper_id": "PECS_combustion_review",
            "paper_title": "Combustion Science Review"
        }
        
        # æ·»åŠ å…ƒæ•°æ®
        insight['metadata'] = {
            "generation_model": GENERATION_MODEL,
            "created_at": datetime.now().isoformat(),
            "milestone": "milestone_1_insights_pro",
            "insight_length": len(insight['insight_text'])
        }
    
    logger.info(f"âœ“ Wrapped {len(insights)} insights")
    return insights


def save_insights(insights: List[Dict[str, Any]]) -> None:
    """ä¿å­˜æ´å¯Ÿåˆ°JSONLæ–‡ä»¶"""
    logger.info("=" * 60)
    logger.info("Saving Insights")
    logger.info("=" * 60)
    
    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        for insight in insights:
            f.write(json.dumps(insight, ensure_ascii=False) + '\n')
    
    logger.info(f"âœ“ Insights saved to: {OUTPUT_FILE}")
    logger.info(f"  Total: {len(insights)} insights")


def generate_report(insights: List[Dict[str, Any]]) -> None:
    """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
    logger.info("=" * 60)
    logger.info("Generating Report")
    logger.info("=" * 60)
    
    # ç»Ÿè®¡æ•°æ®
    total = len(insights)
    citation_verified = sum(1 for i in insights if i.get('citation_verification', {}).get('verified', False))
    
    # é¢†åŸŸåˆ†å¸ƒ
    domain_count = {}
    for insight in insights:
        domain = insight.get('domain', 'unknown')
        domain_count[domain] = domain_count.get(domain, 0) + 1
    
    # æ´å¯Ÿé•¿åº¦ç»Ÿè®¡
    lengths = [i['metadata']['insight_length'] for i in insights]
    avg_length = sum(lengths) / len(lengths) if lengths else 0
    min_length = min(lengths) if lengths else 0
    max_length = max(lengths) if lengths else 0
    
    # ç”ŸæˆMarkdownæŠ¥å‘Š
    report = f"""# Milestone 1 Insights Pro - Quality Report

**Generation Time**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**Model**: {GENERATION_MODEL}  
**Total Insights**: {total}

---

## ğŸ“Š OVERALL RESULTS

| Metric | Count | Percentage |
|--------|-------|------------|
| **Citations Verified** | {citation_verified}/{total} | {citation_verified/total*100:.1f}% |

---

## ğŸ“ INSIGHT LENGTH STATISTICS

| Metric | Value |
|--------|-------|
| **Average Length** | {avg_length:.0f} characters |
| **Shortest Insight** | {min_length} characters |
| **Longest Insight** | {max_length} characters |

---

## ğŸ¯ DOMAIN DISTRIBUTION

| Domain | Count |
|--------|-------|
"""
    
    for domain, count in sorted(domain_count.items(), key=lambda x: -x[1]):
        report += f"| {domain} | {count} |\n"
    
    report += "\n---\n\n## ğŸ“‹ DETAILED INSIGHTS\n\n"
    
    # è¯¦ç»†æ´å¯Ÿ
    for i, insight in enumerate(insights, 1):
        verified = insight.get('citation_verification', {}).get('verified', False)
        status = "âœ…" if verified else "âŒ"
        
        report += f"\n### Insight {i} {status}\n\n"
        report += f"**Text**: {insight['insight_text']}\n\n"
        report += f"**Domain**: {insight.get('domain', 'unknown')}\n\n"
        report += f"**Tags**: {', '.join(insight.get('tags', []))}\n\n"
        report += f"**Length**: {insight['metadata']['insight_length']} chars\n\n"
        
        # å¼•æ–‡éªŒè¯ç»“æœ
        verification = insight.get('citation_verification', {})
        if verification:
            verified_cites = verification.get('verified_citations', 0)
            total_cites = verification.get('total_citations', 0)
            report += f"**Citations verified**: {status} ({verified_cites}/{total_cites})\n\n"
            
            if verification.get('failed_citations'):
                report += "**Citation issues**:\n"
                for failed in verification['failed_citations']:
                    report += f"  - Citation {failed['citation_id']}: {failed['similarity']*100:.1f}% similarity\n"
                report += "\n"
        
        # åŸæ–‡å¼•ç”¨
        report += "**Original Text**:\n"
        for cite_id, cite_text in insight.get('original_text', {}).items():
            report += f"{cite_id}. {cite_text}\n"
        report += "\n"
    
    # ä¿å­˜æŠ¥å‘Š
    with open(REPORT_FILE, 'w', encoding='utf-8') as f:
        f.write(report)
    
    logger.info(f"âœ“ Report saved to: {REPORT_FILE}")


def main():
    """ä¸»å‡½æ•°"""
    setup_logging()
    load_env_variables()
    
    logger.info("=" * 80)
    logger.info("Milestone 1 Insights Pro Generator - START")
    logger.info("=" * 80)
    
    try:
        # åŠ è½½è®ºæ–‡æ•°æ®
        paper_data = load_paper_data()
        
        # ç”Ÿæˆæ´å¯Ÿ
        insights = generate_insights(paper_data)
        
        if not insights:
            logger.error("âŒ Failed to generate insights")
            sys.exit(1)
        
        # éªŒè¯å¼•æ–‡ï¼ˆä»…æ£€æŸ¥å¼•æ–‡å­˜åœ¨æ€§ï¼Œä¸åšåˆè§„æ€§æ£€æŸ¥ï¼‰
        insights = verify_all_citations(insights, paper_data['entire_text'])
        
        # æ·»åŠ å…ƒæ•°æ®
        insights = add_metadata(insights)
        
        # ä¿å­˜ç»“æœ
        save_insights(insights)
        
        # ç”ŸæˆæŠ¥å‘Š
        generate_report(insights)
        
        logger.info("=" * 80)
        logger.info("âœ… Milestone 1 Insights Pro completed!")
        logger.info(f"   Output: {OUTPUT_FILE}")
        logger.info(f"   Report: {REPORT_FILE}")
        logger.info("=" * 80)
        
    except Exception as e:
        logger.error(f"âŒ Fatal error: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()

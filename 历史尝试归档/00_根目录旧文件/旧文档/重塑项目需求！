# QA生成系统工作定义

## 📦 Milestone 1：初步验证

### 目标
验证基于PECS文献的自动出题方案可行性

---

### 输入
- **1篇PECS综述论文**（txt格式，用于测试）

---

### 输出

#### 1. 测试题集
生成**20道问题**，格式：
```json
{
  "question_id": "comb_qa_001",
  "question_text": "Why does increasing pressure reduce ignition delay time?",
  "standard_answer": "Increasing pressure raises molecular collision frequency...",
  "type": "reasoning",
  "difficulty": 3,
  "topic": "ignition_theory",
  
  "source": {
    "type": "with_reference",
    "paper_id": "PECS_2020_Vol85_p1",
    "paper_title": "Ignition phenomena in combustion"
  },
  
  "metadata": {
    "generation_model": "gemini-2.5-pro",
    "created_at": "2025-10-13T10:00:00"
  }
}
```

**字段说明**：
- **AI生成字段**（LLM直接输出）：
  - `question_text`：问题文本
  - `standard_answer`：标准答案
  - `type`：问题类型（concept/reasoning/application/calculation）
  - `difficulty`：难度等级（1-5）
  - `topic`：燃烧子领域（如ignition_theory, flame_propagation等）

- **系统添加字段**（代码自动填充）：
  - `question_id`：唯一标识符
  - `source.type`：生成方式
    - `with_reference`：基于论文生成（有paper_id）
    - `without_reference`：纯prompt生成（无paper_id）
  - `source.paper_id`：来源论文ID
  - `source.paper_title`：论文标题
  - `metadata.generation_model`：使用的LLM模型
  - `metadata.created_at`：生成时间戳

#### 2. 质量评估报告
- 题目类型分布（概念/推理/应用各多少道）
- 难度分布（简单/中等/困难）
- 可用题目数量（符合标准的有几道）
- 问题识别（如果有废题，记录原因）

---

### 验收标准
- [ ] 成功生成20道完整的Q&A
- [ ] 至少15道题符合质量标准（非定义题、有深度、标答合理）
- [ ] 生成时间 <5分钟
- [ ] 输出为标准JSON格式

---

## 📦 Milestone 2：批量生成

### 目标
基于100篇PECS文献，生成候选题库

---

### 输入
- **100篇PECS综述论文**（txt格式）

---

### 输出

#### 1. 候选题库
- **1000-2000道候选题**（每篇论文10-20道）
- 格式同Milestone 1
- 存储为JSONL文件（每行一道题）

#### 2. 生成日志
- 每篇论文的处理状态
- 生成题目数量统计
- API调用成本记录
- 错误/异常记录

---

## 📦 Milestone 3：自动验证

### 目标
使用多模型验证标答正确性

---

### 输入
- Milestone 2生成的候选题库

---

### 输出

#### 1. 验证结果
每道题增加验证字段：
```json
{
  "question": "...",
  "answer": "...",
  "verification": {
    "gpt5": {
      "correct": true,
      "confidence": "high",
      "issues": []
    },
    "gemini_2_5_pro": {
      "correct": true,
      "confidence": "high",
      "issues": []
    },
    "claude_sonnet_4_5": {
      "correct": true,
      "confidence": "medium",
      "issues": ["答案略显不完整"]
    }
  },
  "status": "approved"  // approved / needs_review / rejected
}
```

#### 2. 筛选后的题库
- **自动通过**：3家模型都高置信度确认正确
- **待人工审核**：有分歧或不确定
- **自动拒绝**：明显错误

**预期分布**：
- 自动通过：60-70%
- 待人工审核：20-30%
- 自动拒绝：5-10%

---

## 📦 Milestone 4：人工评估（可选）

### 目标
人工审核质量，确保benchmark不掉价

---

### 输入
- Milestone 3的"待人工审核"题目

---

### 输出
- **最终题库**：500-1000道高质量题目
- **评估报告**：人工审核通过率、常见问题类型

---

## 附录：技术栈推荐

### 1. LLM模型选择

**题目生成**（推荐）：
- **Gemini 2.5 Pro**：1M context，最适合处理长文献
- GPT-5：质量稳定
- Claude Sonnet 4.5：推理能力强

**标答验证**（3家都用）：
- GPT-5
- Gemini 2.5 Pro  
- Claude Sonnet 4.5

### 2. 现有代码库
- 基础框架：https://github.com/Sithcighce/distillation_generation
- 可复用：数据存储、多模型调用、问题分类逻辑

### 3. Prompt模板位置
- 生成题Prompt: `prompts/生成题Prompt.md`
- 判题Prompt: `prompts/判题Prompt.md`

### 4. 数据存储
- 候选题库：`data/candidate_bank.jsonl`
- 验证通过：`data/validation_set.jsonl`
- 最终benchmark：`data/combustion_qa_benchmark.jsonl`
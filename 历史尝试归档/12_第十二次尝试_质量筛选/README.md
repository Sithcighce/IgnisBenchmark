# 12 第十二次尝试：质量筛选

**批次编号**: 12  
**原阶段名**: 第十二阶段
**时间**: 2025-10-15 验证系统建立后  
**状态**: ✅ 完成  

---

## 📋 批次概述

### 目标
从批次11的984道通过验证的题目中，筛选出最高质量的题目作为IgnisBenchmark的核心题库。

### 关键特点
- **严格筛选**: 基于 `all_correct = true` 标记
- **去重处理**: 移除重复和相似题目
- **质量导向**: 只保留最高质量的题目
- **分类整理**: 按类型/难度组织

---

## 🎯 核心价值

### 筛选标准
1. **all_correct = true**: 三模型（Claude/GPT-5/Gemini）一致通过
2. **无重复**: 去除内容相似或重复的题目
3. **高质量**: 题目清晰、答案准确、原文引用完整

### 筛选结果
- ✅ **best.json**: 984道题目（全部通过验证）
- ⚠️ **notpass.json**: 88道题目（包含needs_review）

---

## 📂 目录结构

```
12_第十二次尝试_质量筛选/
├── best.json           # 984题 - 最高质量题目（6.8 MB）
├── question.json       # 原始question数据（4.4 MB）
└── README.md           # 本文档
```

---

## 📊 数据统计

### best.json
- **题目数量**: 984道
- **文件大小**: 6,816,691 字节（~6.8 MB）
- **质量标准**: 三模型一致通过（all_correct = true）
- **数据结构**: 
  ```json
  [
    {
      "question": "题目文本",
      "standard_answer": "标准答案",
      "original_text": {"1": "原文引用1", "2": "原文引用2"},
      "metadata": {
        "type": "concept/calculation/application",
        "difficulty": 1-10,
        "paper_id": "论文ID",
        "all_correct": true  // 三模型一致通过
      },
      "verification": {
        "claude": {"correct": true, ...},
        "gpt5": {"correct": true, ...},
        "gemini": {"correct": true, ...}
      }
    }
  ]
  ```

### notpass.json
- **题目数量**: 88道
- **质量标准**: 至少一个模型认为需要复审或有错误
- **包含类型**:
  - needs_review: 边界情况，建议人工复审
  - correct = false: 至少一个模型认为有错误

---

## 🔧 筛选过程

### 输入数据
- **来源**: 批次11验证系统的输出
- **原始数据**: ~1490道题目
- **验证结果**: 
  - 984道 → pass.json（all_correct = true）
  - 88道 → notpass.json（需要复审或有错误）

### 筛选步骤
1. **加载验证结果**: 读取批次11的pass.json和notpass.json
2. **质量分层**: 
   - 最高质量: all_correct = true → best.json
   - 需复审: needs_review → notpass.json
3. **去重处理**: 移除重复或相似题目（如有）
4. **数据整理**: 按类型/难度重新组织

### 数据流
```
批次11验证结果（1490题）
  ↓
质量分层
  ├→ 984题（all_correct = true）→ best.json
  └→ 88题（needs_review/错误）→ notpass.json
  ↓
输出: 12批次筛选结果
  ↓
流向: 批次13（GPT-5测试）
```

---

## 📖 相关批次

- **上游**: 批次11（三模型验证系统，1490道题验证）
- **下游**: 批次13（GPT-5答题测试，使用best.json的984题）
- **最终**: 批次15（最终交付，从GPT-5测试结果中筛选145道挑战题）

---

## 🎯 质量保证

### best.json的质量特点
1. **三模型共识**: Claude、GPT-5、Gemini三者一致认为正确
2. **原文忠实**: 标准答案与PECS综述原文一致
3. **逻辑严谨**: 推理过程合理，因果关系正确
4. **表达清晰**: 题目和答案表达清楚，易于理解

### notpass.json的处理
- **needs_review**: 保留，供人工复审
- **明确错误**: 记录，用于改进生成系统
- **价值**: 帮助理解模型判断的边界

---

## 💡 关键发现

### 1. 筛选效率
- **通过率**: 984/1490 ≈ 66%
- **拒绝率**: 88/1490 ≈ 6%
- **其他**: ~28%（可能包含中途筛除的题目）

### 2. 质量标准的有效性
- **all_correct机制**: 确实能筛选出高质量题目
- **三模型验证**: 比单模型更可靠
- **needs_review**: 约6%的题目需要人工复审，比例合理

### 3. 题目分布
根据metadata统计（如有）：
- **类型分布**: concept、calculation、application
- **难度分布**: 1-10级，覆盖全范围
- **来源分布**: 298篇PECS综述论文

---

## 🎓 数据使用

### best.json的用途
1. **GPT-5测试**: 批次13使用这984题进行答题测试
2. **Benchmark基础**: 这是IgnisBenchmark的核心题库
3. **质量标杆**: 可作为后续题目生成的质量参考

### question.json的用途
- **原始数据**: 保留question格式数据（4.4 MB）
- **对比参考**: 可与best.json对比，分析筛选差异

---

## 🔍 数据质量分析

### 文件大小对比
- **best.json**: 6.8 MB（包含完整验证信息）
- **question.json**: 4.4 MB（基础question数据）
- **差异**: best.json包含verification字段，记录三模型判断

### 数据完整性
每道题目包含：
- ✅ 题目文本（question）
- ✅ 标准答案（standard_answer）
- ✅ 原文引用（original_text）
- ✅ 元数据（metadata: type、difficulty、paper_id）
- ✅ 验证结果（verification: claude、gpt5、gemini）

---

## 📊 统计对比

### 批次11 → 批次12的变化

| 指标 | 批次11（验证） | 批次12（筛选） |
|------|----------------|----------------|
| 输入题目数 | ~1490 | 984 |
| 输出题目数 | 984 (pass) + 88 (notpass) | 984 (best) |
| 质量标准 | all_correct标记 | all_correct = true |
| 数据格式 | pass.json / notpass.json | best.json / notpass.json |
| 文件大小 | - | 6.8 MB (best) |

---

## 🎯 经验教训

### ✅ 成功经验
1. **严格筛选**: 质量>数量，984题比1490题更有价值
2. **all_correct机制**: 三模型一致的标准很有效
3. **数据保留**: 保留notpass.json，用于改进和复审
4. **完整记录**: best.json包含完整验证信息，可追溯

### ⚠️ 注意事项
1. **去重重要性**: 需要仔细检查是否有重复题目
2. **边界情况**: 88道needs_review题目需要人工处理
3. **数据结构**: 确保best.json格式与后续使用兼容

### 🔄 后续改进
1. **自动去重**: 使用相似度算法自动检测重复题目
2. **质量评分**: 为每道题添加综合质量分数
3. **难度校准**: 基于GPT-5测试结果调整难度标注

---

## 📌 总结

批次12完成了**质量筛选**，这是从验证到benchmark的关键环节：

1. **输入**: 批次11的1490道验证题目
2. **过程**: 基于all_correct标记严格筛选
3. **输出**: 984道最高质量题目（best.json）
4. **价值**: 建立IgnisBenchmark的核心题库

这984道题目成为了后续GPT-5测试（批次13）的基础，也是最终交付（批次15）的源泉。质量筛选确保了benchmark的价值和可信度。

---

**生成时间**: 2025-10-17  
**文档版本**: v1.0  
**下一步**: 批次13 - GPT-5答题测试

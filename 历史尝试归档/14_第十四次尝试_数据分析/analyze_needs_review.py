#!/usr/bin/env python3
"""
åˆ†æ needs_review é¢˜ç›®çš„ GPT-5 è¡¨ç°
"""
import json

def main():
    # åŠ è½½æ–‡ä»¶
    with open(r'c:\Users\13031\Desktop\workspace\distillation_generation\éªŒè¯\notpass.json', 'r', encoding='utf-8') as f:
        notpass = json.load(f)
    
    with open(r'c:\Users\13031\Desktop\workspace\distillation_generation\éªŒè¯\benchmarkGPT5_recovered.json', 'r', encoding='utf-8') as f:
        gpt5_results = json.load(f)
    
    # åˆ›å»º GPT-5 ç»“æœçš„æ˜ å°„
    gpt5_map = {r['question_id']: r for r in gpt5_results}
    
    print(f"\n{'='*70}")
    print(f"Needs Review é¢˜ç›®åˆ†æ")
    print(f"{'='*70}\n")
    
    # ç»Ÿè®¡ notpass ä¸­çš„çŠ¶æ€
    status_counts = {}
    for q in notpass:
        status = q.get('verification', {}).get('status', 'unknown')
        status_counts[status] = status_counts.get(status, 0) + 1
    
    print(f"ğŸ“Š notpass.json çŠ¶æ€åˆ†å¸ƒ:")
    for status, count in sorted(status_counts.items()):
        print(f"   {status}: {count}")
    
    # æå– needs_review é¢˜ç›®
    needs_review = [q for q in notpass if q.get('verification', {}).get('status') == 'needs_review']
    
    print(f"\nâš ï¸  Needs Review é¢˜ç›®æ€»æ•°: {len(needs_review)}\n")
    
    # æ£€æŸ¥æœ‰å¤šå°‘ needs_review é¢˜ç›®åœ¨ GPT-5 æµ‹è¯•ä¸­
    tested = []
    not_tested = []
    
    for q in needs_review:
        qid = q['question_id']
        if qid in gpt5_map:
            tested.append({
                'question_id': qid,
                'question_text': q['question_text'][:100] + '...' if len(q['question_text']) > 100 else q['question_text'],
                'difficulty': q.get('difficulty'),
                'topic': q.get('topic'),
                'type': q.get('type'),
                'verification_reasons': [v.get('reasoning', '')[:150] for v in q.get('verification', {}).get('verifiers', [])],
                'gpt5_correct': gpt5_map[qid]['grading']['correct'],
                'gpt5_score': gpt5_map[qid]['grading']['score']
            })
        else:
            not_tested.append(qid)
    
    print(f"âœ… åœ¨ GPT-5 æµ‹è¯•ä¸­: {len(tested)}")
    print(f"âŒ æœªæµ‹è¯•ï¼ˆä½™é¢ä¸è¶³å‰æœªå®Œæˆï¼‰: {len(not_tested)}\n")
    
    if tested:
        # ç»Ÿè®¡ GPT-5 åœ¨ needs_review é¢˜ç›®ä¸Šçš„è¡¨ç°
        correct_count = sum(1 for t in tested if t['gpt5_correct'])
        accuracy = correct_count / len(tested) * 100
        avg_score = sum(t['gpt5_score'] for t in tested) / len(tested)
        
        print(f"ğŸ¯ GPT-5 åœ¨ Needs Review é¢˜ç›®ä¸Šçš„è¡¨ç°:")
        print(f"   æ­£ç¡®ç‡: {accuracy:.2f}% ({correct_count}/{len(tested)})")
        print(f"   å¹³å‡åˆ†: {avg_score:.2f}/100\n")
        
        # æŒ‰éš¾åº¦åˆ†æ
        by_difficulty = {}
        for t in tested:
            diff = t['difficulty']
            if diff not in by_difficulty:
                by_difficulty[diff] = {'total': 0, 'correct': 0, 'scores': []}
            by_difficulty[diff]['total'] += 1
            if t['gpt5_correct']:
                by_difficulty[diff]['correct'] += 1
            by_difficulty[diff]['scores'].append(t['gpt5_score'])
        
        print(f"ğŸ“ˆ æŒ‰éš¾åº¦åˆ†æ:")
        for diff in sorted(by_difficulty.keys()):
            data = by_difficulty[diff]
            acc = data['correct'] / data['total'] * 100
            avg = sum(data['scores']) / len(data['scores'])
            print(f"   éš¾åº¦ {diff}: {acc:.2f}% ({data['correct']}/{data['total']}) - å¹³å‡åˆ†: {avg:.2f}")
        
        # æ˜¾ç¤ºç­”é”™çš„é¢˜ç›®
        incorrect = [t for t in tested if not t['gpt5_correct']]
        if incorrect:
            print(f"\nâŒ GPT-5 ç­”é”™çš„ Needs Review é¢˜ç›® ({len(incorrect)} é¢˜):\n")
            for i, t in enumerate(incorrect, 1):
                print(f"{i}. [{t['question_id']}] (éš¾åº¦:{t['difficulty']}, åˆ†æ•°:{t['gpt5_score']})")
                print(f"   ä¸»é¢˜: {t['topic']}, ç±»å‹: {t['type']}")
                print(f"   é—®é¢˜: {t['question_text']}")
                print(f"   éªŒè¯é—®é¢˜: {t['verification_reasons'][0][:100] if t['verification_reasons'] else 'N/A'}...\n")
        
        # æ˜¾ç¤ºç­”å¯¹çš„é¢˜ç›®
        correct = [t for t in tested if t['gpt5_correct']]
        if correct:
            print(f"\nâœ… GPT-5 ç­”å¯¹çš„ Needs Review é¢˜ç›® ({len(correct)} é¢˜):\n")
            for i, t in enumerate(correct[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"{i}. [{t['question_id']}] (éš¾åº¦:{t['difficulty']}, åˆ†æ•°:{t['gpt5_score']})")
                print(f"   ä¸»é¢˜: {t['topic']}, ç±»å‹: {t['type']}")
                print(f"   é—®é¢˜: {t['question_text']}\n")
            if len(correct) > 10:
                print(f"   ... è¿˜æœ‰ {len(correct) - 10} é¢˜\n")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        output_path = r'c:\Users\13031\Desktop\workspace\distillation_generation\éªŒè¯\gpt5_needs_review_analysis.json'
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump({
                'summary': {
                    'total_needs_review': len(needs_review),
                    'tested': len(tested),
                    'not_tested': len(not_tested),
                    'accuracy': round(accuracy, 2),
                    'average_score': round(avg_score, 2),
                    'correct': correct_count,
                    'incorrect': len(incorrect)
                },
                'by_difficulty': {str(k): {
                    'total': v['total'],
                    'correct': v['correct'],
                    'accuracy': round(v['correct'] / v['total'] * 100, 2),
                    'average_score': round(sum(v['scores']) / len(v['scores']), 2)
                } for k, v in by_difficulty.items()},
                'incorrect_questions': incorrect,
                'correct_questions': correct
            }, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ è¯¦ç»†åˆ†æå·²ä¿å­˜è‡³: {output_path}\n")
    
    print(f"{'='*70}\n")

if __name__ == "__main__":
    main()

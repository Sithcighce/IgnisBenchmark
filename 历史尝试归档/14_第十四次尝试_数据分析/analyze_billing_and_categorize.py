#!/usr/bin/env python3
"""
åˆ†æOpenRouterè´¦å•è®°å½•ï¼Œç¡®è®¤GPT-5è¯·æ±‚çš„çœŸå®è¿”å›æƒ…å†µ
å¹¶æ•´ç†æ‰€æœ‰é¢˜ç›®çš„å®Œæ•´åˆ†ç±»ï¼šç­”å¯¹ã€çœŸå®é”™è¯¯ã€APIå¤±è´¥ã€æœªæµ‹è¯•
"""

import json
import csv
from collections import defaultdict
from datetime import datetime

# æ–‡ä»¶è·¯å¾„
BILLING_CSV = r"c:\Users\13031\Desktop\workspace\distillation_generation\éªŒè¯\openrouter_activity_2025-10-17.csv"
LOG_FILE = r"c:\Users\13031\Desktop\workspace\distillation_generation\éªŒè¯\gpt5_benchmark.log"
RECOVERED_JSON = r"c:\Users\13031\Desktop\workspace\distillation_generation\éªŒè¯\benchmarkGPT5_recovered.json"
BEST_JSON = r"c:\Users\13031\Desktop\workspace\distillation_generation\éªŒè¯\best.json"
OUTPUT_JSON = r"c:\Users\13031\Desktop\workspace\distillation_generation\éªŒè¯\complete_question_categorization.json"

def parse_billing_csv():
    """è§£æè´¦å•CSVï¼Œæå–GPT-5è¯·æ±‚çš„è¯¦ç»†ä¿¡æ¯"""
    print("=" * 70)
    print("è§£æOpenRouterè´¦å•è®°å½•")
    print("=" * 70)
    
    billing_data = []
    failed_requests = []
    
    with open(BILLING_CSV, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            # åªå…³æ³¨GPT-5çš„è¯·æ±‚
            if 'gpt-5' in row.get('model_permaslug', '').lower():
                # æå–å…³é”®ä¿¡æ¯
                record = {
                    'generation_id': row['generation_id'],
                    'created_at': row['created_at'],
                    'cost_total': float(row['cost_total']) if row['cost_total'] else 0,
                    'tokens_prompt': int(row['tokens_prompt']) if row['tokens_prompt'] else 0,
                    'tokens_completion': int(row['tokens_completion']) if row['tokens_completion'] else 0,
                    'tokens_reasoning': int(row['tokens_reasoning']) if row['tokens_reasoning'] else 0,
                    'finish_reason_raw': row['finish_reason_raw'],
                    'finish_reason_normalized': row['finish_reason_normalized'],
                    'cancelled': row['cancelled'] == 'true',
                    'generation_time_ms': int(row['generation_time_ms']) if row['generation_time_ms'] else 0,
                }
                
                billing_data.append(record)
                
                # æ£€æµ‹å¤±è´¥çš„è¯·æ±‚
                if (record['tokens_completion'] == 0 or 
                    record['cancelled'] or 
                    record['finish_reason_normalized'] not in ['stop', 'completed']):
                    failed_requests.append(record)
    
    print(f"\nğŸ“Š GPT-5è´¦å•ç»Ÿè®¡:")
    print(f"   æ€»è¯·æ±‚æ•°: {len(billing_data)}")
    print(f"   å¤±è´¥/å¼‚å¸¸è¯·æ±‚: {len(failed_requests)}")
    print(f"   æˆåŠŸå®Œæˆ: {len(billing_data) - len(failed_requests)}")
    
    # ç»Ÿè®¡finish_reasonåˆ†å¸ƒ
    finish_reasons = defaultdict(int)
    for record in billing_data:
        finish_reasons[record['finish_reason_normalized']] += 1
    
    print(f"\nğŸ“ˆ å®ŒæˆçŠ¶æ€åˆ†å¸ƒ:")
    for reason, count in sorted(finish_reasons.items(), key=lambda x: -x[1]):
        print(f"   {reason}: {count}")
    
    # ç»Ÿè®¡tokenåˆ†å¸ƒ
    total_prompt = sum(r['tokens_prompt'] for r in billing_data)
    total_completion = sum(r['tokens_completion'] for r in billing_data)
    total_reasoning = sum(r['tokens_reasoning'] for r in billing_data)
    
    print(f"\nğŸ¯ Tokenç»Ÿè®¡:")
    print(f"   æ€»Prompt tokens: {total_prompt:,}")
    print(f"   æ€»Completion tokens: {total_completion:,}")
    print(f"   æ€»Reasoning tokens: {total_reasoning:,}")
    print(f"   å¹³å‡Completion tokens/è¯·æ±‚: {total_completion/len(billing_data):.0f}")
    
    # é›¶completion tokençš„è¯·æ±‚
    zero_completion = [r for r in billing_data if r['tokens_completion'] == 0]
    print(f"\nâš ï¸  é›¶Completion tokenè¯·æ±‚: {len(zero_completion)}")
    
    return billing_data, failed_requests

def parse_log_for_question_timing():
    """ä»æ—¥å¿—ä¸­è§£ææ¯ä¸ªé¢˜ç›®çš„å¤„ç†æ—¶é—´ï¼Œç”¨äºåŒ¹é…è´¦å•"""
    print("\n" + "=" * 70)
    print("ä»æ—¥å¿—ä¸­æå–é¢˜ç›®å¤„ç†æ—¶é—´")
    print("=" * 70)
    
    question_times = {}
    
    with open(LOG_FILE, 'r', encoding='utf-8') as f:
        current_question = None
        for line in f:
            # åŒ¹é… Processing è¡Œ
            if 'Processing [' in line and '] deepseek_q_' in line:
                parts = line.split('] ')
                if len(parts) >= 2:
                    question_id = parts[1].split()[0]
                    # æå–æ—¶é—´æˆ³ (æ ¼å¼: 2025-10-15 13:03:41,321)
                    timestamp_str = line.split(' - ')[0]
                    try:
                        # å»æ‰æ¯«ç§’éƒ¨åˆ†çš„é€—å·ï¼Œæ”¹ä¸ºç‚¹å·
                        timestamp_str = timestamp_str.replace(',', '.')
                        timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S.%f')
                        question_times[question_id] = timestamp
                        current_question = question_id
                    except:
                        pass
    
    print(f"   æ‰¾åˆ° {len(question_times)} ä¸ªé¢˜ç›®çš„å¤„ç†æ—¶é—´")
    return question_times

def load_recovered_results():
    """åŠ è½½å·²æ¢å¤çš„æµ‹è¯•ç»“æœ"""
    with open(RECOVERED_JSON, 'r', encoding='utf-8') as f:
        return json.load(f)

def load_best_questions():
    """åŠ è½½best.jsonä¸­çš„æ‰€æœ‰é¢˜ç›®"""
    with open(BEST_JSON, 'r', encoding='utf-8') as f:
        return json.load(f)

def categorize_all_questions():
    """å®Œæ•´åˆ†ç±»æ‰€æœ‰é¢˜ç›®"""
    print("\n" + "=" * 70)
    print("å®Œæ•´é¢˜ç›®åˆ†ç±»åˆ†æ")
    print("=" * 70)
    
    # åŠ è½½æ•°æ®
    billing_data, failed_billing = parse_billing_csv()
    question_times = parse_log_for_question_timing()
    recovered = load_recovered_results()
    all_questions = load_best_questions()
    
    print(f"\nğŸ“š æ•°æ®åŠ è½½:")
    print(f"   best.jsonæ€»é¢˜ç›®æ•°: {len(all_questions)}")
    print(f"   å·²æ¢å¤æµ‹è¯•ç»“æœ: {len(recovered)}")
    print(f"   è´¦å•GPT-5è¯·æ±‚: {len(billing_data)}")
    
    # åˆ›å»ºæ¢å¤ç»“æœçš„æ˜ å°„
    recovered_map = {item['question_id']: item for item in recovered}
    
    # åˆ†ç±»
    categories = {
        'correct': [],           # ç­”å¯¹çš„
        'real_errors': [],       # çœŸå®é”™è¯¯ï¼ˆæœ‰å®è´¨å›ç­”ä½†ç­”é”™ï¼‰
        'api_failures': [],      # APIå¤±è´¥ï¼ˆæ— å›ç­”æˆ–å›ç­”å¤ªçŸ­ï¼‰
        'untested': []           # æœªæµ‹è¯•çš„
    }
    
    for question in all_questions:
        qid = question['question_id']
        
        if qid in recovered_map:
            result = recovered_map[qid]
            grading = result.get('grading', {})
            gpt5_answer = result.get('gpt5_answer', {})
            
            if grading.get('correct', False):
                # ç­”å¯¹äº†
                categories['correct'].append({
                    'question_id': qid,
                    'score': grading.get('score', 0),
                    'difficulty': question['difficulty'],
                    'topic': question['topic'],
                    'type': question['type'],
                    'answer_length': gpt5_answer.get('length', 'unknown') if isinstance(gpt5_answer, dict) else 'unknown'
                })
            else:
                # ç­”é”™äº†ï¼Œéœ€è¦åŒºåˆ†çœŸå®é”™è¯¯è¿˜æ˜¯APIå¤±è´¥
                answer_length = gpt5_answer.get('length', 'unknown') if isinstance(gpt5_answer, dict) else 'unknown'
                score = grading.get('score', 0)
                
                if answer_length != 'unknown' and (isinstance(answer_length, int) and answer_length >= 500):
                    # çœŸå®é”™è¯¯ï¼šæœ‰å®è´¨å›ç­”ä½†ç­”é”™
                    categories['real_errors'].append({
                        'question_id': qid,
                        'score': score,
                        'difficulty': question['difficulty'],
                        'topic': question['topic'],
                        'type': question['type'],
                        'answer_length': answer_length,
                        'question': question['question_text'][:100] + '...'
                    })
                else:
                    # APIå¤±è´¥ï¼šæ— å›ç­”æˆ–å›ç­”å¤ªçŸ­
                    categories['api_failures'].append({
                        'question_id': qid,
                        'score': score,
                        'difficulty': question['difficulty'],
                        'topic': question['topic'],
                        'type': question['type'],
                        'answer_length': answer_length,
                        'question': question['question_text'][:100] + '...'
                    })
        else:
            # æœªæµ‹è¯•
            categories['untested'].append({
                'question_id': qid,
                'difficulty': question['difficulty'],
                'topic': question['topic'],
                'type': question['type'],
                'question': question['question_text'][:100] + '...'
            })
    
    # è¾“å‡ºç»Ÿè®¡
    print("\n" + "=" * 70)
    print("é¢˜ç›®åˆ†ç±»ç»“æœ")
    print("=" * 70)
    
    print(f"\nâœ… ç­”å¯¹çš„é¢˜ç›®: {len(categories['correct'])} é¢˜")
    print(f"   å best.jsonæ€»æ•°: {len(categories['correct'])/len(all_questions)*100:.2f}%")
    
    print(f"\nâŒ çœŸå®é”™è¯¯ï¼ˆæœ‰å®è´¨å›ç­”ä½†ç­”é”™ï¼‰: {len(categories['real_errors'])} é¢˜")
    print(f"   å å·²æµ‹è¯•é¢˜ç›®: {len(categories['real_errors'])/len(recovered)*100:.2f}%")
    
    print(f"\nâš ï¸  APIå¤±è´¥ï¼ˆæ— å›ç­”æˆ–å›ç­”å¤ªçŸ­ï¼‰: {len(categories['api_failures'])} é¢˜")
    print(f"   å å·²æµ‹è¯•é¢˜ç›®: {len(categories['api_failures'])/len(recovered)*100:.2f}%")
    
    print(f"\nâ­ï¸  æœªæµ‹è¯•çš„é¢˜ç›®: {len(categories['untested'])} é¢˜")
    print(f"   å best.jsonæ€»æ•°: {len(categories['untested'])/len(all_questions)*100:.2f}%")
    
    # è¯¦ç»†åˆ†æçœŸå®é”™è¯¯
    if categories['real_errors']:
        print(f"\n" + "=" * 70)
        print(f"çœŸå®é”™è¯¯è¯¦ç»†åˆ†æ ({len(categories['real_errors'])} é¢˜)")
        print("=" * 70)
        
        # æŒ‰åˆ†æ•°æ®µç»Ÿè®¡
        score_ranges = defaultdict(int)
        for item in categories['real_errors']:
            score = item['score']
            if score < 20:
                score_ranges['0-20'] += 1
            elif score < 40:
                score_ranges['21-40'] += 1
            elif score < 60:
                score_ranges['41-60'] += 1
            else:
                score_ranges['61-80'] += 1
        
        print(f"\næŒ‰åˆ†æ•°æ®µåˆ†å¸ƒ:")
        for range_name in ['0-20', '21-40', '41-60', '61-80']:
            count = score_ranges[range_name]
            if count > 0:
                print(f"   {range_name}åˆ†: {count} é¢˜")
        
        # æŒ‰éš¾åº¦ç»Ÿè®¡
        diff_stats = defaultdict(list)
        for item in categories['real_errors']:
            diff_stats[item['difficulty']].append(item['score'])
        
        print(f"\næŒ‰éš¾åº¦åˆ†å¸ƒ:")
        for diff in sorted(diff_stats.keys()):
            scores = diff_stats[diff]
            print(f"   éš¾åº¦ {diff}: {len(scores)} é¢˜, å¹³å‡åˆ† {sum(scores)/len(scores):.1f}")
        
        # æŒ‰ä¸»é¢˜ç»Ÿè®¡
        topic_stats = defaultdict(list)
        for item in categories['real_errors']:
            topic_stats[item['topic']].append(item['score'])
        
        print(f"\næŒ‰ä¸»é¢˜åˆ†å¸ƒ (Top 10):")
        sorted_topics = sorted(topic_stats.items(), key=lambda x: -len(x[1]))[:10]
        for topic, scores in sorted_topics:
            print(f"   {topic}: {len(scores)} é¢˜, å¹³å‡åˆ† {sum(scores)/len(scores):.1f}")
        
        # æœ€å·®çš„10é“é¢˜
        print(f"\nğŸ”¥ æœ€å·®çš„10é“é¢˜:")
        sorted_errors = sorted(categories['real_errors'], key=lambda x: x['score'])[:10]
        for i, item in enumerate(sorted_errors, 1):
            print(f"\n{i}. [{item['question_id']}] å¾—åˆ†: {item['score']}/100")
            print(f"   éš¾åº¦ {item['difficulty']} | {item['topic']} | {item['type']}")
            print(f"   å›ç­”é•¿åº¦: {item['answer_length']} chars")
            print(f"   é—®é¢˜: {item['question']}")
    
    # è¯¦ç»†åˆ†æAPIå¤±è´¥
    if categories['api_failures']:
        print(f"\n" + "=" * 70)
        print(f"APIå¤±è´¥è¯¦ç»†åˆ†æ ({len(categories['api_failures'])} é¢˜)")
        print("=" * 70)
        
        # ç»Ÿè®¡æœ‰åˆ†æ•°çš„APIå¤±è´¥ï¼ˆå¯èƒ½éƒ¨åˆ†è¿”å›äº†æ•°æ®ï¼‰
        with_score = [item for item in categories['api_failures'] if item['score'] > 0]
        zero_score = [item for item in categories['api_failures'] if item['score'] == 0]
        
        print(f"\n   æœ‰åˆ†æ•° (>0): {len(with_score)} é¢˜ (å¯èƒ½éƒ¨åˆ†è¿”å›)")
        print(f"   é›¶åˆ†: {len(zero_score)} é¢˜ (å¾ˆå¯èƒ½å®Œå…¨å¤±è´¥)")
        
        if zero_score:
            print(f"\n   é›¶åˆ†é¢˜ç›®ç¤ºä¾‹ (å‰5ä¸ª):")
            for item in zero_score[:5]:
                print(f"   - {item['question_id']}: é•¿åº¦={item['answer_length']}")
    
    # ä¿å­˜ç»“æœ
    output = {
        'summary': {
            'total_questions': len(all_questions),
            'tested': len(recovered),
            'untested': len(categories['untested']),
            'correct': len(categories['correct']),
            'real_errors': len(categories['real_errors']),
            'api_failures': len(categories['api_failures']),
            'accuracy_all': f"{len(categories['correct'])/len(recovered)*100:.2f}%" if recovered else "0%",
            'accuracy_excluding_failures': f"{len(categories['correct'])/(len(categories['correct'])+len(categories['real_errors']))*100:.2f}%" if (categories['correct'] or categories['real_errors']) else "0%",
            'real_error_rate': f"{len(categories['real_errors'])/len(recovered)*100:.2f}%" if recovered else "0%",
        },
        'categories': categories,
        'billing_summary': {
            'total_gpt5_requests': len(billing_data),
            'failed_requests': len(failed_billing),
            'zero_completion_tokens': len([r for r in billing_data if r['tokens_completion'] == 0])
        }
    }
    
    with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    
    print(f"\n" + "=" * 70)
    print(f"ğŸ’¾ å®Œæ•´åˆ†ç±»ç»“æœå·²ä¿å­˜è‡³:")
    print(f"   {OUTPUT_JSON}")
    print("=" * 70)
    
    return output

if __name__ == '__main__':
    categorize_all_questions()

# 13 第十三次尝试：GPT-5答题测试

**批次编号**: 13  
**原阶段名**: 第十一阶段（已更新为第十三阶段）  
**时间**: 2025-10-15 质量筛选完成后  
**状态**: ⚠️ 部分完成（中断于第908题，OpenRouter余额不足）  

---

## 📋 批次概述

### 目标
使用GPT-5对984道筛选后的题目进行实际答题测试，验证benchmark的有效性和难度。

### 关键特点
- **GPT-5作答**: 对每道题目生成完整答案
- **DeepSeek判分**: 使用DeepSeek模型进行自动判分
- **完整记录**: 记录答案、分数、判分理由
- **中途中断**: 第908题时余额不足，实际完成872题

---

## 🎯 核心价值

### 测试意义
1. **验证benchmark质量**: 通过GPT-5实测验证题目的有效性
2. **发现知识盲区**: 识别GPT-5的知识盲点和弱项
3. **难度校准**: 基于GPT-5表现调整题目难度标注
4. **成本评估**: 了解大规模benchmark测试的成本

### 测试结果
- **完成题数**: 872/984（88.6%）
- **原始准确率**: 82.57%（720/872）
- **调整后准确率**: 90.45%（720/796有效测试）
- **总花费**: $62.02

---

## 📂 目录结构

```
13_第十三次尝试_GPT5测试/
├── benchmark_gpt5.py           # GPT-5答题脚本
├── 判题prompt                  # 判分prompt（英文版）
├── 判完的scheme.md             # 判分标准说明
├── data/
│   └── benchmarkGPT5_recovered.json  # 恢复的测试结果（872题）
├── 测试数据/                   # 测试过程数据
└── logs/
    └── gpt5_benchmark.log      # 完整测试日志（关键！）
└── README.md                   # 本文档
```

---

## 🔧 测试配置

### 使用的模型
- **答题模型**: GPT-5（OpenAI via OpenRouter）
- **判分模型**: DeepSeek（用于评判答案正确性）

### 脚本配置
```python
# benchmark_gpt5.py 关键配置
ANSWER_MODEL = "openai/gpt-5"
GRADING_MODEL = "deepseek/..."  # DeepSeek判分

# 并发和超时
MAX_CONCURRENT = 10  # GPT-5较慢，降低并发
REQUEST_TIMEOUT = 300  # 5分钟超时

# 成本估算
GPT-5_COST_PER_1K_TOKENS = $0.01  # 输入
GPT-5_OUTPUT_COST_PER_1K_TOKENS = $0.03  # 输出
```

---

## 📊 测试结果分析

### 完成情况
| 指标 | 数值 |
|------|------|
| 计划测试 | 984题 |
| 实际完成 | 872题 |
| 中断位置 | 第908题 |
| 完成率 | 88.6% |
| 未测试 | 112题（第873-984题）|

### 答题表现
| 类别 | 题数 | 占比（已测试） | 占比（总题目） |
|------|------|----------------|----------------|
| ✅ 答对 | 720 | 82.57% | 73.17% |
| ❌ 真实错误 | 76 | 8.72% | 7.72% |
| ⚠️ API失败（有分数）| 69 | 7.91% | 7.01% |
| ⚠️ API失败（零分）| 7 | 0.80% | 0.71% |
| ⏭️ 未测试 | 112 | - | 11.38% |

### 调整后准确率
```
有效测试 = 答对 + 真实错误 = 720 + 76 = 796题
调整后准确率 = 720 / 796 = 90.45%
```
（排除API失败的76题）

---

## 🎓 脚本说明

### benchmark_gpt5.py
**功能**: GPT-5批量答题 + DeepSeek判分

**核心流程**:
1. **加载题目**: 从best.json读取984题
2. **GPT-5作答**: 
   - 输入：题目 + 原文引用
   - 输出：完整答案（try to give a comprehensive answer）
3. **DeepSeek判分**:
   - 输入：题目 + 标准答案 + GPT-5答案 + 原文
   - 输出：分数（0-100）+ 判分理由
4. **保存结果**: 记录到JSON和日志文件

**容错机制**:
- API超时重试（3次）
- 分批保存（每10题保存一次）
- 完整日志记录（**救命稻草**）

---

## 📝 Prompt设计

### 答题Prompt（给GPT-5）
```
You are an expert in combustion science. Please answer the following question based on the provided original text.

Question: {question}

Original Text:
{original_text}

Please provide a comprehensive answer, covering all key mechanisms and principles.
```

### 判题Prompt（给DeepSeek）
位置: `13_第十三次尝试_GPT5测试/判题prompt`

**核心标准**:
1. **事实准确性**: 与原文和标准答案一致
2. **逻辑一致性**: 推理合理，因果正确
3. **完整性**: 覆盖核心要点（长短灵活）

**评分输出**:
```json
{
  "score": 0-100,
  "correct": true/false,
  "explanation": "判分理由",
  "needs_review": false
}
```

---

## 💡 关键发现

### 1. GPT-5的知识盲区
- **真实错误**: 76题（8.72%）
- **特点**: GPT-5给出了实质性回答（≥500字符），但被判错
- **价值**: 这些题目是benchmark的核心价值 —— 揭示GPT-5的知识边界

### 2. API稳定性问题
- **部分失败**: 69题有分数但可能回答太短（<500字符）
- **完全失败**: 7题零分，可能API完全无返回
- **总失败率**: 8.72%（76/872）
- **原因**: OpenRouter API不稳定，或GPT-5超时

### 3. 日志的救命价值
- **中断情况**: 第908题时余额不足，脚本中断
- **数据恢复**: 通过 `gpt5_benchmark.log` 恢复了全部872题结果
- **工具**: 批次14的 `recover_from_log.py` 脚本
- **结果**: 零损失，所有$62.02的投入都被保留

### 4. 成本与效率
- **总花费**: $62.02
- **完成题数**: 872题
- **平均成本**: ~$0.071/题
- **时间**: 估计3-4小时（10并发）

---

## 🔗 数据流向

```
输入: 批次12的984道题目（best.json）
  ↓
GPT-5作答（872题完成，112题未测试）
  ↓
DeepSeek判分
  ↓
分类:
  ├→ 答对: 720题（82.57%）
  ├→ 真实错误: 76题（8.72%）
  ├→ API失败（有分数）: 69题（7.91%）
  └→ API失败（零分）: 7题（0.80%）
  ↓
保存: benchmarkGPT5_recovered.json + gpt5_benchmark.log
  ↓
流向: 批次14（数据分析）→ 批次15（最终交付）
```

---

## 📖 相关批次

- **上游**: 批次12（质量筛选，984道题）
- **下游**: 
  - 批次14（数据分析，分类统计）
  - 批次15（最终交付，筛选145道挑战题）
- **数据恢复**: 批次14的recover_from_log.py从日志恢复数据

---

## 🎯 经验教训

### ✅ 成功经验
1. **日志记录至关重要**: gpt5_benchmark.log救了整个项目
2. **分批保存**: 每10题保存一次，减少数据丢失风险
3. **真实测试价值**: 发现GPT-5知识盲区，验证benchmark有效性
4. **数据完整性**: 记录答案、分数、判分理由，便于后续分析

### ⚠️ 教训
1. **成本控制**: $62.02不是小数目，需要预先估算和控制
2. **余额监控**: 应该监控OpenRouter余额，避免中途中断
3. **API稳定性**: 8.72%的API失败率需要处理（重试机制）
4. **进度保存**: 应该更频繁地保存（每题保存）

### 🔄 后续改进
1. **余额监控**: 实时检查OpenRouter余额，避免中断
2. **断点续传**: 支持从中断位置继续测试
3. **API重试**: 对失败的题目自动重试（批次15做了retest）
4. **成本优化**: 考虑更便宜的模型或批量优惠

---

## 🔍 技术细节

### 数据恢复机制
```python
# recover_from_log.py (批次14)
# 从gpt5_benchmark.log恢复数据

# 日志格式:
# [2025-10-15 16:30:45] Question 1: ...
# [2025-10-15 16:30:50] GPT-5 Answer: ...
# [2025-10-15 16:30:55] Score: 85

# 解析步骤:
1. 读取日志文件
2. 按时间戳分组
3. 提取题目、答案、分数
4. 重建JSON结构
5. 保存到benchmarkGPT5_recovered.json
```

### API调用优化
```python
# benchmark_gpt5.py

def call_gpt5(question, original_text):
    # 重试机制
    for attempt in range(3):
        try:
            response = requests.post(...)
            return response.json()
        except Exception as e:
            if attempt < 2:
                time.sleep(5)  # 等待5秒重试
            else:
                log_error(f"Failed after 3 attempts: {e}")
                return None
```

---

## 📊 详细统计

### 答题表现分布
```
正确答题（720题，82.57%）
  ├─ 完全正确: ~600题（分数90-100）
  ├─ 基本正确: ~100题（分数70-89）
  └─ 勉强通过: ~20题（分数60-69）

真实错误（76题，8.72%）
  ├─ 答案长度≥500字符
  ├─ 但与标准答案或原文不符
  └─ GPT-5的知识盲区

API失败（76题，8.72%）
  ├─ 有分数（69题）: 回答太短或部分返回
  └─ 零分（7题）: 完全无返回
```

### 未测试题目（112题）
- **范围**: 第873-984题
- **原因**: OpenRouter余额不足
- **处理**: 未纳入最终benchmark（不确定质量）

---

## 📌 总结

批次13完成了**GPT-5实测**，这是验证benchmark有效性的关键步骤：

1. **输入**: 批次12的984道高质量题目
2. **过程**: GPT-5作答 + DeepSeek判分（872题完成）
3. **输出**: 
   - 720道正确答题（82.57%）
   - 76道真实错误（GPT-5知识盲区）
   - 76道API失败（需重测）
4. **价值**: 
   - 验证benchmark的挑战性
   - 发现GPT-5的知识边界
   - 为最终交付筛选145道挑战题奠定基础

尽管中途因余额不足中断，但通过完整的日志记录，我们零损失地恢复了所有数据。这872题的测试结果成为了批次14数据分析和批次15最终交付的基础。

---

**生成时间**: 2025-10-17  
**文档版本**: v1.0  
**下一步**: 批次14 - 数据分析与分类

# 01 第一次尝试：基础生成

## 📋 基本信息

- **时间**: 2024年10月
- **目标**: 验证从PECS论文自动生成题目的可行性
- **方法**: 使用基础prompt直接生成
- **模型**: Gemini 2.5 Flash
- **数据规模**: 1篇论文 → 20道题目

## 🎯 尝试目标

这是整个项目的**第一次尝试**，主要验证：
1. AI能否从专业论文中理解内容并生成题目
2. 生成的题目是否符合燃烧科学领域
3. 摸索prompt设计方向

## 📂 文件结构

```
01_第一次尝试_基础生成/
├── data/
│   ├── milestone1_candidates.jsonl    # 生成的20道题目
│   ├── milestone1_raw_response.txt    # 模型原始响应
│   └── milestone1_report.md           # 生成报告
├── prompts/
│   └── 生成题Prompt.md               # 使用的prompt模板
├── scripts/
└── README.md                          # 本文档
```

## 📊 生成结果

- **生成题目**: 20道
- **论文来源**: 1篇PECS综述（main.txt）
- **成功率**: 100%（模型响应正常）

## 💡 主要发现

### ✅ 证明了可行性
- AI能够理解专业论文内容
- 能够生成符合领域的题目
- JSON格式输出可以正常解析

### ❌ 发现的问题
1. **质量不稳定** - 部分题目过于简单
2. **缺乏验证** - 无法保证答案正确性
3. **Prompt简单** - 缺少详细要求和示例

## 🔄 后续改进

基于这次探索，后续尝试改进方向：
- **02次**: 增加对比策略
- **03次**: 保留原文引用
- **04次**: 详细答案要求

## 📝 关键经验

1. **Prompt需要详细化** - 简单的要求不够
2. **需要质量验证机制** - 不能只生成不验证
3. **答案长度要控制** - 需要明确最小长度要求

---

*这次尝试虽然题目未进入最终benchmark，但验证了技术路线，为后续工作奠定基础。*

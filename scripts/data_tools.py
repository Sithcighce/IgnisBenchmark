#!/usr/bin/env python3
"""
æ•°æ®åˆ†æå’Œæ‰¹é‡å¤„ç†å·¥å…·
"""
import os
import sys
import json
import datetime
from pathlib import Path
from collections import defaultdict

def analyze_benchmark_data():
    """åˆ†æbenchmarkæ•°æ®"""
    print("ğŸ“Š åˆ†æBenchmarkæ•°æ®...")
    
    file_path = Path("data/benchmark_bank.jsonl")
    if not file_path.exists():
        print("âŒ benchmark_bank.jsonl æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    questions = []
    topics = defaultdict(int)
    difficulties = defaultdict(int)
    types = defaultdict(int)
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            
            try:
                data = json.loads(line)
                questions.append(data)
                
                # ç»Ÿè®¡ä¸»é¢˜ã€éš¾åº¦ã€ç±»å‹
                if 'topic' in data:
                    topics[data['topic']] += 1
                if 'difficulty' in data:
                    difficulties[data['difficulty']] += 1
                if 'type' in data:
                    types[data['type']] += 1
                    
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSONè§£æé”™è¯¯: {e}")
    
    print(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
    print(f"  æ€»é¢˜ç›®æ•°: {len(questions)}")
    
    print(f"\nğŸ·ï¸ ä¸»é¢˜åˆ†å¸ƒ:")
    for topic, count in sorted(topics.items()):
        print(f"  {topic}: {count}")
    
    print(f"\nâ­ éš¾åº¦åˆ†å¸ƒ:")
    for difficulty, count in sorted(difficulties.items()):
        print(f"  éš¾åº¦{difficulty}: {count}")
    
    print(f"\nğŸ“‹ ç±»å‹åˆ†å¸ƒ:")
    for type_name, count in sorted(types.items()):
        print(f"  {type_name}: {count}")

def clean_failed_attempts():
    """æ¸…ç†å¤±è´¥çš„åˆ¤é¢˜è®°å½•"""
    print("\nğŸ§¹ æ¸…ç†å¤±è´¥çš„åˆ¤é¢˜è®°å½•...")
    
    file_path = Path("data/benchmark_bank.jsonl")
    if not file_path.exists():
        print("âŒ benchmark_bank.jsonl æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    backup_path = Path(f"data/benchmark_bank_backup_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.jsonl")
    
    # å¤‡ä»½åŸæ–‡ä»¶
    print(f"ğŸ’¾ åˆ›å»ºå¤‡ä»½: {backup_path}")
    
    cleaned_lines = []
    removed_count = 0
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            
            try:
                data = json.loads(line)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¤±è´¥çš„åˆ¤é¢˜è®°å½•
                if 'failed_attempt' in data:
                    grading_result = data.get('failed_attempt', {}).get('grading_result', {})
                    reasoning = grading_result.get('reasoning', '')
                    
                    if "åˆ¤é¢˜ç³»ç»Ÿé”™è¯¯: JSONè§£æå¤±è´¥" in reasoning or "cannot schedule new futures after shutdown" in reasoning:
                        print(f"ğŸ—‘ï¸ ç§»é™¤å¤±è´¥è®°å½•: {data.get('question_data', {}).get('question_id', 'unknown')[:8]}...")
                        removed_count += 1
                        continue
                
                cleaned_lines.append(line)
                
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSONè§£æé”™è¯¯ï¼Œè·³è¿‡è¯¥è¡Œ: {e}")
                removed_count += 1
    
    if removed_count > 0:
        # åˆ›å»ºå¤‡ä»½
        with open(file_path, 'r', encoding='utf-8') as src:
            with open(backup_path, 'w', encoding='utf-8') as dst:
                dst.write(src.read())
        
        # å†™å…¥æ¸…ç†åçš„æ•°æ®
        with open(file_path, 'w', encoding='utf-8') as f:
            for line in cleaned_lines:
                f.write(line + '\n')
        
        print(f"âœ… å·²ç§»é™¤ {removed_count} ä¸ªå¤±è´¥è®°å½•")
        print(f"ğŸ“ å¤‡ä»½æ–‡ä»¶: {backup_path}")
    else:
        print("âœ… æœªå‘ç°éœ€è¦æ¸…ç†çš„å¤±è´¥è®°å½•")

def export_statistics():
    """å¯¼å‡ºç»Ÿè®¡ä¿¡æ¯"""
    print("\nğŸ“‹ å¯¼å‡ºç»Ÿè®¡ä¿¡æ¯...")
    
    stats = {
        'generated_at': datetime.datetime.now().isoformat(),
        'files': {}
    }
    
    # ç»Ÿè®¡å„ä¸ªæ•°æ®æ–‡ä»¶
    data_files = [
        'data/benchmark_bank.jsonl',
        'data/seed_examples.jsonl', 
        'data/validation_set.jsonl'
    ]
    
    for file_path in data_files:
        path = Path(file_path)
        if path.exists():
            line_count = 0
            valid_count = 0
            with open(path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        line_count += 1
                        try:
                            json.loads(line)
                            valid_count += 1
                        except:
                            pass
            
            stats['files'][file_path] = {
                'exists': True,
                'total_lines': line_count,
                'valid_lines': valid_count,
                'size_bytes': path.stat().st_size
            }
        else:
            stats['files'][file_path] = {'exists': False}
    
    # å†™å…¥ç»Ÿè®¡æ–‡ä»¶
    stats_file = Path("logs/data_statistics.json")
    stats_file.parent.mkdir(exist_ok=True)
    
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯å·²å¯¼å‡ºåˆ°: {stats_file}")

def main():
    """ä¸»å‡½æ•°"""
    # ç¡®ä¿åœ¨æ­£ç¡®çš„å·¥ä½œç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_dir = os.path.dirname(script_dir)
    os.chdir(project_dir)
    
    print("ğŸ”§ æ•°æ®åˆ†æå’Œæ‰¹é‡å¤„ç†å·¥å…·")
    print("=" * 50)
    
    analyze_benchmark_data()
    clean_failed_attempts()
    export_statistics()
    
    print("\nâœ… å¤„ç†å®Œæˆ!")

if __name__ == "__main__":
    main()
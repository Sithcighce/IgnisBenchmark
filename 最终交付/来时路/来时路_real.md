# 来时路：从11%到96%的真实探索历程

**文档声明**: 本文档基于实际批次数据、日志文件和脚本代码撰写，所有数字经过验证  
**核心价值**: 记录真实的失败与成功，不编造、不夸大  
**更新时间**: 2025-10-17

---

## ⚠️ 重要说明

这份文档与之前的版本不同，**所有数据都经过验证**：
- 完成率数字来自实际统计pass.json文件数量
- 时间信息来自文件CreationTime和日志
- 技术细节来自实际脚本代码

**真实数据**:
- 批次07: V3 33/298=**11.1%**, V3.2 36/199=**18.1%**
- 批次08: 189/247=**76.5%**  
- 批次10: 287/298=**96.3%** (不是100%！)

---

## 📅 时间线（基于文件时间戳）

```
2024-10-XX  批次01-06  单篇测试阶段
2025-10-15  批次07     SiliconFlow测试
            00:18      questions_test创建
            07:27      questions_v3创建  
            07:29      questions_v32创建
2025-10-15  批次08     DeepSeek官方
            10:57      question_reverse创建
2025-10-15  批次10     DeepSeek英文
            16:10      question_english创建
```

---

## 🎯 批量生产阶段（批次07-10）

这是整个项目的核心阶段，从惨痛失败到接近成功。

### 批次07：SiliconFlow的惨痛失败

**时间**: 2025-10-15 00:18 - 07:42  
**供应商**: SiliconFlow API（中转服务）  
**目标**: 批量处理298篇论文

#### 三个阶段的快速迭代

**阶段0: 早期测试 (00:18)**
- 2篇论文测试
- 结果: 100%成功
- 证明: 脚本逻辑正确

**阶段1: V3英文 (07:27)**
- 模型: DeepSeek-V3 Pro
- Prompt: 英文
- 论文: 298篇
- **结果: 33/298 = 11.1%** ❌

**阶段2: V3.2中文 (07:29)** ← 仅2分钟后！
- 模型: DeepSeek-V3.2 Exp
- Prompt: 中文
- 论文: 199篇
- **结果: 36/199 = 18.1%** ❌

#### 核心发现

**排除的因素**:
- ❌ 不是模型问题（V3和V3.2结果相近）
- ❌ 不是语言问题（英文和中文结果相近）
- ❌ 不是脚本问题（小规模100%成功）

**确认的原因**:
- ✅ **SiliconFlow API并发限制**
- 现象: 大量429错误
- 估计: ~60 RPM, ~100k TPM
- 20并发严重超限

#### 快速迭代的价值

**仅2分钟**内完成两次测试的意义:
- 快速排除模型版本因素
- 快速排除语言因素
- 精准定位: 供应商API是根本问题

**教训**:
```
供应商选择 > 模型版本 > Prompt语言
```

---

### 批次08：DeepSeek官方的关键突破

**时间**: 2025-10-15 10:57  
**供应商**: ✨ **DeepSeek官方API**（关键决策）  
**模型**: `deepseek-chat`  
**完成度**: 189/247 = **76.5%**

#### 核心改变

**API切换**:
```
SiliconFlow中转 → DeepSeek官方直连
```

**效果对比**:
```
批次07: SiliconFlow → 11-18%
批次08: DeepSeek官方 → 76.5%

提升倍数: 5-7倍！
```

#### 官方API的优势

- ✅ 无中转层，延迟低
- ✅ 稳定性高，错误率低
- ✅ 支持20并发无压力
- ✅ 响应速度快

#### 智能重试机制

```python
MAX_RETRIES_PER_QUESTION = 3

# 流程
生成题目 → 质量检查
  ↓ 失败
提取审核意见 → 针对性重生成
  ↓ 最多3次
仍失败 → notpass.json
```

#### 遗留问题

**为什么还有23.5%失败？**

深入分析发现: **中文prompt的局限**

1. **专业术语不精确**
   ```
   英文: "chain-branching pathway"
   中文: "链分支途径" / "链式分支路径" / "支链反应路径"
   ```

2. **公式表达困难**
   ```
   英文: "ΔG = ΔH - TΔS" (简洁)
   中文: "自由能变化ΔG等于..." (冗长)
   ```

3. **文献原文多为英文**
   - 语言转换增加理解难度
   - 引用匹配困难

---

### 批次10：英文prompt的最终优化

**时间**: 2025-10-15 16:10  
**供应商**: DeepSeek官方API  
**语言**: ✨ **英文**（关键改进）  
**完成度**: 287/298 = **96.3%**

#### 三大改进叠加

**1. DeepSeek官方API**（继承自08）
```
稳定性: 官方API > 中转服务
```

**2. 英文prompt**（解决08问题）
```
精确性: 英文 > 中文（专业领域）
```

**3. 50并发**（提升效率）
```
效率: 50并发 > 20并发（官方API稳定支持）
```

#### 成果对比

| 批次 | 供应商 | 语言 | 并发 | 完成率 |
|------|--------|------|------|--------|
| 07 | SiliconFlow | 英/中 | 20 | 11-18% |
| 08 | DeepSeek官方 | 中文 | 20 | 76.5% |
| 10 | DeepSeek官方 | 英文 | 50 | **96.3%** |

#### 真实的96.3%

**未完成的11篇**:
- 论文特殊格式
- 超长论文token限制
- 专业性过高
- 随机API错误

**这不是缺陷，而是真实**:
- 96.3%已经是极高的成功率
- 剩余3.7%需要人工处理或特殊策略

---

## 💡 核心经验

### 1. 基础设施优先

**批次07的教训**:
```
在错误的API上优化prompt = 徒劳
在不稳定的基础上提升并发 = 灾难
```

**正确顺序**:
```
1. 选对供应商（稳定性）
2. 选对语言（精确性）
3. 优化并发（效率）
4. 调整prompt（质量）
```

---

### 2. 快速迭代验证假设

**批次07的价值**:
- 仅2分钟完成V3和V3.2两次测试
- 快速排除干扰因素
- 精准定位根本原因

**避免的陷阱**:
- ❌ 花几天优化prompt（供应商不对都白搭）
- ❌ 测试更多模型版本（问题不在这）
- ❌ 调整并发参数（API限制改不了）

---

### 3. 语言选择的技术考量

**不是"英文比中文好"，而是**:
- 论文原文是英文
- 专业术语英文表达更精确
- 公式用符号比文字描述清晰

**数据验证**:
```
批次08中文: 76.5%
批次10英文: 96.3%

提升: +19.8个百分点
```

---

### 4. 真实数据的重要性

**之前的错误**:
- 声称批次10是100%
- 实际: 96.3%（287/298）

**为什么要真实**:
- 96.3%已经很优秀了
- 夸大100%反而失去可信度
- 真实的问题才有改进空间

---

## 📊 最终数据

### 完成率演进（真实数字）
```
批次07: 11.1% (V3) / 18.1% (V3.2)
  ↓ 换官方API
批次08: 76.5%
  ↓ 换英文prompt
批次10: 96.3%
```

### 题目规模
- **论文数**: 287篇（成功）
- **题目数**: ~1435道（287 × 5题/篇）
- **答案长度**: ≥300字符
- **引用要求**: 1-3段逐字引用

### Prompt演进
- 批次01-06: 20题/篇（单篇测试）
- 批次07-10: 5题/篇（批量生产）
- 批次01: 中文，100字符
- 批次10: 英文，300字符

---

## 🎯 最终方案（批次10）

### API配置
```python
API_BASE = "https://api.deepseek.com"
MODEL = "deepseek-chat"
MAX_WORKERS = 50
TIMEOUT = 180
```

### Prompt设计（英文）
```markdown
# Generation Prompt
- 5题/篇
- 答案≥300字符
- 1-3段原文引用（≥50字符）
- 类型: reasoning/concept/calculation/application
- 难度: 3-5级为主
- 领域: combustion/heat transfer/fluid/CFD/energy

# Quality Check Prompt
- 领域聚焦性
- 答案正确性（<300字符, 事实错误, 基本原理错误）
- 其他合规性
```

### 处理流程
```
论文全文
  ↓
生成5题（Generation Prompt）
  ↓
质量检查（Quality Check Prompt）
  ↓
失败 → 重试（最多3次，带反馈）
  ↓
成功 → pass.json
失败 → notpass.json
```

---

## 🔮 未来改进

### 1. 处理剩余3.7%
- 特殊格式论文预处理
- Token分片策略
- 人工辅助处理

### 2. 质量提升
- 基于批次11三模型验证
- 人工抽检校准
- 建立难度评分体系

### 3. 效率优化
- 探索更高并发（50 → 100?）
- 优化重试策略
- 缓存机制

---

## 📚 相关文档

### 批次文档
- `历史尝试归档/07_批量详细题目_最早批次/README.md`
- `历史尝试归档/08_批量详细题目_中间批次/README.md`
- `历史尝试归档/10_DeepSeek英文生成_最晚批次/README.md`

### Prompt文档
- `历史尝试归档/*/prompts/` - 各批次实际使用的prompt
- `历史尝试归档/PROMPT_EXTRACTION_REPORT.md`

---

## ✍️ 后记

**这份文档的不同**:
- 所有数字都经过验证
- 不隐瞒失败（07的11%）
- 不夸大成功（10是96.3%不是100%）
- 基于真实的文件时间戳、日志和代码

**最重要的三点**:

1. **失败比成功更有价值**  
   批次07的失败用2分钟就精准定位了问题

2. **基础设施优先于优化**  
   供应商选错了，再优化prompt也没用

3. **真实比完美更重要**  
   96.3%已经很优秀，诚实比100%的虚假更可贵

---

**生成时间**: 2025-10-17  
**版本**: v3.0_real（避免VSCode自动合并）  
**数据来源**: 实际pass.json文件统计
